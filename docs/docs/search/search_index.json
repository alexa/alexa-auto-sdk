{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Alexa Auto SDK","text":""},{"location":"#what-is-auto-sdk","title":"What is Auto SDK?","text":"<p>The Alexa Auto SDK contains essential client-side software required to integrate Alexa into the automobile. The Auto SDK provides libraries that connect to Alexa and expose interfaces for your vehicle software to implement the platform-specific behavior for audio input, media streaming, calling through a connected phone, turn-by-turn navigation, controlling vehicle features such as heaters and lights, and more. You can use the included sample application to learn about the Auto SDK interfaces and to test interactions before integration.</p>"},{"location":"#product-guidelines","title":"Product guidelines","text":"<p>The Product Requirements and Guidelines docs describe requirements and principals to follow when designing and implementing an Auto SDK client integration for your vehicle. Your integration must follow the product requirements and pass Amazon's automotive certification process.</p>"},{"location":"#whats-new-in-auto-sdk","title":"What's new in Auto SDK?","text":"<p>Auto SDK is always improving. See the Auto SDK release notes to learn about the latest features and enhancements.</p>"},{"location":"#developer-resources","title":"Developer resources","text":"<ul> <li> <p>Follow the Get Started with Auto SDK guide to set up the Auto SDK development prerequisites.</p> </li> <li> <p>Read the Explore Auto SDK Concepts docs to learn how Auto SDK works and understand its core APIs.</p> </li> <li> <p>Read the Explore Auto SDK Features docs to learn about all the different features Auto SDK provides.</p> </li> <li> <p>Follow the developer docs for Native C++ to guide you through integrating Auto SDK into your vehicle. If your vehicle uses the Android platform, follow the developer documentation for Alexa Auto App instead.</p> </li> <li> <p>Use the Auto SDK Migration Guide to ease your upgrade to the latest Auto SDK version.</p> </li> </ul>"},{"location":"CONTRIBUTING/","title":"Contribution Guidelines","text":"<p>Thank you for your interest in contributing to Alexa Auto SDK. Whether it's a bug report, new feature request, documentation request, or a correction, we greatly value feedback and contributions from the developer community.</p> <p>Read the following guidelines before submitting any issues to ensure we have all the necessary information to respond to your request or contribution.</p>"},{"location":"CONTRIBUTING/#report-a-bug-or-request-a-feature","title":"Report a bug or request a feature","text":"<p>We do not use the GitHub issue tracker. See the Need Help? page of Auto SDK documentation for details about reporting issues.</p>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull requests","text":"<p>At this time, we do not accept pull requests. If you want to contribute a code change, follow the same process used to report bugs and request features.</p>"},{"location":"CONTRIBUTING/#report-security-issues","title":"Report security issues","text":"<p>If you discover a potential security issue in this project, we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public Github issue.</p>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>See the LICENSE file for Auto SDK licensing. We will ask you to confirm the licensing of your contribution.</p> <p>We may ask you to sign a Contributor License Agreement (CLA) for larger changes.</p>"},{"location":"get-started/","title":"Get Started with Auto SDK","text":"<p>This guide outlines the one-time steps required to get started building an Auto SDK integration for your vehicle.</p>"},{"location":"get-started/#register-an-avs-product","title":"Register an AVS product","text":"<p>The Alexa features enabled by Auto SDK are built upon the Alexa Voice Service (AVS). Prior to using Auto SDK, follow the Register a Product with AVS guide to set up an Amazon developer account, register a product for your vehicle, and create a security profile.</p> <ul> <li>For the Please select your product type option, select Device with Alexa built-in.</li> <li>For the Product category option, select Automotive.</li> </ul> <p>In the product details page of your new AVS product, take note of the following fields for later use:</p> <ul> <li>The Amazon ID from the top of the page</li> <li>The Client ID from the Other devices and platforms tab</li> </ul>"},{"location":"get-started/#clone-the-auto-sdk-source-code","title":"Clone the Auto SDK source code","text":"<p>Auto SDK is open source. Clone the <code>alexa-auto-sdk</code> project from Github on your development machine: <pre><code>git clone https://github.com/alexa/alexa-auto-sdk.git\n</code></pre> Auto SDK documentation refers to the root directory of the cloned project as <code>AUTO_SDK_HOME</code>.</p>"},{"location":"get-started/#install-prerequisites","title":"Install prerequisites","text":"<p>Prior to building Auto SDK, install the build prerequisites outlined the Auto SDK build system documentation.</p>"},{"location":"get-started/#read-the-overview-documentation","title":"Read the overview documentation","text":"<p>To get a high-level understanding of how to use Auto SDK, read the concepts documentation. After understanding the API concepts, read the feature overview documentation to get a sense of which Auto SDK features you will use in your integration and to identify which Auto SDK extensions you want to download.</p>"},{"location":"get-started/#optional-download-extensions","title":"(Optional) Download extensions","text":"<p>If you want to use any of the optional features provided by Auto SDK extensions, request your Amazon Solutions Architect (SA) or Partner Manager to grant Alexa developer console access to the extensions you need. Download the extension archives and follow the documentation in each extension archive to move the extension source code and dependencies into your Auto SDK source tree.</p> <p>Some extensions, such as Local Voice Control (LVC), have additional resources to use, so ensure you thoroughly read the extension documentation for any more setup steps.</p>"},{"location":"get-started/#follow-a-developer-guide","title":"Follow a developer guide","text":"<p>Use the developer guide for Native C++ to guide you through the next steps to develop your Auto SDK integration. If your vehicle uses the Android platform, follow the developer documentation for Alexa Auto App instead.</p>"},{"location":"help/","title":"Need Help?","text":""},{"location":"help/#request-additional-functionality","title":"Request additional functionality","text":"<p>The following functionality is available with help from your designated Amazon Solutions Architect (SA) or Partner Manager:</p> <ul> <li>Address Book contact and navigation favorites uploading</li> <li>Amazon Music and other music service providers</li> <li>Wake Word support</li> <li>Alexa Communication</li> <li>Local Voice Control</li> <li>Device Client Metrics</li> </ul> <p>To use this functionality, your product must be placed on an allow list by Amazon. Contact your SA or Partner Manager, provide the Amazon ID of your development device, and request the functionality you want to add.</p> <p>Note: If you would like to request additional functionality but don't have a designated SA or Partner Manager, please reach out using the \"Request More Information\" form at the end of the Alexa Auto Software Development Kit page on the developer console.</p> <p>To find the Amazon ID for your development device:</p> <ol> <li>Log in to the AVS developer console.</li> <li>Click PRODUCTS.</li> <li>Take note of the Amazon ID for your device.</li> </ol>"},{"location":"help/#report-an-issue","title":"Report an issue","text":""},{"location":"help/#existing-alexa-auto-sdk-users","title":"Existing Alexa Auto SDK users","text":"<p>Please reach out to the designated Amazon Solutions Architect (SA) or Partner Manager for your company, and include the following information:</p> <ul> <li>Overview - provide a brief overview of the issue</li> <li>Steps to reproduce - provide details of how to reproduce the issue</li> <li>Logs - include relevant logs</li> <li>Platform and environment - provide details about your hardware platform, operating system, compiler, API level, etc.</li> </ul>"},{"location":"help/#new-alexa-auto-sdk-users","title":"New Alexa Auto SDK users","text":"<p>Please fill out the form \"Request more information\" at the bottom of the Alexa Auto Software Development Kit page on the developer console. Once you have submitted your request, someone from Amazon will contact you.</p>"},{"location":"product-guidelines/","title":"Product Requirements and Guidelines","text":"<p>Amazon provides requirements you must follow when integrating Alexa Auto SDK into your vehicle. To verify your integration meets the requirements, passing Amazon's automotive certification process is a prerequisite to launch your Alexa in-vehicle experience. Refer to the guidelines below when designing and developing your integration, and contact your Amazon Solutions Architect (SA) or Partner Manager to guide you through the certification process.</p>"},{"location":"product-guidelines/#product-and-ux-guidelines","title":"Product and UX guidelines","text":"<p>The Alexa Automotive design guidelines define principles, user interface patterns, and multi-modal best practices for Alexa automotive experiences.</p>"},{"location":"product-guidelines/#security-best-practices","title":"Security best practices","text":"<p>All Alexa products are required to follow the Security Best Practices for Alexa. When building an Alexa experience using the Auto SDK, additionally adhere to the following security principles:</p> <ul> <li>Protect configuration files for Auto SDK from tampering and inspection.</li> <li>Protect configuration parameters, such as those found in Auto SDK configuration files, from tampering and inspection, including but not limited to the following: SQLite database files, Unix Domain Sockets, wake word models, and metrics sink files.</li> <li>Protect components used for the Local Voice Control (LVC) extension, including associated LVC language model packages (Linux), from tampering and inspection, including but not limited to the following: Unix Domain Sockets, model directories, skill and service executables, prompts and assets JSON files, and all files configuring these components.</li> <li>Your implementation of Auto SDK interfaces must not retain locks, crash, hang, or throw uncaught exceptions.</li> <li>Use exploit mitigation flags and memory randomization techniques when you compile your source code to prevent vulnerabilities from exploiting buffer overflows and memory corruptions.</li> </ul>"},{"location":"aasb/","title":"AASB Message Reference","text":"<p>Use the AASB message interfaces to provide platform-specific deep integration to the Auto SDK Engine. </p> <p>The AASB message reference is organized by module and interface name.</p>"},{"location":"aasb/aasb/AASB/","title":"AASB","text":""},{"location":"aasb/aasb/AASB/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/aasb/AASB/#startservice","title":"StartService","text":"<p>Notifies the platform that the AASB service has started.</p>"},{"location":"aasb/aasb/AASB/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AASB\",\n            \"action\": \"StartService\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/aasb/AASB/#stopservice","title":"StopService","text":"<p>Notifies the platform that the AASB service is about to stop.</p>"},{"location":"aasb/aasb/AASB/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AASB\",\n            \"action\": \"StopService\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/","title":"AddressBook","text":""},{"location":"aasb/address-book/AddressBook/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/address-book/AddressBook/#addaddressbookreply","title":"AddAddressBookReply","text":"<p>Reply for AddAddressBook message.</p>"},{"location":"aasb/address-book/AddressBook/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AddressBook\",\n            \"action\": \"AddAddressBook\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#payload","title":"Payload","text":"Property Type Required Description Example success Bool Yes False if address book was already added or some internal error, otherwise true on successful."},{"location":"aasb/address-book/AddressBook/#removeaddressbookreply","title":"RemoveAddressBookReply","text":"<p>Reply for RemoveAddressBook message.</p>"},{"location":"aasb/address-book/AddressBook/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AddressBook\",\n            \"action\": \"RemoveAddressBook\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#payload_1","title":"Payload","text":"Property Type Required Description Example success Bool Yes False if address book is not already added or some internal error, otherwise true on successful."},{"location":"aasb/address-book/AddressBook/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/address-book/AddressBook/#addaddressbook","title":"AddAddressBook","text":"<p>Notifies the engine on an availability of an address book.</p>"},{"location":"aasb/address-book/AddressBook/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AddressBook\",\n            \"action\": \"AddAddressBook\"\n        }\n    },\n    \"payload\": {\n        \"addressBookSourceId\": {{String}},\n        \"name\": {{String}},\n        \"type\": {{AddressBookType}},\n        \"addressBookData\": {{AddressBook}}        \n    }\n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#payload_2","title":"Payload","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. name String Yes Friendly name of the address book, or an empty string if not available. type AddressBookType Yes Type of the address book AddressBookType. addressBookData AddressBook Yes A filled out AddressBook object."},{"location":"aasb/address-book/AddressBook/#removeaddressbook","title":"RemoveAddressBook","text":"<p>Notifies the engine on a non-availability of an already available address book.</p>"},{"location":"aasb/address-book/AddressBook/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AddressBook\",\n            \"action\": \"RemoveAddressBook\"\n        }\n    },\n    \"payload\": {\n        \"addressBookSourceId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#payload_3","title":"Payload","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. Set this to empty string for engine to remove all uploaded address books."},{"location":"aasb/address-book/AddressBook/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/address-book/AddressBook/#addressbook_1","title":"AddressBook","text":""},{"location":"aasb/address-book/AddressBook/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"navigationNames\": [{{NavigationName}}],\n    \"contactNames\": [{{ContactName}}],\n    \"phoneData\": [{{PhoneData}}],\n    \"postalAddresses\": [{{PostalAddress}}]        \n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#properties","title":"Properties","text":"Property Type Required Description Example navigationNames NavigationName[] Yes List of NavigationName. contactNames ContactName[] Yes List of ContactName. phoneData PhoneData[] Yes List of PhoneData. postalAddresses PostalAddress[] Yes List of PostalAddresses."},{"location":"aasb/address-book/AddressBook/#navigationname","title":"NavigationName","text":""},{"location":"aasb/address-book/AddressBook/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"entryId\": {{String}},\n    \"name\": {{String}},\n    \"phoneticName\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#properties_1","title":"Properties","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. name String Yes Name of the entry, or an empty string if not available. If the name field contains Kanji characters, you must also provide the corresponding phoneticName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". phoneticName String No Phonetic name of the entry if available."},{"location":"aasb/address-book/AddressBook/#contactname","title":"ContactName","text":""},{"location":"aasb/address-book/AddressBook/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"entryId\": {{String}},\n    \"firstName\": {{String}},\n    \"lastName\": {{String}},\n    \"nickname\": {{String}},\n    \"phoneticFirstName\": {{String}},\n    \"phoneticLastName\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#properties_2","title":"Properties","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. firstName String Yes First name of the entry, or an empty string if not available. If the firstName field contains Kanji characters, you must also provide the corresponding phoneticFirstName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". lastName String Yes Last name of the entry, or an empty string if not available. If the lastName field contains Kanji characters, you must also provide the corresponding phoneticLastName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". nickname String Yes Name of the entry, or an empty string if not available. phoneticFirstName String No Phonetic first name of entry if available. phoneticLastName String No Phonetic last name of entry if available."},{"location":"aasb/address-book/AddressBook/#phonedata","title":"PhoneData","text":""},{"location":"aasb/address-book/AddressBook/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"entryId\": {{String}},\n    \"label\": {{String}},\n    \"number\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#properties_3","title":"Properties","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. If multiple numbers are associated with a contact, Alexa will verbally ask the customer to confirm which number they want. If labels are assigned to the numbers and Alexa recognizes the types Alexa asks for confirmation; otherwise, Alexa says the last four digits of each number for the customer to select the one to call. number String Yes Numeric phone number, or an empty string if not available."},{"location":"aasb/address-book/AddressBook/#postaladdress","title":"PostalAddress","text":""},{"location":"aasb/address-book/AddressBook/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"entryId\": {{String}},\n    \"label\": {{String}},\n    \"addressLine1\": {{String}},\n    \"addressLine2\": {{String}},\n    \"addressLine3\": {{String}},\n    \"city\": {{String}},\n    \"stateOrRegion\": {{String}},\n    \"districtOrCounty\": {{String}},\n    \"postalCode\": {{String}},\n    \"country\": {{String}},\n    \"latitudeInDegrees\": {{Float}},\n    \"longitudeInDegrees\": {{Float}},\n    \"accuracyInMeters\": {{Float}}        \n}\n</code></pre>"},{"location":"aasb/address-book/AddressBook/#properties_4","title":"Properties","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. addressLine1 String Yes First line of the postal address, or an empty string if not available. addressLine2 String Yes Second line of the postal address, or an empty string if not available. addressLine3 String Yes addressLine3 Third line of the postal address, or an empty string if not available. city String Yes City name, or an empty string if not available. stateOrRegion String Yes State or Region name, or an empty string if not available. districtOrCounty String Yes District or County name, or an empty string if not available. postalCode String Yes Postal code or Zip code, or an empty string if not available. country String Yes Country name, or an empty string if not available. latitudeInDegrees Float No (default: <code>0.0f</code>) Geo latitude in degrees. Optional when AddressBookType is CONTACT. longitudeInDegrees Float No (default: <code>0.0f</code>) Geo longitude in degrees. Optional when AddressBookType is CONTACT. accuracyInMeters Float No (default: <code>0.0f</code>) Accuracy in meters, or zero if not available. Optional when AddressBookType is CONTACT."},{"location":"aasb/address-book/AddressBook/#enums","title":"Enums","text":""},{"location":"aasb/address-book/AddressBook/#addressbooktype","title":"AddressBookType","text":""},{"location":"aasb/address-book/AddressBook/#values","title":"Values","text":"Value Description \"CONTACT\" Contacts. \"NAVIGATION\" Navigation Address."},{"location":"aasb/alexa/AlexaClient/","title":"AlexaClient","text":""},{"location":"aasb/alexa/AlexaClient/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/AlexaClient/#connectionstatuschanged","title":"ConnectionStatusChanged","text":"<p>Notifies the platform implementation of an AVS connection status change.</p>"},{"location":"aasb/alexa/AlexaClient/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaClient\",\n            \"action\": \"ConnectionStatusChanged\"\n        }\n    },\n    \"payload\": {\n        \"status\": {{ConnectionStatus}},\n        \"reason\": {{ConnectionChangedReason}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#payload","title":"Payload","text":"Property Type Required Description Example status ConnectionStatus Yes The new AVS connection status. reason ConnectionChangedReason Yes The reason for the status change."},{"location":"aasb/alexa/AlexaClient/#connectionstatuschanged_1","title":"ConnectionStatusChanged","text":"<p>Notifies a listener about changes in connection status for multiple Alexa endpoints. There are multiple connections when using Local Voice Control.</p>"},{"location":"aasb/alexa/AlexaClient/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaClient\",\n            \"action\": \"ConnectionStatusChanged\"\n        }\n    },\n    \"payload\": {\n        \"status\": {{ConnectionStatus}},\n        \"reason\": {{ConnectionChangedReason}},\n        \"detailed\": {{ConnectionStatusDetails}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#payload_1","title":"Payload","text":"Property Type Required Description Example status ConnectionStatus Yes The Alexa connection status. This is an aggregated status for the multiple connections. reason ConnectionChangedReason Yes The reason for the status change. detailed ConnectionStatusDetails Yes A detailed breakdown of connection status info per connection type."},{"location":"aasb/alexa/AlexaClient/#dialogstatechanged","title":"DialogStateChanged","text":"<p>Notifies the platform implementation of a dialog state change.</p>"},{"location":"aasb/alexa/AlexaClient/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaClient\",\n            \"action\": \"DialogStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{DialogState}},\n        \"assistantId\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#payload_2","title":"Payload","text":"Property Type Required Description Example state DialogState Yes The new dialog state. assistantId Int Yes The ID of the assistant that the dialog state change is associated with. The assistantId is 2 for Alexa dialog state changes; For applications using multiple assistants, the value will be an integer greater than 2, corresponding to the assistant ID in Engine configuration field \"aace.coassistant.assistants[i].id\" for each additional assistant. 2"},{"location":"aasb/alexa/AlexaClient/#authstatechanged","title":"AuthStateChanged","text":"<p>Notifies the platform implementation of an AVS authorization state change.</p>"},{"location":"aasb/alexa/AlexaClient/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaClient\",\n            \"action\": \"AuthStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{AuthState}},\n        \"error\": {{AuthError}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#payload_3","title":"Payload","text":"Property Type Required Description Example state AuthState Yes The new authorization state. error AuthError Yes The error state of the authorization attempt."},{"location":"aasb/alexa/AlexaClient/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/AlexaClient/#stopforegroundactivity","title":"StopForegroundActivity","text":"<p>Notifies the Engine to stop foreground activity.</p>"},{"location":"aasb/alexa/AlexaClient/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaClient\",\n            \"action\": \"StopForegroundActivity\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/alexa/AlexaClient/#connectionstatusinfo","title":"ConnectionStatusInfo","text":""},{"location":"aasb/alexa/AlexaClient/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"status\": {{ConnectionStatus}},\n    \"reason\": {{ConnectionChangedReason}}        \n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#properties","title":"Properties","text":"Property Type Required Description Example status ConnectionStatus No (default: <code>ConnectionStatus::DISCONNECTED</code>) The connection status. reason ConnectionChangedReason No (default: <code>ConnectionChangedReason::NONE</code>) The reason for the connection status change."},{"location":"aasb/alexa/AlexaClient/#connectionstatusdetails","title":"ConnectionStatusDetails","text":""},{"location":"aasb/alexa/AlexaClient/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"avs\": {{ConnectionStatusInfo}},\n    \"local\": {{ConnectionStatusInfo}}        \n}\n</code></pre>"},{"location":"aasb/alexa/AlexaClient/#properties_1","title":"Properties","text":"Property Type Required Description Example avs ConnectionStatusInfo Yes Describes the connection to the Alexa Voice Service. local ConnectionStatusInfo Yes Describes the connection to the local endpoint."},{"location":"aasb/alexa/AlexaClient/#enums","title":"Enums","text":""},{"location":"aasb/alexa/AlexaClient/#dialogstate","title":"DialogState","text":""},{"location":"aasb/alexa/AlexaClient/#values","title":"Values","text":"Value Description \"IDLE\" Alexa is idle and ready for an interaction. \"LISTENING\" Alexa is currently listening. \"EXPECTING\" Alexa is currently expecting a response from the user. \"THINKING\" A user request has completed, and no more user input is being accepted. Alexa is waiting for a response from AVS. \"SPEAKING\" Alexa is responding to a request with speech. \"FINISHED\" Alexa has finished processing a single Speak directive. If the Speak directive is part of a speech burst, the state will transition back to SPEAKING; if the Speak directive was the last in the burst, the state will transition back to IDLE."},{"location":"aasb/alexa/AlexaClient/#connectionstatus","title":"ConnectionStatus","text":""},{"location":"aasb/alexa/AlexaClient/#values_1","title":"Values","text":"Value Description \"DISCONNECTED\" Not connected to AVS. \"PENDING\" Attempting to establish a connection to AVS. \"CONNECTED\" Connected to AVS."},{"location":"aasb/alexa/AlexaClient/#connectionchangedreason","title":"ConnectionChangedReason","text":""},{"location":"aasb/alexa/AlexaClient/#values_2","title":"Values","text":"Value Description \"NONE\" No reason specified. \"SUCCESS\" The connection status changed due to a successful operation. \"UNRECOVERABLE_ERROR\" The connection status changed due to an error from which there is no recovery. \"ACL_CLIENT_REQUEST\" The connection status changed due to a client request. \"ACL_DISABLED\" The connection attempt failed because connection was disabled. \"DNS_TIMEDOUT\" The connection attempt failed due to a DNS resolution timeout. \"CONNECTION_TIMEDOUT\" The connection attempt failed due to a connection timeout. \"CONNECTION_THROTTLED\" The connection attempt failed due to excessive load on the server. \"INVALID_AUTH\" The provided access credentials were invalid. \"PING_TIMEDOUT\" There was a timeout sending a ping request. \"WRITE_TIMEDOUT\" There was a timeout writing to AVS. \"READ_TIMEDOUT\" There was a timeout reading from AVS. \"FAILURE_PROTOCOL_ERROR\" There was an underlying protocol error. \"INTERNAL_ERROR\" There was an internal error. \"SERVER_INTERNAL_ERROR\" There was an internal error on the server. \"SERVER_SIDE_DISCONNECT\" The server asked the client to reconnect. \"SERVER_ENDPOINT_CHANGED\" The server endpoint has changed."},{"location":"aasb/alexa/AlexaSpeaker/","title":"AlexaSpeaker","text":""},{"location":"aasb/alexa/AlexaSpeaker/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/AlexaSpeaker/#speakersettingschanged","title":"SpeakerSettingsChanged","text":"<p>Notifies the platform implementation that the speaker settings have changed for a specific speaker type.</p>"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaSpeaker\",\n            \"action\": \"SpeakerSettingsChanged\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{SpeakerType}},\n        \"local\": {{Bool}},\n        \"volume\": {{Int}},\n        \"mute\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaSpeaker/#payload","title":"Payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. local Bool Yes True if the change originated from calling localSetVolume(). volume Int Yes he new volume setting of the Speaker. mute Bool Yes The mute setting of the Speaker."},{"location":"aasb/alexa/AlexaSpeaker/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/AlexaSpeaker/#localadjustvolume","title":"LocalAdjustVolume","text":"<p>Notifies the Engine of a relative adjustment to the volume setting of the Speaker, originating on the platform. The delta value is relative to the current volume setting  and is positive to increase volume or negative to reduce volume. The volume delta value  should be scaled to fit the needs of the platform.</p>"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaSpeaker\",\n            \"action\": \"LocalAdjustVolume\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{SpeakerType}},\n        \"delta\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaSpeaker/#payload_1","title":"Payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. delta Int Yes The volume adjustment to apply to the Speaker."},{"location":"aasb/alexa/AlexaSpeaker/#localsetvolume","title":"LocalSetVolume","text":"<p>Notifies the Engine of a volume change event originating on the platform, such as a user  pressing a \"volume up\" or \"volume down\" button. If the Speaker is AVS_SPEAKER_VOLUME,  the Engine will respond with a call to setVolume() on each AVS-synced Speaker.</p>"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaSpeaker\",\n            \"action\": \"LocalSetVolume\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{SpeakerType}},\n        \"volume\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaSpeaker/#payload_2","title":"Payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. volume Int Yes The new volume setting of the Speaker."},{"location":"aasb/alexa/AlexaSpeaker/#localsetmute","title":"LocalSetMute","text":"<p>Notifies the Engine of a mute setting change event originating on the platform, such as a  user pressing a \"mute\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setMute() on each AVS-synced Speaker.</p>"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaSpeaker\",\n            \"action\": \"LocalSetMute\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{SpeakerType}},\n        \"mute\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AlexaSpeaker/#payload_3","title":"Payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. mute Bool Yes The new mute setting of the Speaker."},{"location":"aasb/alexa/AlexaSpeaker/#enums","title":"Enums","text":""},{"location":"aasb/alexa/AlexaSpeaker/#speakertype","title":"SpeakerType","text":""},{"location":"aasb/alexa/AlexaSpeaker/#values","title":"Values","text":"Value Description \"ALEXA_VOLUME\" The Speaker type that is controlled by AVS. \"ALERTS_VOLUME\" The Speaker type that is controlled locally by the platform."},{"location":"aasb/alexa/AudioPlayer/","title":"AudioPlayer","text":""},{"location":"aasb/alexa/AudioPlayer/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/AudioPlayer/#playeractivitychanged","title":"PlayerActivityChanged","text":"<p>Notifies the platform implementation of a change in audio playback state.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"PlayerActivityChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{PlayerActivity}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#payload","title":"Payload","text":"Property Type Required Description Example state PlayerActivity Yes The new playback state."},{"location":"aasb/alexa/AudioPlayer/#getplayerpositionreply","title":"GetPlayerPositionReply","text":"<p>Reply for GetPlayerPosition message.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"GetPlayerPosition\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"playbackPosition\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#payload_1","title":"Payload","text":"Property Type Required Description Example playbackPosition Int Yes The audio player's playback position in milliseconds."},{"location":"aasb/alexa/AudioPlayer/#getplayerdurationreply","title":"GetPlayerDurationReply","text":"<p>Reply for GetPlayerDuration message.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"GetPlayerDuration\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"playbackDuration\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#payload_2","title":"Payload","text":"Property Type Required Description Example playbackDuration Int Yes The audio player's playback duration in milliseconds."},{"location":"aasb/alexa/AudioPlayer/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/AudioPlayer/#getplayerposition","title":"GetPlayerPosition","text":"<p>Returns the current playback position of the audio player.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"GetPlayerPosition\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#getplayerduration","title":"GetPlayerDuration","text":"<p>Returns the playback duration of the audio player.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"GetPlayerDuration\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#setasforegroundactivity","title":"SetAsForegroundActivity","text":"<p>Sets the Alexa <code>AudioPlayer</code> interface as the foreground player the user sees on screen. This message is useful for scenarios in which the user played an <code>AudioPlayer</code> media source, then played a different Alexa-aware <code>ExternalMediaPlayer</code> media source, such as a deep-linked media app or a local media source, and then manually returned visual activity to the Alexa <code>AudioPlayer</code> GUI. This message ensures the next VUI command or GUI interaction with the playback control buttons acts on the <code>AudioPlayer</code> source rather than the more recently played <code>ExternalMediaPlayer</code> source.  Note: The <code>AudioPlayer</code> had to be previously playing at least once during this Engine cycle in order for this message to make Alexa act on <code>AudioPlayer</code>.</p>"},{"location":"aasb/alexa/AudioPlayer/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioPlayer\",\n            \"action\": \"SetAsForegroundActivity\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AudioPlayer/#enums","title":"Enums","text":""},{"location":"aasb/alexa/AudioPlayer/#playeractivity","title":"PlayerActivity","text":""},{"location":"aasb/alexa/AudioPlayer/#values","title":"Values","text":"Value Description \"IDLE\" Audio playback has not yet begun. \"PLAYING\" Audio is currently playing. \"STOPPED\" Audio playback is stopped, either from a stop directive or playback error. \"PAUSED\" Audio playback is paused. \"BUFFER_UNDERRUN\" Audio playback is stalled because a buffer underrun has occurred. \"FINISHED\" Audio playback is finished."},{"location":"aasb/alexa/AuthProvider/","title":"AuthProvider","text":""},{"location":"aasb/alexa/AuthProvider/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/AuthProvider/#getauthtoken","title":"GetAuthToken","text":"<p>Returns the token used by the platform implementation for authorization with AVS. The platform  implementation should retrieve an auth token if it does not have one.</p>"},{"location":"aasb/alexa/AuthProvider/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AuthProvider\",\n            \"action\": \"GetAuthToken\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AuthProvider/#getauthstate","title":"GetAuthState","text":"<p>Returns the AVS authorization state of the platform implementation.</p>"},{"location":"aasb/alexa/AuthProvider/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AuthProvider\",\n            \"action\": \"GetAuthState\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AuthProvider/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/AuthProvider/#authstatechanged","title":"AuthStateChanged","text":"<p>Notifies the Engine of a change in AVS authorization state in the platform implementation.</p>"},{"location":"aasb/alexa/AuthProvider/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AuthProvider\",\n            \"action\": \"AuthStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"authState\": {{AuthState}},\n        \"authError\": {{AuthError}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AuthProvider/#payload","title":"Payload","text":"Property Type Required Description Example authState AuthState Yes The new authorization state. authError AuthError Yes The error state of the authorization attempt."},{"location":"aasb/alexa/AuthProvider/#getauthtokenreply","title":"GetAuthTokenReply","text":"<p>Reply for GetAuthToken message.</p>"},{"location":"aasb/alexa/AuthProvider/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AuthProvider\",\n            \"action\": \"GetAuthToken\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"authToken\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AuthProvider/#payload_1","title":"Payload","text":"Property Type Required Description Example authToken String Yes The token used to authorize with AVS."},{"location":"aasb/alexa/AuthProvider/#getauthstatereply","title":"GetAuthStateReply","text":"<p>Reply for GetAuthState message.</p>"},{"location":"aasb/alexa/AuthProvider/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AuthProvider\",\n            \"action\": \"GetAuthState\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"state\": {{AuthState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/AuthProvider/#payload_2","title":"Payload","text":"Property Type Required Description Example state AuthState Yes The AVS authorization state."},{"location":"aasb/alexa/AuthProvider/#enums","title":"Enums","text":""},{"location":"aasb/alexa/AuthProvider/#autherror","title":"AuthError","text":""},{"location":"aasb/alexa/AuthProvider/#values","title":"Values","text":"Value Description \"NO_ERROR\" No error encountered. \"UNKNOWN_ERROR\" An error was encountered, but no error description can be determined. \"AUTHORIZATION_FAILED\" The client authorization failed. \"UNAUTHORIZED_CLIENT\" The client is not authorized to use authorization codes. \"SERVER_ERROR\" The server encountered a runtime error. \"INVALID_REQUEST\" The request is missing a required parameter, has an invalid value, or is otherwise malformed. \"INVALID_VALUE\" One of the values in the request was invalid. \"AUTHORIZATION_EXPIRED\" The authorization code is invalid, expired, revoked, or was issued to a different client. \"UNSUPPORTED_GRANT_TYPE\" The client specified the wrong token type. \"INVALID_CODE_PAIR\" Invalid code pair provided in Code-based linking token request. \"AUTHORIZATION_PENDING\" Waiting for user to authorize the specified code pair. \"SLOW_DOWN\" Client should slow down in the rate of requests polling for an access token. \"INTERNAL_ERROR\" Internal error in client code. \"INVALID_CBL_CLIENT_ID\" Client ID not valid for use with code based linking."},{"location":"aasb/alexa/AuthProvider/#authstate","title":"AuthState","text":""},{"location":"aasb/alexa/AuthProvider/#values_1","title":"Values","text":"Value Description \"UNINITIALIZED\" Authorization has not yet been acquired. \"REFRESHED\" Authorization has been refreshed. \"EXPIRED\" Authorization has expired. \"UNRECOVERABLE_ERROR\" Authorization has failed in a manner that cannot be corrected by retrying."},{"location":"aasb/alexa/CaptionPresenter/","title":"CaptionPresenter","text":""},{"location":"aasb/alexa/CaptionPresenter/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/CaptionPresenter/#setcaption","title":"SetCaption","text":"<p>Notifies the platform of the caption for the assistant's most recent utterance.</p>"},{"location":"aasb/alexa/CaptionPresenter/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CaptionPresenter\",\n            \"action\": \"SetCaption\"\n        }\n    },\n    \"payload\": {\n        \"caption\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/CaptionPresenter/#payload","title":"Payload","text":"Property Type Required Description Example caption String Yes A string of the caption."},{"location":"aasb/alexa/DeviceSetup/","title":"DeviceSetup","text":""},{"location":"aasb/alexa/DeviceSetup/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/DeviceSetup/#setupcompletedresponse","title":"SetupCompletedResponse","text":"<p>SetupCompletedResponse description</p>"},{"location":"aasb/alexa/DeviceSetup/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"DeviceSetup\",\n            \"action\": \"SetupCompletedResponse\"\n        }\n    },\n    \"payload\": {\n        \"statusCode\": {{StatusCode}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/DeviceSetup/#payload","title":"Payload","text":"Property Type Required Description Example statusCode StatusCode Yes Status description."},{"location":"aasb/alexa/DeviceSetup/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/DeviceSetup/#setupcompleted","title":"SetupCompleted","text":"<p>SetupCompleted description.</p>"},{"location":"aasb/alexa/DeviceSetup/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"DeviceSetup\",\n            \"action\": \"SetupCompleted\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/DeviceSetup/#enums","title":"Enums","text":""},{"location":"aasb/alexa/DeviceSetup/#statuscode","title":"StatusCode","text":""},{"location":"aasb/alexa/DeviceSetup/#values","title":"Values","text":"Value Description \"SUCCESS\" Successful description. \"FAIL\" Failure description."},{"location":"aasb/alexa/DoNotDisturb/","title":"DoNotDisturb","text":""},{"location":"aasb/alexa/DoNotDisturb/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/DoNotDisturb/#setdonotdisturb","title":"SetDoNotDisturb","text":"<p>Handle setting of DND directive.</p>"},{"location":"aasb/alexa/DoNotDisturb/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"DoNotDisturb\",\n            \"action\": \"SetDoNotDisturb\"\n        }\n    },\n    \"payload\": {\n        \"doNotDisturb\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/DoNotDisturb/#payload","title":"Payload","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state."},{"location":"aasb/alexa/DoNotDisturb/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/DoNotDisturb/#donotdisturbchanged","title":"DoNotDisturbChanged","text":"<p>Notifies the Engine of a platform request to set the DND State.</p>"},{"location":"aasb/alexa/DoNotDisturb/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"DoNotDisturb\",\n            \"action\": \"DoNotDisturbChanged\"\n        }\n    },\n    \"payload\": {\n        \"doNotDisturb\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/DoNotDisturb/#payload_1","title":"Payload","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state."},{"location":"aasb/alexa/EqualizerController/","title":"EqualizerController","text":""},{"location":"aasb/alexa/EqualizerController/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/EqualizerController/#getbandlevels","title":"GetBandLevels","text":"<p>Retrieves the current equalizer gain settings on the device for each supported band.  If unsupported band levels are provided, the Engine will truncate levels to the  configured range.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"GetBandLevels\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#setbandlevels","title":"SetBandLevels","text":"<p>Notifies the platform implementation to apply the provided gain settings to the corresponding  equalizer bands.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"SetBandLevels\"\n        }\n    },\n    \"payload\": {\n        \"bandLevels\": [{{EqualizerBandLevel}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#payload","title":"Payload","text":"Property Type Required Description Example bandLevels EqualizerBandLevel[] Yes The equalizer bands and their gain settings to apply as integer dB values."},{"location":"aasb/alexa/EqualizerController/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/EqualizerController/#localresetbands","title":"LocalResetBands","text":"<p>Notifies the Engine that the gain levels for the equalizer bands are being reset  to their defaults.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"LocalResetBands\"\n        }\n    },\n    \"payload\": {\n        \"bands\": [{{EqualizerBand}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#payload_1","title":"Payload","text":"Property Type Required Description Example bands EqualizerBand[] No The equalizer bands to reset. Empty @a bands resets all supported equalizer bands."},{"location":"aasb/alexa/EqualizerController/#localsetbandlevels","title":"LocalSetBandLevels","text":"<p>Notifies the Engine that gain levels for one or more equalizer bands are being set directly  on the device. If unsupported levels are provided, the Engine will truncate the settings to  the configured range.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"LocalSetBandLevels\"\n        }\n    },\n    \"payload\": {\n        \"bandLevels\": [{{EqualizerBandLevel}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#payload_2","title":"Payload","text":"Property Type Required Description Example bandLevels EqualizerBandLevel[] Yes The equalizer bands to change and their gain settings as integer dB values."},{"location":"aasb/alexa/EqualizerController/#localadjustbandlevels","title":"LocalAdjustBandLevels","text":"<p>Notifies the Engine that relative adjustments to equalizer band gain levels are being made  directly on the device. If adjustments put the band level settings beyond the configured dB  range, the Engine will truncate the settings to the configured range.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"LocalAdjustBandLevels\"\n        }\n    },\n    \"payload\": {\n        \"bandAdjustments\": [{{EqualizerBandLevel}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#payload_3","title":"Payload","text":"Property Type Required Description Example bandAdjustments EqualizerBandLevel[] Yes he equalizer bands to adjust and their relative gain adjustments as integer dB values."},{"location":"aasb/alexa/EqualizerController/#getbandlevelsreply","title":"GetBandLevelsReply","text":"<p>Reply for GetBandLevels message.</p>"},{"location":"aasb/alexa/EqualizerController/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"EqualizerController\",\n            \"action\": \"GetBandLevels\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"bandLevels\": [{{EqualizerBandLevel}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#payload_4","title":"Payload","text":"Property Type Required Description Example bandLevels EqualizerBandLevel[] Yes The supported equalizer bands and their current gain settings as integer dB values."},{"location":"aasb/alexa/EqualizerController/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/alexa/EqualizerController/#equalizerbandlevel","title":"EqualizerBandLevel","text":""},{"location":"aasb/alexa/EqualizerController/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"band\": {{EqualizerBand}},\n    \"level\": {{Int}}        \n}\n</code></pre>"},{"location":"aasb/alexa/EqualizerController/#properties","title":"Properties","text":"Property Type Required Description Example band EqualizerBand Yes Describes the equalizer bands supported by Alexa. The platform implementation may support  a subset of these. level Int Yes Describes the level of gain of a particular equalizer band as an integer dB value."},{"location":"aasb/alexa/EqualizerController/#enums","title":"Enums","text":""},{"location":"aasb/alexa/EqualizerController/#equalizerband","title":"EqualizerBand","text":""},{"location":"aasb/alexa/EqualizerController/#values","title":"Values","text":"Value Description \"BASS\" Bass equalizer band. \"MIDRANGE\" Mid-range equalizer band. \"TREBLE\" Treble equalizer band."},{"location":"aasb/alexa/ExternalMediaAdapter/","title":"ExternalMediaAdapter","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#playcontrol","title":"PlayControl","text":"<p>Occurs during playback control via voice interaction or PlaybackController  interface.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"PlayControl\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"controlType\": {{PlayControlType}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. controlType PlayControlType Yes Playback control type being invoked."},{"location":"aasb/alexa/ExternalMediaAdapter/#seek","title":"Seek","text":"<p>Called when the user invokes media seek via speech.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"Seek\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"offset\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_1","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. offset Int Yes Offset position within media item, in milliseconds."},{"location":"aasb/alexa/ExternalMediaAdapter/#logout","title":"Logout","text":"<p>Directive called after a discovered player initiates the logoutComplete event.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"Logout\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_2","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app."},{"location":"aasb/alexa/ExternalMediaAdapter/#play","title":"Play","text":"<p>Called when the user first calls play for the external media via voice control.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"Play\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"playContextToken\": {{String}},\n        \"index\": {{Int}},\n        \"offset\": {{Int}},\n        \"preload\": {{Bool}},\n        \"navigation\": {{Navigation}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_3","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. playContextToken String Yes Track/playlist/album/artist/station/podcast context identifier. index Int Yes If the playback context is an indexable container like a playlist, the index of  the media item in the container. offset Int Yes Offset position within media item, in milliseconds. preload Bool Yes Whether the media item should preload or not. navigation Navigation Yes The app transition behavior."},{"location":"aasb/alexa/ExternalMediaAdapter/#getstate","title":"GetState","text":"<p>Must provide the local external media player apps @PlaybackStateExternal, and  @SessionStateExternal information to maintain cloud sync.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"GetState\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_4","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app."},{"location":"aasb/alexa/ExternalMediaAdapter/#login","title":"Login","text":"<p>Directive called after a discovered player initiates the loginComplete event.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"Login\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"accessToken\": {{String}},\n        \"userName\": {{String}},\n        \"forceLogin\": {{Bool}},\n        \"tokenRefreshInterval\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_5","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. accessToken String Yes The handshake token between AVS, and the external media player app session. userName String Yes The username provided by the external media player app, if available. forceLogin Bool Yes True if no handshake is needed, and login is simply assumed. tokenRefreshInterval Int Yes refresh interval of the accessToken, if available."},{"location":"aasb/alexa/ExternalMediaAdapter/#adjustseek","title":"AdjustSeek","text":"<p>Called when the user invokes media seek adjustment via speech.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"AdjustSeek\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"deltaOffset\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_6","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. deltaOffset Int Yes Change in offset position within media item, in milliseconds."},{"location":"aasb/alexa/ExternalMediaAdapter/#mutedstatechanged","title":"MutedStateChanged","text":"<p>Notifies the platform implementation to apply a mute state change to the output channel.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"MutedStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{MutedState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_7","title":"Payload","text":"Property Type Required Description Example state MutedState Yes The muted state to apply to the output channel. MUTED when the output channel be muted,  UNMUTED when unmuted."},{"location":"aasb/alexa/ExternalMediaAdapter/#volumechanged","title":"VolumeChanged","text":"<p>Notifies the platform implementation to set the volume of the output channel. The volume value  should be scaled to fit the needs of the platform.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"VolumeChanged\"\n        }\n    },\n    \"payload\": {\n        \"volume\": {{Float}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_8","title":"Payload","text":"Property Type Required Description Example volume Float Yes The volume to set on the output channel.    volume is in the range [0,1]."},{"location":"aasb/alexa/ExternalMediaAdapter/#authorize","title":"Authorize","text":"<p>Called after discovered media players have been reported. Returns a list of reported players  and whether they have been authorized for use with Alexa.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"Authorize\"\n        }\n    },\n    \"payload\": {\n        \"authorizedPlayers\": [{{AuthorizedPlayerInfo}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_9","title":"Payload","text":"Property Type Required Description Example authorizedPlayers AuthorizedPlayerInfo[] Yes A list of discovered players with their status of authorization for use with Alexa."},{"location":"aasb/alexa/ExternalMediaAdapter/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#playerevent","title":"PlayerEvent","text":"<p>Should be called on a local external media player event. This will sync the  context with AVS.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"PlayerEvent\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"eventName\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_10","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. eventName String Yes Canonical event name."},{"location":"aasb/alexa/ExternalMediaAdapter/#logoutcomplete","title":"LogoutComplete","text":"<p>Should be called on a local external media player logout. This will unset  authorization of the app with AVS.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"LogoutComplete\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_11","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app."},{"location":"aasb/alexa/ExternalMediaAdapter/#logincomplete","title":"LoginComplete","text":"<p>Should be called on a local external media player login. This will set authorization  of the app with AVS.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"LoginComplete\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_12","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes Should be called on a local external media player login. This will set  authorization of the app with AVS."},{"location":"aasb/alexa/ExternalMediaAdapter/#setfocus","title":"SetFocus","text":"<p>Should be called on local external media player events. This will switch the media  focus to that context.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"SetFocus\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_13","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app."},{"location":"aasb/alexa/ExternalMediaAdapter/#reportdiscoveredplayers","title":"ReportDiscoveredPlayers","text":"<p>Should be called on startup in order to notify AVS of the local external media  players.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_14","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"ReportDiscoveredPlayers\"\n        }\n    },\n    \"payload\": {\n        \"discoveredPlayers\": [{{DiscoveredPlayerInfo}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_14","title":"Payload","text":"Property Type Required Description Example discoveredPlayers DiscoveredPlayerInfo[] Yes The List of discovered players."},{"location":"aasb/alexa/ExternalMediaAdapter/#removediscoveredplayer","title":"RemoveDiscoveredPlayer","text":"<p>RemoveDiscoveredPlayer description.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_15","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"RemoveDiscoveredPlayer\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_15","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes localPlayerId description."},{"location":"aasb/alexa/ExternalMediaAdapter/#requesttoken","title":"RequestToken","text":"<p>The device is responsible for requesting an access token when needed. This is typically done  immediately upon connection to AVS.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_16","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"RequestToken\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_16","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app."},{"location":"aasb/alexa/ExternalMediaAdapter/#playererror","title":"PlayerError","text":"<p>Should be called on a player error.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_17","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"PlayerError\"\n        }\n    },\n    \"payload\": {\n        \"localPlayerId\": {{String}},\n        \"errorName\": {{String}},\n        \"code\": {{Int}},\n        \"description\": {{String}},\n        \"fatal\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_17","title":"Payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal."},{"location":"aasb/alexa/ExternalMediaAdapter/#getstatereply","title":"GetStateReply","text":"<p>Reply for GetState message.</p>"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_18","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"ExternalMediaAdapter\",\n            \"action\": \"GetState\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"state\": {{ExternalMediaAdapterState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_18","title":"Payload","text":"Property Type Required Description Example state ExternalMediaAdapterState Yes The ExternalMediaAdapterState to be initialized by the platform."},{"location":"aasb/alexa/ExternalMediaAdapter/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#externalmediaadapterstate","title":"ExternalMediaAdapterState","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_19","title":"JSON Structure","text":"<pre><code>{\n    \"sessionState\": {{SessionStateExternal}},\n    \"playbackState\": {{PlaybackStateExternal}}        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties","title":"Properties","text":"Property Type Required Description Example sessionState SessionStateExternal Yes Variable to hold the session state. playbackState PlaybackStateExternal Yes Variable to hold the playback state."},{"location":"aasb/alexa/ExternalMediaAdapter/#sessionstateexternal","title":"SessionStateExternal","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_20","title":"JSON Structure","text":"<pre><code>{\n    \"endpointId\": {{String}},\n    \"loggedIn\": {{Bool}},\n    \"userName\": {{String}},\n    \"isGuest\": {{Bool}},\n    \"launched\": {{Bool}},\n    \"active\": {{Bool}},\n    \"accessToken\": {{String}},\n    \"tokenRefreshInterval\": {{int64}},\n    \"playerCookie\": {{String}},\n    \"spiVersion\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_1","title":"Properties","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean  different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer  token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. playerCookie String Yes A player may declare arbitrary information for itself. spiVersion String Yes The only spiVersion that currently exists is \"1.0\"."},{"location":"aasb/alexa/ExternalMediaAdapter/#playbackstateexternal","title":"PlaybackStateExternal","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_21","title":"JSON Structure","text":"<pre><code>{\n    \"state\": {{String}},\n    \"supportedOperations\": [{{SupportedPlaybackOperation}}],\n    \"trackOffset\": {{Int}},\n    \"shuffleEnabled\": {{Bool}},\n    \"repeatEnabled\": {{Bool}},\n    \"favorites\": {{Favorites}},\n    \"type\": {{String}},\n    \"playbackSource\": {{String}},\n    \"playbackSourceId\": {{String}},\n    \"trackName\": {{String}},\n    \"trackId\": {{String}},\n    \"trackNumber\": {{String}},\n    \"artistName\": {{String}},\n    \"artistId\": {{String}},\n    \"albumName\": {{String}},\n    \"albumId\": {{String}},\n    \"tinyURL\": {{String}},\n    \"smallURL\": {{String}},\n    \"mediumURL\": {{String}},\n    \"largeURL\": {{String}},\n    \"coverId\": {{String}},\n    \"mediaProvider\": {{String}},\n    \"mediaType\": {{MediaType}},\n    \"duration\": {{Int}}        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_2","title":"Properties","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PLAYING. supportedOperations SupportedPlaybackOperation[] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled or not. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled or not. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g.  a URI that can be saved as a preset or queried to Music Service Provider services for  additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music  provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track  in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g.  a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g.  a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource. smallURL String Yes The URL for small cover art image resource. mediumURL String Yes The URL for medium cover art image resource. largeURL String Yes The URL for large cover art image resource. coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider,  for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the  application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of  the media. duration Int Yes Media item duration in milliseconds."},{"location":"aasb/alexa/ExternalMediaAdapter/#authorizedplayerinfo","title":"AuthorizedPlayerInfo","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_22","title":"JSON Structure","text":"<pre><code>{\n    \"localPlayerId\": {{String}},\n    \"authorized\": {{Bool}}        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_3","title":"Properties","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. authorized Bool Yes Authorization status."},{"location":"aasb/alexa/ExternalMediaAdapter/#validationdata","title":"ValidationData","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_23","title":"JSON Structure","text":"<pre><code>{\n    \"certificate\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_4","title":"Properties","text":"Property Type Required Description Example certificate String Yes Validation data."},{"location":"aasb/alexa/ExternalMediaAdapter/#discoveredplayerinfo","title":"DiscoveredPlayerInfo","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_24","title":"JSON Structure","text":"<pre><code>{\n    \"localPlayerId\": {{String}},\n    \"spiVersion\": {{String}},\n    \"validationMethod\": {{ValidationMethod}},\n    \"validationData\": [{{ValidationData}}]        \n}\n</code></pre>"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_5","title":"Properties","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. spiVersion String Yes The only spiVersion that currently exists is '1.0'. validationMethod ValidationMethod Yes Validation methods. validationData ValidationData[] Yes Validation data: 1. Device platform issued app signing certificate. A List of certificates may be attached. 2. In some cases validation is performed locally. The certificate is trasmitted as validationData during discovery to announce the activated app's identity in order to allow app activation to be revoked. 3. empty."},{"location":"aasb/alexa/ExternalMediaAdapter/#enums","title":"Enums","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#supportedplaybackoperation","title":"SupportedPlaybackOperation","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values","title":"Values","text":"Value Description \"PLAY\" Play is supported (voice only). \"PAUSE\" Pause is supported. \"STOP\" Stop is supported. \"NEXT\" Next is supported. \"PREVIOUS\" Previous is supported. \"START_OVER\" Start Over is supported. \"FAST_FORWARD\" Fast Forward is supported. \"REWIND\" Rewind is supported. \"ENABLE_REPEAT\" Enable Repeat is supported. \"ENABLE_REPEAT_ONE\" Enable Repeat One is supported. \"DISABLE_REPEAT\" Disbale Repeat is supported. \"ENABLE_SHUFFLE\" Enable Shuffle is supported. \"DISABLE_SHUFFLE\" Disable Shuffle is supported. \"FAVORITE\" Favorite is supported. \"UNFAVORITE\" Unfavorite is supported. \"SEEK\" Seek is supported. \"ADJUST_SEEK\" Adjust Seek is supported."},{"location":"aasb/alexa/ExternalMediaAdapter/#playcontroltype","title":"PlayControlType","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_1","title":"Values","text":"Value Description \"PAUSE\" pause playback. \"RESUME\" resume playback. \"STOP\" stop playback. \"NEXT\" next song. \"PREVIOUS\" previous playback. \"START_OVER\" start playback over. \"FAST_FORWARD\" fast forward external media described time. \"REWIND\" rewind external media described time. \"ENABLE_REPEAT_ONE\" enable repeat current song. \"ENABLE_REPEAT\" enable playlist looping. \"DISABLE_REPEAT\" disable playlist looping. \"ENABLE_SHUFFLE\" enable playlist shuffling. \"DISABLE_SHUFFLE\" disable playlist shuffling. \"FAVORITE\" favorite song. \"UNFAVORITE\" unfavorite song."},{"location":"aasb/alexa/ExternalMediaAdapter/#validationmethod","title":"ValidationMethod","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_2","title":"Values","text":"Value Description \"SIGNING_CERTIFICATE\" description for SIGNING_CERTIFICATE. \"GENERATED_CERTIFICATE\" description for GENERATED_CERTIFICATE. \"NONE\" description for NONE."},{"location":"aasb/alexa/ExternalMediaAdapter/#favorites","title":"Favorites","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_3","title":"Values","text":"Value Description \"FAVORITED\" song is favorited. \"UNFAVORITED\" song is unfavorited. \"NOT_RATED\" song is not rated."},{"location":"aasb/alexa/ExternalMediaAdapter/#mutedstate","title":"MutedState","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_4","title":"Values","text":"Value Description \"MUTED\" The audio channel state id muted. \"UNMUTED\" The audio channel state id unmuted."},{"location":"aasb/alexa/ExternalMediaAdapter/#navigation","title":"Navigation","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_5","title":"Values","text":"Value Description \"DEFAULT\" Source dependant behavior. \"NONE\" No navigation should occur. \"FOREGROUND\" External app should take foreground."},{"location":"aasb/alexa/ExternalMediaAdapter/#mediatype","title":"MediaType","text":""},{"location":"aasb/alexa/ExternalMediaAdapter/#values_6","title":"Values","text":"Value Description \"TRACK\" A single song source. \"PODCAST\" A podcast source. \"STATION\" A station source. \"AD\" An advertisement source. \"SAMPLE\" A sample source. \"OTHER\" A miscellaneous source."},{"location":"aasb/alexa/FeatureDiscovery/","title":"FeatureDiscovery","text":""},{"location":"aasb/alexa/FeatureDiscovery/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/FeatureDiscovery/#getfeaturesreply","title":"GetFeaturesReply","text":"<p>Reply for GetFeatures message.</p>"},{"location":"aasb/alexa/FeatureDiscovery/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"FeatureDiscovery\",\n            \"action\": \"GetFeatures\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"discoveryResponses\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/FeatureDiscovery/#payload","title":"Payload","text":"Property Type Required Description Example discoveryResponses String Yes An escaped JSON string containing the discovery responses. See the Alexa module documentation for complete details of the schema."},{"location":"aasb/alexa/FeatureDiscovery/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/FeatureDiscovery/#getfeatures","title":"GetFeatures","text":"<p>Get a list of Alexa features based on the domain, eventType, locale and limit.</p>"},{"location":"aasb/alexa/FeatureDiscovery/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"FeatureDiscovery\",\n            \"action\": \"GetFeatures\"\n        }\n    },\n    \"payload\": {\n        \"discoveryRequests\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/FeatureDiscovery/#payload_1","title":"Payload","text":"Property Type Required Description Example discoveryRequests String Yes An escaped JSON string containing the discovery requests. See the Alexa module documentation for complete details of the schema."},{"location":"aasb/alexa/GlobalPreset/","title":"GlobalPreset","text":""},{"location":"aasb/alexa/GlobalPreset/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/GlobalPreset/#setglobalpreset","title":"SetGlobalPreset","text":"<p>Called after receiving a global preset play directive.</p>"},{"location":"aasb/alexa/GlobalPreset/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"GlobalPreset\",\n            \"action\": \"SetGlobalPreset\"\n        }\n    },\n    \"payload\": {\n        \"preset\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/GlobalPreset/#payload","title":"Payload","text":"Property Type Required Description Example preset Int Yes The preset integer from the playbackContextToken."},{"location":"aasb/alexa/LocalMediaSource/","title":"LocalMediaSource","text":""},{"location":"aasb/alexa/LocalMediaSource/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/LocalMediaSource/#playcontrol","title":"PlayControl","text":"<p>Occurs during playback control via voice interaction or PlaybackController interface.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"PlayControl\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"controlType\": {{PlayControlType}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. controlType PlayControlType Yes Playback control type being invoked."},{"location":"aasb/alexa/LocalMediaSource/#seek","title":"Seek","text":"<p>Called when the user invokes media seek via speech.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"Seek\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"offset\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_1","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. offset Int Yes Offset position within media item, in milliseconds."},{"location":"aasb/alexa/LocalMediaSource/#play","title":"Play","text":"<p>Called when the user calls play with a content selection type.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"Play\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"contentSelectorType\": {{ContentSelector}},\n        \"payload\": {{String}},\n        \"sessionId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_2","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. contentSelectorType ContentSelector Yes Content selection type. payload String Yes Content selector payload. sessionId String Yes Universally unique identifier (UUID) generated according to the RFC 4122 specification. Since Alexa is starting the session here, use this session Id for further events and errors."},{"location":"aasb/alexa/LocalMediaSource/#getstate","title":"GetState","text":"<p>Must provide the local media source @PlaybackState, and @SessionState information to maintain cloud sync.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"GetState\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_3","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type."},{"location":"aasb/alexa/LocalMediaSource/#adjustseek","title":"AdjustSeek","text":"<p>Called when the user invokes media seek adjustment via speech.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"AdjustSeek\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"deltaOffset\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_4","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. deltaOffset Int Yes Change in offset position within media item, in milliseconds."},{"location":"aasb/alexa/LocalMediaSource/#mutedstatechanged","title":"MutedStateChanged","text":"<p>Notifies the platform implementation to apply a muted state has changed for the output  channel.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"MutedStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"state\": {{MutedState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_5","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. state MutedState Yes The muted state to apply to the output channel."},{"location":"aasb/alexa/LocalMediaSource/#volumechanged","title":"VolumeChanged","text":"<p>Notifies the platform implementation to set the volume of the output channel. The volume  value should be scaled to fit the needs of the platform.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"VolumeChanged\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"volume\": {{Float}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_6","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. volume Float Yes The volume to set on the output channel."},{"location":"aasb/alexa/LocalMediaSource/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/LocalMediaSource/#playerevent","title":"PlayerEvent","text":"<p>Should be called on a local media source player event. This will sync the context with AVS.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"PlayerEvent\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"eventName\": {{String}},\n        \"sessionId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_7","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. eventName String Yes Canonical event name. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended."},{"location":"aasb/alexa/LocalMediaSource/#setfocus","title":"SetFocus","text":"<p>Should be called on local media source player events. This will switch the media focus to  that context.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"SetFocus\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_8","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type."},{"location":"aasb/alexa/LocalMediaSource/#playererror","title":"PlayerError","text":"<p>Should be called on a local media source player error.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"PlayerError\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{Source}},\n        \"errorName\": {{String}},\n        \"code\": {{Int}},\n        \"description\": {{String}},\n        \"fatal\": {{Bool}},\n        \"sessionId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_9","title":"Payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended."},{"location":"aasb/alexa/LocalMediaSource/#getstatereply","title":"GetStateReply","text":"<p>Reply for GetState message.</p>"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocalMediaSource\",\n            \"action\": \"GetState\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"state\": {{LocalMediaSourceState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#payload_10","title":"Payload","text":"Property Type Required Description Example state LocalMediaSourceState Yes state description."},{"location":"aasb/alexa/LocalMediaSource/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/alexa/LocalMediaSource/#localmediasourcestate","title":"LocalMediaSourceState","text":""},{"location":"aasb/alexa/LocalMediaSource/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"sessionState\": {{SessionState}},\n    \"playbackState\": {{PlaybackState}}        \n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#properties","title":"Properties","text":"Property Type Required Description Example sessionState SessionState Yes Variable to hold the session state. playbackState PlaybackState Yes Variable to hold the playback state."},{"location":"aasb/alexa/LocalMediaSource/#playbackstate","title":"PlaybackState","text":""},{"location":"aasb/alexa/LocalMediaSource/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"state\": {{String}},\n    \"supportedOperations\": [{{SupportedPlaybackOperation}}],\n    \"trackOffset\": {{Int}},\n    \"shuffleEnabled\": {{Bool}},\n    \"repeatEnabled\": {{Bool}},\n    \"favorites\": {{Favorites}},\n    \"type\": {{String}},\n    \"playbackSource\": {{String}},\n    \"playbackSourceId\": {{String}},\n    \"trackName\": {{String}},\n    \"trackId\": {{String}},\n    \"trackNumber\": {{String}},\n    \"artistName\": {{String}},\n    \"artistId\": {{String}},\n    \"albumName\": {{String}},\n    \"albumId\": {{String}},\n    \"tinyURL\": {{String}},\n    \"smallURL\": {{String}},\n    \"mediumURL\": {{String}},\n    \"largeURL\": {{String}},\n    \"coverId\": {{String}},\n    \"mediaProvider\": {{String}},\n    \"mediaType\": {{MediaType}},\n    \"duration\": {{Int}}        \n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#properties_1","title":"Properties","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PAUSED/PLAYING/FINISHED/FAST_FORWARDING/REWINDING/BUFFER_UNDERRUN. supportedOperations SupportedPlaybackOperation[] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g.  a URI that can be saved as a preset or queried to Music Service Provider services for  additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track  in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can  be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can  be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource} . smallURL String Yes The URL for small cover art image resource} . mediumURL String Yes The URL for medium cover art image resource} . largeURL String Yes The URL for large cover art image resource} . coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval  from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application  identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds."},{"location":"aasb/alexa/LocalMediaSource/#sessionstate","title":"SessionState","text":""},{"location":"aasb/alexa/LocalMediaSource/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"endpointId\": {{String}},\n    \"loggedIn\": {{Bool}},\n    \"userName\": {{String}},\n    \"isGuest\": {{Bool}},\n    \"launched\": {{Bool}},\n    \"active\": {{Bool}},\n    \"accessToken\": {{String}},\n    \"tokenRefreshInterval\": {{int64}},\n    \"supportedContentSelectors\": [{{ContentSelector}}],\n    \"spiVersion\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/alexa/LocalMediaSource/#properties_2","title":"Properties","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things  for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter  makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. supportedContentSelectors ContentSelector[] Yes Array of content selector types supported by the player. spiVersion String Yes The only spiVersion that currently exists is '1.0'."},{"location":"aasb/alexa/LocalMediaSource/#enums","title":"Enums","text":""},{"location":"aasb/alexa/LocalMediaSource/#source","title":"Source","text":""},{"location":"aasb/alexa/LocalMediaSource/#values","title":"Values","text":"Value Description \"BLUETOOTH\" bluetooth source. \"USB\" USB source. \"FM_RADIO\" FM radio source. \"AM_RADIO\" AM radio source. \"SATELLITE_RADIO\" satellite radio source. \"LINE_IN\" audio line source. \"COMPACT_DISC\" CD player source. \"SIRIUS_XM\" SIRIUS XM source. \"DAB\" DAB source. \"DEFAULT\" DEFAULT source."},{"location":"aasb/alexa/LocalMediaSource/#contentselector","title":"ContentSelector","text":""},{"location":"aasb/alexa/LocalMediaSource/#values_1","title":"Values","text":"Value Description \"FREQUENCY\" radio station selection. \"CHANNEL\" radio channel selection. \"PRESET\" preset selection."},{"location":"aasb/alexa/MediaPlaybackRequestor/","title":"MediaPlaybackRequestor","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#mediaplaybackresponse","title":"MediaPlaybackResponse","text":"<p>Result of the RequestMediaPlayback request.</p>"},{"location":"aasb/alexa/MediaPlaybackRequestor/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MediaPlaybackRequestor\",\n            \"action\": \"MediaPlaybackResponse\"\n        }\n    },\n    \"payload\": {\n        \"mediaPlaybackRequestStatus\": {{MediaPlaybackRequestStatus}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/MediaPlaybackRequestor/#payload","title":"Payload","text":"Property Type Required Description Example mediaPlaybackRequestStatus MediaPlaybackRequestStatus Yes Enum value representing the response of the RequestMediaPlaybackMessage request."},{"location":"aasb/alexa/MediaPlaybackRequestor/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#requestmediaplayback","title":"RequestMediaPlayback","text":"<p>OEM Developers are expected to call this method whenever Alexa is the right candidate for the media resume.</p>"},{"location":"aasb/alexa/MediaPlaybackRequestor/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MediaPlaybackRequestor\",\n            \"action\": \"RequestMediaPlayback\"\n        }\n    },\n    \"payload\": {\n        \"invocationReason\": {{InvocationReason}},\n        \"elapsedBootTime\": {{int64}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/MediaPlaybackRequestor/#payload_1","title":"Payload","text":"Property Type Required Description Example invocationReason InvocationReason Yes Reason for calling this API. elapsedBootTime int64 Yes Provide the elapsed boot time in mili seconds if your platform does not provide a right value using https://developer.android.com/reference/android/os/SystemClock#elapsedRealtime() or https://man7.org/linux/man-pages/man2/sysinfo.2.html uptime."},{"location":"aasb/alexa/MediaPlaybackRequestor/#enums","title":"Enums","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#mediaplaybackrequeststatus","title":"MediaPlaybackRequestStatus","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#values","title":"Values","text":"Value Description \"SUCCESS\" Successful description. \"FAILED_CAN_RETRY\" Failure description. \"FAILED_TIMEOUT\" Too late to send RequestMediaPlaybackMessage, Failed to deliver. \"ERROR\" Event call is failed because of an error."},{"location":"aasb/alexa/MediaPlaybackRequestor/#invocationreason","title":"InvocationReason","text":""},{"location":"aasb/alexa/MediaPlaybackRequestor/#values_1","title":"Values","text":"Value Description \"AUTOMOTIVE_STARTUP\" System call for the automatic media resume. \"EXPLICIT_USER_ACTION\" Driver action for the media resume."},{"location":"aasb/alexa/Notifications/","title":"Notifications","text":""},{"location":"aasb/alexa/Notifications/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/Notifications/#setindicator","title":"SetIndicator","text":"<p>Notifies the platform implementation of whether a notification indicator should be rendered.</p>"},{"location":"aasb/alexa/Notifications/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Notifications\",\n            \"action\": \"SetIndicator\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{IndicatorState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/Notifications/#payload","title":"Payload","text":"Property Type Required Description Example state IndicatorState Yes The new notification indicator state."},{"location":"aasb/alexa/Notifications/#onnotificationreceived","title":"OnNotificationReceived","text":"<p>Notifies the platform implementation of notification received.</p>"},{"location":"aasb/alexa/Notifications/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Notifications\",\n            \"action\": \"OnNotificationReceived\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/Notifications/#enums","title":"Enums","text":""},{"location":"aasb/alexa/Notifications/#indicatorstate","title":"IndicatorState","text":""},{"location":"aasb/alexa/Notifications/#values","title":"Values","text":"Value Description \"OFF\" The notification indicator should be turned off. \"ON\" The notification indicator should be turned on. \"UNKNOWN\" The notification indicator state is unknown."},{"location":"aasb/alexa/PlaybackController/","title":"PlaybackController","text":""},{"location":"aasb/alexa/PlaybackController/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/PlaybackController/#buttonpressed","title":"ButtonPressed","text":"<p>Notifies the Engine of a platform button request (i.e. Play/Pause/Next/Previous/Skip Forward/Skip Backward) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer to control playback on the platform.</p>"},{"location":"aasb/alexa/PlaybackController/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PlaybackController\",\n            \"action\": \"ButtonPressed\"\n        }\n    },\n    \"payload\": {\n        \"button\": {{PlaybackButton}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/PlaybackController/#payload","title":"Payload","text":"Property Type Required Description Example button PlaybackButton Yes The playback button type."},{"location":"aasb/alexa/PlaybackController/#togglepressed","title":"TogglePressed","text":"<p>Notifies the Engine of a platform toggle request (i.e. Shuffle/Loop/Repeat/Thumbs Up/Thumbs Down) For certain  playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer.</p>"},{"location":"aasb/alexa/PlaybackController/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PlaybackController\",\n            \"action\": \"TogglePressed\"\n        }\n    },\n    \"payload\": {\n        \"toggle\": {{PlaybackToggle}},\n        \"action\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/PlaybackController/#payload_1","title":"Payload","text":"Property Type Required Description Example toggle PlaybackToggle Yes The playback toggle type. action Bool Yes The toggle action."},{"location":"aasb/alexa/PlaybackController/#enums","title":"Enums","text":""},{"location":"aasb/alexa/PlaybackController/#playbackbutton","title":"PlaybackButton","text":""},{"location":"aasb/alexa/PlaybackController/#values","title":"Values","text":"Value Description \"PLAY\" Play button. \"PAUSE\" Pause button. \"NEXT\" Next button. \"PREVIOUS\" Previous button. \"SKIP_FORWARD\" Skip Forward button. \"SKIP_BACKWARD\" Skip Backward button."},{"location":"aasb/alexa/PlaybackController/#playbacktoggle","title":"PlaybackToggle","text":""},{"location":"aasb/alexa/PlaybackController/#values_1","title":"Values","text":"Value Description \"SHUFFLE\" Shuffle toggle. \"LOOP\" Loop toggle. \"REPEAT\" Repeat toggle. \"THUMBS_UP\" Thumbs Up toggle. \"THUMBS_DOWN\" Thumbs Down toggle."},{"location":"aasb/alexa/SpeechRecognizer/","title":"SpeechRecognizer","text":""},{"location":"aasb/alexa/SpeechRecognizer/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/SpeechRecognizer/#wakeworddetected","title":"WakewordDetected","text":"<p>Notifies the platform implementation when a wake word is detected.</p>"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"SpeechRecognizer\",\n            \"action\": \"WakewordDetected\"\n        }\n    },\n    \"payload\": {\n        \"wakeword\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/SpeechRecognizer/#payload","title":"Payload","text":"Property Type Required Description Example wakeword String Yes The wake word that was detected."},{"location":"aasb/alexa/SpeechRecognizer/#endofspeechdetected","title":"EndOfSpeechDetected","text":"<p>Notifies the platform implementation when end of speech is detected for the  current recognize event.</p>"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"SpeechRecognizer\",\n            \"action\": \"EndOfSpeechDetected\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/SpeechRecognizer/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/SpeechRecognizer/#stopcapture","title":"StopCapture","text":"<p>Notifies the Engine to terminate the current recognize event. The Engine will  call stopAudioInput() to notify the platform implementation when to stop writing  audio samples.</p>"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"SpeechRecognizer\",\n            \"action\": \"StopCapture\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/SpeechRecognizer/#startcapture","title":"StartCapture","text":"<p>Notifies the Engine of a speech recognition event. The Engine will call startAudioInput()  to notify the platform implementation when to start writing audio samples. If the initator  type is HOLD_TO_TALK, then the platform implementation should call stopCapture() to terminate  speech recognition on release of the press-and-hold action. Otherwise, the Engine will terminate the recognize event when end of speech is detected.</p>"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"SpeechRecognizer\",\n            \"action\": \"StartCapture\"\n        }\n    },\n    \"payload\": {\n        \"initiator\": {{Initiator}},\n        \"keywordBegin\": {{Int}},\n        \"keywordEnd\": {{Int}},\n        \"keyword\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/SpeechRecognizer/#payload_1","title":"Payload","text":"Property Type Required Description Example initiator Initiator Yes Initiator type for the speech recognition event. keywordBegin Int No (default: <code>-1</code>) The sample index where the keyword begins. Must be provided when initiator type is WAKEWORD. keywordEnd Int No (default: <code>-1</code>) The sample index where the keyword ends. Must be provided when initiator type is WAKEWORD. keyword String No The keyword being recognized, e.g. alexa. Must be provided when initiator type is WAKEWORD."},{"location":"aasb/alexa/SpeechRecognizer/#enums","title":"Enums","text":""},{"location":"aasb/alexa/SpeechRecognizer/#initiator","title":"Initiator","text":""},{"location":"aasb/alexa/SpeechRecognizer/#values","title":"Values","text":"Value Description \"HOLD_TO_TALK\" Hold-to-talk speech initiator type. \"TAP_TO_TALK\" Tap-to-talk speech initiator type. \"WAKEWORD\" Wakeword speech initiator type."},{"location":"aasb/alexa/TemplateRuntime/","title":"TemplateRuntime","text":""},{"location":"aasb/alexa/TemplateRuntime/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/alexa/TemplateRuntime/#rendertemplate","title":"RenderTemplate","text":"<p>Provides visual metadata associated with a user request to Alexa.</p>"},{"location":"aasb/alexa/TemplateRuntime/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TemplateRuntime\",\n            \"action\": \"RenderTemplate\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}},\n        \"focusState\": {{FocusState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/TemplateRuntime/#payload","title":"Payload","text":"Property Type Required Description Example payload String Yes Renderable template metadata in structured JSON format. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface."},{"location":"aasb/alexa/TemplateRuntime/#clearplayerinfo","title":"ClearPlayerInfo","text":"<p>Notifies the platform implementation to dismiss the player info display card.</p>"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TemplateRuntime\",\n            \"action\": \"ClearPlayerInfo\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/TemplateRuntime/#cleartemplate","title":"ClearTemplate","text":"<p>Notifies the platform implementation to dismiss the template display card.</p>"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TemplateRuntime\",\n            \"action\": \"ClearTemplate\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/TemplateRuntime/#renderplayerinfo","title":"RenderPlayerInfo","text":"<p>Provides visual metadata associated with a user request to Alexa for audio playback.</p>"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TemplateRuntime\",\n            \"action\": \"RenderPlayerInfo\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}},\n        \"audioPlayerState\": {{PlayerActivity}},\n        \"offset\": {{Int}},\n        \"focusState\": {{FocusState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/alexa/TemplateRuntime/#payload_1","title":"Payload","text":"Property Type Required Description Example payload String Yes Renderable player info metadata in structured JSON format. audioPlayerState PlayerActivity Yes The state of the AudioPlayer. offset Int Yes The offset in millisecond of the media that AudioPlayer is handling. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface."},{"location":"aasb/alexa/TemplateRuntime/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/alexa/TemplateRuntime/#displaycardcleared","title":"DisplayCardCleared","text":"<p>Notifies the Engine that a display card has been cleared from the screen. Upon getting this  notification, the TemplateRuntime will release the visual channel.</p>"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TemplateRuntime\",\n            \"action\": \"DisplayCardCleared\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/alexa/TemplateRuntime/#enums","title":"Enums","text":""},{"location":"aasb/alexa/TemplateRuntime/#focusstate","title":"FocusState","text":""},{"location":"aasb/alexa/TemplateRuntime/#values","title":"Values","text":"Value Description \"FOREGROUND\" Represents the highest focus a Channel can have. \"BACKGROUND\" Represents the intermediate level focus a Channel can have. \"NONE\" This focus is used to represent when a Channel is not being used."},{"location":"aasb/apl/APL/","title":"APL","text":""},{"location":"aasb/apl/APL/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/apl/APL/#datasourceupdate","title":"DataSourceUpdate","text":"<p>Notifies the platform implementation of a dynamic data source update.</p>"},{"location":"aasb/apl/APL/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"DataSourceUpdate\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{String}},\n        \"payload\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload","title":"Payload","text":"Property Type Required Description Example type String Yes The type of data source update received. payload String Yes The data source update payload in JSON format. token String Yes The presentation token associated with the APL document."},{"location":"aasb/apl/APL/#interruptcommandsequence","title":"InterruptCommandSequence","text":"<p>Notifies the platform implementation to clear the APL document rendering.</p>"},{"location":"aasb/apl/APL/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"InterruptCommandSequence\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_1","title":"Payload","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document."},{"location":"aasb/apl/APL/#updateaplruntimeproperties","title":"UpdateAPLRuntimeProperties","text":"<p>Notifies the platform implementation of APL runtime properties to be used during rendering.</p>"},{"location":"aasb/apl/APL/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"UpdateAPLRuntimeProperties\"\n        }\n    },\n    \"payload\": {\n        \"properties\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_2","title":"Payload","text":"Property Type Required Description Example properties String Yes String in JSON format containing updated APL runtime properties."},{"location":"aasb/apl/APL/#renderdocument","title":"RenderDocument","text":"<p>Notifies the platform implementation that an APL document needs rendering.</p>"},{"location":"aasb/apl/APL/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"RenderDocument\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}},\n        \"token\": {{String}},\n        \"windowId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_3","title":"Payload","text":"Property Type Required Description Example payload String Yes The APL document to be rendered represented as a JSON string. token String Yes The presentation token associated with the APL document. windowId String Yes The window ID where the APL document will be rendered or empty string for default window."},{"location":"aasb/apl/APL/#executecommands","title":"ExecuteCommands","text":"<p>Notifies the platform implementation that an APL document needs rendering.</p>"},{"location":"aasb/apl/APL/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ExecuteCommands\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_4","title":"Payload","text":"Property Type Required Description Example payload String Yes The APL commands to be executed represented as a JSON string. token String Yes The presentation token associated with the APL document."},{"location":"aasb/apl/APL/#cleardocument","title":"ClearDocument","text":"<p>Notifies the platform implementation to clear the APL document rendering.</p>"},{"location":"aasb/apl/APL/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ClearDocument\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_5","title":"Payload","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document."},{"location":"aasb/apl/APL/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/apl/APL/#processactivityevent","title":"ProcessActivityEvent","text":"<p>Notifies the Engine of an activity event.</p>"},{"location":"aasb/apl/APL/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ProcessActivityEvent\"\n        }\n    },\n    \"payload\": {\n        \"source\": {{String}},\n        \"event\": {{ActivityEvent}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_6","title":"Payload","text":"Property Type Required Description Example source String Yes The source value for the activity event. event ActivityEvent Yes The activity event type."},{"location":"aasb/apl/APL/#setaplmaxversion","title":"SetAPLMaxVersion","text":"<p>Notifies the Engine of the maximum APL version supported.</p>"},{"location":"aasb/apl/APL/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SetAPLMaxVersion\"\n        }\n    },\n    \"payload\": {\n        \"version\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_7","title":"Payload","text":"Property Type Required Description Example version String Yes The maximum APL version supported."},{"location":"aasb/apl/APL/#senduserevent","title":"SendUserEvent","text":"<p>Notifies the Engine that user generated an event.</p>"},{"location":"aasb/apl/APL/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SendUserEvent\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_8","title":"Payload","text":"Property Type Required Description Example payload String Yes The APL user event represented as a JSON string."},{"location":"aasb/apl/APL/#senddatasourcefetchrequestevent","title":"SendDataSourceFetchRequestEvent","text":"<p>Notifies the Engine of a data source fetch request.</p>"},{"location":"aasb/apl/APL/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SendDataSourceFetchRequestEvent\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{String}},\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_9","title":"Payload","text":"Property Type Required Description Example type String Yes The type of data source fetch request. payload String Yes The APL user event represented as a JSON string."},{"location":"aasb/apl/APL/#senddevicewindowstate","title":"SendDeviceWindowState","text":"<p>Notifies the Engine of the current window state.</p>"},{"location":"aasb/apl/APL/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SendDeviceWindowState\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_10","title":"Payload","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the window state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/display-window.html#windowstate-context-object."},{"location":"aasb/apl/APL/#senddocumentstate","title":"SendDocumentState","text":"<p>Notifies the Engine that APL runtime generated visual document state.</p>"},{"location":"aasb/apl/APL/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SendDocumentState\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_11","title":"Payload","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the rendered document state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/presentation-apl.html#rendereddocumentstate."},{"location":"aasb/apl/APL/#sendruntimeerrorevent","title":"SendRuntimeErrorEvent","text":"<p>Notifies the Engine that an APL runtime error occurred.</p>"},{"location":"aasb/apl/APL/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SendRuntimeErrorEvent\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_12","title":"Payload","text":"Property Type Required Description Example payload String Yes The APL runtime error event represented as a JSON string."},{"location":"aasb/apl/APL/#clearallexecutecommands","title":"ClearAllExecuteCommands","text":"<p>Notifies the Engine that APL render finished clearing all commands.</p>"},{"location":"aasb/apl/APL/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ClearAllExecuteCommands\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#setplatformproperty","title":"SetPlatformProperty","text":"<p>Notifies the Engine of properties such as vehicle driving state, day/night mode, and custom theme id.</p>"},{"location":"aasb/apl/APL/#json-structure_14","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SetPlatformProperty\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"value\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_13","title":"Payload","text":"Property Type Required Description Example name String Yes The name of the property to be set. value String Yes The value that the property will be set to."},{"location":"aasb/apl/APL/#executecommandsresult","title":"ExecuteCommandsResult","text":"<p>Notifies the Engine of the command execution result.</p>"},{"location":"aasb/apl/APL/#json-structure_15","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ExecuteCommandsResult\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"result\": {{Bool}},\n        \"error\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_14","title":"Payload","text":"Property Type Required Description Example token String Yes The token associated with the commands. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty."},{"location":"aasb/apl/APL/#setdocumentidletimeout","title":"SetDocumentIdleTimeout","text":"<p>Notifies the Engine of the idle timeout value.</p>"},{"location":"aasb/apl/APL/#json-structure_16","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"SetDocumentIdleTimeout\"\n        }\n    },\n    \"payload\": {\n        \"timeout\": {{int64}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_15","title":"Payload","text":"Property Type Required Description Example timeout int64 Yes Idle timeout value in milliseconds."},{"location":"aasb/apl/APL/#renderdocumentresult","title":"RenderDocumentResult","text":"<p>Notifies the Engine of command execution result.</p>"},{"location":"aasb/apl/APL/#json-structure_17","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"RenderDocumentResult\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"result\": {{Bool}},\n        \"error\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#payload_16","title":"Payload","text":"Property Type Required Description Example token String Yes The token associated with the APL document. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty."},{"location":"aasb/apl/APL/#clearcard","title":"ClearCard","text":"<p>Notifies the Engine that APL render finished clearing document.</p>"},{"location":"aasb/apl/APL/#json-structure_18","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"APL\",\n            \"action\": \"ClearCard\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/apl/APL/#enums","title":"Enums","text":""},{"location":"aasb/apl/APL/#activityevent","title":"ActivityEvent","text":""},{"location":"aasb/apl/APL/#values","title":"Values","text":"Value Description \"ACTIVATED\" GUI switched to active state. \"DEACTIVATED\" GUI become inactive. \"ONE_TIME\" GUI processed one-time event (touch/scroll/etc). \"INTERRUPT\" Interrupt event (touch). \"UNKNOWN\" Guard option for unknown received state."},{"location":"aasb/car-control/CarControl/","title":"CarControl","text":""},{"location":"aasb/car-control/CarControl/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue","title":"AdjustControllerValue","text":"<p>Adjusts the range setting identified by endpointId and instanceId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"AdjustControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"RANGE\",\n        \"capabilityType\": \"RANGE\",\n        \"endpointId\": {{String}},\n        \"controllerId\": {{String}},\n        \"instanceId\": {{String}},\n        \"delta\": {{double}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta double Yes The delta by which to adjust the range setting."},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue_1","title":"AdjustControllerValue","text":"<p>Adjusts the mode of the setting identified by endpointId and instanceId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"AdjustControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"MODE\",\n        \"capabilityType\": \"MODE\",\n        \"endpointId\": {{String}},\n        \"controllerId\": {{String}},\n        \"instanceId\": {{String}},\n        \"delta\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_1","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta Int Yes The delta by which to adjust the mode."},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue_2","title":"AdjustControllerValue","text":""},{"location":"aasb/car-control/CarControl/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"AdjustControllerValue\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#setcontrollervalue","title":"SetControllerValue","text":"<p>Sets the power state of the endpoint identified by endpointId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"POWER\",\n        \"capabilityType\": \"POWER\",\n        \"endpointId\": {{String}},\n        \"turnOn\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_2","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. turnOn Bool Yes The power setting. True to turn on the endpoint or False to turn off."},{"location":"aasb/car-control/CarControl/#setcontrollervalue_1","title":"SetControllerValue","text":"<p>Sets the range setting identified by endpointId and instanceId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"RANGE\",\n        \"capabilityType\": \"RANGE\",\n        \"endpointId\": {{String}},\n        \"controllerId\": {{String}},\n        \"instanceId\": {{String}},\n        \"value\": {{double}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_3","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value double Yes The new range setting."},{"location":"aasb/car-control/CarControl/#setcontrollervalue_2","title":"SetControllerValue","text":"<p>Sets the toggle state of the setting identified by endpointId and instanceId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"TOGGLE\",\n        \"capabilityType\": \"TOGGLE\",\n        \"endpointId\": {{String}},\n        \"controllerId\": {{String}},\n        \"instanceId\": {{String}},\n        \"turnOn\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_4","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. turnOn Bool Yes The power state of the setting. True to turn on the setting or False to turn off."},{"location":"aasb/car-control/CarControl/#setcontrollervalue_3","title":"SetControllerValue","text":"<p>Sets the mode of the setting identified by endpointId and instanceId.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\"\n        }\n    },\n    \"payload\": {\n        \"controllerType\": \"MODE\",\n        \"capabilityType\": \"MODE\",\n        \"endpointId\": {{String}},\n        \"controllerId\": {{String}},\n        \"instanceId\": {{String}},\n        \"value\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_5","title":"Payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value String Yes The new mode to set."},{"location":"aasb/car-control/CarControl/#setcontrollervalue_4","title":"SetControllerValue","text":""},{"location":"aasb/car-control/CarControl/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/car-control/CarControl/#adjustcontrollervaluereply","title":"AdjustControllerValueReply","text":"<p>Reply for AdjustControllerValue message.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"AdjustControllerValue\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_6","title":"Payload","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted. Failure to send the asynchronous reply message within 5 seconds results in a timeout."},{"location":"aasb/car-control/CarControl/#setcontrollervaluereply","title":"SetControllerValueReply","text":"<p>Reply for SetControllerValue message.</p>"},{"location":"aasb/car-control/CarControl/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CarControl\",\n            \"action\": \"SetControllerValue\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/car-control/CarControl/#payload_7","title":"Payload","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully. Failure to send the asynchronous reply message within 5 seconds results in a timeout."},{"location":"aasb/cbl/CBL/","title":"CBL","text":""},{"location":"aasb/cbl/CBL/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/cbl/CBL/#cblstatechanged","title":"CBLStateChanged","text":"<p>(Deprecated) Notifies the platform implementation of an authorization flow state change.</p>"},{"location":"aasb/cbl/CBL/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"CBLStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{CBLState}},\n        \"reason\": {{CBLStateChangedReason}},\n        \"url\": {{String}},\n        \"code\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#payload","title":"Payload","text":"Property Type Required Description Example state CBLState Yes State of the CBL Authorization flow. reason CBLStateChangedReason Yes The state change reason. url String Yes The localeized url to enter the CBL code. code String Yes The CBL code."},{"location":"aasb/cbl/CBL/#clearrefreshtoken","title":"ClearRefreshToken","text":"<p>(Deprecated) Notifies the platform implementation to clear the refresh token.</p>"},{"location":"aasb/cbl/CBL/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"ClearRefreshToken\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#setrefreshtoken","title":"SetRefreshToken","text":"<p>(Deprecated) Notifies the platform implemnentation to set the refresh token.</p>"},{"location":"aasb/cbl/CBL/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"SetRefreshToken\"\n        }\n    },\n    \"payload\": {\n        \"refreshToken\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#payload_1","title":"Payload","text":"Property Type Required Description Example refreshToken String Yes The refresh token."},{"location":"aasb/cbl/CBL/#getrefreshtoken","title":"GetRefreshToken","text":"<p>(Deprecated) Returns the refresh token stored by the platform implementation, otherwise return an empty string.</p>"},{"location":"aasb/cbl/CBL/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"GetRefreshToken\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#setuserprofile","title":"SetUserProfile","text":"<p>(Deprecated) Notifies the platform implementation about the user profile. This is notified only when <code>requestUserProfile</code> is enabled in the configuration.</p>"},{"location":"aasb/cbl/CBL/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"SetUserProfile\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"email\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#payload_2","title":"Payload","text":"Property Type Required Description Example name String Yes The logged in user name. email String Yes The logged in user email."},{"location":"aasb/cbl/CBL/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/cbl/CBL/#start","title":"Start","text":"<p>(Deprecated) Notifies the Engine to cancel the authorization process.</p>"},{"location":"aasb/cbl/CBL/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"Start\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#cancel","title":"Cancel","text":"<p>(Deprecated) Notifies the Engine to cancel the authorization process.</p>"},{"location":"aasb/cbl/CBL/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"Cancel\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#reset","title":"Reset","text":"<p>(Deprecated) Notifies the Engine to reset the authorization state.</p>"},{"location":"aasb/cbl/CBL/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"Reset\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#getrefreshtokenreply","title":"GetRefreshTokenReply","text":"<p>Reply for GetRefreshToken message.</p>"},{"location":"aasb/cbl/CBL/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CBL\",\n            \"action\": \"GetRefreshToken\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"refreshToken\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/cbl/CBL/#payload_3","title":"Payload","text":"Property Type Required Description Example refreshToken String Yes The refresh token."},{"location":"aasb/cbl/CBL/#enums","title":"Enums","text":""},{"location":"aasb/cbl/CBL/#cblstate","title":"CBLState","text":"<p>Specifies the state of the authorization flow.</p>"},{"location":"aasb/cbl/CBL/#values","title":"Values","text":"Value Description \"STARTING\" CBL process is starting. \"REQUESTING_CODE_PAIR\" Initiating the process to request a code pair. \"CODE_PAIR_RECEIVED\" Code pair is received and is waiting on user to authenticate. \"REFRESHING_TOKEN\" Refreshing token stage has begun. \"REQUESTING_TOKEN\" Requesting for authorization token. \"STOPPING\" CBL process is ending."},{"location":"aasb/cbl/CBL/#cblstatechangedreason","title":"CBLStateChangedReason","text":"<p>Specifies the reason for the state change.</p>"},{"location":"aasb/cbl/CBL/#values_1","title":"Values","text":"Value Description \"SUCCESS\" The CBL state changed successfully. \"ERROR\" Error occurred in the CBL process. \"TIMEOUT\" Request timed out. \"CODE_PAIR_EXPIRED\" Code pair has expired and user will need to initiate the authentication process again. \"AUTHORIZATION_EXPIRED\" The refresh token is invalid, revoked, or was issued to a different client. \"NONE\" No reason specified."},{"location":"aasb/connectivity/AlexaConnectivity/","title":"AlexaConnectivity","text":""},{"location":"aasb/connectivity/AlexaConnectivity/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/connectivity/AlexaConnectivity/#getconnectivitystate","title":"GetConnectivityState","text":"<p>Retrieve the connectivity state from the platform implementation.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"GetConnectivityState\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#getidentifier","title":"GetIdentifier","text":"<p>Retrieve the identifier from the platform implementation.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"GetIdentifier\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#connectivitystatechangereply","title":"ConnectivityStateChangeReply","text":"<p>Reply for ConnectivityStateChange message.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"ConnectivityStateChange\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#payload","title":"Payload","text":"Property Type Required Description Example success Bool Yes Returns true if connectivity state was processed successfully, false otherwise."},{"location":"aasb/connectivity/AlexaConnectivity/#sendconnectivityeventreply","title":"SendConnectivityEventReply","text":"<p>Reply for SendConnectivityEvent message.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"SendConnectivityEvent\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"statusCode\": {{StatusCode}}        \n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_1","title":"Payload","text":"Property Type Required Description Example statusCode StatusCode Yes Represents the delivery status of event."},{"location":"aasb/connectivity/AlexaConnectivity/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/connectivity/AlexaConnectivity/#connectivitystatechange","title":"ConnectivityStateChange","text":"<p>Notifies the Engine of a change in the connectivity state. The Engine calls getConnectivityState to retrieve the the connectivity state and communicate any changes to Alexa.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"ConnectivityStateChange\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#sendconnectivityevent","title":"SendConnectivityEvent","text":"<p>Notifies an event in the connectivity to the Engine.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"SendConnectivityEvent\"\n        }\n    },\n    \"payload\": {\n        \"event\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_2","title":"Payload","text":"Property Type Required Description Example event String Yes The stringified JSON containing the event."},{"location":"aasb/connectivity/AlexaConnectivity/#getconnectivitystatereply","title":"GetConnectivityStateReply","text":"<p>Reply for GetConnectivityState message.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"GetConnectivityState\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"connectivityState\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_3","title":"Payload","text":"Property Type Required Description Example connectivityState String Yes A string representing the connectivity state in structured JSON format."},{"location":"aasb/connectivity/AlexaConnectivity/#getidentifierreply","title":"GetIdentifierReply","text":"<p>Reply for GetIdentifier message.</p>"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AlexaConnectivity\",\n            \"action\": \"GetIdentifier\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"identifier\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_4","title":"Payload","text":"Property Type Required Description Example identifier String Yes A string representing the identifier."},{"location":"aasb/connectivity/AlexaConnectivity/#enums","title":"Enums","text":""},{"location":"aasb/connectivity/AlexaConnectivity/#statuscode","title":"StatusCode","text":""},{"location":"aasb/connectivity/AlexaConnectivity/#values","title":"Values","text":"Value Description \"SUCCESS\" The event was sent to AVS successfully. \"FAIL\" The event was not sent to AVS successfully."},{"location":"aasb/core/Arbitrator/","title":"Arbitrator","text":""},{"location":"aasb/core/Arbitrator/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/Arbitrator/#onagentstateupdated","title":"OnAgentStateUpdated","text":"<p>Notifies platform of an update to the agent state.</p>"},{"location":"aasb/core/Arbitrator/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"OnAgentStateUpdated\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"name\": {{String}},\n        \"state\": {{AgentState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload","title":"Payload","text":"Property Type Required Description Example assistantId String Yes The unique identifier of agent whose state is updated. name String Yes The name of agent whose state is updated. state AgentState Yes The updated state."},{"location":"aasb/core/Arbitrator/#ondialogterminated","title":"OnDialogTerminated","text":"<p>Notifies platform that the dialog is terminated for the agent.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"OnDialogTerminated\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"dialogId\": {{String}},\n        \"reason\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_1","title":"Payload","text":"Property Type Required Description Example assistantId String Yes The unique identifier of agent whose dialog is terminated. dialogId String Yes The unique identifier of dialog request that is terminated. reason String Yes The reason for terminating the dialog."},{"location":"aasb/core/Arbitrator/#registeragentreply","title":"RegisterAgentReply","text":"<p>Reply for RegisterAgent message.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"RegisterAgent\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_2","title":"Payload","text":"Property Type Required Description Example success Bool Yes True if agent was successfully registered, False otherwise."},{"location":"aasb/core/Arbitrator/#deregisteragentreply","title":"DeregisterAgentReply","text":"<p>Reply for DeregisterAgent message.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"DeregisterAgent\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_3","title":"Payload","text":"Property Type Required Description Example success Bool Yes True if agent was successfully deregistered, False otherwise."},{"location":"aasb/core/Arbitrator/#startdialogreply","title":"StartDialogReply","text":"<p>Reply for StartDialog message.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"StartDialog\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}},\n        \"assistantId\": {{String}},\n        \"dialogId\": {{String}},\n        \"reason\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_4","title":"Payload","text":"Property Type Required Description Example success Bool Yes True if dialog was started, False otherwise. assistantId String Yes A unique identifier of agent for whom the dialog is requested. dialogId String Yes The unique identifier generated for the started dialog, returned if the dialog was started, empty otherwise reason String Yes The reason for the dialog not started, returned if request was denied, empty otherwise. This field is informational and is used only for logging purpose."},{"location":"aasb/core/Arbitrator/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/Arbitrator/#registeragent","title":"RegisterAgent","text":"<p>Register an agent with the Engine.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"RegisterAgent\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"name\": {{String}},\n        \"dialogStateRules\": [{{DialogStateRule}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_5","title":"Payload","text":"Property Type Required Description Example assistantId String Yes A unique identifier of agent to register. name String Yes A name of agent that is registered. dialogStateRules DialogStateRule[] Yes List of dialog state rules for the agent."},{"location":"aasb/core/Arbitrator/#deregisteragent","title":"DeregisterAgent","text":"<p>Deregister an agent with the Engine.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"DeregisterAgent\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_6","title":"Payload","text":"Property Type Required Description Example assistantId String Yes A unique identifier of agent to deregister."},{"location":"aasb/core/Arbitrator/#startdialog","title":"StartDialog","text":"<p>Start a dialog request to become the active agent. A dialog represents the lifecycle of user interaction with the agent.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"StartDialog\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"mode\": {{Mode}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_7","title":"Payload","text":"Property Type Required Description Example assistantId String Yes A unique identifier of agent for whom the dialog is requested. mode Mode Yes The mode of dialog request."},{"location":"aasb/core/Arbitrator/#setdialogstate","title":"SetDialogState","text":"<p>Notifies Engine to set the dialog state for the specified agent.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"SetDialogState\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"dialogId\": {{String}},\n        \"state\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_8","title":"Payload","text":"Property Type Required Description Example assistantId String Yes The unique identifier of agent whose dialog state should be set. dialogId String Yes The unique identifier of dialog whose state should be set. This refers to the same Id that was returned when the dialog was started. state String Yes The new state to set to."},{"location":"aasb/core/Arbitrator/#stopdialog","title":"StopDialog","text":"<p>Notifies Engine to stop the dialog state for the specified agent. Stopping the dialog results in the agent becoming INACTIVE. This triggers the Engine to send the OnAgentStateUpdated message.</p>"},{"location":"aasb/core/Arbitrator/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Arbitrator\",\n            \"action\": \"StopDialog\"\n        }\n    },\n    \"payload\": {\n        \"assistantId\": {{String}},\n        \"dialogId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#payload_9","title":"Payload","text":"Property Type Required Description Example assistantId String Yes The unique identifier of agent whose dialog should be stopped. dialogId String Yes The unique identifier of dialog to stop."},{"location":"aasb/core/Arbitrator/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/core/Arbitrator/#dialogstaterule","title":"DialogStateRule","text":""},{"location":"aasb/core/Arbitrator/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"state\": {{String}},\n    \"wakewordInterruptionAllowed\": {{Bool}}        \n}\n</code></pre>"},{"location":"aasb/core/Arbitrator/#properties","title":"Properties","text":"Property Type Required Description Example state String Yes Name of the dialog state wakewordInterruptionAllowed Bool Yes Whether interruption (barge in) via wakeword allowed for this state"},{"location":"aasb/core/Arbitrator/#enums","title":"Enums","text":""},{"location":"aasb/core/Arbitrator/#mode","title":"Mode","text":""},{"location":"aasb/core/Arbitrator/#values","title":"Values","text":"Value Description \"WAKEWORD\" Dialog request is through wakeword. \"GESTURE\" Dialog request is through gesture (PTT, TTT, etc)."},{"location":"aasb/core/Arbitrator/#agentstate","title":"AgentState","text":""},{"location":"aasb/core/Arbitrator/#values_1","title":"Values","text":"Value Description \"ACTIVE\" Denotes agent is active. \"INACTIVE\" Denotes agent is inactive."},{"location":"aasb/core/AudioInput/","title":"AudioInput","text":""},{"location":"aasb/core/AudioInput/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/AudioInput/#stopaudioinput","title":"StopAudioInput","text":"<p>Notifies the platform implementation to stop writing audio samples to the Engine.</p>"},{"location":"aasb/core/AudioInput/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioInput\",\n            \"action\": \"StopAudioInput\"\n        }\n    },\n    \"payload\": {\n        \"streamId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioInput/#payload","title":"Payload","text":"Property Type Required Description Example streamId String Yes Stream ID that is used to write audio data to. 4f52d5a6-2b36-4723-93d5-4e569be99961"},{"location":"aasb/core/AudioInput/#startaudioinput","title":"StartAudioInput","text":"<p>Notifies the platform implementation to start writing audio samples to the Engine.</p>"},{"location":"aasb/core/AudioInput/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioInput\",\n            \"action\": \"StartAudioInput\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"audioType\": {{AudioInputAudioType}},\n        \"streamId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioInput/#payload_1","title":"Payload","text":"Property Type Required Description Example name String Yes Name of the Engine component that is requesting audio. audioType AudioInputAudioType Yes The type of audio data being requested. streamId String Yes Stream ID that is used to write audio data to."},{"location":"aasb/core/AudioInput/#enums","title":"Enums","text":""},{"location":"aasb/core/AudioInput/#audioinputaudiotype","title":"AudioInputAudioType","text":""},{"location":"aasb/core/AudioInput/#values","title":"Values","text":"Value Description \"VOICE\" Voice audio type. \"COMMUNICATION\" Communication audio type. \"LOOPBACK\" Loopback audio type."},{"location":"aasb/core/AudioOutput/","title":"AudioOutput","text":""},{"location":"aasb/core/AudioOutput/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/AudioOutput/#getnumbytesbuffered","title":"GetNumBytesBuffered","text":"<p>Returns the amount of audio data buffered.</p>"},{"location":"aasb/core/AudioOutput/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetNumBytesBuffered\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#resume","title":"Resume","text":"<p>Notifies the platform implementation to resume an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Resume\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_1","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#play","title":"Play","text":"<p>Notifies the platform implementation to play an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Play\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_2","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being played."},{"location":"aasb/core/AudioOutput/#setposition","title":"SetPosition","text":"<p>Notifies the platform implementation to set the playback position of the current audio source in the platform media player.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"SetPosition\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}},\n        \"position\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_3","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. position Int Yes The playback position in milliseconds to set in the platform media player."},{"location":"aasb/core/AudioOutput/#prepare","title":"Prepare","text":"<p>Notifies the platform implementation to prepare an audio URL for playback.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Prepare\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"audioType\": {{AudioOutputAudioType}},\n        \"token\": {{String}},\n        \"source\": \"URL\",\n        \"url\": {{String}},\n        \"repeating\": {{Bool}},\n        \"playbackContext\": {{PlaybackContext}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_4","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio source. source String Yes Stream source description. url String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. playbackContext PlaybackContext Yes The context related to playback of an audio item."},{"location":"aasb/core/AudioOutput/#getposition","title":"GetPosition","text":"<p>Returns the current playback position of the platform media player. If the audio source is not playing, the most recent position played should be returned.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetPosition\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_5","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#pause","title":"Pause","text":"<p>Notifies the platform implementation to pause an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Pause\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_6","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being paused."},{"location":"aasb/core/AudioOutput/#getduration","title":"GetDuration","text":"<p>Request the duration of the current audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetDuration\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_7","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#stop","title":"Stop","text":"<p>Notifies the platform implementation to stop an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Stop\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_8","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#prepare_1","title":"Prepare","text":"<p>Notifies the platform implementation to prepare an audio stream for playback.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"Prepare\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"audioType\": {{AudioOutputAudioType}},\n        \"token\": {{String}},\n        \"source\": \"STREAM\",\n        \"streamId\": {{String}},\n        \"repeating\": {{Bool}},\n        \"encoding\": {{AudioStreamEncoding}},\n        \"properties\": {{dict}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_9","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio stream. source String Yes Stream source description. streamId String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream."},{"location":"aasb/core/AudioOutput/#mutedstatechanged","title":"MutedStateChanged","text":"<p>Notifies the platform implementation that the muted state has changed for an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"MutedStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"state\": {{MutedState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_10","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. state MutedState Yes The muted state to apply to the audio source."},{"location":"aasb/core/AudioOutput/#volumechanged","title":"VolumeChanged","text":"<p>Notifies the platform implementation that the volume has changed for an audio source.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"VolumeChanged\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"volume\": {{Float}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_11","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. volume Float Yes The volume to set on the audio source. The volume is in the range [0,1]."},{"location":"aasb/core/AudioOutput/#mayduck","title":"MayDuck","text":"<p>Notifies the platform implementation only if prepared media may duck the volume.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"MayDuck\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_12","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#startducking","title":"StartDucking","text":"<p>Notifies the platform implementation to move the playback in background. If platform implementation supports audio ducking, reduce the media player volume according to platform guidelines.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"StartDucking\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_13","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#stopducking","title":"StopDucking","text":"<p>Notifies the platform implementation to move the playback in foreground. If platform implementation supports audio ducking, restore the media player volume to original value.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_14","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"StopDucking\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_14","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source."},{"location":"aasb/core/AudioOutput/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/AudioOutput/#mediaerror","title":"MediaError","text":"<p>Notifies the Engine of an error during audio playback.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_15","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"MediaError\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}},\n        \"error\": {{MediaError}},\n        \"description\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_15","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. error MediaError Yes The error encountered by the platform media player during playback. description String No A description of the error."},{"location":"aasb/core/AudioOutput/#mediastatechanged","title":"MediaStateChanged","text":"<p>Notifies the Engine of an audio playback state change in the platform implementation. Must be called when the platform media player transitions between stopped and playing states.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_16","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"MediaStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}},\n        \"state\": {{MediaState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_16","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. state MediaState Yes The new playback state of the platform media player."},{"location":"aasb/core/AudioOutput/#audiofocusevent","title":"AudioFocusEvent","text":"<p>Report the engine about the Audio Focus action. Request engine to perform the action mentioned in the parameter.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_17","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"AudioFocusEvent\"\n        }\n    },\n    \"payload\": {\n        \"channel\": {{String}},\n        \"token\": {{String}},\n        \"focusAction\": {{FocusAction}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_17","title":"Payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. focusAction FocusAction Yes Report the engine what focus action client has taken due to the external audio focus event."},{"location":"aasb/core/AudioOutput/#getnumbytesbufferedreply","title":"GetNumBytesBufferedReply","text":"<p>Reply for GetNumBytesBuffered message.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_18","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetNumBytesBuffered\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"bufferedBytes\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_18","title":"Payload","text":"Property Type Required Description Example bufferedBytes Int Yes The number of bytes of the audio data buffered, or 0 if it's unknown."},{"location":"aasb/core/AudioOutput/#getpositionreply","title":"GetPositionReply","text":"<p>Reply for GetPosition message.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_19","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetPosition\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"position\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_19","title":"Payload","text":"Property Type Required Description Example position Int Yes The platform media player's playback position in milliseconds."},{"location":"aasb/core/AudioOutput/#getdurationreply","title":"GetDurationReply","text":"<p>Reply for GetDuration message.</p>"},{"location":"aasb/core/AudioOutput/#json-structure_20","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"AudioOutput\",\n            \"action\": \"GetDuration\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"duration\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#payload_20","title":"Payload","text":"Property Type Required Description Example duration Int Yes The duration of the current audio source. If the duration is unknown, then -1 should be returned."},{"location":"aasb/core/AudioOutput/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/core/AudioOutput/#audiostreamproperty","title":"AudioStreamProperty","text":""},{"location":"aasb/core/AudioOutput/#json-structure_21","title":"JSON Structure","text":"<pre><code>{\n    \"name\": {{String}},\n    \"value\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#properties","title":"Properties","text":"Property Type Required Description Example name String Yes Stream property name. value String Yes Stream property value."},{"location":"aasb/core/AudioOutput/#playbackcontext","title":"PlaybackContext","text":""},{"location":"aasb/core/AudioOutput/#json-structure_22","title":"JSON Structure","text":"<pre><code>{\n    \"keyConfig\": {{dict}},\n    \"manifestConfig\": {{dict}},\n    \"audioSegmentConfig\": {{dict}},\n    \"allConfig\": {{dict}}        \n}\n</code></pre>"},{"location":"aasb/core/AudioOutput/#properties_1","title":"Properties","text":"Property Type Required Description Example keyConfig dict Yes Headers to use when fetching encryption keys. The map contains up to 20 pairs of header name and value. Header names may be \"Authorization\" or strings prefixed with \"x-\", containing up to 256 characters. Values may contain up to 4096 characters. manifestConfig dict Yes Headers to use when fetching manifests. The map contains up to 20 pairs of header name and value. Header names may be \"Authorization\" or strings prefixed with \"x-\", containing up to 256 characters. Values may contain up to 4096 characters. audioSegmentConfig dict Yes Headers to use when fetching audio chunks described in the manifest. The map contains up to 20 pairs of header name and value. Header names may be \"Authorization\" or strings prefixed with \"x-\", containing up to 256 characters. Values may contain up to 4096 characters. allConfig dict Yes A catch-all list of headers to use in all URL requests. The map contains up to 20 pairs of header name and value. The headers in keyConfig, manifestConfig, and audioSegmentConfig take priority over the \"all\" headers, and hence any name-value pairs in the higher priority lists must overwrite any pair with the same name from allConfig. Header names may be \"Authorization\" or strings prefixed with \"x-\", containing up to 256 characters. Values may contain up to 4096 characters."},{"location":"aasb/core/AudioOutput/#enums","title":"Enums","text":""},{"location":"aasb/core/AudioOutput/#mediastate","title":"MediaState","text":""},{"location":"aasb/core/AudioOutput/#values","title":"Values","text":"Value Description \"STOPPED\" The audio source is not currently playing. It may have paused, stopped, or finished. \"PLAYING\" The audio source is currently playing. \"BUFFERING\" The audio source is currently buffering data."},{"location":"aasb/core/AudioOutput/#mediaerror_1","title":"MediaError","text":""},{"location":"aasb/core/AudioOutput/#values_1","title":"Values","text":"Value Description \"MEDIA_ERROR_UNKNOWN\" An unknown error occurred. \"MEDIA_ERROR_INVALID_REQUEST\" The server recognized the request as malformed (e.g. bad request, unauthorized, forbidden, not found, etc). \"MEDIA_ERROR_SERVICE_UNAVAILABLE\" The client was unable to reach the service. \"MEDIA_ERROR_INTERNAL_SERVER_ERROR\" The server accepted the request but was unable to process it as expected. \"MEDIA_ERROR_INTERNAL_DEVICE_ERROR\" There was an internal error on the client."},{"location":"aasb/core/AudioOutput/#audiooutputaudiotype","title":"AudioOutputAudioType","text":""},{"location":"aasb/core/AudioOutput/#values_2","title":"Values","text":"Value Description \"TTS\" Text-to-Speech audio type. \"MUSIC\" Music audio type. \"NOTIFICATION\" Notification audio type. \"ALARM\" Alarm audio type. \"EARCON\" Earcon audio type. \"COMMUNICATION\" Communication audio type. \"RINGTONE\" Ringtone audio type."},{"location":"aasb/core/AudioOutput/#audiostreamencoding","title":"AudioStreamEncoding","text":""},{"location":"aasb/core/AudioOutput/#values_3","title":"Values","text":"Value Description \"UNKNOWN\" Unknown encoding type. \"LPCM\" LPCM encoding type. \"MP3\" MP3 encoding type. \"OPUS\" Opus encoding type."},{"location":"aasb/core/AudioOutput/#mutedstate","title":"MutedState","text":""},{"location":"aasb/core/AudioOutput/#values_4","title":"Values","text":"Value Description \"MUTED\" Muted audio state. \"UNMUTED\" Unmuted audio state."},{"location":"aasb/core/AudioOutput/#audiooutputsourcetype","title":"AudioOutputSourceType","text":""},{"location":"aasb/core/AudioOutput/#values_5","title":"Values","text":"Value Description \"URI\" URI source type. \"STREAM\" Stream audio type."},{"location":"aasb/core/AudioOutput/#focusaction","title":"FocusAction","text":""},{"location":"aasb/core/AudioOutput/#values_6","title":"Values","text":"Value Description \"REPORT_DUCKING_STARTED\" This action informs Alexa engine that ducking is initiated by platform interface. Highly recommended to provide information so that engine would not override the action. \"REPORT_DUCKING_STOPPED\" This action informs Alexa engine that ducking is stopped by platform interface. Highly recommended to provide information so that engine can duck if required."},{"location":"aasb/core/Authorization/","title":"Authorization","text":""},{"location":"aasb/core/Authorization/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/Authorization/#getauthorizationdata","title":"GetAuthorizationData","text":"<p>Get the authorization data from the platform implementation.</p>"},{"location":"aasb/core/Authorization/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"GetAuthorizationData\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"key\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data."},{"location":"aasb/core/Authorization/#authorizationerror","title":"AuthorizationError","text":"<p>Notifies the platform implementation of an authorization error.</p>"},{"location":"aasb/core/Authorization/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"AuthorizationError\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"error\": {{String}},\n        \"message\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_1","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. error String Yes The authorization error that occurred. message String Yes The message describing the authorization error."},{"location":"aasb/core/Authorization/#setauthorizationdata","title":"SetAuthorizationData","text":"<p>Notifies the platform implementation to store authorization data.</p>"},{"location":"aasb/core/Authorization/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"SetAuthorizationData\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"key\": {{String}},\n        \"data\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_2","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. data String Yes The value of the data."},{"location":"aasb/core/Authorization/#eventreceived","title":"EventReceived","text":"<p>Notifies the platform implementation of a received authorization event.</p>"},{"location":"aasb/core/Authorization/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"EventReceived\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"event\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_3","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the received event."},{"location":"aasb/core/Authorization/#authorizationstatechanged","title":"AuthorizationStateChanged","text":"<p>Notifies the platform implementation that the authorization state changed.</p>"},{"location":"aasb/core/Authorization/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"AuthorizationStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"state\": {{AuthorizationState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_4","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. state AuthorizationState Yes The new authorization state."},{"location":"aasb/core/Authorization/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/Authorization/#sendevent","title":"SendEvent","text":"<p>Notifies the Engine of an authorization event.</p>"},{"location":"aasb/core/Authorization/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"SendEvent\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"event\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_5","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the payload of the event."},{"location":"aasb/core/Authorization/#cancelauthorization","title":"CancelAuthorization","text":"<p>Notifies the Engine to cancel the authorization process.</p>"},{"location":"aasb/core/Authorization/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"CancelAuthorization\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_6","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization."},{"location":"aasb/core/Authorization/#logout","title":"Logout","text":"<p>Notifies the Engine that device has been logged out.</p>"},{"location":"aasb/core/Authorization/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"Logout\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_7","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization."},{"location":"aasb/core/Authorization/#startauthorization","title":"StartAuthorization","text":"<p>Notifies the Engine to start the authorization process.</p>"},{"location":"aasb/core/Authorization/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"StartAuthorization\"\n        }\n    },\n    \"payload\": {\n        \"service\": {{String}},\n        \"data\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_8","title":"Payload","text":"Property Type Required Description Example service String Yes The service used for authorization. data String Yes The value of the data."},{"location":"aasb/core/Authorization/#getauthorizationdatareply","title":"GetAuthorizationDataReply","text":"<p>Reply for GetAuthorizationData message.</p>"},{"location":"aasb/core/Authorization/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Authorization\",\n            \"action\": \"GetAuthorizationData\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"data\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/Authorization/#payload_9","title":"Payload","text":"Property Type Required Description Example data String Yes The data associated with the key if available, otherwise an empty string."},{"location":"aasb/core/Authorization/#enums","title":"Enums","text":""},{"location":"aasb/core/Authorization/#authorizationstate","title":"AuthorizationState","text":""},{"location":"aasb/core/Authorization/#values","title":"Values","text":"Value Description \"UNAUTHORIZED\" Device is unauthorized. \"AUTHORIZING\" Device authorization is in progress. \"AUTHORIZED\" Device is authorized."},{"location":"aasb/core/DeviceUsage/","title":"DeviceUsage","text":""},{"location":"aasb/core/DeviceUsage/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/DeviceUsage/#reportnetworkdatausage","title":"ReportNetworkDataUsage","text":"<p>Report network usage data to the Engine.</p>"},{"location":"aasb/core/DeviceUsage/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"DeviceUsage\",\n            \"action\": \"ReportNetworkDataUsage\"\n        }\n    },\n    \"payload\": {\n        \"usage\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/DeviceUsage/#payload","title":"Payload","text":"Property Type Required Description Example usage String Yes A JSON String representation of the network usage data of the application. See the Core module documentation for complete details of the schema."},{"location":"aasb/core/LocationProvider/","title":"LocationProvider","text":""},{"location":"aasb/core/LocationProvider/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/LocationProvider/#getcountry","title":"GetCountry","text":"<p>Requests the ISO country code for the current geolocation of the device.</p>"},{"location":"aasb/core/LocationProvider/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocationProvider\",\n            \"action\": \"GetCountry\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#getlocation","title":"GetLocation","text":"<p>Requests the current geolocation of the device.</p>"},{"location":"aasb/core/LocationProvider/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocationProvider\",\n            \"action\": \"GetLocation\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/LocationProvider/#locationserviceaccesschanged","title":"LocationServiceAccessChanged","text":"<p>Notifies the Engine of a change in location service access.</p>"},{"location":"aasb/core/LocationProvider/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocationProvider\",\n            \"action\": \"LocationServiceAccessChanged\"\n        }\n    },\n    \"payload\": {\n        \"access\": {{LocationServiceAccess}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#payload","title":"Payload","text":"Property Type Required Description Example access LocationServiceAccess Yes Describes the access to the geolocation service on the device."},{"location":"aasb/core/LocationProvider/#getcountryreply","title":"GetCountryReply","text":"<p>Reply for GetCountry message.</p>"},{"location":"aasb/core/LocationProvider/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocationProvider\",\n            \"action\": \"GetCountry\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"country\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#payload_1","title":"Payload","text":"Property Type Required Description Example country String Yes The current country."},{"location":"aasb/core/LocationProvider/#getlocationreply","title":"GetLocationReply","text":"<p>Reply for GetLocation message.</p>"},{"location":"aasb/core/LocationProvider/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"LocationProvider\",\n            \"action\": \"GetLocation\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"location\": {{Location}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#payload_2","title":"Payload","text":"Property Type Required Description Example location Location Yes The current location."},{"location":"aasb/core/LocationProvider/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/core/LocationProvider/#location","title":"Location","text":""},{"location":"aasb/core/LocationProvider/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"latitude\": {{Float}},\n    \"longitude\": {{Float}},\n    \"altitude\": {{Float}},\n    \"accuracy\": {{Float}}        \n}\n</code></pre>"},{"location":"aasb/core/LocationProvider/#properties","title":"Properties","text":"Property Type Required Description Example latitude Float Yes Location latitude. Use -1 if the location is not available. longitude Float Yes Location longitude. Use -1 if the location is not available. altitude Float No (default: <code>-1</code>) A location altitude in meters. accuracy Float No (default: <code>-1</code>) A location accuracy in meters."},{"location":"aasb/core/LocationProvider/#enums","title":"Enums","text":""},{"location":"aasb/core/LocationProvider/#locationserviceaccess","title":"LocationServiceAccess","text":""},{"location":"aasb/core/LocationProvider/#values","title":"Values","text":"Value Description \"DISABLED\" The location service on the device is disabled (e.g., GPS is turned off). \"ENABLED\" The location service on the device is enabled (e.g., GPS is turned on)."},{"location":"aasb/core/NetworkInfoProvider/","title":"NetworkInfoProvider","text":""},{"location":"aasb/core/NetworkInfoProvider/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/NetworkInfoProvider/#getwifisignalstrength","title":"GetWifiSignalStrength","text":"<p>Requests the signal strength (RSSI) of the WiFi connection on the platform.</p>"},{"location":"aasb/core/NetworkInfoProvider/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"NetworkInfoProvider\",\n            \"action\": \"GetWifiSignalStrength\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/core/NetworkInfoProvider/#getnetworkstatus","title":"GetNetworkStatus","text":"<p>Requests the network connection status on the platform.</p>"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"NetworkInfoProvider\",\n            \"action\": \"GetNetworkStatus\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/core/NetworkInfoProvider/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/NetworkInfoProvider/#networkstatuschanged","title":"NetworkStatusChanged","text":"<p>Notifies the Engine of a network status change on the platform.</p>"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"NetworkInfoProvider\",\n            \"action\": \"NetworkStatusChanged\"\n        }\n    },\n    \"payload\": {\n        \"status\": {{NetworkStatus}},\n        \"wifiSignalStrength\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/NetworkInfoProvider/#payload","title":"Payload","text":"Property Type Required Description Example status NetworkStatus Yes The connection status CONNECTED wifiSignalStrength Int Yes The RSSI of the WiFi connection."},{"location":"aasb/core/NetworkInfoProvider/#getwifisignalstrengthreply","title":"GetWifiSignalStrengthReply","text":"<p>Reply for GetWifiSignalStrength message.</p>"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"NetworkInfoProvider\",\n            \"action\": \"GetWifiSignalStrength\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"wifiSignalStrength\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/NetworkInfoProvider/#payload_1","title":"Payload","text":"Property Type Required Description Example wifiSignalStrength Int Yes The RSSI of the WiFi connection."},{"location":"aasb/core/NetworkInfoProvider/#getnetworkstatusreply","title":"GetNetworkStatusReply","text":"<p>Reply for GetNetworkStatus message.</p>"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"NetworkInfoProvider\",\n            \"action\": \"GetNetworkStatus\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"status\": {{NetworkStatus}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/NetworkInfoProvider/#payload_2","title":"Payload","text":"Property Type Required Description Example status NetworkStatus Yes The network connection status"},{"location":"aasb/core/NetworkInfoProvider/#enums","title":"Enums","text":""},{"location":"aasb/core/NetworkInfoProvider/#networkstatus","title":"NetworkStatus","text":""},{"location":"aasb/core/NetworkInfoProvider/#values","title":"Values","text":"Value Description \"UNKNOWN\" The network status is unknown \"DISCONNECTED\" The network is disconnected. \"DISCONNECTING\" The network is disconnecting \"CONNECTED\" The network is connected \"CONNECTING\" The network is connecting"},{"location":"aasb/core/PropertyManager/","title":"PropertyManager","text":""},{"location":"aasb/core/PropertyManager/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/PropertyManager/#propertychanged","title":"PropertyChanged","text":"<p>Notifies the platform implementation about a change in a property value in the Engine that is  not initiated by the platform implementation.</p>"},{"location":"aasb/core/PropertyManager/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PropertyManager\",\n            \"action\": \"PropertyChanged\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"newValue\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/PropertyManager/#payload","title":"Payload","text":"Property Type Required Description Example name String Yes Name of the property. newValue String Yes The new value of the property."},{"location":"aasb/core/PropertyManager/#propertystatechanged","title":"PropertyStateChanged","text":"<p>Notifies the platform implementation of the status of a property change after a call to  setProperty().</p>"},{"location":"aasb/core/PropertyManager/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PropertyManager\",\n            \"action\": \"PropertyStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"value\": {{String}},\n        \"state\": {{PropertyState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/PropertyManager/#payload_1","title":"Payload","text":"Property Type Required Description Example name String Yes Name of the property. value String Yes The value of the property. state PropertyState Yes The property state."},{"location":"aasb/core/PropertyManager/#getpropertyreply","title":"GetPropertyReply","text":"<p>Reply for GetProperty message.</p>"},{"location":"aasb/core/PropertyManager/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PropertyManager\",\n            \"action\": \"GetProperty\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"value\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/PropertyManager/#payload_2","title":"Payload","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value."},{"location":"aasb/core/PropertyManager/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/PropertyManager/#getproperty","title":"GetProperty","text":"<p>Retrieves the property setting from the Engine.</p>"},{"location":"aasb/core/PropertyManager/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PropertyManager\",\n            \"action\": \"GetProperty\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/PropertyManager/#payload_3","title":"Payload","text":"Property Type Required Description Example name String Yes The property name."},{"location":"aasb/core/PropertyManager/#setproperty","title":"SetProperty","text":"<p>Sets the property setting in the Engine.</p>"},{"location":"aasb/core/PropertyManager/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PropertyManager\",\n            \"action\": \"SetProperty\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"value\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/PropertyManager/#payload_4","title":"Payload","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value."},{"location":"aasb/core/PropertyManager/#enums","title":"Enums","text":""},{"location":"aasb/core/PropertyManager/#propertystate","title":"PropertyState","text":""},{"location":"aasb/core/PropertyManager/#values","title":"Values","text":"Value Description \"SUCCEEDED\" The property change was successful. \"FAILED\" The property change failed."},{"location":"aasb/core/WakewordManager/","title":"WakewordManager","text":""},{"location":"aasb/core/WakewordManager/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/core/WakewordManager/#onwakeworddetected","title":"OnWakewordDetected","text":"<p>Notifies the platform 3P wakeword detected</p>"},{"location":"aasb/core/WakewordManager/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"WakewordManager\",\n            \"action\": \"OnWakewordDetected\"\n        }\n    },\n    \"payload\": {\n        \"wakeword\": {{String}},\n        \"beginIndex\": {{Int}},\n        \"endIndex\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/WakewordManager/#payload","title":"Payload","text":"Property Type Required Description Example wakeword String Yes Wakeword detected beginIndex Int Yes Begin index of wakeword detected endIndex Int Yes End index of wakeword detected"},{"location":"aasb/core/WakewordManager/#setwakewordstatusreply","title":"SetWakewordStatusReply","text":"<p>Reply for SetWakewordStatus message.</p>"},{"location":"aasb/core/WakewordManager/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"WakewordManager\",\n            \"action\": \"SetWakewordStatus\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/WakewordManager/#payload_1","title":"Payload","text":"Property Type Required Description Example success Bool Yes True if SetWakewordStatus was successful, False otherwise."},{"location":"aasb/core/WakewordManager/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/core/WakewordManager/#setwakewordstatus","title":"SetWakewordStatus","text":"<p>Enables/disables wakeword detection</p>"},{"location":"aasb/core/WakewordManager/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"WakewordManager\",\n            \"action\": \"SetWakewordStatus\"\n        }\n    },\n    \"payload\": {\n        \"name\": {{String}},\n        \"value\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/core/WakewordManager/#payload_2","title":"Payload","text":"Property Type Required Description Example name String Yes name of the wakeword to be enabled/disabled value Bool Yes vaues of enable/disable wakeword"},{"location":"aasb/custom-domain/CustomDomain/","title":"CustomDomain","text":""},{"location":"aasb/custom-domain/CustomDomain/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/custom-domain/CustomDomain/#handledirective","title":"HandleDirective","text":"<p>Notifies the platform on a new custom directive.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"HandleDirective\"\n        }\n    },\n    \"payload\": {\n        \"directiveNamespace\": {{String}},\n        \"directiveName\": {{String}},\n        \"directivePayload\": {{String}},\n        \"correlationToken\": {{String}},\n        \"messageId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload","title":"Payload","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive to be handled. directiveName String Yes The name of the custom directive. directivePayload String Yes An opaque JSON payload sent to the device. correlationToken String Yes An opaque token that must be included in any events responding to this directive. messageId String Yes A unique ID used to identify a specific directive. Used to report directive handling result."},{"location":"aasb/custom-domain/CustomDomain/#canceldirective","title":"CancelDirective","text":"<p>Notifies the platform to cancel the specific directive with given messageId.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"CancelDirective\"\n        }\n    },\n    \"payload\": {\n        \"directiveNamespace\": {{String}},\n        \"directiveName\": {{String}},\n        \"correlationToken\": {{String}},\n        \"messageId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload_1","title":"Payload","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the cancelled directive. directiveName String Yes The name of the cancelled directive. correlationToken String Yes The correlationToken of the cancelled directive. messageId String Yes A unique ID used to identify a specific directive."},{"location":"aasb/custom-domain/CustomDomain/#getcontext","title":"GetContext","text":"<p>Called to query the current custom states under given namespace from the device.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"GetContext\"\n        }\n    },\n    \"payload\": {\n        \"contextNamespace\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload_2","title":"Payload","text":"Property Type Required Description Example contextNamespace String Yes The namespace of the queried context."},{"location":"aasb/custom-domain/CustomDomain/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/custom-domain/CustomDomain/#reportdirectivehandlingresult","title":"ReportDirectiveHandlingResult","text":"<p>Notifies the engine about the result of a directive handling.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"ReportDirectiveHandlingResult\"\n        }\n    },\n    \"payload\": {\n        \"directiveNamespace\": {{String}},\n        \"messageId\": {{String}},\n        \"result\": {{ResultType}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload_3","title":"Payload","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive. messageId String Yes The messageId that uniquely identifies which directive this report is for. result ResultType Yes The result of the handling."},{"location":"aasb/custom-domain/CustomDomain/#sendevent","title":"SendEvent","text":"<p>Notifes the engine to send a custom event.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"SendEvent\"\n        }\n    },\n    \"payload\": {\n        \"eventNamespace\": {{String}},\n        \"eventName\": {{String}},\n        \"eventPayload\": {{String}},\n        \"requiresContext\": {{Bool}},\n        \"correlationToken\": {{String}},\n        \"customContext\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload_4","title":"Payload","text":"Property Type Required Description Example eventNamespace String Yes The namespace of the custom event to be sent. eventName String Yes The name of the event. eventPayload String Yes An opaque JSON payload in the format of escaped JSON string sent to the cloud with the event. requiresContext Bool Yes A boolean indicating if this event must be sent with context. correlationToken String No The token correlating this event to a directive. Required only if this event is sent as a response to a directive. customContext String No The context corresponding to eventNamespace in a String representation of a valid JSON object (escaped). It's optional but recommended to provide the context with the event to reduce the amount of AASB message transactions. You can find the defined structure of context JSON in Custom Domain Platform Interface."},{"location":"aasb/custom-domain/CustomDomain/#getcontextreply","title":"GetContextReply","text":"<p>Reply for GetContext message.</p>"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"CustomDomain\",\n            \"action\": \"GetContext\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"customContext\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/custom-domain/CustomDomain/#payload_5","title":"Payload","text":"Property Type Required Description Example customContext String Yes The context for the queried namespace in a String representation of a valid JSON object (escaped). You can find the defined structure of context JSON in Custom Domain Platform Interface."},{"location":"aasb/custom-domain/CustomDomain/#enums","title":"Enums","text":""},{"location":"aasb/custom-domain/CustomDomain/#resulttype","title":"ResultType","text":""},{"location":"aasb/custom-domain/CustomDomain/#values","title":"Values","text":"Value Description \"UNEXPECTED_INFORMATION_RECEIVED\" The directive sent to your client was malformed or the payload does not conform to the directive specification. \"UNSUPPORTED_OPERATION\" The operation specified by the namespace/name in the directive's header are not supported by the client. \"INTERNAL_ERROR\" An error occurred while the device was handling the directive and the error does not fall into the specified categories. \"SUCCESS\" The directive handling is successful."},{"location":"aasb/messaging/Messaging/","title":"Messaging","text":""},{"location":"aasb/messaging/Messaging/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/messaging/Messaging/#sendmessage","title":"SendMessage","text":"<p>Send SMS message.</p>"},{"location":"aasb/messaging/Messaging/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"SendMessage\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"message\": {{String}},\n        \"recipients\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request. message String Yes Body of the SMS text message to be sent. recipients String Yes String in JSON format containing the recipient of the SMS message."},{"location":"aasb/messaging/Messaging/#updatemessagesstatus","title":"UpdateMessagesStatus","text":"<p>Update status of SMS messages.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"UpdateMessagesStatus\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"conversationId\": {{String}},\n        \"status\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_1","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request. conversationId String Yes The id of the conversation whose messages need to be updated. status String Yes String in JSON format representing the message ids and status to be updated."},{"location":"aasb/messaging/Messaging/#uploadconversations","title":"UploadConversations","text":"<p>Upload SMS unread messages message.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"UploadConversations\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_2","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request."},{"location":"aasb/messaging/Messaging/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/messaging/Messaging/#updatemessagesstatusfailed","title":"UpdateMessagesStatusFailed","text":"<p>Notifies the Engine the message status update failed.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"UpdateMessagesStatusFailed\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"code\": {{ErrorCode}},\n        \"message\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_3","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error."},{"location":"aasb/messaging/Messaging/#updatemessagingendpointstate","title":"UpdateMessagingEndpointState","text":"<p>Notifies the Engine of updates to the messaging endpoint state.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"UpdateMessagingEndpointState\"\n        }\n    },\n    \"payload\": {\n        \"connectionState\": {{ConnectionState}},\n        \"sendPermission\": {{PermissionState}},\n        \"readPermission\": {{PermissionState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_4","title":"Payload","text":"Property Type Required Description Example connectionState ConnectionState Yes The value for the connection state. sendPermission PermissionState Yes The value for the send permission. readPermission PermissionState Yes The value for the read permission."},{"location":"aasb/messaging/Messaging/#sendmessagesucceeded","title":"SendMessageSucceeded","text":"<p>Notifies the Engine that message send was successful.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"SendMessageSucceeded\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_5","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request."},{"location":"aasb/messaging/Messaging/#sendmessagefailed","title":"SendMessageFailed","text":"<p>Notifies the Engine the message send failed.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"SendMessageFailed\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"code\": {{ErrorCode}},\n        \"message\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_6","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error."},{"location":"aasb/messaging/Messaging/#conversationsreport","title":"ConversationsReport","text":"<p>Notifies the Engine to upload conversations report to the cloud.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"ConversationsReport\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}},\n        \"conversations\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_7","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request. conversations String Yes String in JSON format representing all conversations with unread SMS messages."},{"location":"aasb/messaging/Messaging/#updatemessagesstatussucceeded","title":"UpdateMessagesStatusSucceeded","text":"<p>Notifies the Engine that message status was successful.</p>"},{"location":"aasb/messaging/Messaging/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Messaging\",\n            \"action\": \"UpdateMessagesStatusSucceeded\"\n        }\n    },\n    \"payload\": {\n        \"token\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/messaging/Messaging/#payload_8","title":"Payload","text":"Property Type Required Description Example token String Yes Token id for send message request."},{"location":"aasb/messaging/Messaging/#enums","title":"Enums","text":""},{"location":"aasb/messaging/Messaging/#connectionstate","title":"ConnectionState","text":""},{"location":"aasb/messaging/Messaging/#values","title":"Values","text":"Value Description \"DISCONNECTED\" Messaging device is disconnected. \"CONNECTED\" Messaging device is connected."},{"location":"aasb/messaging/Messaging/#permissionstate","title":"PermissionState","text":""},{"location":"aasb/messaging/Messaging/#values_1","title":"Values","text":"Value Description \"OFF\" Permission is not granted. \"ON\" Permission is granted."},{"location":"aasb/messaging/Messaging/#errorcode","title":"ErrorCode","text":""},{"location":"aasb/messaging/Messaging/#values_2","title":"Values","text":"Value Description \"GENERIC_FAILURE\" Generic error handling SMS request. \"NO_CONNECTIVITY\" Messaging device is not connected. \"NO_PERMISSION\" Permission denied."},{"location":"aasb/mobile-bridge/MobileBridge/","title":"MobileBridge","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#protectsocket","title":"ProtectSocket","text":"<p>Protect a socket from VPN connections.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"ProtectSocket\"\n        }\n    },\n    \"payload\": {\n        \"socket\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload","title":"Payload","text":"Property Type Required Description Example socket Int Yes The socket to protect."},{"location":"aasb/mobile-bridge/MobileBridge/#onactivetransportchange","title":"OnActiveTransportChange","text":"<p>Notify transport change.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"OnActiveTransportChange\"\n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}},\n        \"transportState\": {{TransportState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_1","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport. transportState TransportState Yes The transport state"},{"location":"aasb/mobile-bridge/MobileBridge/#ondevicehandshaked","title":"OnDeviceHandshaked","text":"<p>Notify a device has completed handshaking.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"OnDeviceHandshaked\"\n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}},\n        \"deviceToken\": {{String}},\n        \"friendlyName\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_2","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport. deviceToken String Yes An unique token to identify the device. friendlyName String Yes Device's friendly name."},{"location":"aasb/mobile-bridge/MobileBridge/#oninfo","title":"OnInfo","text":"<p>Notify an info sent from a connected device.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"OnInfo\"\n        }\n    },\n    \"payload\": {\n        \"deviceToken\": {{String}},\n        \"infoId\": {{Int}},\n        \"info\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_3","title":"Payload","text":"Property Type Required Description Example deviceToken String Yes An unique token to identify the device. infoId Int Yes info String Yes The info string."},{"location":"aasb/mobile-bridge/MobileBridge/#gettransports","title":"GetTransports","text":"<p>Get the list of transports.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"GetTransports\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#connect","title":"Connect","text":"<p>Connect to the specified transport.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"Connect\"\n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}},\n        \"inputStreamId\": {{String}},\n        \"outputStreamId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_4","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport. inputStreamId String Yes Stream ID of incoming transport data. outputStreamId String Yes Stream ID of outgoing transport data."},{"location":"aasb/mobile-bridge/MobileBridge/#disconnect","title":"Disconnect","text":"<p>Disconnect with specified transport.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"Disconnect\"\n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_5","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport."},{"location":"aasb/mobile-bridge/MobileBridge/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#startmobilebridge","title":"StartMobileBridge","text":"<p>Start mobile bridge.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"StartMobileBridge\"\n        }\n    },\n    \"payload\": {\n        \"tunFd\": {{Int}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_6","title":"Payload","text":"Property Type Required Description Example tunFd Int Yes The file descriptor for the TUN interface."},{"location":"aasb/mobile-bridge/MobileBridge/#stopmobilebridge","title":"StopMobileBridge","text":"<p>Stop mobile bridge.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"StopMobileBridge\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#authorizedevice","title":"AuthorizeDevice","text":"<p>Notify a device has completed handshaking.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"AuthorizeDevice\"\n        }\n    },\n    \"payload\": {\n        \"deviceToken\": {{String}},\n        \"authorized\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_7","title":"Payload","text":"Property Type Required Description Example deviceToken String Yes An unique token to identify the device. authorized Bool Yes Whether the device is authorized."},{"location":"aasb/mobile-bridge/MobileBridge/#sendinfo","title":"SendInfo","text":"<p>Send an info to the specified device.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"SendInfo\"\n        }\n    },\n    \"payload\": {\n        \"deviceToken\": {{String}},\n        \"infoId\": {{Int}},\n        \"info\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_8","title":"Payload","text":"Property Type Required Description Example deviceToken String Yes An unique token to identify the device. infoId Int Yes info String Yes The info string."},{"location":"aasb/mobile-bridge/MobileBridge/#protectsocketreply","title":"ProtectSocketReply","text":"<p>Reply for ProtectSocket message.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"ProtectSocket\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_9","title":"Payload","text":"Property Type Required Description Example success Bool Yes Success to protect the socket."},{"location":"aasb/mobile-bridge/MobileBridge/#gettransportsreply","title":"GetTransportsReply","text":"<p>Reply for GetTransports message.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"GetTransports\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"transports\": [{{Transport}}]        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_10","title":"Payload","text":"Property Type Required Description Example transports Transport[] Yes The list of transports."},{"location":"aasb/mobile-bridge/MobileBridge/#connectreply","title":"ConnectReply","text":"<p>Reply for Connect message.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"Connect\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}},\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_11","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport. success Bool Yes Success of connection attempt."},{"location":"aasb/mobile-bridge/MobileBridge/#disconnectreply","title":"DisconnectReply","text":"<p>Reply for Disconnect message.</p>"},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_14","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"MobileBridge\",\n            \"action\": \"Disconnect\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"transportId\": {{String}},\n        \"success\": {{Bool}}        \n    }\n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#payload_12","title":"Payload","text":"Property Type Required Description Example transportId String Yes The string to identify the transport. success Bool Yes Success of disconnection attempt."},{"location":"aasb/mobile-bridge/MobileBridge/#type-definitions","title":"Type Definitions","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#app","title":"App","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_15","title":"JSON Structure","text":"<pre><code>{\n    \"appId\": {{String}}        \n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#properties","title":"Properties","text":"Property Type Required Description Example appId String Yes The unique identifier of the app."},{"location":"aasb/mobile-bridge/MobileBridge/#transport","title":"Transport","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#json-structure_16","title":"JSON Structure","text":"<pre><code>{\n    \"transportId\": {{String}},\n    \"type\": {{TransportType}}        \n}\n</code></pre>"},{"location":"aasb/mobile-bridge/MobileBridge/#properties_1","title":"Properties","text":"Property Type Required Description Example transportId String Yes The unique identifier of the transport. type TransportType Yes The transport type."},{"location":"aasb/mobile-bridge/MobileBridge/#enums","title":"Enums","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#transporttype","title":"TransportType","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#values","title":"Values","text":"Value Description \"BLUETOOTH\" \"WIFI\" \"USB\" \"EAP\" \"UNKNOWN\""},{"location":"aasb/mobile-bridge/MobileBridge/#transportstate","title":"TransportState","text":""},{"location":"aasb/mobile-bridge/MobileBridge/#values_1","title":"Values","text":"Value Description \"INITIALIZED\" \"CONNECTING\" \"CONNECTED\" \"HANDSHAKED\" \"AUTHORIZED\" \"DISCONNECTED\""},{"location":"aasb/navigation/Navigation/","title":"Navigation","text":""},{"location":"aasb/navigation/Navigation/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/navigation/Navigation/#showalternativeroutes","title":"ShowAlternativeRoutes","text":"<p>Notifies the platform implementation to show alternative routes.</p>"},{"location":"aasb/navigation/Navigation/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"ShowAlternativeRoutes\"\n        }\n    },\n    \"payload\": {\n        \"alternateRouteType\": {{AlternateRouteType}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload","title":"Payload","text":"Property Type Required Description Example alternateRouteType AlternateRouteType Yes alternateRouteType The type of alternate route requested."},{"location":"aasb/navigation/Navigation/#showpreviouswaypoints","title":"ShowPreviousWaypoints","text":"<p>Notifies the platform implementation to display list of previous waypoints.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"ShowPreviousWaypoints\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#controldisplay","title":"ControlDisplay","text":"<p>Notifies the platform implementation to perform user interaction with the onscreen map application.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"ControlDisplay\"\n        }\n    },\n    \"payload\": {\n        \"controlDisplay\": {{ControlDisplay}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_1","title":"Payload","text":"Property Type Required Description Example controlDisplay ControlDisplay Yes the user requested map control."},{"location":"aasb/navigation/Navigation/#announceroadregulation","title":"AnnounceRoadRegulation","text":"<p>Notifies the platform implementation to give details about road regulations about the road segments that the user is on.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"AnnounceRoadRegulation\"\n        }\n    },\n    \"payload\": {\n        \"roadRegulation\": {{RoadRegulation}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_2","title":"Payload","text":"Property Type Required Description Example roadRegulation RoadRegulation Yes Type of road regulation requested."},{"location":"aasb/navigation/Navigation/#cancelnavigation","title":"CancelNavigation","text":"<p>Notifies the platform implementation to cancel navigation.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"CancelNavigation\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#announcemaneuver","title":"AnnounceManeuver","text":"<p>Notifies the platform implementation to give details about a maneuver to next waypoint on the route or a completely different waypoint off route.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"AnnounceManeuver\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_3","title":"Payload","text":"Property Type Required Description Example payload String Yes JSON data containing the manueuver information."},{"location":"aasb/navigation/Navigation/#navigatetopreviouswaypoint","title":"NavigateToPreviousWaypoint","text":"<p>Notifies the platform implementation to start navigation to the previous waypoint.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"NavigateToPreviousWaypoint\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#getnavigationstate","title":"GetNavigationState","text":"<p>Retrieve the navigation state from the platform.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"GetNavigationState\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#startnavigation","title":"StartNavigation","text":"<p>Notifies the platform implementation to start the navigation.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"StartNavigation\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_4","title":"Payload","text":"Property Type Required Description Example payload String Yes JSON data containing the destination information."},{"location":"aasb/navigation/Navigation/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/navigation/Navigation/#showalternativeroutessucceeded","title":"ShowAlternativeRoutesSucceeded","text":"<p>Notifies AVS of successful showing of alternative routes to the user.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"ShowAlternativeRoutesSucceeded\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_5","title":"Payload","text":"Property Type Required Description Example payload String Yes data containing the alternative route information."},{"location":"aasb/navigation/Navigation/#navigationerror","title":"NavigationError","text":"<p>Notifies the Engine of error in handling a Navigation directive.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"NavigationError\"\n        }\n    },\n    \"payload\": {\n        \"type\": {{ErrorType}},\n        \"code\": {{ErrorCode}},\n        \"description\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_6","title":"Payload","text":"Property Type Required Description Example type ErrorType Yes ErrorType describing which operation failed. code ErrorCode Yes ErrorCode describing the type of failure. description String Yes String providing additional information."},{"location":"aasb/navigation/Navigation/#navigationevent","title":"NavigationEvent","text":"<p>Notifies the Engine of successful handling of a Navigation directive.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"NavigationEvent\"\n        }\n    },\n    \"payload\": {\n        \"event\": {{EventName}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_7","title":"Payload","text":"Property Type Required Description Example event EventName Yes EventName describing which operation was successful."},{"location":"aasb/navigation/Navigation/#getnavigationstatereply","title":"GetNavigationStateReply","text":"<p>Reply for GetNavigationState message.</p>"},{"location":"aasb/navigation/Navigation/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"Navigation\",\n            \"action\": \"GetNavigationState\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"navigationState\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/navigation/Navigation/#payload_8","title":"Payload","text":"Property Type Required Description Example navigationState String Yes the current NavigationState JSON payload."},{"location":"aasb/navigation/Navigation/#enums","title":"Enums","text":""},{"location":"aasb/navigation/Navigation/#alternateroutetype","title":"AlternateRouteType","text":""},{"location":"aasb/navigation/Navigation/#values","title":"Values","text":"Value Description \"DEFAULT\" description for DEFAULT. \"SHORTER_TIME\" description for SHORTER_TIME. \"SHORTER_DISTANCE\" description for SHORTER_DISTANCE."},{"location":"aasb/navigation/Navigation/#controldisplay_1","title":"ControlDisplay","text":""},{"location":"aasb/navigation/Navigation/#values_1","title":"Values","text":"Value Description \"SHOW_ROUTE_OVERVIEW\" description for SHOW_ROUTE_OVERVIEW. \"SHOW_DIRECTIONS_LIST\" description for SHOW_DIRECTIONS_LIST. \"ZOOM_IN\" description for ZOOM_IN. \"ZOOM_OUT\" description for ZOOM_OUT. \"CENTER_MAP_ON_CURRENT_LOCATION\" description for CENTER_MAP_ON_CURRENT_LOCATION. \"ORIENT_NORTH\" description for ORIENT_NORTH. \"SCROLL_NORTH\" description for SCROLL_NORTH. \"SCROLL_UP\" description for SCROLL_UP. \"SCROLL_EAST\" description for SCROLL_EAST. \"SCROLL_RIGHT\" description for SCROLL_RIGHT. \"SCROLL_SOUTH\" description for SCROLL_SOUTH. \"SCROLL_DOWN\" description for SCROLL_DOWN. \"SCROLL_WEST\" description for SCROLL_WEST. \"SCROLL_LEFT\" description for SCROLL_LEFT. \"MUTE_ROUTE_GUIDANCE\" navigation sounds off. \"UNMUTE_ROUTE_GUIDANCE\" navigation sounds on."},{"location":"aasb/navigation/Navigation/#roadregulation","title":"RoadRegulation","text":""},{"location":"aasb/navigation/Navigation/#values_2","title":"Values","text":"Value Description \"SPEED_LIMIT\" description for SHOW_ROUTE_OVERVIEW. \"CARPOOL_RULES\" description for SHOW_DIRECTIONS_LIST."},{"location":"aasb/navigation/Navigation/#errortype","title":"ErrorType","text":""},{"location":"aasb/navigation/Navigation/#values_3","title":"Values","text":"Value Description \"NAVIGATION_START_FAILED\" Navigation failed to start. Send in response to startNavigation() directive. \"SHOW_PREVIOUS_WAYPOINTS_FAILED\" List of previous waypoints failed to display. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_START_FAILED\" The previous navigation route failed to start. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_FAILED\" Overview of route was failed to display. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_FAILED\" List of directions was failed to display. Send in response to controlDisplay() directive. \"ZOOM_IN_FAILED\" Map zoom-in unsuccessful. Send in response to controlDisplay() directive. \"ZOOM_OUT_FAILED\" Map zoom-out unsuccessful. Send in response to controlDisplay() directive. \"CENTER_FAILED\" Map centering unsuccessful. Send in response to controlDisplay() directive. \"ORIENT_NORTH_FAILED\" Map alignment to north unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_NORTH_FAILED\" Moving map North was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_UP_FAILED\" Moving map upwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_EAST_FAILED\" Moving map East was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_RIGHT_FAILED\" Moving map rightwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_SOUTH_FAILED\" Moving map South was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_DOWN_FAILED\" Moving map downwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_WEST_FAILED\" Moving map west was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_LEFT_FAILED\" Moving map leftwards was unsuccessful. Send in response to controlDisplay() directive. \"MUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be muted. Send in response to controlDisplay() directive. \"UNMUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_FAILED\" Displaying default alternate routes was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_FAILED\" Displaying alternate routes with shorter times was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_FAILED\" Displaying alternate routes with shorter distances was unsuccessful. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_FAILED\" Next turn announcement was unsuccessful. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_FAILED\" Next exit announcement was unsuccessful. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_FAILED\" Announcement for entering directions was unsuccessful. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_FAILED\" Announcement for merging directions was unsuccessful. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_FAILED\" Lane guidance announcement was unsuccessful. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_FAILED\" Current speed limit announcement was unsuccessful. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_FAILED\" Carpool status announcement was unsuccessful. Send in response to announceRoadRegulation() directive."},{"location":"aasb/navigation/Navigation/#errorcode","title":"ErrorCode","text":""},{"location":"aasb/navigation/Navigation/#values_4","title":"Values","text":"Value Description \"INTERNAL_SERVICE_ERROR\" Failure caused by an unexpected service or client implementation error. \"ROUTE_NOT_FOUND\" Failed because the route could not be found. \"NO_PREVIOUS_WAYPOINTS\" Failed because there are no previous waypoints available. \"NOT_SUPPORTED\" The requested operation is not supported. \"NOT_ALLOWED\" The requested operation is not allowed right now. \"NOT_NAVIGATING\" The requested operation can't be performed because the vehicle is not navigating."},{"location":"aasb/navigation/Navigation/#eventname","title":"EventName","text":""},{"location":"aasb/navigation/Navigation/#values_5","title":"Values","text":"Value Description \"NAVIGATION_STARTED\" Navigation was started. Send in response to startNavigation() directive. \"PREVIOUS_WAYPOINTS_SHOWN\" List of previous waypoints was displayed. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_STARTED\" The previous navigation route was started. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_SHOWN\" Overview of route was displayed. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_SHOWN\" List of directions was displayed. Send in response to controlDisplay() directive. \"ZOOMED_IN\" Map successfully zoomed in. Send in response to controlDisplay() directive. \"ZOOMED_OUT\" Map successfully zoomed out. Send in response to controlDisplay() directive. \"MAP_CENTERED\" Map successfully centered. Send in response to controlDisplay() directive. \"ORIENTED_NORTH\" Map successfully aligned with north up. Send in response to controlDisplay() directive. \"SCROLLED_NORTH\" Map successfully moved in North direction. Send in response to controlDisplay() directive. \"SCROLLED_UP\" Map successfully moved upwards. Send in response to controlDisplay() directive. \"SCROLLED_EAST\" Map successfully moved in East direction. Send in response to controlDisplay() directive. \"SCROLLED_RIGHT\" Map successfully moved rightwards. Send in response to controlDisplay() directive. \"SCROLLED_SOUTH\" Map successfully moved in South direction. Send in response to controlDisplay() directive. \"SCROLLED_DOWN\" Map successfully moved downwards. Send in response to controlDisplay() directive. \"SCROLLED_WEST\" Map successfully moved in West direction. Send in response to controlDisplay() directive. \"SCROLLED_LEFT\" Map successfully moved leftwards. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_MUTED\" Map sounds were muted. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_UNMUTED\" Map sounds were unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_SHOWN\" Default alternate routes were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_SHOWN\" Alternate routes with shorter times were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_SHOWN\" Alternate routes with shorter distances were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_ANNOUNCED\" Next turn was successfully announced. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_ANNOUNCED\" Next exit was successfully announced. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_ANNOUNCED\" Directions for entering successfully announced. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_ANNOUNCED\" Directions for merging successfully announced. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_ANNOUNCED\" Lane guidance was successfully announced. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_ANNOUNCED\" Current speed limit successfully announced. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_ANNOUNCED\" Carpool status successfully announced. Send in response to announceRoadRegulation() directive."},{"location":"aasb/phone-control/PhoneCallController/","title":"PhoneCallController","text":""},{"location":"aasb/phone-control/PhoneCallController/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/phone-control/PhoneCallController/#senddtmf","title":"SendDTMF","text":"<p>Notifies the platform implementation to send a DTMF signal to the calling device.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"SendDTMF\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload","title":"Payload","text":"Property Type Required Description Example payload String Yes Details of the DTMF request in structured JSON format."},{"location":"aasb/phone-control/PhoneCallController/#dial","title":"Dial","text":"<p>Notifies the platform implementation to initiate an outgoing phone call to the destination address.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"Dial\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_1","title":"Payload","text":"Property Type Required Description Example payload String Yes Details of the dial request in structured JSON format."},{"location":"aasb/phone-control/PhoneCallController/#redial","title":"Redial","text":"<p>Notifies the platform implementation to redial the last called phone number.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"Redial\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_2","title":"Payload","text":"Property Type Required Description Example payload String Yes Details of the redial request in structured JSON format."},{"location":"aasb/phone-control/PhoneCallController/#stop","title":"Stop","text":"<p>Notifies the platform implementation to end an ongoing call or stop inbound or outbound call setup.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"Stop\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_3","title":"Payload","text":"Property Type Required Description Example payload String Yes Details of the stop request in structured JSON format."},{"location":"aasb/phone-control/PhoneCallController/#answer","title":"Answer","text":"<p>Notifies the platform implementation to answer an inbound call.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"Answer\"\n        }\n    },\n    \"payload\": {\n        \"payload\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_4","title":"Payload","text":"Property Type Required Description Example payload String Yes Details of the answer request in structured JSON format."},{"location":"aasb/phone-control/PhoneCallController/#createcallidreply","title":"CreateCallIdReply","text":"<p>Reply for CreateCallId message.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_5","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"CreateCallId\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"callId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_5","title":"Payload","text":"Property Type Required Description Example callId String Yes Unique identifier for a call."},{"location":"aasb/phone-control/PhoneCallController/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/phone-control/PhoneCallController/#createcallid","title":"CreateCallId","text":"<p>Generates a unique identifier for a call.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_6","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"CreateCallId\"\n        }\n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#callstatechanged","title":"CallStateChanged","text":"<p>Notifies the Engine of a change in the state of an ongoing call.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_7","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"CallStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{CallState}},\n        \"callId\": {{String}},\n        \"callerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_6","title":"Payload","text":"Property Type Required Description Example state CallState Yes The state of the call. callId String Yes The unique identifier associated with the call. callerId String No The identifier for a contact."},{"location":"aasb/phone-control/PhoneCallController/#senddtmfsucceeded","title":"SendDTMFSucceeded","text":"<p>Notifies the Engine that sending the DTMF signal succeeded.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_8","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"SendDTMFSucceeded\"\n        }\n    },\n    \"payload\": {\n        \"callId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_7","title":"Payload","text":"Property Type Required Description Example callId String Yes The unique identifier for the associated call."},{"location":"aasb/phone-control/PhoneCallController/#connectionstatechanged","title":"ConnectionStateChanged","text":"<p>Notifies the Engine of a change in connection to a calling device.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_9","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"ConnectionStateChanged\"\n        }\n    },\n    \"payload\": {\n        \"state\": {{ConnectionState}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_8","title":"Payload","text":"Property Type Required Description Example state ConnectionState Yes The state of connection to a calling device."},{"location":"aasb/phone-control/PhoneCallController/#callfailed","title":"CallFailed","text":"<p>Notifies the Engine of an error related to a call.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_10","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"CallFailed\"\n        }\n    },\n    \"payload\": {\n        \"callId\": {{String}},\n        \"code\": {{CallError}},\n        \"message\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_9","title":"Payload","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the error. code CallError Yes The error type. message String No A description of the error."},{"location":"aasb/phone-control/PhoneCallController/#calleridreceived","title":"CallerIdReceived","text":"<p>Notifies the Engine that a caller id was received for an inbound call.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_11","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"CallerIdReceived\"\n        }\n    },\n    \"payload\": {\n        \"callId\": {{String}},\n        \"callerId\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_10","title":"Payload","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the callId. callerId String Yes The caller's identifier or phone number."},{"location":"aasb/phone-control/PhoneCallController/#deviceconfigurationupdated","title":"DeviceConfigurationUpdated","text":"<p>Notifies the Engine of the calling feature configuration of the connected calling device.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_12","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"DeviceConfigurationUpdated\"\n        }\n    },\n    \"payload\": {\n        \"configurationMap\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_11","title":"Payload","text":"Property Type Required Description Example configurationMap String Yes A map of configuration properties to the boolean state of the properties."},{"location":"aasb/phone-control/PhoneCallController/#senddtmffailed","title":"SendDTMFFailed","text":"<p>Notifies the Engine that the DTMF signal could not be delivered to the remote party.</p>"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_13","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"PhoneCallController\",\n            \"action\": \"SendDTMFFailed\"\n        }\n    },\n    \"payload\": {\n        \"callId\": {{String}},\n        \"code\": {{DTMFError}},\n        \"message\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/phone-control/PhoneCallController/#payload_12","title":"Payload","text":"Property Type Required Description Example callId String Yes callId The unique identifier for the associated call. code DTMFError Yes The error type. message String No A description of the error."},{"location":"aasb/phone-control/PhoneCallController/#enums","title":"Enums","text":""},{"location":"aasb/phone-control/PhoneCallController/#callingdeviceconfigurationproperty","title":"CallingDeviceConfigurationProperty","text":""},{"location":"aasb/phone-control/PhoneCallController/#values","title":"Values","text":"Value Description \"DTMF_SUPPORTED\" Whether the device supports DTMF signaling."},{"location":"aasb/phone-control/PhoneCallController/#connectionstate","title":"ConnectionState","text":""},{"location":"aasb/phone-control/PhoneCallController/#values_1","title":"Values","text":"Value Description \"CONNECTED\" A calling device is connected. \"DISCONNECTED\" No calling device is connected."},{"location":"aasb/phone-control/PhoneCallController/#dtmferror","title":"DTMFError","text":""},{"location":"aasb/phone-control/PhoneCallController/#values_2","title":"Values","text":"Value Description \"CALL_NOT_IN_PROGRESS\" There is no active call through which a DTMF signal can be sent. \"DTMF_FAILED\" Generic DTMF error."},{"location":"aasb/phone-control/PhoneCallController/#callerror","title":"CallError","text":""},{"location":"aasb/phone-control/PhoneCallController/#values_3","title":"Values","text":"Value Description \"NO_CARRIER\" No carrier is available on the calling device. \"BUSY\" The calling device is busy when setting up an outbound call, such as when a call is already in progress. \"NO_ANSWER\" The remote party did not answer the call. \"NO_NUMBER_FOR_REDIAL\" Redial was requested, but there is no previously dialed number available. \"OTHER\" Generic error."},{"location":"aasb/phone-control/PhoneCallController/#callstate","title":"CallState","text":""},{"location":"aasb/phone-control/PhoneCallController/#values_4","title":"Values","text":"Value Description \"IDLE\" The call is not in an active state. \"DIALING\" The outbound call is initiated by the user. Call setup is in progress. \"OUTBOUND_RINGING\" The outbound call has been set up, and the remote party is alerted. \"ACTIVE\" The call is active, and media is being transmitted between the caller and remote party. \"CALL_RECEIVED\" An alert for the inbound call has been received. \"INBOUND_RINGING\" The inbound call is ringing."},{"location":"aasb/text-to-speech/TextToSpeech/","title":"TextToSpeech","text":""},{"location":"aasb/text-to-speech/TextToSpeech/#outgoing-messages","title":"Outgoing Messages","text":""},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeechfailed","title":"PrepareSpeechFailed","text":"<p>Notifies the platform implementation about a failed speech synthesis.</p>"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TextToSpeech\",\n            \"action\": \"PrepareSpeechFailed\"\n        }\n    },\n    \"payload\": {\n        \"speechId\": {{String}},\n        \"reason\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/text-to-speech/TextToSpeech/#payload","title":"Payload","text":"Property Type Required Description Example speechId String Yes The speech ID. reason String Yes The failure reason."},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeechcompleted","title":"PrepareSpeechCompleted","text":"<p>Notifies the platform implementation about a successful speech synthesis.</p>"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_1","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TextToSpeech\",\n            \"action\": \"PrepareSpeechCompleted\"\n        }\n    },\n    \"payload\": {\n        \"speechId\": {{String}},\n        \"token\": {{String}},\n        \"source\": \"STREAM\",\n        \"streamId\": {{String}},\n        \"encoding\": {{AudioStreamEncoding}},\n        \"properties\": {{dict}},\n        \"metadata\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_1","title":"Payload","text":"Property Type Required Description Example speechId String Yes The speech ID. token String Yes A unique token for this audio stream. source String Yes source description. streamId String Yes The URL audio stream being provided. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. metadata String Yes The metadata associated with the speech resource."},{"location":"aasb/text-to-speech/TextToSpeech/#getcapabilitiesreply","title":"GetCapabilitiesReply","text":"<p>Reply for GetCapabilities message.</p>"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_2","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Reply\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TextToSpeech\",\n            \"action\": \"GetCapabilities\",\n            \"replyToId\": {{String}}        \n        }\n    },\n    \"payload\": {\n        \"capabilities\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_2","title":"Payload","text":"Property Type Required Description Example capabilities String Yes The capabilities of the Text to Speech provider."},{"location":"aasb/text-to-speech/TextToSpeech/#incoming-messages","title":"Incoming Messages","text":""},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeech","title":"PrepareSpeech","text":"<p>Prepare Speech from a text/SSML input.</p>"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_3","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TextToSpeech\",\n            \"action\": \"PrepareSpeech\"\n        }\n    },\n    \"payload\": {\n        \"speechId\": {{String}},\n        \"text\": {{String}},\n        \"provider\": {{String}},\n        \"options\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_3","title":"Payload","text":"Property Type Required Description Example speechId String Yes The speech ID. text String Yes The text/SSML to be used for speech synthesis. provider String Yes The text to speech provider to be used for speech synthesis. options String No The options to be used for speech synthesis."},{"location":"aasb/text-to-speech/TextToSpeech/#getcapabilities","title":"GetCapabilities","text":"<p>Get Capabilities of a Text to Speech provider.</p>"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_4","title":"JSON Structure","text":"<pre><code>{\n    \"header\": {\n        \"version\": \"4.0\",\n        \"messageType\": \"Publish\",\n        \"id\": {{String}},\n        \"messageDescription\": {\n            \"topic\": \"TextToSpeech\",\n            \"action\": \"GetCapabilities\"\n        }\n    },\n    \"payload\": {\n        \"provider\": {{String}}        \n    }\n}\n</code></pre>"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_4","title":"Payload","text":"Property Type Required Description Example provider String Yes The provider string. Use text-to-speech-provider here."},{"location":"android/","title":"Alexa Auto App","text":"<p>Alexa Auto App (AAA) is a pre-built, ready-to-integrate Alexa app for in-vehicle Android infotainment systems. AAA enables a delightful multi-modal Alexa customer experience that includes in-car, home-to-car, and car-to-home features. AAA builds on the foundation of Alexa Auto SDK and Android Automotive OS (AAOS and AOSP 10+) to reduce development and certification effort for OEMs and enable faster time to market.</p> <p>Contact your Amazon Solutions Architect or Partner Manager for access to Alexa Auto App and the Alexa Auto App documentation.</p>"},{"location":"builder/","title":"Builder Tool Command Reference","text":"<pre><code>$ build.py [-h] {build,clean,configure,imports} ...\n\noptional arguments:\n  -h, --help            show this help message and exit\n\ncommands:\n  {build,clean,configure,imports}\nbuild               builds auto sdk components (default)\nclean               cleans builder cache\n    configure           builder configuration\n    imports             manages external search paths    </code></pre>"},{"location":"builder/#build-command","title":"Build command","text":"<p><pre><code>$ build.py build [-h] [--home PATH] [-v] [-p PLATFORM] [-a ARCH] [-g]\n[-m MODULE [MODULE ...]] [-n NAME] [-y]\n[-f PACKAGE [PACKAGE ...]] [-i PATH [PATH ...]]\n[-o OPTION] [-s SETTING] [--with-aasb] [--no-aasb]\n[--with-docs] [--no-docs] [--with-unit-tests]\n[--no-unit-tests] [--with-sampleapp] [--no-sampleapp]\n[--with-sensitive-logs] [--no-sensitive-logs]\n[--with-metrics] [--no-metrics]\n[--output FILE] [--no-output] [--skip-config]\n</code></pre> Used to build Auto SDK modules and components.</p> <pre><code>optional arguments:\n  -h, --help            show this help message and exit\n--home PATH, --builder-home PATH\n                        override builder home path\n  -v, --verbose         enable verbose logging\n  -p PLATFORM, --platform PLATFORM\n                        target platform - android,qnx,etc.\n  -a ARCH, --arch ARCH  target architecture\n  -g, --debug           specify debug build type\n-m MODULE [MODULE ...], --modules MODULE [MODULE ...]\nlist of modules to build\n  -n NAME, --name NAME  optional package identifier\n  -y, --accept-licenses\n                        auto-accept licenses\n  -f PACKAGE [PACKAGE ...], --force PACKAGE [PACKAGE ...]\nforce export and build package\n  -i PATH [PATH ...], --include PATH [PATH ...]\nadd include path to conan configuration\n  -o OPTION, --conan-option OPTION\n                        specify a conan build option\n  -s SETTING, --conan-setting SETTING\n                        specify a conan build setting\n  --with-aasb, --aasb   include aasb messages (default: True)\n--no-aasb\n  --with-docs, --docs   include docs (default: True)\n--no-docs\n  --with-unit-tests, --unit-tests\n                        include unit tests (default: False)\n--no-unit-tests\n  --with-sampleapp, --sampleapp\n                        include sample app (default: False)\n--no-sampleapp\n  --with-sensitive-logs, --sensitive-logs\n                        emit sensitive data in debugging logs (default: False)\n--no-sensitive-logs\n  --with-metrics        Enables metrics emission (default: True)\n--no-metrics          Disables metrics emission --output FILE         filename for output build archive\n  --no-output           don't create output package\n  --skip-config         skip build configuration\n</code></pre>"},{"location":"builder/#clean-command","title":"Clean command","text":"<p><pre><code>$ build.py clean [-h] [--home PATH] [-v] [--skip-conan] [--skip-gradle] pattern\n</code></pre> Used to clean packages from the Builder, Conan, and Gradle caches.</p> <pre><code>positional arguments:\n  pattern        pattern or package name\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n  --skip-conan   skips cleaning the conan cache\n  --skip-gradle  skips cleaning the gradle cache\n</code></pre>"},{"location":"builder/#configure-command","title":"Configure command","text":"<pre><code>$ build.py configure [-h] [--home PATH] [-v] {init,export} ...\n\noptional arguments:\n  -h, --help     show this help message and exit\n\ncommands:\n  {init,export}\ninit         initializes the builder configuration\n    export       exports packages from the builder configuration\n</code></pre>"},{"location":"builder/#configure-init","title":"configure init","text":"<p><pre><code>$ build.py configure init [-h] [--home PATH] [-v]\n</code></pre> Used to initialize the Builder configuration settings.</p> <pre><code>optional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#configure-export","title":"configure export","text":"<p><pre><code>$ build.py configure export [-h] [--home PATH] [-v] PATTERN\n</code></pre> Used to re-export packages that are configured by the builder.</p> <pre><code>positional arguments:\n  PATTERN        pattern or package name\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-command","title":"Imports command","text":"<pre><code>$ build.py imports [-h] {init,list,add,remove,enable,disable} ...\n\noptional arguments:\n  -h, --help            show this help message and exit\n\ncommands:\n  {init,list,add,remove,enable,disable}\ninit                initialize the imports configuration\n    list                lists imports managed by the configuration\n    add                 adds a new import\n    remove              removes imports\n    enable              enables imports\n    disable             disables imports\n</code></pre>"},{"location":"builder/#imports-init","title":"imports init","text":"<p><pre><code>$ build.py imports init [-h] [--home PATH] [-v]\n</code></pre> Used to initialize the Builder imports settings.</p> <pre><code>optional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-list","title":"imports list","text":"<p><pre><code>$ build.py imports list [-h] [--home PATH] [-v]\n</code></pre> Used to display the imports in the Builder settings.</p> <pre><code>optional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-add","title":"imports add","text":"<p><pre><code>$ build.py imports add [-h] [--home PATH] [-v] NAME PATH\n</code></pre> Used create a new import in the Builder settings.</p> <pre><code>positional arguments:\n  NAME           import name\n  PATH           import search path\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-remove","title":"imports remove","text":"<p><pre><code>$ build.py imports remove [-h] [--home PATH] [-v] PATTERN\n</code></pre> Used to remove imports from the Builder settings.</p> <pre><code>positional arguments:\n  PATTERN        import name or pattern\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-enable","title":"imports enable","text":"<p><pre><code>$ build.py imports enable [-h] [--home PATH] [-v] PATTERN\n</code></pre> Used to enable imports in the Builder settings.</p> <pre><code>positional arguments:\n  PATTERN        import name or pattern\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"builder/#imports-disable","title":"imports disable","text":"<p><pre><code>$ build.py imports disable [-h] [--home PATH] [-v] PATTERN\n</code></pre> Used to disable imports in the Builder settings.</p> <pre><code>positional arguments:\n  PATTERN        import name or pattern\n\noptional arguments:\n  -h, --help     show this help message and exit\n--home PATH    override builder home path\n  -v, --verbose  enable verbose logging\n</code></pre>"},{"location":"explore/concepts/","title":"Explore Auto SDK Concepts","text":"<p>Learn about the fundamental components that comprise the Auto SDK API.</p>"},{"location":"explore/concepts/#core-api-overview","title":"Core API overview","text":"<p>The core Auto SDK API provides the \"Engine\" to manage communication with Alexa and other Amazon services on behalf of your application. The core API includes an asynchronous message-based mechanism, consisting of a \"Message Broker\" and \"AASB messages\", for the Engine and your application to communicate.</p> <p>&gt;&gt; Auto SDK Core API Overview</p>"},{"location":"explore/concepts/#modules-overview","title":"Modules overview","text":"<p>Auto SDK organizes its features into \"modules\" that enable you to select the features you want to use in your application.</p> <p>&gt;&gt; Understand Auto SDK Modules</p>"},{"location":"explore/concepts/core-api-overview/","title":"Auto SDK Core API Overview","text":"<p>The <code>Engine</code>, <code>MessageBroker</code>, and <code>AASB message interfaces</code> comprise the core Auto SDK API. An application uses these three components, alongside a custom platform-specific integration, to build a complete Alexa client implementation for the vehicle. An Alexa client system architecture built with Auto SDK may look something like the following diagram:</p> <p></p>"},{"location":"explore/concepts/core-api-overview/#the-engine","title":"The Engine","text":"<p>The Auto SDK Engine is a system of components that provide the core implementation of all Auto SDK features. The Engine manages communication with Amazon services, such as Alexa, on behalf of your application. With respect to Alexa, your application's Alexa client stack uses the Engine as the layer that sets up the connection to Alexa, publishes device capabilities, sends Alexa events, processes Alexa directives, and more.</p> <p>Your application creates and configures an instance of the Engine and uses a simple interface to manage the Engine lifecycle for the duration of the application run time. Aside from setting up the Engine, the primary responsibility of your application is to provide the platform-specific, custom integration details that make Alexa and other core SDK features work for your vehicle, in particular. Platform-specific integration might include building UI and interacting with external libraries, applications, or the underlying software frameworks of your operating system in order to complete the Auto SDK client stack with deep integration into your system.</p> <p>The Engine implements as much of the general functionality as possible; for integration details that it can't implement, the Engine delegates responsibility to your application \"handlers\" via AASB messages published through the MessageBroker.</p>"},{"location":"explore/concepts/core-api-overview/#the-message-broker","title":"The Message Broker","text":"<p>The Message Broker is the bridge in the Alexa Auto Services Bridge (AASB). The Message Broker provides a publish-subscribe API for the Engine and your application to communicate with each other by exchanging asynchronous AASB messages. In order to consume a message that the Engine publishes to your application, your application uses the <code>MessageBroker</code> class to subscribe to the message by specifying the message <code>topic</code> and <code>action</code> as well as a handler function for <code>MessageBroker</code> to invoke to deliver the message. Similarly, the Engine uses the Message Broker to subscribe to messages published by your application.</p>"},{"location":"explore/concepts/core-api-overview/#aasb-message-interfaces","title":"AASB Message Interfaces","text":""},{"location":"explore/concepts/core-api-overview/#overview","title":"Overview","text":"<p>A typical Auto SDK module defines one or more \"interfaces\" that your application uses to communicate with the Engine. Interface refers to a logical grouping of related AASB messages that share the same <code>topic</code>. For example, messages pertaining to vehicle navigation belong to the <code>Navigation</code> interface, and each individual AASB message in the <code>Navigation</code> interface uses <code>topic</code> \"Navigation\". Within the <code>topic</code>, each interface has one or more <code>actions</code> to represent individual messages, so a <code>topic</code> + <code>action</code> combination identifies a single message. Some AASB messages are fire-and-forget, whereas others require a reply.</p> <p>There are two directions AASB messages can travel:</p> <ul> <li> <p>\"Outgoing\" AASB messages are messages that the Engine publishes to your application. There are several reasons why the Engine might publish an outgoing message, such as requesting your application to handle a platform-specific deep integration, react to a state change, display a custom UI, and more. Your application subscribes to outgoing messages and performs the necessary actions upon receipt.</p> </li> <li> <p>\"Incoming\" AASB messages are messages that your application publishes to the Engine. An incoming message might be an asynchronous response to a particular outgoing message that your application received and handled. Alternatively, an incoming message might request the Engine to perform an operation or react to a state change.</p> </li> </ul> <p>Auto SDK documentation refers to any component in your application that handles AASB messages for one particular interface as a \"handler\". For example, \"Navigation handler\" is the component in your application that handles outgoing and incoming AASB messages within the \"Navigation\" message topic.</p>"},{"location":"explore/concepts/core-api-overview/#message-structure","title":"Message Structure","text":"<p>AASB messages use a standard JSON protocol. Each AASB message has the following structure:</p> <pre><code>{\n    \"header\": {\n        \"version\": {{STRING}},\n        \"messageType\": {{STRING}},\n        \"id\": {{STRING}},\n        \"messageDescription\": {\n            \"topic\": {{STRING}},\n            \"action\": {{STRING}},\n            \"replyToId\": {{String}}   \n        }\n    },\n    \"payload\": {\n        // payload as defined by the interface\n    }\n}\n</code></pre> Property Type Required Description header Object Yes Contains metadata about the message. header.version String Yes The version of the message <code>payload</code>. The version follows the \"major.minor\" convention. header.messageType String Yes The type of the message. Accepted values:<ul><li><code>Publish</code>: The standard message type. </li><li><code>Reply</code>: The message type that correlates a reply to a previous message. E.g., a response to a request for data. header.id String Yes A universally unique identifier (UUID) for the message, generated to the RFC 4122 specification. header.messageDescription.topic String Yes The name of the interface. header.messageDescription.action String Yes The name of the individual message, unique within the <code>topic</code>, which determines the contents of the <code>payload</code>. header.messageDescription.replyToId String Yes if <code>messageType</code> is <code>Reply</code>, no otherwise The <code>id</code> of the message to which this message replies. Used to correlate a message to its response. payload Object No The content of the message. The combination of <code>topic</code>, <code>action</code>, and <code>version</code> define the structure."},{"location":"explore/concepts/core-api-overview/#example","title":"Example","text":"<p>The following example describes a sample AASB message exchange when a user in the vehicle invokes Alexa with a button press.</p> <p>Your application provides an Alexa invocation button in its UI, and when the user taps the button, your application publishes a <code>SpeechRecognizer.StartCapture</code> message:</p> <pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"7604450c-61c1-11ec-90d6-0242ac120003\",\n\"messageDescription\": {\n\"topic\": \"SpeechRecognizer\",\n\"action\": \"StartCapture\"\n}\n},\n\"payload\": {\n\"initiator\": \"TAP_TO_TALK\"\n}\n}\n</code></pre> <p>The Engine subscribes to this message at startup time, so it is ready to consume the message when published by your application. In response to the message, the Engine determines everything it needs in order to invoke Alexa as a result of this request from your application, such as an access token, an audio stream, and states of components on the head unit. If the Engine needs something from your application, it will publish AASB messages; for example, if your application isn't already providing the user speech audio, the Engine publishes an <code>AudioInput.StartAudioInput</code> message to open the audio stream:</p> <pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"9d4cedf3-eccd-4851-9c77-c1cec8af76e4\",\n\"messageDescription\": {\n\"topic\": \"AudioInput\",\n\"action\": \"StartAudioInput\"\n}\n},\n\"payload\": {\n\"name\": \"SpeechRecognizer\",\n\"audioType\": \"VOICE\",\n\"streamId\": \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\"        }\n}\n</code></pre> <p>Your application receives this message from the Message Broker if it subscribed to the <code>AudioInput</code> topic and <code>StartAudioInput</code> action. The Message Broker delivers the message as an argument to the function specified when subscribing. Your application then records the user's audio from the microphone and provides it to the Engine through <code>MessageBroker</code>.</p> <p>Since Alexa will also need to know the state of the head unit in order to properly respond to the user, the Engine may request states from your application with additional AASB messages. For example, the Engine might publish a <code>Navigation.GetNavigationState</code> message because it needs to know details about any active navigation session in case the user is asking Alexa something about the route:</p> <p><pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"50d7397a-6408-4754-a694-35b6c633b756\",\n\"messageDescription\": {\n\"topic\": \"Navigation\",\n\"action\": \"GetNavigationState\"\n}\n}\n}\n</code></pre> Your application will receive this request if supports navigation and subscribed to the outgoing <code>Navigation</code> messages. Your application publishes a reply message with the current state:</p> <p><pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Reply\",\n\"id\": \"539abbb5-2a4d-43cf-b867-840f2b206f07\",\n\"messageDescription\": {\n\"topic\": \"Navigation\",\n\"action\": \"GetNavigationState\",\n\"replyToId\": \"50d7397a-6408-4754-a694-35b6c633b756\"        }\n},\n\"payload\": {\n\"navigationState\": \"&lt;the state details are a JSON in this field&gt;\"       }\n}\n</code></pre> Once the Engine has everything it needs, it forwards the user's request to Alexa. Alexa processes the speech, and when she detects the user has finished speaking, the Engine publishes a <code>SpeechRecognizer.EndOfSpeechDetected</code> message to your application:</p> <pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"8028e40c-61c1-11ec-90d6-0242ac120003\",\n\"messageDescription\": {\n\"topic\": \"SpeechRecognizer\",\n\"action\": \"EndOfSpeechDetected\"\n}\n}\n}\n</code></pre> <p>Your application might use this as a trigger to play an end of listening audio cue. If the Engine doesn't need the audio stream any more (e.g., when hands-free listening is disabled), the Engine will tell your application to close the stream with an <code>AudioInput.StopAudioInput</code> message:</p> <pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"1f3bfc25-d4cb-4b88-b7bc-a536f36e4402\",\n\"messageDescription\": {\n\"topic\": \"AudioInput\",\n\"action\": \"StopAudioInput\"\n}\n},\n\"payload\": {\n\"streamId\": \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\"     }\n}\n</code></pre> <p>Alexa might send directives to the Engine depending what the user asked for. For example, if the user said \"turn on the fan\", the Engine publishes a message requesting your application's deep integration with the vehicle hardware to perform the action:</p> <pre><code>{\n\"header\": {\n\"version\": \"4.0\",\n\"messageType\": \"Publish\",\n\"id\": \"b033e4b9-5420-47b4-949c-666e0c2d6c36\",\n\"messageDescription\": {\n\"topic\": \"CarControl\",\n\"action\": \"SetControllerValue\"\n}\n},\n\"payload\": {\n\"capabilityType\": \"POWER\",\n\"endpointId\": \"default.fan\",\n\"turnOn\": true   }\n}\n</code></pre>"},{"location":"explore/concepts/modules-overview/","title":"Understand Auto SDK Modules","text":""},{"location":"explore/concepts/modules-overview/#overview","title":"Overview","text":"<p>Auto SDK organizes its features into <code>modules</code>. A single module groups the logically related Auto SDK components that are required to enable a particular feature area. For example, the <code>Navigation</code> module contains the SDK components that enable your application to build a deep integration with a navigation provider, whereas the <code>Address Book</code> module contains the SDK components that enable your application to upload a user's contacts to Alexa.</p> <p>A typical Auto SDK module includes the following types of components:</p> <ul> <li> <p>Platform abstraction components such as AASB message interfaces and Engine configuration specifications. These components define the module-specific API that your application interacts with.</p> </li> <li> <p>Engine implementation components such as Engine infrastructure and implementations that correspond to platform APIs in the module. The module's Engine components augment the Engine with the feature set that the module provides.</p> </li> <li> <p>Dependencies such as external libraries (e.g., AVS Device SDK) that the module uses to enable its feature set. Only the build system and Engine implementation components of the module directly use these dependencies, so they are abstracted from your application.</p> </li> <li> <p>Build system tools such as scripts, Conan recipes, dependency management tools, and more, that support building the Auto SDK code and dependencies that belong to the particular module.</p> </li> </ul> <p>The module organization of Auto SDK enables you to easily use only the features you want and leave out the ones you don't. \"Using a module\" typically means including the module in the Auto SDK build, linking the generated module library in your application, configuring the Engine with any configuration the module specifies, and implementing the logic to integrate with the AASB messages defined by the module. On Android, the Auto SDK Android API further simplifies this setup and integration.</p> <p>The <code>Core</code> module is the only module that your application is required to use for a bare minimum Auto SDK integration. <code>Core</code> is required because it defines Auto SDK infrastructure and AASB message interfaces that all other modules depend on, and it provides the <code>Engine</code> and <code>MessageBroker</code> classes that are the primary surface API to the native integration layer. To add Alexa to your application, the <code>Alexa</code> module is required because it adds the support for Auto SDK to communicate with Alexa; however, you are not required to integrate every AASB message interface in the <code>Alexa</code> module platform layer. See Auto SDK Features for detailed descriptions and integration guides for <code>Core</code>, <code>Alexa</code>, and all other Auto SDK modules available to your application.</p>"},{"location":"explore/concepts/modules-overview/#extensions","title":"Extensions","text":"<p>Some Auto SDK modules are not available on Github with the rest of Auto SDK. With help from your Amazon Solutions Architect (SA) or Partner Manager, you can access these modules from each respective \"Auto SDK extension\" on the Alexa developer console. For each extension you download, use the version that corresponds to the Auto SDK version that you use. When you upgrade Auto SDK versions, ensure you download and use the corresponding version of any extensions as well.</p> <p>An extension includes one or more modules and the documentation for each module's API and setup instructions. In general, the contents of a particular extension look, build, and function as any other standard Auto SDK modules; only the delivery mechanism differs.</p>"},{"location":"explore/features/","title":"Explore Auto SDK Features","text":"<p>Learn about the Auto SDK features that you can integrate into your application.</p>"},{"location":"explore/features/#modules-on-github","title":"Modules on Github","text":"<p>Auto SDK provides the following modules on Github:</p>"},{"location":"explore/features/#address-book-module","title":"Address Book module","text":"<p>The <code>Address Book</code> module personalizes the communications and navigation capabilities of Alexa by linking the user's phone contacts and favorite navigation locations. When used with the <code>Phone Control</code> and <code>Navigation</code> modules, <code>Address Book</code> enables the user to call contacts by name and navigate to their favorite destinations.</p> <p>&gt;&gt; Address Book module reference</p>"},{"location":"explore/features/#alexa-module","title":"Alexa module","text":"<p>The <code>Alexa</code> module provides the core Alexa client implementation to your application. The Engine components of the Alexa module manage the connection to the Alexa Voice Service (AVS) and support the standard AVS capabilities such as speaking to Alexa, streaming media, viewing visual content and more.</p> <p>&gt;&gt; Alexa module reference</p>"},{"location":"explore/features/#alexa-presentation-language-apl-module","title":"Alexa Presentation Language (APL) module","text":"<p>The <code>APL</code> module enables your application to display rich visual experiences when the user interacts with Alexa.</p> <p>&gt;&gt; APL module reference</p>"},{"location":"explore/features/#bluetooth-module","title":"Bluetooth module","text":"<p>The <code>Bluetooth</code> module allows the Auto SDK Engine to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Additional Auto SDK modules use the functionality of the <code>Bluetooth</code> module to provide bluetooth-based features, such as mobile authorization, to users of Android or iOS smartphones.</p> <p>&gt;&gt; Bluetooth module reference</p>"},{"location":"explore/features/#car-control-module","title":"Car Control module","text":"<p>The <code>Car Control</code> module enables the user to control vehicle features\u2014turning on seat heaters, adjusting the AC setting, opening windows, and much more\u2014just by asking Alexa.</p> <p>&gt;&gt; Car Control module reference</p>"},{"location":"explore/features/#code-based-linking-cbl-module","title":"Code-Based Linking (CBL) module","text":"<p>The <code>CBL</code> module implements the code-based linking mechanism of acquiring Login with Amazon (LWA) access tokens, which are required to use Alexa. Your application displays a URL and code to the user to complete the sign-in from a second device, and the Engine takes care of fetching the tokens.</p> <p>&gt;&gt; CBL module reference</p>"},{"location":"explore/features/#connectivity-module","title":"Connectivity module","text":"<p>The <code>Connectivity</code> module enables a reduced data consumption mode for Alexa. Your application can offer different tiers of Alexa functionality based on the status of the head unit's data connectivity plan.</p> <p>&gt;&gt; Connectivity module reference</p>"},{"location":"explore/features/#core-module","title":"Core module","text":"<p>The <code>Core</code> module provides the Auto SDK infrastructure upon which all other modules depend. <code>Core</code> includes interfaces for audio input and output, authorization, logging, location reporting, metrics, setting management, network status reporting, and more.</p> <p>&gt;&gt; Core module reference</p>"},{"location":"explore/features/#custom-domain-module","title":"Custom Domain module","text":"<p>The <code>Custom Domain</code> module enables you to enhance your voice assistant with custom functionality. <code>Custom Domain</code> creates a bi-directional communication channel between the head unit and your own cloud skills so your application can exchange custom events and directives with your skills.</p> <p>&gt;&gt; Custom Domain module reference</p>"},{"location":"explore/features/#loopback-detector-module","title":"Loopback Detector module","text":"<p>The <code>Loopback Detector</code> module suppresses false wake word detections in which Alexa uses her own name in her speech output. The Engine uses a loopback audio stream from the vehicle's own speakers to detect any wake words and prevent false wake-ups during interactions.</p> <p>&gt;&gt; Loopback Detector module reference</p>"},{"location":"explore/features/#messaging-module","title":"Messaging module","text":"<p>The <code>Messaging</code> module adds voice-forward Short Message Service (SMS) features to your application. Users can request Alexa to send or read text messages using the phone connected to the head unit.</p> <p>&gt;&gt; Messaging module reference</p>"},{"location":"explore/features/#navigation-module","title":"Navigation module","text":"<p>The <code>Navigation</code> module provides support for Alexa to interface with the head unit's onboard navigation system. Users can ask Alexa to navigate to points of interest and addresses, add stops to the route, answer questions about the route, and more.</p> <p>&gt;&gt; Navigation module reference</p>"},{"location":"explore/features/#phone-control-module","title":"Phone Control module","text":"<p>The <code>Phone Control</code> module adds voice-forward telephony features to your application. Users can ask Alexa to call numbers or contacts using the vehicle's native telephony system or connected phone.</p> <p>&gt;&gt; Phone Control module reference</p>"},{"location":"explore/features/#system-audio-module","title":"System Audio module","text":"<p>The <code>System Audio</code> module provides an out-of-box implementation of the <code>Core</code> module's audio input and output interfaces to simplify the audio management your native C++ integration.</p> <p>&gt;&gt; System Audio module reference</p>"},{"location":"explore/features/#text-to-speech-module","title":"Text-To-Speech module","text":"<p>The <code>Text-To-Speech</code> module enables your application to request synthesis of Alexa speech on demand from text or Speech Synthesis Markup Language (SSML) string. You can use <code>Text-To-Speech</code> with <code>Text-To-Speech-Provider</code> to provide turn-by-turn navigation instructions in Alexa's voice.</p> <p>&gt;&gt; Text-To-Speech module reference</p>"},{"location":"explore/features/#text-to-speech-provider-module","title":"Text-To-Speech Provider module","text":"<p>The <code>Text-To-Speech Provider</code> module synthesizes Alexa speech on demand. The <code>Text-To-Speech Provider</code> module requires the <code>Local Voice Control</code> Auto SDK extension.</p> <p>&gt;&gt; Text-To-Speech Provider module reference</p>"},{"location":"explore/features/#extension-modules","title":"Extension modules","text":"<p>Auto SDK provides the following modules in Alexa Auto SDK Extensions at Alexa Developer Portal. Contact your Amazon Solutions Architect (SA) or Partner Manager for access.</p>"},{"location":"explore/features/#alexa-communication-module","title":"Alexa Communication module","text":"<p>The <code>Alexa Communication</code> (or <code>Alexa Comms</code>) module enables users to place two-way Alexa-to-Alexa calls to a remote Alexa device, drop in on a remote Alexa device, or send an announcement to a remote Alexa device.</p>"},{"location":"explore/features/#alexa-custom-assistant-module","title":"Alexa Custom Assistant module","text":"<p>The <code>Alexa Custom Assistant</code> module enables you to develop in-vehicle infotainment (IVI) software in which the user can easily interact with both Alexa and your own branded voice assistant.</p>"},{"location":"explore/features/#amazonlite-module","title":"Amazonlite module","text":"<p>The <code>Amazonlite</code> module enables hands-free voice-initiated interactions with Alexa powered by the Amazonlite wake word detection engine.</p>"},{"location":"explore/features/#device-client-metrics-dcm-module","title":"Device Client Metrics (DCM) module","text":"<p>The <code>DCM</code> module enables the Engine to upload Auto SDK performance metrics, such as user-perceived latency, to the Amazon cloud.</p>"},{"location":"explore/features/#geolocation-module","title":"Geolocation module","text":"<p>The <code>Geolocation</code> module adds location consent features to Auto SDK. Without the <code>Geolocation</code> module, the user consents to share location with Alexa while registering the head unit to their Amazon account (i.e., during the sign in flow). With <code>Geolocation</code>, the user can provide or revoke consent directly from your application.</p>"},{"location":"explore/features/#local-voice-control-lvc-extension","title":"Local Voice Control (LVC) extension","text":"<p>The <code>Local Voice Control</code> (<code>LVC</code>) extension provides several modules that work together to enable features\u2014car control, calling, navigation, local search, entertainment, and more\u2014without an internet connection. In addition to Auto SDK modules, the LVC extension provides separate components that run a local Alexa endpoint inside the vehicle head unit.</p>"},{"location":"explore/features/#local-voice-control-module","title":"Local Voice Control module","text":"<p>The<code>Local Voice Control</code> module adds core functionality to Auto SDK to enable offline features. The module infrastructure bridges the Auto SDK Engine to the offline Alexa endpoint running in the head unit and is necessary for all other modules in the LVC extension.</p>"},{"location":"explore/features/#local-skill-service-module","title":"Local Skill Service module","text":"<p>The <code>Local Skill Service</code> module provides a multipurpose service to the Auto SDK Engine that enables components running alongside the offline Alexa endpoint to communicate with the Auto SDK Engine. The <code>Local Skill Service</code> infrastructure is necessary for other modules in the LVC extension.</p>"},{"location":"explore/features/#local-navigation-module","title":"Local Navigation module","text":"<p>The <code>Local Navigation</code> module enables you to provide customers with offline Alexa local search and navigation to points of interest and addresses.</p>"},{"location":"explore/features/#address-book-local-service-module","title":"Address Book Local Service module","text":"<p>The <code>Address Book Local Service</code> module works with the <code>Address Book</code> module and the <code>Local Skill Service</code> module to augment the offline communications and navigation capabilities of Alexa with the user's phone contacts and favorite navigation locations.</p>"},{"location":"explore/features/#car-control-local-service-module","title":"Car Control Local Service module","text":"<p>The <code>Car Control Local Service</code> module works with the <code>Car Control</code> module and the <code>Local Skill Service</code> module to enable users to control vehicle features offline with Alexa.</p>"},{"location":"explore/features/address-book/","title":"Address Book Module","text":""},{"location":"explore/features/address-book/#overview","title":"Overview","text":"<p>The <code>Address Book</code> module enables your Alexa Auto SDK client application to augment the communication and navigation capabilities of Alexa with the user's contacts and favorite addresses. By using this module in your application, the user can upload their phone contacts or navigation favorites to Alexa.</p> <p>This module works alongside the <code>Phone Control</code> module for calling contacts on a paired phone (e.g., \"Alexa, call Mom\") and the <code>Navigation</code> module for requesting directions to favorite destinations (e.g., \"Alexa, take me to work\"). Additionally, these features are supported offline if your application integrates with the modules of the Local Voice Control (LVC) extension.</p> <p>The user contacts and favorite addresses uploaded with the <code>Address Book</code> module are only available for use on the head unit that uploaded them and not any other Alexa devices.</p> <p>Note: To use the Address Book functionality, your product must be placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details.</p>"},{"location":"explore/features/address-book/#managing-address-books","title":"Managing Address Books","text":"<p>Your application's <code>Address Book</code> module integration is responsible for managing the lifecycle of each address book (i.e., a set of contacts or navigation favorites). These responsibilities include the following:</p> <ul> <li>Prior to uploading any address books to the Auto SDK Engine, obtain consent from the user to allow Alexa to access their data.</li> <li>If the user revokes the permission for Alexa to access their data, immediately notify the Engine to remove the address book(s) so the Engine can delete the data from Alexa. Your implementation must ensure that the address books are removed successfully.</li> <li>If a previously uploaded address book becomes unavailable, such as when the user disconnects their phone from the head unit, notify the Engine to remove the address book. When the address book is available again, such as when the user reconnects their phone, notify the Engine to upload the address book again.</li> <li>Upload address books after starting the Engine if the user already granted permission. By default, the Engine deletes all address books from Alexa at Engine start to account for any cases in which deletion previously failed (e.g., network connection issues). This ensures the user's data is up-to-date across ignition cycles. However, note that there is an option to reduce the frequency of address book uploads described below.</li> </ul>"},{"location":"explore/features/address-book/#reducing-data-usage","title":"Reducing Data Usage","text":"<p>Note: The below enhancement is not available for applications that use the LVC extension.</p> <p>Since uploading an address book might consume significant data, your <code>Address Book</code> module integration has an option to reduce the data usage of repeated uploads. You can disable automatic address book removal at Engine start by providing the configuration specified in the Configuring the Address Book Module section.</p> <p>If your integration disables the automatic address book deletion at Engine start, an address book might not need to be uploaded to Alexa at every start. Skip reuploading address books when all of the following conditions are true:</p> <ul> <li>The last successful upload was less than 30 days ago. Note that Alexa periodically removes uploaded address books to comply with the Alexa data retention policy, so Amazon recommends reuploading the address books after 30 days.</li> <li>The user connects the same phone used for the last successful upload.</li> <li>The phone contacts and navigation favorites on the phone are the same as the address book contents of the last successful upload.</li> </ul>"},{"location":"explore/features/address-book/#configuring-the-address-book-module","title":"Configuring the Address Book Module","text":"<p>To configure the <code>Address Book</code> module, use the \"aace.addressBook\" JSON object specified below in your Engine configuration:</p> <pre><code>{\n    \"aace.addressBook\": {\n        \"cleanAllAddressBooksAtStart\": {{BOOLEAN}}\n    }\n}\n</code></pre> Property Type Required Description Example aace.addressBook.cleanAllAddressBooksAtStart boolean No Whether the Engine should automatically delete all of the user's address books from Alexa at Engine start. This defaults to true if the configuration is omitted. false <p>Note: The  \"aace.addressBook\" configuration is optional since its only property is optional.</p> <p>Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an <code>EngineConfiguration</code> from that file, or you can use the provided configuration factory function <code>aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig</code> to programmatically construct the <code>EngineConfiguration</code> in the proper format.</p> <p>Click to expand or collapse AddressBookConfiguration C++ sample code</p> <pre><code>#include &lt;AACE/AddressBook/AddressBookConfiguration.h&gt;\n\nstd::vector&lt;std::shared_ptr&lt;aace::core::config::EngineConfiguration&gt;&gt; configurations;\n\nauto addressBookConfig = aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig(false);\nconfigurations.push_back(addressBookConfig);\n\n// ... create other EngineConfiguration objects and add them to configurations...\n\nm_engine-&gt;configure(configurations);\n</code></pre>"},{"location":"explore/features/address-book/#using-the-address-book-module-aasb-messages","title":"Using the Address Book Module AASB Messages","text":""},{"location":"explore/features/address-book/#uploading-an-address-book","title":"Uploading an Address Book","text":"<p>To upload an address book to Alexa, publish the <code>AddAddressBook</code> message. The Engine publishes the <code>AddAddressBookReply</code> message to indicate upload completion or failure.</p> <p>Click to expand or collapse sequence diagram: Uploading Contacts </p> <p></p> <p>Click to expand or collapse sequence diagram: Uploading Navigation Favorites </p> <p></p>"},{"location":"explore/features/address-book/#removing-an-address-book","title":"Removing an Address Book","text":"<p>To remove an address book to Alexa, publish the <code>RemoveAddressBook</code> message. The Engine publishes the <code>RemoveAddressBookReply</code> message to indicate removal completion or failure.</p> <p>Click to expand or collapse sequence diagram: Removing Contacts </p> <p></p> <p>Click to expand or collapse sequence diagram: Removing Navigation Favorites </p> <p></p>"},{"location":"explore/features/address-book/#integrating-the-address-book-module-into-your-application","title":"Integrating the Address Book Module Into Your Application","text":""},{"location":"explore/features/address-book/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to publish \"AddressBook\" AASB messages and subscribe to their replies.</p> <p>Click to expand or collapse C++ sample code</p> <p></p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/AddressBook/AddressBook/ContactName.h&gt;\n#include &lt;AASB/Message/AddressBook/AddressBook/NavigationName.h&gt;\n#include &lt;AASB/Message/AddressBook/AddressBook/PhoneData.h&gt;\n#include &lt;AASB/Message/AddressBook/AddressBook/PostalAddress.h&gt;\n\n#include &lt;AASB/Message/AddressBook/AddressBook/AddAddressBookMessage.h&gt;\n#include &lt;AASB/Message/AddressBook/AddressBook/RemoveAddressBookMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyAddressBookHandler {\n\n// Subscribe to reply messages from the Engine\nvoid MyAddressBookHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleAddAddressBookReplyMessage(message); },\nAddAddressBookMessageReply::topic(),\nAddAddressBookMessageReply::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleRemoveAddressBookReplyMessage(message); },\nRemoveAddressBookMessageReply::topic(),\nRemoveAddressBookMessageReply::action());\n}\n\n// Handle the AddAddressBook reply message from the Engine\nvoid MyAddressBookHandler::handleAddAddressBookReplyMessage(const std::string&amp; message) {\nAddAddressBookMessageReply msg = json::parse(message);\n\nstd::string messageId = msg.header.messageDescription.replyToId;\nbool uploadWasSuccessful = msg.payload.success;\n\n// ...Handle the upload result for the message...\n}\n\n// Handle the RemoveAddressBook reply message from the Engine\nvoid MyAddressBookHandler::handleRemoveAddressBookReplyMessage(const std::string&amp; message) {\nRemoveAddressBookMessageReply msg = json::parse(message);\n\nstd::string messageId = msg.header.messageDescription.replyToId;\nbool uploadWasSuccessful = msg.payload.success;\n\n// ...Handle the removal result for the message...\n}\n\n// To upload contacts to Alexa, publish an AddAddressBook message to the Engine\nbool MyAddressBookHandler::uploadContacts(\nconst std::string&amp; id,\nconst std::string&amp; name) {\nAddAddressBookMessage msg;\nmsg.payload.addressBookSourceId = id;\nmsg.payload.name = name;\nmsg.payload.type = AddressBookType::CONTACT;\nmsg.payload.addressBookData = populateContacts(id);\n\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the AddAddressBookReply message\n// Return the success status from reply message payload\n}\n\nAddressBook MyAddressBookHandler::populateContacts(const std::string&amp; id) {\n// Populate an AddressBook object with the contacts data from the connected phone\nAddressBook addressBook;\n\n// For each contact, add a ContactName to addressBook.contactNames\n// and add a PhoneData to addressBook.phoneData\n// ...\n\nreturn addressBook;\n}\n\n// To upload navigation favorites to Alexa, publish an AddAddressBook message to the Engine\nbool MyAddressBookHandler::uploadNavigationFavorites(\nconst std::string&amp; id,\nconst std::string&amp; name) {\nAddAddressBookMessage msg;\nmsg.payload.addressBookSourceId = id;\nmsg.payload.name = name;\nmsg.payload.type = AddressBookType::NAVIGATION;\nmsg.payload.addressBookData = populateNavigationFavorites(id);\n\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the AddAddressBookReply message\n// Return the success status from reply message payload\n}\n\nAddressBook MyAddressBookHandler::populateNavigationFavorites(const std::string&amp; id) {\n// Populate an AddressBook object with the navigation favorites data from the head unit\nAddressBook addressBook;\n\n// For each navigation address, add a NavigationName to addressBook.navigationNames\n// and add a PostalAddress to addressBook.postalAddresses\n// ...\n\nreturn addressBook;\n}\n\n// To remove an address book, publish a RemoveAddressBook message to the Engine\nbool MyAddressBookHandler::removeAddressBook(const std::string&amp; id) {\nRemoveAddressBookMessage msg;\nmsg.payload.addressBookSourceId = id;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the RemoveAddressBookReply message\n// Return the success status from reply message payload\n}\n\n};\n</code></pre>"},{"location":"explore/features/alexa/","title":"Alexa Module","text":""},{"location":"explore/features/alexa/#overview","title":"Overview","text":"<p>The Alexa Auto SDK Alexa module provides interfaces for standard Alexa features. The Engine handles steps to send events and sequence directives so you can focus on using the provided AASB messages to interact with Alexa.</p>"},{"location":"explore/features/alexa/#configure-the-alexa-module","title":"Configure the Alexa module","text":"<p>The <code>Alexa</code> module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions.</p> <p>Your application must provide the <code>aace.alexa</code> configuration in the same format as the example specified below. Alternatively, use the <code>AlexaConfiguration</code> factory functions to generate individual elements of this configuration.</p> <pre><code>{\n\"aace.alexa\": {\n\"alexaClientInfo\": {\n\"clientId\": \"${CLIENT_ID}\",\n\"productId\": \"${PRODUCT_ID}\",\n\"amazonId\": \"${AMAZON_ID}\"\n},\n\"avsDeviceSDK\": {\n\"libcurlUtils\": {\n\"CURLOPT_CAPATH\": \"${CERTS_PATH}\"\n},\n\"miscDatabase\": {\n\"databaseFilePath\": \"${DATA_PATH}/miscDatabase.db\"\n},\n\"certifiedSender\": {\n\"databaseFilePath\": \"${DATA_PATH}/certifiedSender.db\"\n},\n\"alertsCapabilityAgent\": {\n\"databaseFilePath\": \"${DATA_PATH}/alertsCapabilityAgent.db\"\n},\n\"notifications\": {\n\"databaseFilePath\": \"${DATA_PATH}/notifications.db\"\n},\n\"capabilitiesDelegate\": {\n\"databaseFilePath\": \"${DATA_PATH}/capabilitiesDatabase.db\"\n},\n\"deviceSettings\": {\n\"databaseFilePath\": \"${DATA_PATH}/deviceSettings.db\",\n\"defaultLocale\":\"en-US\",\n\"localeCombinations\": [\n[\"{{STRING}}\",\"{{STRING}}\"],\n[\"{{STRING}}\", \"{{STRING}}\"],\n...\n],\n\"defaultTimezone\":\"America/Vancouver\"\n}\n},\n\"requestMediaPlayback\": {\n\"mediaResumeThreshold\": 20000\n}\n},\n\"aasb.alexa\": {\n\"LocalMediaSource\": {\n\"types\": [\"FM_RADIO\", \"AM_RADIO\",\"BLUETOOTH\", \"USB\", \"SATELLITE_RADIO\",\n\"LINE_IN\", \"COMPACT_DISC\", \"DAB\", \"DEFAULT\"]\n}\n}\n}\n</code></pre> <p>The <code>alexaClientInfo</code> field contains the details of the Alexa client. The fields <code>libcurlUtils</code>, <code>miscDatabase</code>, <code>certifiedSender</code>, <code>alertsCapabilityAgent</code>, <code>notifications</code>, and <code>capabilitiesDelegate</code> specify the respective database file paths.</p> <p>The <code>deviceSettings</code> field specifies the settings on the device. The following list describes the settings:</p> <ul> <li><code>databaseFilePath</code> is the path to the SQLite database that stores persistent settings. The database will be created on initialization if it does not already exist.</li> <li><code>defaultLocale</code> specifies the default locale setting, which is Alexa's locale setting until updated on the device. The default value of <code>defaultLocale</code> is \u201cen-US\u201d.</li> <li><code>locales</code> specifies the list of locales supported by the device. The default value is <code>[\"en-US\",\"en-GB\",\"de-DE\",\"en-IN\",\"en-CA\",\"ja-JP\",\"en-AU\",\"fr-FR\",\"it-IT\",\"es-ES\",\"es-MX\",\"fr-CA\",\"es-US\", \"hi-IN\", \"pt-BR\", \"ar-SA\"]</code>.</li> <li> <p><code>localeCombinations</code> specifies the list of locale pairs available on a device that supports multi-locale mode. Through the Dynamic Language Switching feature, Alexa can communicate with the user of such device in languages specified in the locale pairs. In each pair, the first value is the primary locale, which Alexa uses most often when interacting with the user. The second value is the secondary locale, which specifies an additional language that Alexa uses when responding to an utterance in the corresponding language. For example, if [\"en-US\", \"es-US\"] is declared in <code>localeCombinations</code> and the device specifies this pair as the current locale setting, Alexa primarily operates in English for the U.S. but can understand and respond to utterances in Spanish for the U.S., without requiring the device to update the locale setting.</p> <p>By default, <code>localeCombinations</code> is a list of the following combinations, which are also the supported combinations as of 2021-02-02. It is possible for the default value to be different from the list of supported combinations in the future. For updates to the supported combinations, see the Alexa Voice Service documentation.</p> <ul> <li>[\"en-US\", \"es-US\"]</li> <li>[\"es-US\", \"en-US\"]</li> <li>[\"en-IN\", \"hi-IN\"]</li> <li>[\"hi-IN\", \"en-IN\"]</li> <li>[\"en-CA\", \"fr-CA\"]</li> <li>[\"fr-CA\", \"en-CA\"]</li> <li>[\"en-US\", \"es-ES\"]</li> <li>[\"es-ES\", \"en-US\"]</li> <li>[\"en-US\", \"de-DE\"]</li> <li>[\"de-DE\", \"en-US\"]</li> <li>[\"en-US\", \"fr-FR\"]</li> <li>[\"fr-FR\", \"en-US\"]</li> <li>[\"en-US\", \"it-IT\"]</li> <li>[\"it-IT\", \"en-US\"]</li> <li>[\"en-US\", \"ja-JP\"]</li> <li>[\"ja-JP\", \"en-US\"]</li> </ul> <p>When a device operates in multi-locale mode, an application can select any locale pair in the list above as the locale setting if the following conditions are met:</p> <ul> <li>The device's primary locale setting is the first locale in the selected pair.</li> <li>The device also supports the secondary locale in the pair.</li> <li>The pair is specified in <code>localeCombinations</code>.</li> </ul> <p>Note: Dynamic Language Switching is only available in online mode.</p> </li> </ul>"},{"location":"explore/features/alexa/#use-the-alexa-module-interfaces","title":"Use the Alexa module interfaces","text":"<p>Explore the following interfaces to learn how to integrate Alexa features in your application.</p>"},{"location":"explore/features/alexa/#invoke-alexa-with-speechrecognizer","title":"Invoke Alexa with SpeechRecognizer","text":"<p>Use <code>SpeechRecognizer</code> to capture the user's speech with the microphone when the user invokes Alexa.</p> <p>SpeechRecognizer interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#play-alexa-speech-to-the-user-with-speechsynthesizer","title":"Play Alexa speech to the user with SpeechSynthesizer","text":"<p>Use <code>SpeechSynthesizer</code> to provide an audio output channel for the Engine to play back Alexa's speech to the user.</p> <p>SpeechSynthesizer interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#track-alexa-state-changes-with-alexaclient","title":"Track Alexa state changes with AlexaClient","text":"<p>Use the <code>AlexaClient</code> interface to observe changes in Alexa's connection and attention state when building the UI for your application.</p> <p>AlexaClient interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#start-the-out-of-box-experience-with-devicesetup","title":"Start the out-of-box experience with DeviceSetup","text":"<p>Trigger an out-of-box introductory conversation with Alexa experience using the <code>DeviceSetup</code> interface.</p> <p>DeviceSetup interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#find-things-to-try-with-featurediscovery","title":"Find things to try with FeatureDiscovery","text":"<p>Use <code>FeatureDiscovery</code> to display dynamic suggested utterances that help users discover new features.</p> <p>FeatureDiscovery interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#display-cards-on-screen-with-templateruntime","title":"Display cards on screen with TemplateRuntime","text":"<p>Provide a visual experience by building a UI based on the templates and media playback info provided by <code>TemplateRuntime</code>.</p> <p>TemplateRuntime interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#stream-alexa-media-content-with-audioplayer","title":"Stream Alexa media content with AudioPlayer","text":"<p>AudioPlayer interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#press-media-playback-control-buttons-with-playbackcontroller","title":"Press media playback control buttons with PlaybackController","text":"<p>PlaybackController interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#adjust-equalizer-settings-with-equalizercontroller","title":"Adjust equalizer settings with EqualizerController","text":"<p>EqualizerController interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#resume-media-playback-at-startup-with-mediaplaybackrequestor","title":"Resume media playback at startup with MediaPlaybackRequestor","text":"<p>MediaPlaybackRequestor interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#control-local-media-with-localmediasource","title":"Control local media with LocalMediaSource","text":"<p>LocalMediaSource interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#deep-link-into-external-media-apps-with-externalmediaadapter","title":"Deep link into external media apps with ExternalMediaAdapter","text":"<p>ExternalMediaAdapter interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#control-volume-with-alexaspeaker","title":"Control volume with AlexaSpeaker","text":"<p>AlexaSpeaker interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#render-notification-indicators-with-notifications","title":"Render notification indicators with Notifications","text":"<p>Notifications interface&gt;&gt;</p>"},{"location":"explore/features/alexa/#block-notifications-with-donotdisturb","title":"Block notifications with DoNotDisturb","text":"<p>DoNotDisturb interface&gt;&gt;</p>"},{"location":"explore/features/alexa/AlexaClient/","title":"AlexaClient Interface","text":""},{"location":"explore/features/alexa/AlexaClient/#render-alexas-attention-state","title":"Render Alexa's attention state","text":"<p>Your application can subscribe to the <code>AlexaClient.DialogStateChanged</code> message to be notified what state Alexa dialog is in (e.g., Alexa started listening to the user's speech or started speaking her response). This message helps your application render Alexa's attention state UI such as Voice Chrome and audio cues without having to derive these states by tracking your application's microphone and media player.</p> <p>The following diagram shows how you might use the dialog state changes to provide Alexa attention feedback during an interaction.</p> Click to expand or collapse sequence diagram: Alexa invocation <p></p> <p></p>"},{"location":"explore/features/alexa/AlexaClient/#monitor-alexas-connection-status","title":"Monitor Alexa's connection status","text":"<p>Your application can subscribe to the <code>AlexaClient.ConnectionStatusChanged</code> message to be notified when the status of the Engine's connection to Alexa has changed (e.g., the Engine lost connection to Alexa). You might use this information, for instance, to enable or disable certain functionality or display information to the user.</p>"},{"location":"explore/features/alexa/AlexaClient/#monitor-alexas-authorization-state","title":"Monitor Alexa's authorization state","text":"<p>Your application can subscribe to the <code>AlexaClient.AuthStateChanged</code> message to be notified what state the Engine is in with respect to the user sign in. For example, the state is <code>REFRESHED</code> when the Engine has an access token.</p>"},{"location":"explore/features/alexa/AlexaSpeaker/","title":"AlexaSpeaker Interface","text":"<p>The Alexa service keeps track of two device volume types: <code>ALEXA_VOLUME</code> and <code>ALERTS_VOLUME</code>. The <code>aace::alexa::AlexaSpeaker</code> class should be implemented by the platform to both set the volume and mute state of these two speaker types and allow the user to set the volume and mute state of these two speaker types locally via GUI if applicable.</p> <p><code>SpeakerManager</code> is a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\".</p> <p>You can programmatically generate speaker manager configuration using the <code>aace::alexa::config::AlexaConfiguration::createSpeakerManagerConfig()</code> factory method, or provide the equivalent JSON values in a configuration file.</p> <pre><code>{\n\"aace.alexa\": {\n\"speakerManager\": {\n\"enabled\": false\n}\n}\n}\n</code></pre>"},{"location":"explore/features/alexa/AlexaSpeaker/#set-a-custom-volume-range","title":"Set a custom volume range","text":"<p>You can use a custom volume control to support an Alexa device's native input volume range. By default, Alexa supports voice utterances that specify volume values between 0 and 10, but some devices may support a different range (i.e. 0 to 100). By placing on Amazon's allow list your Alexa device's volume range for your target platform, you can specify input volume levels per your device's range. Your device's input volume range is then mapped appropriately to the Alexa volume range.</p> <p>Contact your Alexa Auto Solution Architect (SA) for help with allow lists. Placing a device on the allow list requires the following parameters:</p> <ul> <li>DeviceTypeID: <code>&lt;YOUR_DEVICE_TYPE_ID&gt;</code></li> <li>Min: <code>&lt;YOUR_MIN_VOLUME_VALUE&gt;</code></li> <li>Max: <code>&lt;YOUR_MAX_VOLUME_VALUE&gt;</code></li> </ul> <p>This does not impact the range used in the directives to the device. You must continue to use the SDK 0-100 volume range used by <code>AudioOutput</code> and <code>AlexaSpeaker</code> and map these values to the correct range in your implementation.</p>"},{"location":"explore/features/alexa/AudioPlayer/","title":"AudioPlayer Interface","text":"<p>When an audio media stream is received from Alexa, it is the responsibility of the platform implementation to play the stream in a platform-specific media player. The <code>aace::alexa::AudioPlayer</code> class informs the platform of the changes in player state being tracked by the Engine. This can be used to update the platform GUI, for example.</p> <p>To implement a custom handler for audio player output, subscribe to <code>AudioPlayer</code> messages:</p> <pre><code>// Include necessary message header files\n#include \"AASB/Message/Alexa/AudioPlayer/GetPlayerDurationMessage.h\"\n#include \"AASB/Message/Alexa/AudioPlayer/GetPlayerPositionMessage.h\"\n#include \"AASB/Message/Alexa/AudioPlayer/PlayerActivityChangedMessage.h\"\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\n// Subscribe to corresponding messages with handlers\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nPlayerActivityChangedMessage msg = json::parse(message);\n// Handle player activity change\n},\nPlayerActivityChangedMessage::topic(),\nPlayerActivityChangedMessage::action());\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nGetPlayerDurationMessageReply msg = json::parse(message);\n// Handle received duration\n},\nGetPlayerDurationMessageReply::topic(),\nGetPlayerDurationMessageReply::action());\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nGetPlayerPositionMessageReply msg = json::parse(message);\n// Handle received position\n},\nGetPlayerPositionMessageReply::topic(),\nGetPlayerPositionMessageReply::action());\n</code></pre>"},{"location":"explore/features/alexa/AudioPlayer/#view-media-metadata-on-screen-with-templateruntime","title":"View media metadata on screen with TemplateRuntime","text":"<p>Your application subscribes to the <code>TemplateRuntime.RenderPlayerInfo</code> AASB message to receive metadata about the active media playback for you to display. See the TemplateRuntime AVS documentation for details about the payload.</p>"},{"location":"explore/features/alexa/AudioPlayer/#manage-multiple-audio-activities","title":"Manage multiple audio activities","text":"<p>Alexa can manage multiple audio activities at the same time. For example, an <code>AudioPlayer</code> activity can be paused in the background while another <code>ExternalMediaPlayer</code> activity is playing on the foreground. User can control these audio activities with their voice or by interacting with GUI on the vehicle. When a user makes an ambiguous request or switches activity on the GUI locally, it's necessary to let Alexa cloud know which activity is active (or in foucs) so that Alexa can respond correctly.</p> <p><code>SetAsForegroundActivity</code> message enables the app to set the Alexa <code>AudioPlayer</code> interface as the foreground player the user sees on screen. This message is useful for scenarios in which the user played an <code>AudioPlayer</code> media source, then played a different Alexa-aware <code>ExternalMediaPlayer</code> media source, such as a deep-linked media app or a local media source, and then manually returned visual activity to the Alexa <code>AudioPlayer</code> GUI. Publishing <code>SetAsForegroundActivity</code> message ensures the next VUI command or GUI interaction with the playback control buttons acts on the <code>AudioPlayer</code> source rather than the more recently played <code>ExternalMediaPlayer</code> source:</p> <pre><code>#include \"AASB/Message/Alexa/AudioPlayer/SetAsForegroundActivityMessage.h\"\nusing namespace aasb::message::alexa::audioPlayer;\n...\nSetAsForegroundActivityMessage msg;\nm_messageBroker-&gt;publish(msg);\n</code></pre> <p>Note that the <code>AudioPlayer</code> had to be previously playing at least once during this Engine cycle in order for this message to make Alexa act on <code>AudioPlayer</code>.</p>"},{"location":"explore/features/alexa/DeviceSetup/","title":"DeviceSetup Interface","text":"<p>Note: This feature requires Amazon to allowlist your device. For help, contact your Amazon Solutions Architect or partner manager.</p> <p>After the user signs in to your application during or after the out-of-box experience, your application starts the Engine and publishes the <code>DeviceSetup.SetupCompleted</code> message to notify Alexa that the setup is complete. The Engine publishes the <code>DeviceSetup.SetupCompletedResponse</code> to your application to indicate Alexa was notified successfully. In response to the <code>SetupCompleted</code> event, Alexa starts an onboarding experience including a short first-time conversation with the user. </p> <p>Because <code>SetupCompleted</code> triggers an onboarding experience, do not publish the message if the signed-in user has already seen the experience. The onboarding experience is for first-time users only and might differ for returning users.</p> <p>Note: Do not publish the <code>SetupCompleted</code> message if user is in Connectivity mode or Preview Mode or if the user has disabled hands-free listening. Publishing <code>SetupCompleted</code> in these conditions causes undesirable user experience.</p>"},{"location":"explore/features/alexa/DoNotDisturb/","title":"DoNotDisturb Interface","text":"<p>The DoNotDisturb (DND) interface allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on.  For details, see the DND Interface documentation. The Engine uses the registered DND implementation to notify the client when DND has been set or unset. A user's voice request to change the DND state triggers audio playback, but no audio playback occurs when a user sets the DND state using the touch screen.</p> <p>To implement a custom handler for DND extend the <code>DoNotDisturb</code> class:</p> <pre><code>#include \"AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h\"\n#include \"AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h\"\nusing namespace aasb::message::alexa::doNotDisturb;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nSetDoNotDisturbMessage msg = json::parse(message);\n\n},\nSetDoNotDisturbMessage::topic(),\nSetDoNotDisturbMessage::action());\n\n// Publish the \"DoNotDisturbChanged\" message\nDoNotDisturbChangedMessage msg;\nmsg.payload.doNotDisturb = true;\nm_messageBroker-&gt;publish(msg);\n</code></pre>"},{"location":"explore/features/alexa/EqualizerController/","title":"EqualizerController Interface","text":"<p>The Equalizer Controller enables Alexa voice control of the device's audio equalizer settings, which includes making gain level adjustments to any of the supported frequency bands (\"BASS\", \"MIDRANGE\", and/or \"TREBLE\") using the device's onboard audio processing.</p> <p>The platform implementation is responsible for the following:</p> <ul> <li>Determining how each supported band affects the audio</li> <li>Mapping Alexa's equalizer bands to the bands supported on the device, if they do not directly correspond</li> <li>Scaling Alexa's level values as necessary so that each step corresponds to one decibel of amplitude gain on the device</li> <li>Applying equalization to only selected portions of the audio output so that Alexa's speech, alarms, etc. will not be affected</li> <li>Persisting settings across power cycles</li> </ul> <p>You can programmatically generate Equalizer Controller configuration with details such as supported bands, default state, and decibel adjustment range using the <code>aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig()</code> factory method, or provide the equivalent JSON values in a configuration file.</p> <pre><code>{\n\"aace.alexa\" {\n\"equalizer\": {\n\"bands\": {\n\"BASS\": true,\n\"MIDRANGE\": false,\n\"TREBLE\": true\n},\n\"defaultState\": {\n\"bands\": {\n\"BASS\": 4,\n\"TREBLE\": -1\n}\n},\n\"minLevel\": -6,\n\"maxLevel\": 6\n}\n}\n}\n</code></pre> <p>For example, 2 supported bands with amplitude gains ranging from -8dB to +8dB, each with a default of 0dB</p> <pre><code>auto eqConfig = aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig(\n{EqualizerBand::BASS, EqualizerBand::TREBLE},\n-8,\n8,\n{ {EqualizerBand::BASS, 0}, {EqualizerBand::TREBLE, 0} } );\nengine-&gt;configure( { //other config objects..., eqConfig, ... } );\n\n...\n</code></pre> <p>To implement a custom handler for Equalizer Controller, subscribe to the <code>EqualizerController</code> messages:</p> <pre><code>#include \"AASB/Message/Alexa/EqualizerController/LocalAdjustBandLevelsMessage.h\"\n#include \"AASB/Message/Alexa/EqualizerController/LocalResetBandsMessage.h\"\n#include \"AASB/Message/Alexa/EqualizerController/LocalSetBandLevelsMessage.h\"\nusing namespace aasb::message::alexa::equalizerController;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nGetBandLevelsMessage msg = json::parse(message);\n// ...\n},\nGetBandLevelsMessage::topic(),\nGetBandLevelsMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nSetBandLevelsMessage msg = json::parse(message);\n// ...\n},\nSetBandLevelsMessage::topic(),\nSetBandLevelsMessage::action());\n...\n\n// If levels are adjusted using local on-device controls, call inherited methods to notify the Engine:\n\n// To set a band to an absolute gain level in decibels\nstd::vector&lt;EqualizerBandLevel&gt; bandLevels{ {EqualizerBand::BASS, 4} }; // Sets bass amplitude to +4dB\nLocalSetBandLevelsMessage msg;\nmsg.payload.bandLevels = bandLevels;\nm_messageBroker-&gt;publish(msg);\n\n// To make a relative adjustment to level settings\nstd::vector&lt;EqualizerBandLevel&gt; bandAdjustments{ {EqualizerBand::BASS, -2} }; // Decreases bass gain by 2dB\nLocalAdjustBandLevelsMessage msg;\nmsg.payload.bandAdjustments = bandAdjustments;\nm_messageBroker-&gt;publish(msg);\n\n// To reset gain levels to the configured defaults (usually 0dB)\nstd::vector&lt;EqualizerBand&gt; bands{EqualizerBand::BASS, EqualizerBand::TREBLE}; // Resets bass and treble bands\nLocalResetBandsMessage msg;\nmsg.payload.bands = bands;\nm_messageBroker-&gt;publish(msg);\n</code></pre>"},{"location":"explore/features/alexa/ExternalMediaAdapter/","title":"ExternalMediaAdapter Interface","text":"<p>The External Media Player (EMP) Adapter allows you to declare and use external media application sources in your application. In order to interface with the EMP Adapter, you must use one of the following:</p> <ul> <li>A media connection client to interface the EMP Adapter to the external app.</li> <li>An embedded media app. For information about external embedded media app solutions, contact your SA or Partner Manager.</li> </ul> <p>Note: If the media app service requires additional customer experience details, incorporate the requirement in your implementation. For example, if the provider requires your application to show the provider's logo in a particular way, modify the implementation to meet the requirement.</p> <p>When advised by your SA or Partner Manager, configure the External Media Player Adapter to the device's capabilities. See <code>aace::alexa::config::AlexaConfiguration::createExternalMediaPlayerConfig</code> for details on configuring the supported agent, or provide the equivalent JSON values in a configuration file.</p> <pre><code>{\n\"aace.alexa\": {\n\"externalMediaPlayer\": {\n\"agent\": \"&lt;agent&gt;\"\n}\n}\n}\n</code></pre> <p>You must register and implement each ExternalMediaAdapter (along with its associated external client or library). After the engine establishes a connection to the Alexa service, you can run discovery to validate each external media application. You can report discovered external media players by calling <code>reportDiscoveredPlayers()</code> at any point during runtime. When the Alexa service recognizes the player, you will get a call to the <code>Authorize</code> message including the player's authorization status. Both the <code>reportDiscoveredPlayers()</code> method and the <code>Authorize</code> message can contain one or more players in their JSON payloads. Validating the application enables Alexa to exercise playback control over the registered source type.</p> <p>The <code>Login</code> and <code>Logout</code> messages inform AVS of login state changes, if applicable. If your application has the ability to handle cloud-based login and logout, you should also publish the <code>LoginComplete</code> and <code>LogoutComplete</code> messages where appropriate.</p> <p>When the user makes an Alexa voice request (for example, \"Play Spotify\"), the <code>Play</code> message is sent. This message contains various fields, including the player id of the player to which the playback information should be routed.</p> <p>Whether through voice or GUI event, the <code>PlayControl</code> message is sent with the relevant <code>PlayControlType</code>. Similar to <code>Play</code> the control should be routed to the appropriate player.</p> <p>The <code>PlayControlType</code> is determined by player's <code>supportedOperations</code>, which are specified by your implementation in the reply message of <code>GetState</code>.</p> <p>The <code>ExternalMediaAdapter</code> interface provides messages <code>PlayerEvent</code> and <code>PlayerError</code> for your implementation to report events regarding the state of the playback session managed by your external player. Even though your player manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the <code>PlayerEvent</code> and <code>PlayerError</code> calls provide important information to the Engine:</p> <ol> <li> <p>The Engine may use calls to these methods to synchronize the state of your player\u2019s playback session with Alexa.</p> </li> <li> <p>The Engine may react to these calls according to the event name specified to update its internal view of your player\u2019s state. Particular event names indicate if the player is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management.</p> </li> </ol> <p>The tables below describe each supported event name and what it means to the Engine. Usage of these events depends on the particular type of player controlled by the <code>ExternalMediaAdapter</code> instance, so contact your Solutions Architect (SA) or Partner Manager for guidance regarding supported embedded and external app solutions.</p> PlayerEvent name Description \"PlaybackSessionStarted\" A new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackStarted\" During an active session, the player has started to play or resumed from a paused state. The Engine considers the player active and in focus. \"TrackChanged\" During an active session, one track has ended and another has started. The Engine uses this primarily for state reporting. \"PlaybackNext\" During an active session, the player skipped from one track to the next track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlaybackPrevious\" During an active session, the player skipped from one track to the previous track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlayModeChanged\" During an active session, some user setting for the track or playback session changed, such as the favorite setting or the shuffle mode. The Engine uses this primarily for state reporting. \"PlaybackStopped\" During an active session, the player has paused or stopped, either as a result of a GUI interaction or a user voice request to Alexa. The Engine considers the player active and in focus, just not currently playing. User voice requests to resume still control the player. \"PlaybackSessionEnded\" An active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. PlayerError name Description \"INTERNAL_ERROR\" Any fatal player error has occurred \"UNKNOWN_ERROR\" An unknown error occurred \"UNPLAYABLE_BY_AUTHORIZATION\" The media couldn't be played due to an unauthorized account \"UNPLAYABLE_BY_STREAM_CONCURRENCY\" The media couldn't be played due to the number of accounts currently streaming \"UNPLAYABLE_BY_ACCOUNT\" The media couldn't be played due to the account type \"UNPLAYABLE_BY_REGION\" The media couldn't be played due to the current region \"UNPLAYABLE_BY_PARENTAL_CONTROL\" The media couldn't be played due to parental settings \"UNPLAYABLE_BY_SUBSCRIPTION\" The media couldn't be played due to the subscription type \"OPERATION_REJECTED_UNINTERRUPTIBLE\" The operation could not be performed due to non interruptible media \"OPERATION_REJECTED_END_OF_QUEUE\" The operation could not be performed due to the end of media being reached \"OPERATION_UNSUPPORTED\" The operation was not supported \"OPERATION_REJECTED_SKIP_LIMIT\" The operation failed because a skip limit was reached \"PLAYER_UNKNOWN\" An unknown player was detected \"PLAYER_NOT_FOUND\" The player was not discovered \"PLAYER_CONNECTION_REJECTED\" The connection to the player failed \"PLAYER_CONNECTION_TIMEOUT\" The connection to the player timed out <p>The <code>Seek</code> and <code>AdjustSeek</code> messages are invokable via Alexa if the currently in-focus external player supports them. <code>Seek</code> specifies an absolute offset, whereas <code>AdjustSeek</code> specifies a relative offset.</p> <p>The <code>VolumeChanged</code> and <code>MutedStateChanged</code> messages are invoked to change the volume and mute state of the currently-focused external player. <code>VolumeChanged</code> specifies the new volume. <code>MutedStateChanged</code> specifies the new <code>MutedState</code>.</p> <p>The <code>GetState</code> message is called to synchronize the external player's state with the cloud. This method is used to maintain correct state during startup, and after every Alexa request.</p> <p>You construct the <code>ExternalMediaAdapterState</code> object using the data taken from the media app connection client or embedded player app (associated via <code>localPlayerId</code>) and return the state information.</p> <p>The following table describes the fields comprising a <code>ExternalMediaAdapterState</code>, which includes two sub-components: <code>PlaybackState</code>, and <code>SessionState</code>.</p> State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedOperation trackOffset long No optional shuffleEnabled boolean Yes report shuffle status repeatEnabled boolean Yes report repeat status favorites Favorites No see Favorites type String Yes must be set as \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No empty trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType Yes see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean Yes true if the application is in an active state accessToken String No empty tokenRefreshInterval long No empty playerCookie String No A player may declare arbitrary information for itself spiVersion String Yes must be set as \"1.0\" <p><code>supportedOperations</code> should be a list of the operations that the external media adapter supports. Below is a list of all possible <code>supportedOperations</code>.</p> <pre><code>SupportedPlaybackOperation.PLAY,\nSupportedPlaybackOperation.PAUSE,\nSupportedPlaybackOperation.STOP,\nSupportedPlaybackOperation.PREVIOUS,\nSupportedPlaybackOperation.NEXT,\nSupportedPlaybackOperation.ENABLE_SHUFFLE,\nSupportedPlaybackOperation.DISABLE_SHUFFLE,\nSupportedPlaybackOperation.ENABLE_REPEAT_ONE,\nSupportedPlaybackOperation.ENABLE_REPEAT,\nSupportedPlaybackOperation.DISABLE_REPEAT,\nSupportedPlaybackOperation.SEEK,\nSupportedPlaybackOperation.ADJUST_SEEK,\nSupportedPlaybackOperation.FAVORITE,\nSupportedPlaybackOperation.UNFAVORITE,\nSupportedPlaybackOperation.FAST_FORWARD,\nSupportedPlaybackOperation.REWIND,\nSupportedPlaybackOperation.START_OVER\n</code></pre> <p>Note: Currently PLAY/PAUSE/STOP will always be supported for a source. Passing null will allow ALL supported operations for the source.</p>"},{"location":"explore/features/alexa/FeatureDiscovery/","title":"FeatureDiscovery Interface","text":""},{"location":"explore/features/alexa/FeatureDiscovery/#overview","title":"Overview","text":"<p>The <code>Feature Discovery</code> interface enables your Alexa Auto SDK client application to dynamically retrieve the Alexa utterances (hints) from the cloud, helping the customers to discover Alexa features and learn how to use Alexa in the different domains.</p> <p>To use the Feature Discovery functionality, your product must be onboarded and placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details.</p> <p>Auto SDK provides the FeatureDiscovery AASB message interface for your application to request a list of suggested utterances. In your application, publish the <code>GetFeatures</code> message to request a list of utterances associated with the specified <code>domain</code> and <code>eventType</code>. Subscribe to the <code>GetFeatures</code> reply message to receive the response.</p> <p>Note: The Auto SDK Engine does not cache the suggested utterances returned by Alexa. Therefore, your application is responsible for implementing caching mechanism for the utterances and deciding when to refresh the local cache.</p>"},{"location":"explore/features/alexa/FeatureDiscovery/#getfeatures-request","title":"GetFeatures Request","text":"<p>The <code>GetFeatures</code> message requests the suggested utterances from Alexa. The <code>discoveryRequests</code> field is a string containing an escaped JSON with the following format:</p> <pre><code>[\n{\n\"locale\" : {{String}},\n\"domain\" : {{String}},\n\"eventType\" : {{String}},\n\"limit\": {{Integer}}\n},\n...\n]\n</code></pre> <p>Definition of the DiscoveryRequests JSON array:</p> Property Type Required Description discoveryRequests List\\&lt;DiscoveryRequest&gt; Yes An array of feature discovery requests <p>Definition of each DiscoveryRequest JSON Object:</p> Property Type Required Description Example domain String Yes The category of the utterances to be returned. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String Yes The event type of the utterances to be returned. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String No The locale of the utterances to be returned. If omitted, the Alexa locale retrieved by <code>PropertyManager</code> will be used in the request. For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation. \"en-US\" limit Integer No The maximum number of utterances to return. The default value is 1. 5 <p>Note: When requesting the utterances, you can combine multiple discovery requests in one <code>GetFeatures</code> message by specifying multiple discovery request objects in the <code>discoveryRequests</code> JSON array. The Auto SDK Engine will reply with a single <code>GetFeatures</code> message that contains a merged response of the multiple requests. If you specify multiple request objects in the <code>GetFeatures</code> message, expect more latency to receive the message reply.</p>"},{"location":"explore/features/alexa/FeatureDiscovery/#domain-and-eventtype","title":"Domain and EventType","text":"<p>Each utterance configured in the Alexa cloud is associated with a scenario, which is a combination of <code>domain</code> and <code>eventType</code>. The combination determines where the utterance should be displayed. When requesting Alexa utterances, your application must specify the <code>domain</code> and <code>eventType</code> values in the <code>GetFeatures</code> message payload.</p> Property Type Accepted Values domain String \"GETTING_STARTED\", \"TALENTS\", \"ENTERTAINMENT\", \"COMMS\", \"WEATHER\", \"SMART_HOME\", \"NEWS\", \"NAVIGATION\", \"TRAFFIC\", \"SKILLS\", \"LISTS\", \"SHOPPING\", \"QUESTIONS_ANSWERS\", \"SPORTS\" or \"CALENDAR\". eventType String \"THINGS_TO_TRY\" or \"SETUP\". <p>The valid combinations of <code>domain</code> and <code>eventType</code> are as follows:</p> Domain EventType Scenario Example Utterance \"GETTING_STARTED\" \"SETUP\" Hints displayed on the success page of the Alexa setup flow. \"Alexa, play music.\" \"Alexa, find a nearby gas station.\" \"GETTING_STARTED\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Getting Started\" category. \"Alexa, what\u2019s the weather?\"  \"Alexa, what's my Flash Briefing?\" \"TALENTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Alexa's Talents\" category. \"Alexa, tell me a story.\" \"ENTERTAINMENT\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Entertainment\" category. \"Alexa, play rock music from the 70s.\" \"COMMS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Communication\" category. \"Alexa, send a message to John.\" \"WEATHER\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Weather\" category. \"Alexa, will it rain today?\" \"SMART_HOME\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Smart Home\" category. \"Alexa, lock the front door.\" \"NEWS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"News and Information\" category. \"Alexa, what\u2019s the news?\" \"NAVIGATION\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Navigation\" category. \"Alexa, take me to the airport.\" \"TRAFFIC\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Traffic Information\" category. \"Alexa, how\u2019s my commute to work?\" \"SKILLS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Skills\" category. \"Alexa, what automotive skills do you have?\" \"LISTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Lists\" category. \"Alexa, what's on my to-do list?\" \"SHOPPING\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Shopping\" category. \"Alexa, reorder toothpaste.\" \"QUESTIONS_ANSWERS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Questions and Answers\" category. \"Alexa, how far away is the moon?\" \"SPORTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Sports\" category. \"Alexa, what's my sports update?\" \"CALENDAR\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Calendar\" category. \"Alexa, add a 2:00 PM coffee chat to my calendar.\""},{"location":"explore/features/alexa/FeatureDiscovery/#getfeatures-reply","title":"GetFeatures Reply","text":"<p>The <code>GetFeaturesReply</code> message returns the suggested utterances from the <code>GetFeatures</code> message request. The <code>discoveryResponses</code> field is a string containing an escaped JSON with the following format:</p> <pre><code>[\n{\n\"domain\" : {{String}},\n\"eventType\" : {{String}},\n\"locale\" : {{String}},\n\"localizedContent\": [\n{\n\"utteranceText\": {{String}},\n\"descriptionText\": {{String}}\n}\n]\n}, ...\n\n]\n</code></pre> <p>Definition of DiscoveryResponses JSON array:</p> Property Type Required Description discoveryResponses List\\&lt;DiscoveryResponse&gt; Yes An array of feature discovery responses <p>Definition of each DiscoveryResponse JSON Object:</p> Property Type Description Example domain String The category of the utterances received. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String The event type of the utterances received. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String The locale of the utterances received. \"en-US\" localizedContent List\\&lt;LocalizedHint&gt; An array of LocalizedHint objects. - <p>Definition of the LocalizedHint JSON Object:</p> Property Type Description Example utteranceText String The exact utterance for the feature. The utterance is represented in plain text. \"Alexa, what time is it?\" descriptionText String The description of the utterance. It can be an empty string if no description is found. \"You can ask Alexa about the time.\""},{"location":"explore/features/alexa/FeatureDiscovery/#integrating-the-featurediscovery-messages-into-your-application","title":"Integrating the FeatureDiscovery messages Into Your Application","text":""},{"location":"explore/features/alexa/FeatureDiscovery/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to publish <code>FeatureDiscovery</code> AASB messages and subscribe to their replies.</p> <p>Click to expand or collapse C++ sample code </p> <pre><code>#include \"AACE/Core/MessageBroker.h\"\n#include \"AASB/Message/Alexa/FeatureDiscovery/GetFeaturesMessage.h\"\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyFeatureDiscoveryHandler {\n\n// Subscribe to reply messages from the Engine\nvoid MyFeatureDiscoveryHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetFeaturesReplyMessage(message); },\nGetFeaturesMessageReply::topic(),\nGetFeaturesMessageReply::action());\n}\n\n\n// Handle the GetFeaturesReply message from the Engine\nvoid MyFeatureDiscoveryHandler::handleGetFeaturesReplyMessage(const std::string&amp; message) {\nGetFeaturesMessageReply msg = json::parse(message);\nparseDiscoveryResponses(msg.payload.discoveryResponses);\n}\n\nvoid MyFeatureDiscoveryHandler::parseDiscoveryResponses(const std::string&amp; discoveryResponses) {\nconst auto&amp; responseArray = json::parse(discoveryResponses);\nif (responseArray.empty()) {\n// No feature was discovered, returning\n} else {\nfor (const auto&amp; response : responseArray) {\nif (!response.contains(\"localizedContent\") || !response[\"localizedContent\"].is_array()) {\ncontinue;\n}\nfor (const auto&amp; feature : response[\"localizedContent\"]) {\nif (feature.contains(\"utteranceText\")) {\n// On another thread, do something with the utterances received...\n}\n}\n}\n}\n}\n\n// Construct and send the FeatureDiscovery requests.\nvoid MyFeatureDiscoveryHandler::getFeatures(const std::string&amp; domain) {\njson requestsArray = json::array();\nrequestsArray.push_back({{\"domain\", domain}, {\"eventType\", \"THINGS_TO_TRY\"}, {\"limit\", 5}});\nGetFeaturesMessage msg;\nmsg.payload.discoveryRequests = requestsArray.dump();\nm_messageBroker-&gt;publish(msg);\n}\n};\n</code></pre>"},{"location":"explore/features/alexa/LocalMediaSource/","title":"LocalMediaSource Interface","text":""},{"location":"explore/features/alexa/LocalMediaSource/#overview","title":"Overview","text":"<p>The <code>LocalMediaSource</code> interface allows the platform to register a local media source by type (<code>BLUETOOTH</code>, <code>USB</code>, <code>AM_RADIO</code>, <code>FM_RADIO</code>, <code>SATELLITE_RADIO</code>, <code>LINE_IN</code>, <code>COMPACT_DISC</code>, <code>SIRIUS_XM</code>, <code>DAB</code>, and <code>DEFAULT</code>). Registering a local media source allows playback control of that source via Alexa (e.g. \"Alexa, play the CD player\"). It also enables playback initiation via Alexa by frequency, channel, or preset for relevant source types (e.g. \"Alexa, play 98.7 FM\").</p> <p><code>DEFAULT</code> media source is a generic media source that can be used for controlling any local media source on the OEM infotainment system. It is recommended to use <code>DEFAULT</code> media source for all local media except Alexa music, MACC-supported deep linked media players, and other registered Local Media Sources. <code>DEFAULT</code> media player can not be launched by name like \"Alexa, Play CD player\" but it can be used to control playback actions reported in the <code>supportedOperations</code>. For example, \"Alexa, play\" resumes the default player playback as long a the DEFAULT source is in focus.</p> <p>The following is an example of registering a CD player local media source using type <code>Source.COMPACT_DISC</code>:</p> <pre><code>// Include necessary message header files:\n#include &lt;AASB/Message/Alexa/LocalMediaSource/PlayMessage.h&gt;\nusing namespace aasb::message::alexa::localMediaSource;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\n// Subscribe to corresponding messages with handlers:\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nPlayMessage msg = json::parse(message);\nif (msg.payload.source == Source::COMPACT_DISC) {\n// Handle CD playback\n}\n}, PlayMessage::topic(), PlayMessage::action());\n</code></pre>"},{"location":"explore/features/alexa/LocalMediaSource/#starting-playback-with-content-selection-by-voice","title":"Starting Playback with Content Selection by Voice","text":"<p>The <code>Play</code> message is sent when Alexa invokes play by <code>ContentSelector</code> type (<code>FREQUENCY</code>, <code>CHANNEL</code>, <code>PRESET</code>) for a radio local media source (<code>AM_RADIO</code>, <code>FM_RADIO</code>, <code>SIRIUS_XM</code>, <code>DAB</code>). The <code>payload</code> is a string that depends on the <code>ContentSelector</code> type and local media <code>Source</code> type (e.g., \"1\", \"98.7 FM HD 1\").</p> <pre><code>bool play( ContentSelector type, std::string payload, const std::string&amp; sessionId ) override {\n// play initiation for frequency, channel, or presets\n...\n}\n\n// Subscribe to corresponding messages with handlers:\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nPlayMessage msg = json::parse(message);\nif (msg.payload.source == Source::FM_RADIO) {\n// Handle FM radio playback specified by:\n// - msg.payload.contentSelectorType\n// - msg.payload.payload:\n// - msg.payload.sessionId\n}\n}, PlayMessage::topic(), PlayMessage::action());\n</code></pre> <p>The table below provides details about the supported <code>ContentSelector</code> types based on <code>Source</code> type:</p> <code>Source</code> Supported <code>ContentSelector</code> <code>payload</code> examples FM FREQUENCY \"105.9\"  \"98.7 HD 1\" PRESET \"2\" AM FREQUENCY \"1100\"  \"840\" PRESET \"1\" SXM CHANNEL \"22\"  \"70\" PRESET \"3\" DAB CHANNEL \u201cBBC Radio Extra 4\u201d DEFAULT PRESET \"5\" <p>The supported ranges and increments for valid frequency, preset, and channel may vary depending on the region you are in. Contact your partner manager for more detailed information.</p> <p>Note: The <code>DAB</code> channel payload is the radio station name string. If supported, then the name string must be handled by the client's DAB implementation.</p> <p>The <code>Play</code> message will not be sent if a source cannot handle the specified <code>ContentSelector</code> type.</p> <p>The <code>DEFAULT</code> <code>Local Media Source</code> handles \"Alexa, play preset \\\\\" utterances without requiring that users explicitly say which local media source (<code>AM_RADIO</code>, <code>FM_RADIO</code>, <code>SIRIUS_XM</code>) actually corresponds to the preset. The meaning of the preset in the <code>msg.payload.payload</code> field is determined by the <code>DEFAULT</code> platform implementation and should suit the needs of the vehicle's infotainment system, i.e. when the <code>Play</code> message is received, your implementation should map the preset to a preset that makes sense for the current context."},{"location":"explore/features/alexa/LocalMediaSource/#controlling-playback-by-voice","title":"Controlling Playback by Voice","text":"<p>The <code>PlayControl</code> message is sent with a <code>PlayControlType</code>(<code>RESUME</code>, <code>PAUSE</code>, <code>STOP</code>, <code>NEXT</code>, <code>PREVIOUS</code>, <code>START_OVER</code>, <code>FAST_FORWARD</code>, <code>REWIND</code>, <code>ENABLE_REPEAT_ONE</code>, <code>ENABLE_REPEAT</code>, <code>DISABLE_REPEAT</code>, <code>ENABLE_SHUFFLE</code>, <code>DISABLE_SHUFFLE</code>, <code>FAVORITE</code>, <code>UNFAVORITE</code>) when Alexa invokes a playback control on the local media source.</p> <pre><code>    PlayControlMessage msg = json::parse(message);\nif (msg.payload.source == m_source) {\nswitch (msg.payload.controlType) {\ncase PlayControlType::RESUME:\nbreak;\ncase PlayControlType::PAUSE:\nbreak;\ncase PlayControlType::STOP:\nbreak;\ndefault:\nbreak;\n}\n}\n</code></pre> <p>Note: The <code>Play</code> message is used to initiate playback with specified content selection, whereas <code>PlayControl</code> message with <code>PlayControlType::RESUME</code> is used to play or resume the source when content is not specified or not supported. E.g. FM receives <code>Play</code> message when the user requests FM with a specific frequency (\"Alexa, play 98.7 FM radio\"), and USB receives <code>PlayControl</code> message with <code>PlayControlType::RESUME</code> when the user requests playback with just the source name (\"Alexa, play USB\").</p> <p>The <code>Seek</code> message and <code>AdjustSeek</code> message are sent to seek the currently focused <code>LocalMediaSource</code>. These messages are only used by sources that are capable of seeking. <code>Seek</code> message is for specifying an absolute offset, whereas <code>AdjustSeek</code> message is for specifying a relative offset.</p> <p>The <code>VolumeChanged</code> message and <code>MutedStateChanged</code> message are sent to change the volume and mute state of the currently focused local media player. <code>VolumeChanged</code> message specifies the new volume. <code>MutedStateChanged</code> message specifies the new <code>MutedState</code>.</p>"},{"location":"explore/features/alexa/LocalMediaSource/#reporting-playback-events","title":"Reporting Playback Events","text":"<p>The <code>LocalMediaSource</code> interface provides <code>PlayerEvent</code> message and <code>PlayerError</code> message for your implementation to report events regarding the state of the playback session managed by your local source. Even though your local source manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, sending  <code>PlayerEvent</code> message and <code>PlayerError</code> message provides important information to the Engine:</p> <ol> <li> <p>The Engine may use these messages to synchronize the state of your local source's playback session with Alexa.</p> </li> <li> <p>The Engine may react to these calls according to the event name specified to update its internal view of your local source's state. Particular event names indicate if the source is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management.</p> </li> </ol> PlayerEvent name Description \"PlaybackSessionStarted\" The local media source is switched from the inactive to active media state or a new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackSessionEnded\" The local media source is switched from the active to inactive media state or an active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. \"PlaybackStarted\" During an active session, the local source has started to play or resumed from a paused state. \"PlaybackStopped\" During an active session, the player stopped, either as a result of a GUI interaction or a user voice request to Alexa. PlayerError name Description \"INTERNAL_ERROR\" During an active session, an internal error caused playback to stop. <p>Both <code>PlayerEvent</code> message and <code>PlayerError</code> message are expected to provide the appropriate sessionId.</p> <p>Send <code>PlayerEventMessage{\"PlaybackSessionStarted\", sessionId}</code> to tell the Engine that the user brought the <code>LocalMediaSource</code> to the foreground with a GUI interaction. The Engine considers the source to have an active playback session, although it may or may not be playing yet. If no other Alexa media source is playing, utterances such as \u201cAlexa, play\u201d target this source. You must also send <code>PlayerEventMessage{\"PlaybackSessionStarted\", sessionId}</code> when the source is brought into the foreground after receiving <code>Player</code> message or <code>PlayerControl</code> message as a result of a user voice request. Once the source starts playing, send <code>PlayerEvent{\"PlaybackStarted\", sessionId}</code>.</p> <p>Send <code>PlayerEventMessage{\"PlaybackSessionEnded\", sessionId}</code> to tell the Engine that the <code>LocalMediaSource</code> is no longer in the foreground, typically as a result of a GUI interaction from the user after the player is stopped. The Engine considers the source inactive or not in focus, and starting a new playback session for the source requires a further GUI interaction or user voice request to Alexa that targets the source by name.</p> <pre><code>    void setAlexaFocusForFMRadio(bool isFocused) {\nif (isFocused) {\n// FM Radio begins playback independently of Alexa\nplayerEvent(\"PlaybackSessionStarted\", m_sessionId);\n} else {\n...\n// Notify Alexa that FM Radio is no longer the active media source on the device as a result of platform driven change\nplayerEvent(\"PlaybackSessionEnded\", m_sessionId);\n}\n}\n\nvoid playerEvent(const std::string&amp; eventName, const std::string&amp; sessionId) {\nPlayerEventMessage msg;\nmsg.payload.source = m_source;\nmsg.payload.eventName = eventName;\nmsg.payload.sessionId = sessionId;\nm_messageBroker-&gt;publish(msg);\n}\n</code></pre> <p>Note: Only one <code>LocalMediaSource</code> type can have Alexa focus at a time.</p> <p>Note: <code>SetFocus</code> message is deprecated for the <code>LocalMediaSource</code> interface. Use <code>PlayerEvent</code> message with <code>\"PlaybackSessionStarted\"</code> or <code>\"PlaybackSessionEnded\"</code> instead.</p> <p>Please abide by following rules related to <code>sessionId</code> in your <code>LocalMediaSource</code> integration:</p> <ul> <li> <p><code>sessionId</code> is a universally unique identifier (UUID) generated according to the RFC 4122 specification.</p> </li> <li> <p>If a media source starts because of a call to <code>PlayMessage{contentSelector, payload, sessionId}</code> from the Engine, note the <code>sessionId</code> field and use it in any <code>PlayerEvent</code> message calls until the session is inactive.</p> </li> <li> <p>If a media source starts for any other reason (e.g. a call to <code>PlayControlMessage{RESUME}</code> from the Engine, or user GUI interaction on the head unit), create a new <code>sessionId</code> and use it in any <code>PlayerEvent</code> message calls until the session is inactive.</p> </li> <li> <p>A <code>sessionId</code> is always associated with one media source playback session, so <code>USB</code>'s <code>sessionId</code> should be different than <code>COMPACT_DISC</code>'s <code>sessionId</code>.</p> </li> <li> <p>An individual <code>LocalMediaSource</code> should maintain the <code>sessionId</code> for the whole cycle from playback session start to playback session end.</p> </li> <li> <p>For any \"opening\" <code>PlayerEvent</code> message call for a particular <code>sessionId</code> (e.g. <code>\"PlaybackSessionStarted\"</code>, <code>\"PlaybackStarted\"</code>), you must report a corresponding closing call (e.g. <code>\"PlaybackStopped\"</code>, <code>\"PlaybackSessionEnded\"</code>) at the appropriate time (i.e., when the source is stopped, switched, etc.)</p> </li> </ul>"},{"location":"explore/features/alexa/LocalMediaSource/#reporting-playback-state","title":"Reporting Playback State","text":"<p>The Engine sends <code>GetState</code> message to synchronize the local player's state with the cloud. This method is used to maintain correct state during startup and with every Alexa request. All relevant information should be added to the <code>LocalMediaSourceState</code> in the reply message.</p> <p>Many fields of the <code>LocalMediaSourceState</code> are not required for local media source players. You should omit these as noted below.</p> <p>The following table describes the fields comprising a <code>LocalMediaSourceState</code>, which includes two sub-components: <code>PlaybackState</code> and <code>SessionState</code>.</p> State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedPlaybackOperation trackOffset long No optional shuffleEnabled boolean No optional repeatEnabled boolean No optional favorites Favorites No see Favorites type String Yes must be set to \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No optional trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType No see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean No empty accessToken String No empty tokenRefreshInterval long No empty supportedContentSelectors ContentSelector[] No see ContentSelector spiVersion String Yes must be \"1.0\" <p><code>supportedOperations</code> should list the operations that the local media source supports. Below is a list of all <code>SupportedPlaybackOperation</code>:</p> <pre><code>LocalMediaSource::SupportedPlaybackOperation::PLAY,\nLocalMediaSource::SupportedPlaybackOperation::PAUSE,\nLocalMediaSource::SupportedPlaybackOperation::STOP,\nLocalMediaSource::SupportedPlaybackOperation::PREVIOUS,\nLocalMediaSource::SupportedPlaybackOperation::NEXT,\nLocalMediaSource::SupportedPlaybackOperation::ENABLE_SHUFFLE,\nLocalMediaSource::SupportedPlaybackOperation::DISABLE_SHUFFLE,\nLocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT_ONE,\nLocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT,\nLocalMediaSource::SupportedPlaybackOperation::DISABLE_REPEAT,\nLocalMediaSource::SupportedPlaybackOperation::SEEK,\nLocalMediaSource::SupportedPlaybackOperation::ADJUST_SEEK,\nLocalMediaSource::SupportedPlaybackOperation::FAVORITE,\nLocalMediaSource::SupportedPlaybackOperation::UNFAVORITE,\nLocalMediaSource::SupportedPlaybackOperation::FAST_FORWARD,\nLocalMediaSource::SupportedPlaybackOperation::REWIND,\nLocalMediaSource::SupportedPlaybackOperation::START_OVER\n</code></pre> <p>Note: Currently PLAY/PAUSE/STOP are always supported for a source. Passing null allows ALL supported operations for the source.</p> <p><code>supportedContentSelectors</code> should list the content selection types the local source can support. Below is a table of valid pairs.</p> Source Supportable <code>ContentSelector</code> Values <code>AM_RADIO</code> <code>PRESET</code>, <code>FREQUENCY</code> <code>FM_RADIO</code> <code>PRESET</code>, <code>FREQUENCY</code> <code>SIRIUS_XM</code> <code>PRESET</code>, <code>CHANNEL</code> <code>DEFAULT</code> <code>PRESET</code> <p><code>launched</code> specifies whether the source is enabled. The player is disabled for use with Alexa when this value is false, such as when a removable source like USB is disconnected.</p>"},{"location":"explore/features/alexa/LocalMediaSource/#example-sequence-diagrams","title":"Example Sequence Diagrams","text":"<p>The following diagrams show examples of Local Media Source usage:</p> <p>1. Starting FM by voice </p> <p>2. Switching from FM to DEFAULT media source with GUI </p> <p>3. Switching between different DEFAULT sources </p>"},{"location":"explore/features/alexa/MediaPlaybackRequestor/","title":"MediaPlaybackRequestor Interface","text":"<p>Alexa Media-Resume is a feature that helps Alexa play customers\u2019 favorite content when they start their Alexa-enabled vehicles. Media-resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. To resume the media, Alexa Auto SDK needs to send <code>RequestMediaPlayback</code> event with the invocation reason set to <code>AUTOMOTIVE_STARTUP</code>. To implement a handler, subscribe to <code>MediaPlaybackResponse</code> messages.</p> <p><code>RequestMediaPlayback</code> is the message to send the event to the cloud. This message needs <code>invocationReason</code> and <code>elapsedBootTime</code> as input parameters.</p> <p><code>MediaPlaybackResponse</code> message receives the status of the <code>RequestMediaPlayback</code> message asynchronously.</p> <p><code>InvocationReason</code> enum indicates the invocation reason for calling the event. <code>AUTOMOTIVE_STARTUP</code> represents a situation where platform automatically sends <code>RequestMediaPlayback</code> message to automatically resume the media after infotainment system reboot. <code>EXPLICIT_USER_ACTION</code> represents resuming the media after explicit driver action by pressing the button or switch. Music resuming on <code>EXPLICIT_USER_ACTION</code> is not yet supported and this will be enabled in the future. Please check with your partner manager before using this action.</p> <p><code>MediaPlaybackRequestStatus</code> enum indicate the status of the <code>RequestMediaPlayback</code> message delivery. <code>SUCCESS</code> means <code>RequestMediaPlayback</code> event is successfully reported to the cloud. <code>FAILED_CAN_RETRY</code> means <code>RequestMediaPlayback</code> message can not be processed because Alexa Auto SDK is not in the connected state but platform implementation can retry after some time. <code>FAILED_TIMEOUT</code> means threshold time is crossed and media can not be resumed now. Driver can play media by making a voice request. <code>ERROR</code> means API could not be called successfully and media can not be resumed.</p> <p>This feature needs following configuration. Please contact to your partner manager for finalizing the threshold numbers.</p> <pre><code>\"aace.alexa\": {\n\"requestMediaPlayback\": {\n\"mediaResumeThreshold\": 30000\n}\n}\n</code></pre> <p><code>mediaResumeThreshold</code> is the maximum time in milliseconds to receive the <code>RequestMediaPlayback</code> message from the platform implementation. Platform implementation should consider their boot time, time to initialize Alexa and get connected to send the <code>RequestMediaPlayback</code> event successfully. Platform team and partner manager should try to keep this time minimum for the better user experience. Delayed media resume can surprise driver and result in driver distraction.</p>"},{"location":"explore/features/alexa/Notifications/","title":"Notifications Interface","text":"<p>It is the responsibility of the platform implementation to provide a visual indication to the user when notifications (for example, package shipment notifications, notifications from skills, etc.) are available from Alexa. See the AVS Notifications interface documentation for more information about notifications. The Engine uses the registered Notifications implementation to notify you when a notification indicator should be displayed or removed. It does not give any information about the notifications. Audio playback for the notification is handled by whichever audio channel is assigned to the <code>NOTIFICATION</code> type.</p> <p>To implement a custom handler for Notifications, subscribe to <code>Notifications</code> messages:</p> <pre><code>#include &lt;AASB/Message/Alexa/Notifications/SetIndicatorMessage.h&gt;\n#include &lt;AASB/Message/Alexa/Notifications/OnNotificationReceivedMessage.h&gt;\nusing namespace aasb::message::alexa::notifications;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nOnNotificationReceivedMessage msg = json::parse(message);\nhandleOnNotificationReceived(msg);\n},\nOnNotificationReceivedMessage::topic(),\nOnNotificationReceivedMessage::action());\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nSetIndicatorMessage msg = json::parse(message);\nhandleSetIndicatorMessage(msg);\n},\nSetIndicatorMessage::topic(),\nSetIndicatorMessage::action());\n</code></pre>"},{"location":"explore/features/alexa/PlaybackController/","title":"PlaybackController Interface","text":"<p>The Engine provides a platform interface <code>aace::alexa::PlaybackController</code> for the platform implementation to report on-device transport control button presses for media playing through Alexa. For example, if the user presses the on-screen pause button while listening to Amazon Music through Alexa's <code>AudioPlayer</code> interface, the platform implementation publishes a <code>PlaybackController</code> message to report the button press to the Engine.</p> <p>Note: <code>PlaybackController</code> method calls to manage <code>AudioPlayer</code>'s state or playback queue proactively report button presses or the equivalent so that Alexa can react; they do not report changes to the playback state that happen locally first. The Alexa cloud manages the playback queue for <code>AudioPlayer</code> content, so each <code>PlaybackController</code> publishing is a request for Alexa to act on the user's local request. The result of the request will come as one or more messages on the <code>AudioOutput</code> associated with the channel used for <code>AudioPlayer</code>.</p> <p>Note: If your implementation needs to stop <code>AudioPlayer</code> media in response to system events, such as audio focus transitions to audio playing outside the scope of the Auto SDK, use <code>PlaybackController</code> to notify the Engine of such changes. However, keep in mind that the expected usage of the interface does not change when it is used in this use case.</p> <p>Note: <code>PlaybackController</code> only controls media coming from Alexa, i.e. the <code>AudioPlayer</code>. <code>PlaybackController</code> should not be used with the expectation of controlling playback for non-media Alexa audio sources like <code>SpeechSynthesizer</code> or Alexa-aware external media sources integrated with <code>ExternalMediaAdapter</code> or <code>LocalMediaSource</code>. Additionally, pulishing a <code>PlaybackController</code> message while audio is playing through another Alexa-aware external media source will produce unexpected results and is not recommended.</p> <p>Whenever Alexa plays media through <code>AudioPlayer</code>, the Engine sends <code>TemplateRuntime.RenderPlayerInfo</code> message to provide visual metadata associated with the media that your implementation should render for the end user. The payload of this message includes descriptions of GUI controls to be displayed and the state in which to display them. When the user interacts with these on-screen controls, your implementation must use the <code>PlaybackController</code> interface to report the button presses to the Engine.</p> <p>The table below maps the controls from the <code>RenderPlayerInfo</code> message payload to the corresponding calls in <code>PlaybackController</code>.</p> RenderPlayerInfo control name PlaybackController PlaybackButton \"PLAY_PAUSE\" PLAY \"PLAY_PAUSE\" PAUSE \"NEXT\" NEXT \"PREVIOUS\" PREVIOUS \"SKIP_FORWARD\" SKIP_FORWARD \"SKIP_BACKWARD\" SKIP_BACKWARD PlaybackToggle \"SHUFFLE\" SHUFFLE \"LOOP\" LOOP \"REPEAT\" REPEAT \"THUMBS_UP\" THUMBS_UP \"THUMBS_DOWN\" THUMBS_DOWN <p>Implement a playback controller by publishing <code>PlaybackController</code> messages:</p> <pre><code>#include &lt;AASB/Message/Alexa/PlaybackController/ButtonPressedMessage.h&gt;\n#include &lt;AASB/Message/Alexa/PlaybackController/TogglePressedMessage.h&gt;\nusing namespace aasb::message::alexa::playbackController;\n\n...\n// Publish the ButtonPressedMessage for the button pressed.\nButtonPressedMessage msg;\nmsg.payload.button = PlaybackButton::PLAY;\nm_messageBroker-&gt;publish(msg);\n\n// Publish the TogglePressedMessage for the button pressed.\nTogglePressedMessage msg;\nmsg.payload.toggle = PlaybackToggle::SHUFFLE;\nmsg.payload.action = true;\nm_messageBroker-&gt;publish(msg);\n</code></pre>"},{"location":"explore/features/alexa/SpeechRecognizer/","title":"SpeechRecognizer Interface","text":"<p>The <code>SpeechRecognizer</code> interface is one of the key required interfaces in the Alexa experience. Integrate with the <code>SpeechRecognizer</code> AASB message interface (and the additional required interfaces as described in the following sections) to allow the user to invoke Alexa.</p>"},{"location":"explore/features/alexa/SpeechRecognizer/#provide-audio-data-to-the-engine","title":"Provide audio data to the Engine","text":"<p>At Engine startup time, the <code>SpeechRecognizer</code> component in the Engine opens an audio input channel of type <code>VOICE</code> for your application to provide the user speech to Alexa. Your application subscribes to the <code>AudioInput.StartAudioInput</code> and <code>AudioInput.StopAudioInput</code> messages as outlined in the AudioInput interface documentation. When the Engine expects to receive audio from your application, the Engine publishes a <code>StartAudioInput</code> message with <code>audioType</code> set to <code>VOICE</code>. Your application provides the voice audio input until the Engine publishes the <code>StopAudioInput</code> message for the same audio type.</p> <p>The user decides when to speak to Alexa by invoking her with a tap-to-talk GUI button press, a push-to-talk physical button press, or\u2014in vehicles supporting voice-initiated listening\u2014an \"Alexa\" utterance.</p>"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-tap-and-release","title":"Invoke Alexa with tap-and-release","text":"<p>For button press-and-release Alexa invocation, your application publishes the <code>SpeechRecognizer.StartCapture</code> message with <code>initiator</code> set to <code>TAP_TO_TALK</code> to tell the Engine that the user pressed the Alexa invocation button and wants to speak to Alexa. When requested, your application provides audio to the Engine until Alexa detects the end of the user's speech. The Engine publishes a <code>SpeechRecognizer.EndOfSpeechDetected</code> message to your application and requests your application to stop providing audio if no other Engine components require it.</p>"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-press-and-hold","title":"Invoke Alexa with press-and-hold","text":"<p>For button press-and-hold Alexa invocation, your application publishes the <code>SpeechRecognizer.StartCapture</code> message with <code>initiator</code> set to <code>HOLD_TO_TALK</code> to tell the Engine that the user is holding down the Alexa invocation button and wants to speak to Alexa until releasing the button. When requested, the application provides audio to the Engine. When the user finishes speaking and releases the button, your application notifies the Engine by publishing the <code>SpeechRecognizer.StopCapture</code> message, and the Engine requests your application to stop providing audio if no other Engine components require it.</p>"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-voice-using-amazonlite-wake-word-engine","title":"Invoke Alexa with voice using Amazonlite wake word engine","text":"<p>Note: To use the Amazonlite wake word engine in your application, contact your Amazon Solutions Architect or partner manager.</p> <p>When the application uses the <code>Amazonlite</code> Auto SDK module for wake word detection, your application notifies the Engine when the user has hands-free listening enabled (i.e., privacy mode is off) by publishing a <code>PropertyManager.SetProperty</code> message with <code>property</code> set to <code>aace.alexa.wakewordEnabled</code> and <code>value</code> set to <code>true</code>. The Engine enables Amazonlite wake word detection and requests audio input from your application. Your application provides audio to the Engine for continuous wake word detection until your application disables hands-free listening by setting the <code>aace.alexa.wakewordEnabled</code> property to <code>false</code>. After disabling Amazonlite wake word detection, the Engine requests your application to stop providing audio if there no other Engine components require it.</p> <p>When Amazonlite detects the \"Alexa\" wake word in the continuous audio stream provided by your application, the Engine publishes the <code>SpeechRecognizer.WakewordDetected</code> message and starts an interaction similar to one triggered by tap-to-talk invocation. When Alexa detects the end of the user's speech, the Engine publishes the <code>SpeechRecognizer.EndOfSpeechDetected</code> message but keeps the audio input stream open for further wake word detection.</p>"},{"location":"explore/features/alexa/SpeechRecognizer/#reduce-data-usage-with-audio-encoding","title":"Reduce data usage with audio encoding","text":"<p>To save bandwidth when the Engine sends user speech to Alexa in <code>SpeechRecognizer.Recognize</code> events, you can configure the Engine to encode the audio with the Opus audio encoding format by adding the following object to your Engine configuration:</p> <p><pre><code>{\n\"aace.alexa\": {\n\"speechRecognizer\": {\n\"encoder\": {\n\"name\": \"opus\"\n}\n}\n}\n}\n</code></pre> When you set this configuration in your application, the Engine still expects your application to provide audio in the Linear PCM format specified in the AudioInput interface documentation; the Engine internally changes the encoding to Opus prior to including the audio attachment in the <code>Recognize</code> event.</p> Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function <p>If your application generates Engine configuration programmatically instead of using a JSON file, you can use the <code>aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig</code> factory function to create the <code>EngineConfiguration</code> object.</p> <pre><code>#include &lt;AACE/Alexa/AlexaConfiguration.h&gt;\n\nstd::vector&lt;std::shared_ptr&lt;aace::core::config::EngineConfiguration&gt;&gt; configurations;\n\nauto speechRecognizerConfig = aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig(\"opus\");\nconfigurations.push_back(speechRecognizerConfig);\n\n// ... create other EngineConfiguration objects and add them to configurations...\n\nm_engine-&gt;configure(configurations);\n</code></pre>"},{"location":"explore/features/alexa/SpeechSynthesizer/","title":"SpeechSynthesizer Interface","text":"<p>At startup time, the <code>SpeechSynthesizer</code> component in the Engine opens an audio output channel of type <code>TTS</code> for the application to play Alexa speech responses to the user. <code>SpeechSynthesizer</code> has no messages of its own for the application to handle because it uses the standard audio output framework specified in the <code>Core</code> module. When Alexa responds to a user request with speech, the Engine publishes an <code>AudioOutput.Prepare</code> message with <code>audioType</code> <code>TTS</code>. The application uses the payload of the message to open the audio stream and buffer the audio data. The application plays the audio to the user when the Engine publishes an <code>AudioOutput.Play</code> message with matching <code>token</code>.</p>"},{"location":"explore/features/alexa/TemplateRuntime/","title":"TemplateRuntime Interface","text":"<p>Alexa sends visual metadata (display card templates) for your device to display. When template information is received from Alexa, it is the responsibility of the platform implementation to handle the rendering of any UI with the information that is received from Alexa. There are two display card template types:</p> <ul> <li>The Template type provides visuals associated with a user request to accompany Alexa speech.</li> <li>The PlayerInfo type provides visuals associated with media playing through the <code>AudioPlayer</code> interface. This includes playback control buttons, which must be used with the <code>PlaybackController</code> interface.</li> </ul> <p>You can programmatically generate template runtime configuration using the <code>aace::alexa::config::AlexaConfiguration::createTemplateRuntimeTimeoutConfig()</code> factory method, or provide the equivalent JSON values in a configuration file.</p> <pre><code>{\n\"aace.alexa\" {\n\"templateRuntimeCapabilityAgent\": {\n\"displayCardTTSFinishedTimeout\": &lt;TIMEOUT_IN_MS&gt;,\n\"displayCardAudioPlaybackFinishedTimeout\": &lt;TIMEOUT_IN_MS&gt;,\n\"displayCardAudioPlaybackStoppedPausedTimeout\": &lt;TIMEOUT_IN_MS&gt;\n}\n}\n</code></pre> <p>To implement a custom handler for GUI templates, subscribe to <code>TemplateRuntime</code> messages:</p> <pre><code>// Include necessary message header files\n#include &lt;AASB/Message/Alexa/TemplateRuntime/RenderTemplateMessage.h&gt;\n#include &lt;AASB/Message/Alexa/TemplateRuntime/RenderPlayerInfoMessage.h&gt;\nusing namespace aasb::message::alexa::templateRuntime;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n...\n\n// Subscribe to corresponding messages with handlers\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nRenderPlayerInfoMessage msg = json::parse(message);\n// handle rendering the player info data specified in msg.payload\n},\nRenderPlayerInfoMessage::topic(),\nRenderPlayerInfoMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) {\nRenderTemplateMessage msg = json::parse(message);\n// handle rendering the template data specified in msg.payload\n},\nRenderTemplateMessage::topic(),\nRenderTemplateMessage::action());\n</code></pre> <p>Note: In the case of lists, it is the responsibility of the platform implementation to handle pagination. Alexa sends down the entire list as a JSON response and starts reading out the first five elements of the list. At the end of the first five elements, Alexa prompts the user whether or not to read the remaining elements from the list. If the user chooses to proceed with the remaining elements, Alexa sends down the entire list as a JSON response but starts reading from the sixth element onwards.</p>"},{"location":"explore/features/apl/","title":"Alexa Presentation Language (APL) Module","text":""},{"location":"explore/features/apl/#overview","title":"Overview","text":"<p>The <code>Alexa Presentation Language (APL)</code> module enables your Alexa Auto SDK client application to use visual capabilities of Alexa. By using this module in your application, you enable your device to receive visual experiences from certified Alexa Skills that support APL. Additionally, this modules provides messages for reporting the driving state of the vehicle, the day/night mode, and theme id. All of those properties affect how APL is rendered in the vehicle. Support for three new Alexa Automotive viewport profiles is now available.</p> <p>APL directives from the Alexa Voice Service (AVS) contain metadata needed to render Alexa's visual responses for devices with a graphical user interface (GUI). The lifecycle of an APL document includes sending events, providing document and window state, and more. For more information about APL, see the APL documentation.</p> <p>Note: The APL module doesn't render APL documents; it provides the conduit to render APL documents and process user events from the GUI or voice user interface (VUI). APL rendering is available separately for Android platforms.</p>"},{"location":"explore/features/apl/#automotive-viewport-profiles","title":"Automotive Viewport Profiles","text":"<p>APL supports various types of viewport profiles for different types of devices and screen sizes. There are three new viewport profiles specifically added for vehicles: auto extra small, auto small and auto medium. Please refer to the viewport profile documentation for specific sizes and configuration information.</p>"},{"location":"explore/features/apl/#vehicle-driving-state","title":"Vehicle Driving State","text":"<p>The vehicle driving state describes the motion state of the vehicle. The two supported values are <code>moving</code> and <code>parked</code>. Setting the appropriate driving state helps make visual experiences safer in the vehicle. When the vehicle is <code>parked</code>, APL experiences may contain more visual elements. When the vehicle is <code>moving</code>, some visual elements may be hidden to reduce cognitive load on the driver and make the experience safer. Video will automatically be disabled when the vehicle is <code>moving</code>.</p>"},{"location":"explore/features/apl/#day-and-night-mode","title":"Day and Night Mode","text":"<p>Day and night mode provide a way to render APL experiences in different contrasts based on the ambient light conditions of the vehicle. During the day when more light is available, the APL experience will typically be rendered with a light background and dark font. During the night or when travelling through a tunnel, the APL experience will be rendered with a dark background and light font.</p>"},{"location":"explore/features/apl/#automotive-themes","title":"Automotive Themes","text":"<p>Automotive themes allow the OEM to customize some aspects of the APL experience such as background and font color. Themes have predefined color values and affect supported Alexa Responsive Templates. This can help make the APL experience match more closely to the look and feel of the native UI in the head unit. There are a total of six available themes that include three for day mode and three for night mode. Day mode includes a default theme, and two additional themes with values <code>gray1</code> and <code>gray2</code>. Night mode includes a default theme, and two additional themes with values <code>black</code> and <code>gray</code>. The OEM application must ensure that a valid theme is set for day and night modes. The theme is optional, and in the case that it is not provided then the default theme is used.</p>"},{"location":"explore/features/apl/#supported-apl-experiences","title":"Supported APL Experiences","text":"<p>Only APL experiences that have been certified for Automotive devices will be allowed to send APL directives. We are working to provide a process for skill developers to support automotive devices. More information will be provided in the online documentation. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information about what Alexa domains and skills support APL in the vehicle.</p>"},{"location":"explore/features/apl/#apl-viewhost","title":"APL Viewhost","text":"<p>The viewhost is a software component responsible for rendering the APL payload on screen. The Auto SDK provides a native Android viewhost solution. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information.</p>"},{"location":"explore/features/apl/#template-runtime","title":"Template Runtime","text":"<p>APL and Template Runtime both provide visual experiences. The Auto SDK supports both capabilities on the vehicle. Alexa skills typically give APL preference if both capabilities are reported, and will return APL directives. The new Auto SDK audio ducking feature is necessary for Template Runtime render player info cards and APL cards to be active at the same time.</p>"},{"location":"explore/features/apl/#configuring-the-apl-module","title":"Configuring the APL Module","text":"<p>The APL module can be optionally configured with the following Engine setting:</p> <pre><code>{\n  \"alexaPresentationCapabilityAgent\": {\n     \"displayDocumentInteractionIdleTimeout\": &lt;TIMEOUT_IN_MS&gt;\n  }\n}\n</code></pre> <p>Note: The default value for the configuration timeout is 30 seconds.</p>"},{"location":"explore/features/apl/#using-the-apl-aasb-messages","title":"Using the APL AASB Messages","text":""},{"location":"explore/features/apl/#general-apl-message","title":"General APL Message","text":"<p>When a user interacts with an APL enabled Alexa skill, the Engine publishes the <code>RenderDocument</code> message. It is the responsibility of the application to integrate a viewhost capable of rendering APL documents. During the APL lifecyle, there will be context information (such as document and window state) as well as user events generated by interaction with the rendered APL document. The skill can send additional directives, which must be forwarded to the viewhost.</p> <p>This diagram illustrates the sequence of interacting with an APL enabled Alexa skill.</p> Click to expand or collapse sequence diagram: General APL Directive Flow <p></p> <p></p> <p></p>"},{"location":"explore/features/apl/#set-platform-property-message","title":"Set Platform Property Message","text":"<p>This diagram illustrates the sequence of setting platform properties for APL.</p> Click to expand or collapse sequence diagram: Setting platform properties <p></p> <p></p> <p></p>"},{"location":"explore/features/apl/#integrating-the-apl-module-into-your-application","title":"Integrating the APL Module Into Your Application","text":"<p>You can use the Engine's <code>MessageBroker</code> to subscribe to and publish \"APL\" AASB messages.</p> Click to expand or collapse C++ sample code <p></p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/APL/APL/ActivityEvent.h&gt;\n#include &lt;AASB/Message/APL/APL/ClearAllExecuteCommandsMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/ClearCardMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/ClearDocumentMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/DataSourceUpdateMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/ExecuteCommandsMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/ExecuteCommandsResultMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/InterruptCommandSequenceMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/ProcessActivityEventMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/RenderDocumentMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/RenderDocumentResultMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SendDataSourceFetchRequestEventMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SendDeviceWindowStateMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SendRuntimeErrorEventMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SendUserEventMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SendDocumentStateMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SetAPLMaxVersionMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SetDocumentIdleTimeoutMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/SetPlatformPropertyMessage.h&gt;\n#include &lt;AASB/Message/APL/APL/UpdateAPLRuntimePropertiesMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyAPLHandler {\n\n    // Subscribe to messages from the Engine\n    void MyAPLHandler::subscribeToAASBMessages() {\n    m_messageBroker-&gt;subscribe(\n        [=](const std::string&amp; message) { handleRenderDocumentMessage(message); },\n        RenderDocumentMessage::topic(),\n        RenderDocumentMessage::action());\n\n    ...\n\n    // Handle the RenderDocument message from the Engine\n    void MyAPLHandler::handleRenderDocumentMessage(const std::string&amp; message) {\n        RenderDocumentMessage msg = json::parse(message);\n        std::string payload = msg.payload.payload;\n        std::string token = msg.payload.token;\n\n        // ...Pass data to viewhost for rendering...\n    }\n</code></pre>"},{"location":"explore/features/apl/#registering-an-apl-handler","title":"Registering an APL Handler","text":"<p>To implement a custom handler for APL, extend the <code>aace::apl::APL</code> class as follows:</p> <pre><code>class APLHandler : public aace::apl::APL {\npublic:\n    APLHandler();\n    void renderDocument(const std::string&amp; jsonPayload, const std::string&amp; token, const std::string&amp; windowId) override;\n    void clearDocument(const std::string&amp; token) override;\n    void executeCommands(const std::string&amp; jsonPayload, const std::string&amp; token) override;\n    void interruptCommandSequence(const std::string&amp; token) override;\n    void dataSourceUpdate(const std::string&amp; sourceType, const std::string&amp; jsonPayload, const std::string&amp; token) override;\n};\n</code></pre>"},{"location":"explore/features/apl/#visual-characteristics","title":"Visual Characteristics","text":"<p>The APL module requires that the platform implementation define the visual characteristics of the device. Visual characteristics are passed directly to the Smart Screen SDK, and therefore have the format described in the Alexa Smart Screen SDK documentation.</p> <p>Include the <code>visualCharacteristics</code> configuration in the JSON object <code>aace.alexa/avsDeviceSDK/gui</code> as shown in the following example. You can pass the configuration to the Engine using a <code>StreamConfiguration</code> or <code>ConfigurationFile</code> object.</p> <pre><code>{\n\"aace.alexa\": {\n\"avsDeviceSDK\": {\n\"gui\": {\n\"visualCharacteristics\": [\n{\n\"type\": \"AlexaInterface\",\n\"interface\": \"Alexa.InteractionMode\",\n\"version\": \"1.1\",\n\"configurations\": {\n\"interactionModes\": [\n{\n\"id\": \"apl-interaction-id\",\n\"uiMode\": \"AUTO\",\n\"interactionDistance\": {\n\"unit\": \"INCHES\",\n\"value\": 24\n},\n\"touch\": \"SUPPORTED\",\n\"keyboard\": \"SUPPORTED\",\n\"video\": \"SUPPORTED\",\n\"dialog\": \"SUPPORTED\"\n}\n]\n}\n},\n{\n\"type\": \"AlexaInterface\",\n\"interface\": \"Alexa.Presentation.APL.Video\",\n\"version\": \"1.0\",\n\"configurations\": {\n\"video\": {\n\"codecs\": [\n\"H_264_42\",\n\"H_264_41\"\n]\n}\n}\n},\n{\n\"type\": \"AlexaInterface\",\n\"interface\": \"Alexa.Display.Window\",\n\"version\": \"1.0\",\n\"configurations\": {\n\"templates\": [\n{\n\"id\": \"apl-window-id\",\n\"type\": \"STANDARD\",\n\"configuration\": {\n\"sizes\": [\n{\n\"type\": \"DISCRETE\",\n\"id\": \"window-size-id\",\n\"value\": {\n\"unit\": \"PIXEL\",\n\"value\": {\n\"width\": 1280,\n\"height\": 720\n}\n}\n}\n],\n\"interactionModes\": [\n\"apl-interaction-id\"\n]\n}\n}\n]\n}\n},\n{\n\"type\": \"AlexaInterface\",\n\"interface\": \"Alexa.Display\",\n\"version\": \"1.0\",\n\"configurations\": {\n\"display\": {\n\"type\": \"PIXEL\",\n\"touch\": [\n\"UNSUPPORTED\"\n],\n\"shape\": \"RECTANGLE\",\n\"dimensions\": {\n\"resolution\": {\n\"unit\": \"PIXEL\",\n\"value\": {\n\"width\": 2048,\n\"height\": 1536\n}\n},\n\"physicalSize\": {\n\"unit\": \"INCHES\",\n\"value\": {\n\"width\": 8.9,\n\"height\": 6.05\n}\n},\n\"pixelDensity\": {\n\"unit\": \"DPI\",\n\"value\": 288\n},\n\"densityIndependentResolution\": {\n\"unit\": \"DP\",\n\"value\": {\n\"width\": 2048,\n\"height\": 1536\n}\n}\n}\n}\n}\n}\n]\n}\n}\n}\n}\n</code></pre>"},{"location":"explore/features/bluetooth/","title":"Bluetooth Module","text":""},{"location":"explore/features/bluetooth/#overview","title":"Overview","text":"<p>The <code>Bluetooth</code> module allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features, such as Alexa Mobile Accessory (AMA) or Mobile Authorization, to users of Android or iOS smartphones.</p>"},{"location":"explore/features/bluetooth/#requirements-for-bluetooth-classic-or-ble","title":"Requirements for Bluetooth Classic or BLE","text":"<p>The variant of the Bluetooth standard determines the tasks required to support the client.</p>"},{"location":"explore/features/bluetooth/#bluetooth-classic","title":"Bluetooth Classic","text":"<p>Complete the following tasks to support different clients:</p> <ul> <li>For Android phones, create a RFCOMM socket with the corresponding Service Discovery Protocol (SDP) record. (RFCOMM is a Bluetooth transport protocol.)</li> <li>For iOS phones, create an iOS Accessory Protocol 2 (iAP2) communication channel.</li> </ul> <p>For information about these tasks, see Supporting Bluetooth Classic.</p>"},{"location":"explore/features/bluetooth/#ble","title":"BLE","text":"<p>Add a new Generic Attribute Profile (GATT) service and advertise the service. For information about this task, see Supporting BLE.</p>"},{"location":"explore/features/bluetooth/#choosing-a-transport-protocol","title":"Choosing a Transport Protocol","text":"<p>Consider the following factors when choosing the protocol to use with Bluetooth:</p> <ul> <li>Capabilities and limitations of remote devices (e.g., Android or iOS phones)</li> <li>Capabilities of the Bluetooth software stack, which includes the system service, driver, and firmware (e.g., whether the software supports RFCOMM or iAP2)</li> <li>Capabilities of the Bluetooth chipset used on the head unit (e.g., single-mode or dual-mode)</li> </ul> <p>The following table shows the transport protocol to use based on the head unit chipset and the type of smartphone.</p> <p>Note: To use Bluetooth for Mobile Authorization, you must use RFCOMM as the transport protocol.</p> Single-mode chipset Dual-mode chipset iOS phone iAP2 iAP2 or GATT Android phone RFCOMM RFCOMM or GATT"},{"location":"explore/features/bluetooth/#supporting-bluetooth-classic","title":"Supporting Bluetooth Classic","text":"<p>Follow one of these steps, depending on the transport protocol, to create a communication channel between the head unit and the phone:</p> <ul> <li> <p>For RFCOMM communication, assign an unused RFCOMM channel to the head unit to listen on. The implementation must register an SDP record with the local SDP server, which is part of the Bluetooth software stack. The server contains the specified UUID, service name, and auto-assigned channel. Remote Bluetooth devices can use the same UUID to query the SDP server and discover the channel to connect to.</p> <p>The SDP record is removed when the socket is closed or if the application closes unexpectedly. Android clients discover the head unit by using the method that is described in BluetoothDevice.getUuids.</p> </li> <li> <p>For iAP2, allocate a communication channel with the specified protocol identifier. For information about iAP2, see the Accessory Interface Specification for Apple Devices.</p> </li> </ul>"},{"location":"explore/features/bluetooth/#supporting-ble","title":"Supporting BLE","text":"<p>In your implementation, create a new GATT service according to the JSON configuration specified in the <code>GATTServer.start</code> call. The following JSON shows a sample configuration:</p> <pre><code>{\n\"characteristics\": [\n{\n\"id\": \"A49921F7-9E7D-46F6-8832-9F44658892AC\",\n\"mtu\": 104,\n\"name\": \"Alexa Characteristic TX\",\n\"permissions\": [\n\"write\"\n],\n\"properties\": [\n\"write\"\n]\n},\n{\n\"descriptors\": [\n{\n\"id\": \"00002902-0000-1000-8000-00805f9b34fb\",\n\"name\": \"Configuration\",\n\"permissions\": [\n\"read\",\n\"write\"\n]\n}\n],\n\"id\": \"34D7A574-5298-4C35-8109-1EAA2E9476E8\",\n\"mtu\": 104,\n\"name\": \"Alexa Characteristic RX\",\n\"permissions\": [\n\"read\"\n],\n\"properties\": [\n\"notify\",\n\"read\"\n]\n}\n]\n}\n</code></pre>"},{"location":"explore/features/bluetooth/#using-the-bluetooth-module","title":"Using the Bluetooth Module","text":"<p>For Linux and QNX, register the following C++ platform interface with the Auto SDK:</p> <p>Note: The <code>Bluetooth</code> interface does not have AASB messages yet. Use the <code>BluetoothProvider</code> platform interface as described below.</p> <pre><code>class BluetoothProvider : public aace::core::PlatformInterface {\n/**\n     * Create a GATT Server.\n     *\n     * @return the created GATT server. nullptr if GATT is not supported.\n     */\nvirtual std::shared_ptr&lt;GATTServer&gt; createGATTServer();\n\n/**\n     * Create an RFCOMM server socket and register the corresponding SDP record.\n     *\n     * @param name service name for SDP record\n     * @param uuid uuid for SDP record\n     * @return the created server socket. nullptr if any error occurs.\n     */\nvirtual std::shared_ptr&lt;BluetoothServerSocket&gt; listenUsingRfcomm(const std::string&amp; name, const std::string&amp; uuid);\n\n/**\n     * Create an iAP2 server socket with specified protocol.\n     *\n     * @param protocol the protocol to use when communicating with the device\n     * @return the created server socket. nullptr if any error occurs.\n     */\nvirtual std::shared_ptr&lt;BluetoothServerSocket&gt; listenUsingiAP2(const std::string&amp; protocol);\n};\n</code></pre> <p>Note: Amazon does not provide reference implementation for Linux and QNX.</p>"},{"location":"explore/features/bluetooth/#sequence-diagrams","title":"Sequence Diagrams","text":"<p>The sequence diagrams illustrate the flow for a Bluetooth Classic connection and the flow for a BLE connection.</p>"},{"location":"explore/features/bluetooth/#bluetooth-classic-connection","title":"Bluetooth Classic Connection","text":""},{"location":"explore/features/bluetooth/#ble-connection","title":"BLE Connection","text":""},{"location":"explore/features/bluetooth/#requirement-for-accepting-connections-from-another-device","title":"Requirement for Accepting Connections from Another Device","text":"<p>The Alexa app hosting either the GATT service or RFCOMM server socket must run in the background to accept connections from another device.</p>"},{"location":"explore/features/car-control/","title":"Car Control Module","text":""},{"location":"explore/features/car-control/#overview","title":"Overview","text":"<p>The Alexa Auto SDK <code>Car Control</code> module enables you to build a custom experience that allows users to use Alexa to voice-control vehicle features. The following concepts comprise the <code>Car Control</code> module APIs:</p>"},{"location":"explore/features/car-control/#endpoints","title":"Endpoints","text":"<p>The head unit device acting as an Alexa Auto SDK client is an \"endpoint\" that connects to the Alexa service. Other Auto SDK modules, such as <code>Alexa</code>, configure capabilities on this \"root\" or \"default\" endpoint because the capabilities pertain to the head unit itself. The <code>Car Control</code> module enables the default Auto SDK client endpoint to act as a proxy to receive events and directives on behalf of connected endpoints. You can configure a separate endpoint for every vehicle component that the head unit can control through device-level connections. This enables the user to target individual vehicle components directly with utterances like \"Alexa, turn on the AC\" or \"Alexa, set the temperature to 65.\"</p>"},{"location":"explore/features/car-control/#capabilities","title":"Capabilities","text":"<p>In the utterance \"Alexa, turn on the AC\", \"turn on\" corresponds to a specific capability configured for the \"AC\" endpoint. Defining an endpoint declares a vehicle feature to be controllable, and defining capabilities on the endpoint declares how the endpoint can be controlled.</p> <p>Car Control supports four capability interfaces that can be declared alone or in combination for a particular endpoint to model its individual control experience:</p> <ul> <li> <p>Power Controller controls the overall power state of an endpoint. For example, configuring an \"AC\" endpoint with a Power Controller capability enables utterances such as \"Alexa, turn on the AC\" and \"Alexa, power off the AC\".</p> </li> <li> <p>Toggle Controller controls a particular named property of an endpoint that can be turned on and off. For example, configuring a \"windshield\" endpoint with a \"defroster\" Toggle Controller capability instance enables utterances such as \"Alexa, turn on the windshield defroster.\"</p> </li> <li> <p>Mode Controller controls a particular named property of an endpoint that can be set to a discrete value from a defined set of values. For example, if an ambient light endpoint has red and green color settings, configuring an \"ambient light\" endpoint with a \"color\" Mode Controller capability instance enables utterances such as \"Alexa, set the ambient light color to red\" and \"Alexa, change the ambient light to green.\"</p> </li> <li> <p>Range Controller controls a particular named property of an endpoint that can be set to a numeric value within a range. For example, if a fan endpoint has a speed property with settings 1 through 3, configuring a \"fan\" endpoint with a \"speed\" Range Controller capability instance enables utterances such as \"Alexa, set the fan speed to 2.\" You can configure names, such as \"medium\", for a range value to enable additional utterances such as \"Alexa, set the fan to medium\" to set the fan speed setting to 2.</p> </li> </ul>"},{"location":"explore/features/car-control/#capability-primitives-and-semantic-annotations","title":"Capability Primitives and Semantic Annotations","text":"<p>Toggle Controller, Mode Controller, and Range Controller are known as \"capability primitives.\" You can use multiple instances of the same capability primitive interface on an endpoint under different instance names. For example, a heater endpoint might have intensity and position properties that are both best modeled as modes. You can declare an \"intensity\" Mode Controller instance and a \"position\" Mode Controller instance on the same \"heater\" endpoint so the user can target each property separately.</p> <p>To provide intuitive experiences for users, capability primitives offer \"semantic annotations\" for the devices to map specific utterances to the behaviors of capability instances. For example, if the vehicle uses a Range Controller to control a window, a user would prefer to say \"Alexa, open the window\" over the default utterances of the Range Controller such as \"Alexa, set the window height to 0\". For any endpoint to which the \"open\", \"close\", \"raise\", or \"lower\" concepts apply, you can configure the capability primitive instances of the endpoint with a \"semantics\" object that maps user utterances for these actions to the appropriate capability directives. Each action (e.g., \"open\") is allowed only once per endpoint since the action expresses intent to control the endpoint as a whole.</p> <p>The actions specified in configuration are action IDs rather than literal strings, which ensures Alexa recognizes all synonyms and translations for the action in the user utterance. The supported actions are \"Alexa.Actions.Open\", \"Alexa.Actions.Close\", \"Alexa.Actions.Raise\", and \"Alexa.Actions.Lower.\"</p>"},{"location":"explore/features/car-control/#zones","title":"Zones","text":"<p>Each endpoint can belong to zero, one, or many \"zones.\" Zones, configured with member endpoints, define named regions of the vehicle and allow users to target endpoints by location. Zones are essential for unambiguous targeting of endpoints that have friendly names that overlap with other endpoints. For example, defining \"driver\" and \"passenger\" zones and assigning distinct \"seat\" endpoints to each allows proper control of the \"driver seat\" and the \"passenger seat\" independently.</p> <p>Assigning one zone in particular as the \"default\" enables endpoints in this zone to take precedence over endpoints sharing the same friendly name but not in the default zone when the user does not specify a zone in the utterance. This is useful for distinguishing \"zoneless\" endpoints from \"zoned\" endpoints with the same name when it is most likely that the user intends to target the \"zoneless\" one. For example, consider a vehicle with zone IDs \"zone.all\", \"zone.rear\", and \"zone.left\" with a distinct fan endpoint in each zone. If the user says \"Alexa, turn on the fan\", it is most likely that he wants to turn on the fan that refers to the vehicle as a whole because there is no natural way to specify its location. You can ensure that Alexa will resolve this utterance to the fan in the \"all\" zone by assigning \"zone.all\" as the default zone.</p> <p>Additionally, the default zone is useful for cases in which you have zoned endpoints with overlapping names, but one of the endpoints is a clear \"default\" to the user. For example, consider a vehicle with zones \"zone.all\" (assigned as default), \"zone.driver\", and \"zone.passenger\". The vehicle has a \"driver window\" in \"zone.driver\" and a \"passenger window\" in \"zone.passenger\", but Alexa cannot resolve which endpoint is the intended target of the user utterance \"Alexa, open the window.\" However, the user probably means \"Alexa, open the driver window\". You can ensure that Alexa considers the \"driver window\" as the \"default\" window by assigning it to \"zone.all\" as well.</p>"},{"location":"explore/features/car-control/#assets","title":"Assets","text":"<p>The definitions of endpoints, capabilities, and zones include \"assets.\" Assets, identified by unique IDs, group a voice-accessible friendly name like \"air conditioner\" into a named group of synonyms and translations for all supported languages. For example, using the asset with ID \"Alexa.Automotive.DeviceName.AirConditioner\" in your car control module configuration for an AC endpoint not only enables the user to target the air conditioner with the default phrase \"air conditioner\", but also with phrases like \"air con\" and \"AC\" in English as well as synonyms in other supported locales.</p> <p>Using assets allows decoupling the many ways of identifying components from the core configuration of the components and enables de-duplication across different components that have overlapping ways to be identified.</p> <p>The Alexa Auto SDK provides a list of IDs for the \"default assets,\" which form an automotive-specific catalog. The catalog contains asset definitions for supported car control features, including endpoint names, zone names, and capability settings. Each default asset ID is prefixed with \"Alexa.Automotive.\" You can use these asset IDs in your <code>Car Control</code> module configuration without the corresponding definitions of friendly names, synonyms, and translations, because the definitions are specified in the Alexa cloud.</p>"},{"location":"explore/features/car-control/#configuring-the-car-control-module","title":"Configuring the Car Control Module","text":"<p><code>Car Control</code> module configuration is vehicle-specific and tells the Auto SDK Engine which vehicle features to advertise to Alexa for control by the user. You must configure the Auto SDK Engine with an <code>EngineConfiguration</code> object that describes the vehicle. Like all Auto SDK Engine configuration, you can either define the JSON in a file and construct an <code>EngineConfiguration</code> from that file, or you can use the provided <code>CarControlConfiguration</code> class to programmatically construct the <code>EngineConfiguration</code> in the proper format. The following subsections describe the JSON schema. See the CarControlConfiguration class for details on how to build configuration programmatically.</p>"},{"location":"explore/features/car-control/#configuration-format","title":"Configuration Format","text":"<p>The Engine configuration for the <code>Car Control</code> module includes definitions of endpoints with their capabilities, zones with their member endpoints, and an optional path to a JSON file defining additional assets.</p> <p>Sample JSON Object</p> <pre><code>{\n    \"aace.carControl\": {\n        \"endpoints\": [\n            {\n                \"endpointId\": \"{{STRING}}\",\n                \"endpointResources\": {\n                    \"friendlyNames\": [\n                        {\n                            \"@type\": \"asset\",\n                            \"value\": {\n                                \"assetId\": \"{{STRING}}\"\n                            }\n                        },\n                        ...\n                    ]\n                },\n                \"capabilities\": [\n                    // list of capability definitions for this endpoint\n                ]\n            }\n        ],\n        \"zones\": [\n            {\n                \"zoneID\": \"{{STRING}}\",\n                \"zoneResources\": {\n                    \"friendlyNames\": [\n                        {\n                            \"@type\": \"asset\",\n                            \"value\": {\n                                \"assetId\": \"{{STRING}}\"\n                            }\n                        }\n                    ]\n                },\n                \"members\": [\n                    {\n                        \"endpointId\": \"{{STRING}}\"\n                    }\n                ]\n            }\n        ],\n        \"defaultZoneID\": \"{{STRING}}\",\n        \"assets\": {\n            \"customAssetsPath\": \"{{STRING}}\"\n        },\n    }\n}\n</code></pre> <p>Object Parameters</p> Property Type Required Description aace.carControl.endpoints list Yes The list of connected endpoints for which the device implements capabilities. Each endpoint describes one controllable vehicle component. aace.carControl.endpoints[i].endpointId string Yes The identifier for the endpoint, unique amongst all endpoints in the vehicle. The same <code>endpointId</code> is used to identify the endpoint targeted in an AASB message sent by the Engine.Note: Do not use this format for the <code>endpointId</code>: \\&lt;clientId&gt;::\\&lt;productId&gt;::\\&lt;serialNumber&gt;::[-\\&lt;extEndpoint&gt;]The Engine internally prepends the 3-part device prefix to your specified <code>endpointId</code> before sending the configuration to Alexa. Configuring the full ID directly results in duplication and excess characters. aace.carControl.endpoints[i].endpointResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this endpoint.Note: Only <code>\u201casset\u201d</code> type labels are supported. aace.carControl.endpoints[i].endpointResources.friendlyNames[j].assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to the endpoint. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at <code>aace.carControl.assets.customAssetsPath</code>. See the \"Additional Notes about Assets\" section for more details. aace.carControl.endpoints[i].capabilities list Yes A list of capability definitions, representing capabilities implemented by the device on behalf of the endpoint, that define how the endpoint can be controlled by the user. Each object in this list must be a valid definition for one of the capabilities supported by the <code>Car Control</code> module:Alexa.PowerController, Alexa.ToggleController, Alexa.ModeController, and Alexa.RangeController aace.carControl.zones list No, but recommended A list of zone definitions for the named regions in the vehicle. aace.carControl.zones[i].zoneId string Yes The identifier for the zone, unique amongst all zones in the vehicle. aace.carControl.zones[i].zoneResources.friendlyNames list Yes A list of label objects that describe the possible ways to refer to this zone.Note: Only <code>\u201casset\u201d</code> type labels are supported. aace.carControl.zones[i].zoneResources.friendlyNames[j].assetId string Yes The ID of an asset definition that includes the list of strings used to refer to the zone in all supported locales.The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at <code>aace.carControl.assets.customAssetsPath</code>. See the \"Additional Notes about Assets\" section for more details. aace.carControl.zones[i].members list Yes A list of endpoints that belong to this zone. aace.carControl.zones[i].members[j].endpointId string Yes The <code>endpointId</code> for an endpoint that belongs to this zone. aace.carControl.defaultZoneId string No, but recommended The <code>zoneId</code> of the default zone. Endpoints in this zone take precedence when a user utterance does not specify a zone.  It is recommended to use a zone that describes the whole vehicle as the default rather than a zone describing a specific region. aace.carControl.assets.customAssetsPath string(file path) No Specifies the path to a JSON file defining additional assets."},{"location":"explore/features/car-control/#power-controller-capability-configuration","title":"Power Controller Capability Configuration","text":"<p>Click to expand or collapse description</p> <p>See \"Alexa.PowerController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control.</p> <p>Sample JSON Object</p> <pre><code>{\n    \"type\": \"AlexaInterface\",\n    \"interface\": \"Alexa.PowerController\",\n    \"version\": \"3\",\n    \"properties\": {\n        \"supported\": [\n            {\n                \"name\": \"powerState\"\n            }\n        ],\n        \"proactivelyReported\": false,\n        \"retrievable\": false\n    }\n}\n</code></pre> <p>Object Parameters</p> Property Type Required Description properties.proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be proactively reported to Alexa via an event.Accepted values:<code>false</code> properties.retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be retrieved by Alexa.Accepted values:<code>false</code>"},{"location":"explore/features/car-control/#toggle-controller-capability-configuration","title":"Toggle Controller Capability Configuration","text":"<p>Click to expand or collapse description</p> <p>See \"Alexa.ToggleController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control.</p> <p>Sample JSON Object</p> <pre><code>{\n    \"type\": \"AlexaInterface\",\n    \"interface\": \"Alexa.ToggleController\",\n    \"version\": \"3\",\n    \"instance\": \"{{STRING}}\",\n    \"capabilityResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"{{STRING}}\"\n                }\n            },\n            ...\n        ]\n    },\n    \"properties\": {\n        \"proactivelyReported\": false,\n        \"retrievable\": false,\n        \"supported\": [\n            {\n                \"name\": \"toggleState\"\n            }\n        ]\n    },\n    \"semantics\": {\n        \"actionMappings\": [\n            {\n                \"@type\": \"ActionsToDirective\",\n                \"actions\": [\"{{STRING}}\", ...],\n                \"directive\": {\n                    \"name\": \"{{STRING}}\",\n                    \"payload\": {}\n                }\n            },\n            ...\n        ]\n    }\n}\n</code></pre> <p>Object Parameters</p> Property Type Required Description instance string Yes The identifier of this instance of Alexa.ToggleController on this endpoint. capabilityResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only <code>\u201casset\u201d</code> type labels are supported. capabilityResources.friendlyNames[i].assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at <code>aace.carControl.assets.customAssetsPath</code>. See the \"Additional Notes about Assets\" section for more details. properties.proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be proactively reported to Alexa via an event.Accepted values:<code>false</code> properties.retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be retrieved by Alexa.Accepted values:<code>false</code> semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance.Note: <code>semantics.stateMappings</code> is not supported. semantics.actionMappings[i].actions[j] string Yes, if <code>semantics</code> is present The identifiers of the utterances that should trigger the specified directive.Accepted values: <ul> <li><code>\"Alexa.Actions.Open\"</code>: \"open {endpoint}\"</li> <li><code>\"Alexa.Actions.Close\"</code>: \"close {endpoint}\"</li> <li><code>\"Alexa.Actions.Raise\"</code>: \"raise {endpoint}\"</li> <li><code>\"Alexa.Actions.Lower\"</code>: \"lower {endpoint}\"</li> </ul> semantics.actionMappings[i].directive.name string Yes, if <code>semantics</code> is present Accepted values: <ul> <li><code>\"TurnOn\"</code>: The specified <code>actions</code> will trigger the \"TurnOn\" directive. The Engine will publish the <code>SetToggleControllerValue</code> message, with the <code>turnOn</code> attribute set to <code>true</code>.</li> <li><code>\"TurnOff\"</code>: The specified <code>actions</code> will trigger the \"TurnOff\" directive. The Engine will publish the <code>SetToggleControllerValue</code> message, with the <code>turnOn</code> attribute set to <code>false</code>.</li> </ul>"},{"location":"explore/features/car-control/#mode-controller-capability-configuration","title":"Mode Controller Capability Configuration","text":"<p>Click to expand or collapse description</p> <p>See \"Alexa.ModeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control.</p> <p>Sample JSON Object</p> <pre><code>{\n    \"type\": \"AlexaInterface\",\n    \"interface\": \"Alexa.ModeController\",\n    \"version\": \"3\",\n    \"instance\": \"{{STRING}}\",\n    \"capabilityResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"{{STRING}}\"\n                }\n            },\n            ...\n        ]\n    },\n    \"properties\": {\n        \"supported\": [\n            {\n                \"name\": \"mode\"\n            }\n        ],\n        \"proactivelyReported\": false,\n        \"retrievable\": false\n    },\n    \"configuration\": {\n        \"ordered\": {{BOOLEAN}},\n        \"supportedModes\": [\n            {\n                \"value\": \"{{STRING}}\",\n                \"modeResources\": {\n                    \"friendlyNames\": [\n                        {\n                            \"@type\": \"asset\",\n                            \"value\": {\n                                \"assetId\": \"{{STRING}}\"\n                            }\n                        }\n                    ]\n                }\n            },\n            ...\n        ]\n    },\n    \"semantics\": {\n        \"actionMappings\": [\n            {\n                \"@type\": \"ActionsToDirective\",\n                \"actions\": [\"{{STRING}}\", ...],\n                \"directive\": {\n                    \"name\": \"{{STRING}}\",\n                    \"payload\": {{OBJECT}}\n                }\n            },\n            ...\n        ]\n    }\n}\n</code></pre> <p>Object Parameters</p> Property Type Required Description instance string Yes The identifier of this instance of Alexa.ModeController on this endpoint. capabilityResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only <code>\u201casset\u201d</code> type labels are supported. capabilityResources.friendlyNames[i].assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at <code>aace.carControl.assets.customAssetsPath</code>. See the \"Additional Notes about Assets\" section for more details. properties.proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be proactively reported to Alexa via an event.Accepted values:<code>false</code> properties.retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be retrieved by Alexa.Accepted values:<code>false</code> configuration.ordered boolean Yes Whether the modes of this capability instance are ordered, enabling iteration through them using the \"AdjustMode\" directive. configuration.supportedModes list Yes A list of objects describing the available modes of this capability instance. If <code>ordered</code> is true, the order of the objects in this list implies the ordering of the modes. configuration.supportedModes[i].value string Yes The identifier of this mode on this capability instance. configuration.supportedModes[i].modeResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this mode.Note: Only <code>\u201casset\u201d</code> type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance.Note: <code>semantics.stateMappings</code> is not supported. semantics.actionMappings[i].actions[j] string Yes, if <code>semantics</code> is present The identifiers of the utterances that should trigger the specified directive.Accepted values: <ul><li><code>\"Alexa.Actions.Open\"</code>: \"open {endpoint}\"</li><li><code>\"Alexa.Actions.Close\"</code>: \"close {endpoint}\"</li><li><code>\"Alexa.Actions.Raise\"</code>: \"raise {endpoint}\"</li><li><code>\"Alexa.Actions.Lower\"</code>: \"lower {endpoint}\"</li></ul> semantics.actionMappings[i].directive.name string Yes, if <code>semantics</code> is present Accepted values:<ul><li><code>\"SetMode\"</code>: The specified actions will trigger the \"SetMode\" directive with the specified <code>payload</code>. The Engine will publish the <code>SetModeControllerValue</code> message.</li><li><code>\"AdjustMode\"</code>: The specified actions will trigger the \"AdjustMode\" directive with the specified <code>payload</code>. The Engine will publish the <code>AdjustModeControllerValue</code> message. \"AdjustMode\" is accepted only if this capability instance is <code>ordered</code>. </li></ul> semantics.actionMappings[i].directive.payload object Yes, if <code>semantics</code> is present If <code>name</code> is \u201cSetMode\u201d, this is the \u201cSetMode\u201d directive payload object that contains the \u201cmode\u201d property and the corresponding value from <code>configuration.supportedModes[].value</code>.If <code>name</code> is \u201cAdjustMode\u201d, this is the \u201cAdjustMode\u201d directive payload object that contains the \u201cmodeDelta\u201d field and the corresponding number of modes to advance."},{"location":"explore/features/car-control/#range-controller-capability-configuration","title":"Range Controller Capability Configuration","text":"<p>Click to expand or collapse description</p> <p>See \"Alexa.RangeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control.</p> <p>Sample JSON Object</p> <pre><code>{\n    \"type\": \"AlexaInterface\",\n    \"interface\": \"Alexa.RangeController\",\n    \"version\": \"3\",\n    \"instance\": \"{{STRING}}\",\n    \"capabilityResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"{{STRING}}\"\n                }\n            },\n            ...\n        ]\n    },\n    \"properties\": {\n        \"supported\": [\n            {\n                \"name\": \"rangeValue\"\n            }\n        ],\n        \"proactivelyReported\": false,\n        \"retrievable\": false\n    },\n    \"configuration\": {\n        \"supportedRange\": {\n            \"minimumValue\": {{LONG}},\n            \"maximumValue\": {{LONG}},\n            \"precision\": {{LONG}}\n        },\n        \"unitOfMeasure\": \"{{STRING}}\",\n        \"presets\": [\n            {\n                \"rangeValue\": {{LONG}},\n                \"presetResources\": {\n                    \"friendlyNames\": [\n                        {\n                            \"@type\": \"asset\",\n                            \"value\": {\n                                \"assetId\": \"{{STRING}}\"\n                            }\n                        },\n                        ...\n                    ]\n                }\n            },\n            ...\n        ],\n        \"semantics\": {\n            \"actionMappings\": [\n                {\n                    \"@type\": \"ActionsToDirective\",\n                    \"actions\": [\"{{STRING}}\", ...],\n                    \"directive\": {\n                        \"name\": \"{{STRING}}\",\n                        \"payload\": {{OBJECT}}\n                    }\n                },\n                ...\n            ]\n        }\n    }\n}\n</code></pre> <p>Object Parameters</p> Property Type Required Description instance string Yes The identifier of this instance of Alexa.RangeController on this endpoint. capabilityResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only <code>\u201casset\u201d</code> type labels are supported. capabilityResources.friendlyNames[i].assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at <code>aace.carControl.assets.customAssetsPath</code>. See the \"Additional Notes about Assets\" section for more details. properties.proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be proactively reported to Alexa via an event.Accepted values:<code>false</code> properties.retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be retrieved by Alexa.Accepted values:<code>false</code> configuration.supportedRange.minimumValue long Yes The minimum value of the range this capability instance supports. configuration.supportedRange.maximumValue long Yes The maximum value of the range this capability instance supports. configuration.supportedRange.precision long Yes The amount by which the set value changes when iterating through the range. For example, if a user asks Alexa to increase the value but doesn't specify by how much, this value will be used. configuration.unitOfMeasure string No The unit of measure for the range. configuration.presets list Yes A list of objects describing values that can be invoked by name. For example, a <code>rangeValue</code> of 10 might be configured as the \"high\" preset. configuration.presets[i].rangeValue long Yes The value within the <code>supportedRange</code> that has an associated named preset. configuration.presets[i].presetResources.friendlyNames list Yes A list of label objects that describe the possible friendly names for this preset.Note: Only <code>\u201casset\u201d</code> type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance.Note: <code>semantics.stateMappings</code> is not supported. semantics.actionMappings[i].actions[j] string Yes, if <code>semantics</code> is present The identifiers of the utterances that should trigger the specified directive.Accepted values: <ul><li><code>\"Alexa.Actions.Open\"</code>: \"open {endpoint}\"</li><li><code>\"Alexa.Actions.Close\"</code>: \"close {endpoint}\"</li><li><code>\"Alexa.Actions.Raise\"</code>: \"raise {endpoint}\"</li><li><code>\"Alexa.Actions.Lower\"</code>: \"lower {endpoint}\"</li></ul> semantics.actionMappings[i].directive.name string Yes, if <code>semantics</code> is present Accepted values:<ul><li><code>\"SetRangeValue\"</code>: The specified actions will trigger the \"SetRangeValue\" directive with the specified <code>payload</code>. The Engine will publish the <code>SetRangeControllerValue</code> message.</li><li><code>\"AdjustRangeValue\"</code>: The specified actions will trigger the \"AdjustRangeValue\" directive with the specified <code>payload</code>. The Engine will publish the <code>AdjustRangeControllerValue</code> message.</li></ul> semantics.actionMappings[i].directive.payload object Yes, if <code>semantics</code> is present If <code>name</code> is \u201cSetRangeValue\u201d, this is the \u201cSetRangeValue\u201d directive payload object that contains the \"rangeValue\" property and the corresponding value between <code>configuration.supportedRange.minumumValue</code> and <code>configuration.supportedRange.maximumValue</code>.If <code>name</code> is \u201cAdjustRangeValue\u201d, this is the \u201cAdjustRangeValue\u201d directive payload object that contains the \u201crangeValueDelta\u201d field."},{"location":"explore/features/car-control/#additional-notes-about-assets","title":"Additional Notes about Assets","text":"<p>The <code>Car Control</code> module provides the full list of asset IDs available in the default automotive catalog of assets in the CarControlAssets.h header file, which defines string constants for these asset IDs to be used when constructing configuration programmatically. The values of the constants are the same asset IDs that you should use if you construct your configuration in a JSON file.</p> <p>This module also provides a reference JSON file with sample definitions of the assets in the automotive catalog. Your implementation does not need to duplicate these asset definitions or specify the path to this file because the definitions also exist in the Alexa cloud. This copy of the file is a reference for you to see the synonyms and translations for the available assets.</p> <p>Note: Because the actual asset definitions are defined in the Alexa cloud, this reference file may be outdated or missing translations.</p> <p>The automotive catalog of assets defines assets for every feature officially supported by car control. The majority of your configuration will use these asset IDs. Amazon recommends that you not create new, custom assets for features that already exist in the default catalog. However, if your vehicle has a feature that cannot be described using the default assets (e.g., an endpoint with a proprietary name), create an additional JSON file defining a complementary set of assets to use alongside the default catalog. The format of this file must follow the same schema as the reference default assets JSON, and the definitions must include entries for each of the locales supported in the default catalog. Prefix every <code>assetId</code> in this file with <code>\"My.\"</code>, and specify the path to the file in the optional <code>aace.carControl.assets.customAssetsPath</code> field of configuration.</p> <p>Note for LVC: When using Local Voice Control and car control custom assets, there are two distinct configurations \u2014 the Auto SDK Engine and the LVC app \u2014 that require the path to the custom assets definition file. See the below subsections for details for this configuration on Linux or Android.</p>"},{"location":"explore/features/car-control/#local-voice-control-custom-assets-for-linux-integration","title":"(Local Voice Control) Custom Assets for Linux Integration","text":"<p>The default LVC app configuration for Linux expects any custom assets to be defined in a file called <code>assets.json</code> located at <code>/opt/LVC/data/led-service/assets/assets.json</code>. Use this path when you configure the <code>aace.carControl.assets.customAssetsPath</code> field in the <code>Car Control</code> module configuration.</p>"},{"location":"explore/features/car-control/#sample-configuration","title":"Sample Configuration","text":"<p>The <code>Car Control</code> module provides a sample JSON file to configure the Auto SDK Engine with a vehicle fully equipped for every use case officially supported for car control. This file models each supported endpoint with a configuration of capabilities and zones that ensures all supported utterances for that endpoint work as expected. It is recommended that you construct the configuration for your application by selecting the parts of this sample that describe features supported by your vehicle. Make adjustments to the endpoints, such as modifying modes and range settings, as needed.</p>"},{"location":"explore/features/car-control/#configuration-for-linux-integration","title":"Configuration for Linux Integration","text":"<p>If your implementation constructs the <code>Car Control</code> module <code>EngineConfiguration</code> programmatically rather than with a JSON file, see the following example usage of the aace::carControl::config::CarControlConfiguration builder class that produces the same fully-equipped vehicle as the sample file:</p> <p>Click to expand or collapse CarControlConfiguration C++ sample code</p> <pre><code>#include &lt;AACE/CarControl/CarControlAssets.h&gt;\n\nusing namespace aace::carControl::config;\nusing namespace aace::carControl::assets;\n\n// Auto SDK Engine configuration\nstd::vector&lt;std::shared_ptr&lt;aace::core::config::EngineConfiguration&gt;&gt; configuration;\n\nauto config = aace::carControl::config::CarControlConfiguration::create();\n\nconfig\n-&gt;createZone(\"zone.default\")\n.addAssetId(alexa::location::ALL)\n.addMembers({\n\"climatecontrol\",\n\"default.ac\",\n\"default.fan\",\n\"default.vent\",\n\"default.heater\",\n\"default.light\",\n\"default.reading.light\",\n\"driver.cupholder\",\n\"driver.armrest\",\n\"driver.seat\",\n\"driver.window\",\n\"front.windshield\",\n\"front.foglight\",\n\"front.wipers\"\n})\n.createZone(\"zone.driver\")\n.addAssetId(alexa::location::DRIVER)\n.addAssetId(alexa::location::FRONT_LEFT)\n.addMembers({\n\"driver.fan\",\n\"driver.vent\",\n\"driver.heater\",\n\"driver.light\",\n\"driver.reading.light\",\n\"driver.cupholder\",\n\"driver.armrest\",\n\"driver.seat\",\n\"driver.window\"\n})\n.createZone(\"zone.passenger\")\n.addAssetId(alexa::location::PASSENGER)\n.addAssetId(alexa::location::FRONT_RIGHT)\n.addMembers({\n\"passenger.fan\",\n\"passenger.vent\",\n\"passenger.heater\",\n\"passenger.light\",\n\"passenger.reading.light\",\n\"passenger.cupholder\",\n\"passenger.armrest\",\n\"passenger.seat\",\n\"passenger.window\"\n})\n.createZone(\"zone.front\")\n.addAssetId(alexa::location::FRONT)\n.addMembers({\n\"front.ac\",\n\"front.fan\",\n\"front.vent\",\n\"front.light\",\n\"front.reading.light\",\n\"front.cupholder\",\n\"front.armrest\",\n\"front.seat\",\n\"front.windshield\",\n\"front.foglight\",\n\"front.wipers\",\n\"front.window\"\n})\n.createZone(\"zone.rear\")\n.addAssetId(alexa::location::REAR)\n.addMembers({\n\"rear.ac\",\n\"rear.fan\",\n\"rear.vent\",\n\"rear.light\",\n\"rear.reading.light\",\n\"rear.cupholder\",\n\"rear.armrest\",\n\"rear.seat\",\n\"rear.windshield\",\n\"rear.foglight\",\n\"rear.wipers\",\n\"rear.window\"\n})\n.createZone(\"zone.left\")\n.addAssetId(alexa::location::LEFT)\n.addMembers({\n\"left.heater\",\n\"driver.seat\",\n\"driver.vent\"\n})\n.createZone(\"zone.right\")\n.addAssetId(alexa::location::RIGHT)\n.addMembers({\n\"right.heater\",\n\"passenger.seat\",\n\"passenger.vent\"\n})\n.createZone(\"zone.rear.driver\")\n.addAssetId(alexa::location::REAR_DRIVER)\n.addAssetId(alexa::location::REAR_LEFT)\n.addMembers({\n\"rear.driver.fan\",\n\"rear.driver.vent\",\n\"rear.driver.light\",\n\"rear.driver.reading.light\",\n\"rear.driver.cupholder\",\n\"rear.driver.armrest\",\n\"rear.driver.seat\",\n\"rear.driver.window\"\n})\n.createZone(\"zone.rear.passenger\")\n.addAssetId(alexa::location::REAR_PASSENGER)\n.addAssetId(alexa::location::REAR_RIGHT)\n.addMembers({\n\"rear.passenger.fan\",\n\"rear.passenger.vent\",\n\"rear.passenger.light\",\n\"rear.passenger.reading.light\",\n\"rear.passenger.cupholder\",\n\"rear.passenger.armrest\",\n\"rear.passenger.seat\",\n\"rear.passenger.window\"\n})\n.createZone(\"zone.secondRow\")\n.addAssetId(alexa::location::SECOND_ROW)\n.addMembers({\n\"secondRow.fan\",\n\"secondRow.vent\",\n\"secondRow.light\",\n\"secondRow.reading.light\",\n\"secondRow.cupholder\",\n\"secondRow.armrest\",\n\"secondRow.seat\",\n\"secondRow.window\",\n\"secondRow.heater\"\n})\n.createZone(\"zone.thirdRow\")\n.addAssetId(alexa::location::THIRD_ROW)\n.addMembers({\n\"thirdRow.fan\",\n\"thirdRow.vent\",\n\"thirdRow.light\",\n\"thirdRow.reading.light\",\n\"thirdRow.cupholder\",\n\"thirdRow.armrest\",\n\"thirdRow.seat\",\n\"thirdRow.window\",\n\"thirdRow.heater\"\n})\n.setDefaultZone(\"zone.default\")\n\n// \"Car\"\n.createEndpoint(\"car\")\n.addAssetId(alexa::device::CAR)\n.addToggleController(\"recirculate\", false)\n.addAssetId(alexa::setting::AIR_RECIRCULATION)\n.addModeController(\"recirculatemode\", false, false)\n.addAssetId(alexa::setting::AIR_RECIRCULATION)\n.addValue(\"INSIDE\")\n.addAssetId(alexa::value::INSIDE_AIR)\n.addValue(\"OUTSIDE\")\n.addAssetId(alexa::value::OUTSIDE_AIR)\n.addValue(\"AUTO\")\n.addAssetId(alexa::setting::AUTO)\n.addToggleController(\"climate.sync\", false)\n.addAssetId(alexa::setting::CLIMATE_SYNC)\n.addModeController(\"driveMode\", false, false)\n.addAssetId(alexa::setting::DRIVE_MODE)\n.addValue(\"ECO\")\n.addAssetId(alexa::setting::ECONOMY)\n.addValue(\"COMFORT\")\n.addAssetId(alexa::value::COMFORT)\n.addValue(\"SPORT\")\n.addAssetId(alexa::value::SPORT)\n.addValue(\"SPORTPLUS\")\n.addAssetId(alexa::value::SPORT_PLUS)\n.addToggleController(\"towingMode\", false)\n.addAssetId(alexa::setting::TOWING_MODE)\n.addToggleController(\"hillAssist\", false)\n.addAssetId(alexa::setting::HILL_ASSIST)\n.addToggleController(\"windowLock\", false)\n.addAssetId(alexa::setting::WINDOW_LOCK)\n.addToggleController(\"autoBrakeHold\", false)\n.addAssetId(alexa::setting::AUTO_BRAKE_HOLD)\n\n// Ambient Light\n.createEndpoint(\"ambient.light\")\n.addAssetId(alexa::device::AMBIENT_LIGHT)\n.addPowerController(false)\n.addModeController(\"color\", false, false)\n.addAssetId(alexa::setting::COLOR)\n.addAssetId(alexa::setting::MODE)\n.addValue(\"RED\")\n.addAssetId(alexa::color::RED)\n.addValue(\"BLUE\")\n.addAssetId(alexa::color::BLUE)\n.addValue(\"GREEN\")\n.addAssetId(alexa::color::GREEN)\n.addValue(\"WHITE\")\n.addAssetId(alexa::color::WHITE)\n.addValue(\"ORANGE\")\n.addAssetId(alexa::color::ORANGE)\n.addValue(\"YELLOW\")\n.addAssetId(alexa::color::YELLOW)\n.addValue(\"INDIGO\")\n.addAssetId(alexa::color::INDIGO)\n.addValue(\"VIOLET\")\n.addAssetId(alexa::color::VIOLET)\n\n// Air Conditioner\n.createEndpoint(\"default.ac\")\n.addAssetId(alexa::device::AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(alexa::setting::MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(alexa::setting::ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(alexa::setting::AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(alexa::setting::MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(alexa::setting::INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(alexa::value::MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Front Air Conditioner\n.createEndpoint(\"front.ac\")\n.addAssetId(alexa::device::AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(alexa::setting::MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(alexa::setting::ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(alexa::setting::AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(alexa::setting::MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(alexa::setting::INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(alexa::value::MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Rear Air Conditioner\n.createEndpoint(\"rear.ac\")\n.addAssetId(alexa::device::AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(alexa::setting::MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(alexa::setting::ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(alexa::setting::AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(alexa::setting::MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(alexa::setting::INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(alexa::value::MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Fan\n.createEndpoint(\"default.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Driver Fan\n.createEndpoint(\"driver.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Passenger Fan\n.createEndpoint(\"passenger.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Front Fan\n.createEndpoint(\"front.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Rear Fan\n.createEndpoint(\"rear.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Rear Driver Fan\n.createEndpoint(\"rear.driver.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Rear Passenger Fan\n.createEndpoint(\"rear.passenger.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Second Row Fan\n.createEndpoint(\"secondRow.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Third Row Fan\n.createEndpoint(\"thirdRow.fan\")\n.addAssetId(alexa::device::FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1)\n.addAssetId(alexa::setting::FAN_SPEED)\n.addAssetId(alexa::setting::SPEED)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Vent\n.createEndpoint(\"default.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Driver Vent\n.createEndpoint(\"driver.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Passenger Vent\n.createEndpoint(\"passenger.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Front Vent\n.createEndpoint(\"front.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Rear Vent\n.createEndpoint(\"rear.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Rear Driver Vent\n.createEndpoint(\"rear.driver.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Rear Passenger Vent\n.createEndpoint(\"rear.passenger.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Second Row Vent\n.createEndpoint(\"secondRow.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Third Row Vent\n.createEndpoint(\"thirdRow.vent\")\n.addAssetId(alexa::device::VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"BODY\")\n.addAssetId(alexa::setting::BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(alexa::setting::FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(alexa::setting::MIX_VENTS)\n\n// Climate Control\n.createEndpoint(\"climatecontrol\")\n.addAssetId(alexa::device::CLIMATE_CONTROL)\n.addAssetId(alexa::setting::AUTO)\n.addPowerController(false)\n\n// Heater\n.createEndpoint(\"default.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Driver Heater\n.createEndpoint(\"driver.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Passenger Heater\n.createEndpoint(\"passenger.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Left Heater\n.createEndpoint(\"left.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Right Heater\n.createEndpoint(\"right.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Second Row Heater\n.createEndpoint(\"secondRow.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Third Row Heater\n.createEndpoint(\"thirdRow.heater\")\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::device::COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, alexa::unit::FAHRENHEIT)\n.addAssetId(alexa::setting::TEMPERATURE)\n.addAssetId(alexa::setting::HEAT)\n.addPreset(60)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(75)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(90)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Light\n.createEndpoint(\"default.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Driver Light\n.createEndpoint(\"driver.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Passenger Light\n.createEndpoint(\"passenger.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Front Light\n.createEndpoint(\"front.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Rear Light\n.createEndpoint(\"rear.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Rear Driver Light\n.createEndpoint(\"rear.driver.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Rear Passenger Light\n.createEndpoint(\"rear.passenger.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Second Row Light\n.createEndpoint(\"secondRow.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Third Row Light\n.createEndpoint(\"thirdRow.light\")\n.addAssetId(alexa::device::LIGHT)\n.addAssetId(alexa::device::DOME_LIGHT)\n.addAssetId(alexa::device::CABIN_LIGHT)\n.addPowerController(false)\n\n// Reading Light\n.createEndpoint(\"default.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Driver Reading Light\n.createEndpoint(\"driver.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Passenger Reading Light\n.createEndpoint(\"passenger.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Front Reading Light\n.createEndpoint(\"front.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Rear Reading Light\n.createEndpoint(\"rear.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Rear Driver Reading Light\n.createEndpoint(\"rear.driver.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Rear Passenger Reading Light\n.createEndpoint(\"rear.passenger.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Second Row Reading Light\n.createEndpoint(\"secondRow.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Third Row Reading Light\n.createEndpoint(\"thirdRow.reading.light\")\n.addAssetId(alexa::device::READING_LIGHT)\n.addPowerController(false)\n\n// Driver Cupholder\n.createEndpoint(\"driver.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Passenger Cupholder\n.createEndpoint(\"passenger.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Front Cupholder\n.createEndpoint(\"front.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Rear Cupholder\n.createEndpoint(\"rear.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Rear Driver Cupholder\n.createEndpoint(\"rear.driver.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Rear Passenger Cupholder\n.createEndpoint(\"rear.passenger.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Second Row Cupholder\n.createEndpoint(\"secondRow.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Third Row Cupholder\n.createEndpoint(\"thirdRow.cupholder\")\n.addAssetId(alexa::device::CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(alexa::device::COOLER)\n.addAssetId(alexa::setting::COOLING)\n\n// Driver Armrest\n.createEndpoint(\"driver.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Passenger Armrest\n.createEndpoint(\"passenger.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Front Armrest\n.createEndpoint(\"front.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Rear Armrest\n.createEndpoint(\"rear.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Rear Driver Armrest\n.createEndpoint(\"rear.driver.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Rear Passenger Armrest\n.createEndpoint(\"rear.passenger.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Second Row Armrest\n.createEndpoint(\"secondRow.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Third Row Armrest\n.createEndpoint(\"thirdRow.armrest\")\n.addAssetId(alexa::device::ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Driver Seat\n.createEndpoint(\"driver.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Passenger Seat\n.createEndpoint(\"passenger.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Front Seat\n.createEndpoint(\"front.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Rear Seat\n.createEndpoint(\"rear.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Rear Driver Seat\n.createEndpoint(\"rear.driver.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Rear Passenger Seat\n.createEndpoint(\"rear.passenger.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Second Row Seat\n.createEndpoint(\"secondRow.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Third Row Seat\n.createEndpoint(\"thirdRow.seat\")\n.addAssetId(alexa::device::SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n.addAssetId(alexa::device::SEAT_HEATER)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(2)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(3)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(alexa::device::VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(alexa::setting::STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(alexa::value::POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(alexa::value::POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(alexa::value::POSITION_THREE)\n\n// Front Window\n.createEndpoint(\"front.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Rear Window\n.createEndpoint(\"rear.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Driver Window\n.createEndpoint(\"driver.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Passenger Window\n.createEndpoint(\"passenger.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Rear Driver Window\n.createEndpoint(\"rear.driver.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Rear Passenger Window\n.createEndpoint(\"rear.passenger.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Second Row Window\n.createEndpoint(\"secondRow.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Third Row Window\n.createEndpoint(\"thirdRow.window\")\n.addAssetId(alexa::device::WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1)\n.addAssetId(alexa::setting::HEIGHT)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n\n// Front Windshield\n.createEndpoint(\"front.windshield\")\n.addAssetId(alexa::device::WINDOW)\n.addAssetId(alexa::device::WINDSHIELD)\n.addToggleController(\"defroster\", false)\n.addAssetId(alexa::setting::DEFROST)\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n\n// Rear Windshield\n.createEndpoint(\"rear.windshield\")\n.addAssetId(alexa::device::WINDOW)\n.addAssetId(alexa::device::WINDSHIELD)\n.addToggleController(\"defroster\", false)\n.addAssetId(alexa::setting::DEFROST)\n.addAssetId(alexa::setting::WINDSHIELD_VENTS)\n\n// Front Foglight\n.createEndpoint(\"front.foglight\")\n.addAssetId(alexa::device::FOG_LIGHT)\n.addPowerController(false)\n\n// Rear Foglight\n.createEndpoint(\"rear.foglight\")\n.addAssetId(alexa::device::FOG_LIGHT)\n.addPowerController(false)\n\n// Hazard Light\n.createEndpoint(\"hazardlight\")\n.addAssetId(alexa::device::HAZARD_LIGHTS)\n.addAssetId(alexa::device::PARKING_LIGHTS)\n.addPowerController(false)\n\n// Front Wipers\n.createEndpoint(\"front.wipers\")\n.addAssetId(alexa::device::WINDSHIELD_WIPERS)\n.addPowerController(false)\n.addModeController(\"speed\", false, true)\n.addAssetId(alexa::setting::SPEED)\n.addValue(\"LOW\")\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(alexa::value::MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Rear Wipers\n.createEndpoint(\"rear.wipers\")\n.addAssetId(alexa::device::WINDSHIELD_WIPERS)\n.addPowerController(false)\n.addModeController(\"speed\", false, true)\n.addAssetId(alexa::setting::SPEED)\n.addValue(\"LOW\")\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(alexa::value::MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// Sunroof\n.createEndpoint(\"sunroof\")\n.addAssetId(alexa::device::SUNROOF)\n.addAssetId(alexa::device::MOONROOF)\n.addRangeController(\"sunroof.position\", false, 0, 10, 1)\n.addAssetId(alexa::setting::POSITION)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n\n// Sunshade\n.createEndpoint(\"sunshade\")\n.addAssetId(alexa::device::SUNSHADE)\n.addRangeController(\"position\", false, 0, 10, 1)\n.addAssetId(alexa::setting::POSITION)\n.addPreset(10)\n.addAssetId(alexa::value::FULL)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addAssetId(alexa::value::HALF)\n.addActionSetRange({action::OPEN, action::LOWER}, 0)\n.addActionSetRange({action::CLOSE, action::RAISE}, 10)\n\n// HUD\n.createEndpoint(\"hud\")\n.addAssetId(alexa::device::HUD)\n.addToggleController(\"power\", false)\n.addAssetId(alexa::device::HUD)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n.addRangeController(\"brightness\", false, 1, 10, 1)\n.addAssetId(alexa::setting::BRIGHTNESS)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n\n// IVI\n.createEndpoint(\"ivi\")\n.addAssetId(alexa::device::DISPLAY_SCREEN)\n.addAssetId(alexa::device::INFO_SCREEN)\n.addToggleController(\"power\", false)\n.addAssetId(alexa::device::DISPLAY_SCREEN)\n.addAssetId(alexa::device::INFO_SCREEN)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n.addRangeController(\"brightness\", false, 1, 10, 1)\n.addAssetId(alexa::setting::BRIGHTNESS)\n.addPreset(1)\n.addAssetId(alexa::value::LOW)\n.addAssetId(alexa::value::MINIMUM)\n.addPreset(5)\n.addAssetId(alexa::value::MEDIUM)\n.addPreset(10)\n.addAssetId(alexa::value::HIGH)\n.addAssetId(alexa::value::MAXIMUM)\n.addModeController(\"autobrightness\", false, false)\n.addAssetId(alexa::setting::BRIGHTNESS)\n.addValue(\"OPTIMAL\")\n.addAssetId(alexa::value::OPTIMAL)\n.addValue(\"AUTO\")\n.addAssetId(alexa::setting::AUTO)\n\n// Dynamics Coordinator Page\n.createEndpoint(\"dynamicsCoordinatorPage\")\n.addAssetId(alexa::value::DYNAMIC_COORDINATOR_PAGE)\n.addToggleController(\"dynamicsCoordinator.screen\", false)\n.addAssetId(alexa::value::DYNAMIC_COORDINATOR_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Performance Page\n.createEndpoint(\"performancePage\")\n.addAssetId(alexa::value::PERFORMANCE_PAGE)\n.addToggleController(\"performance.screen\", false)\n.addAssetId(alexa::value::PERFORMANCE_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Home Page\n.createEndpoint(\"homepage\")\n.addAssetId(alexa::value::HOME_PAGE)\n.addToggleController(\"home.screen\", false)\n.addAssetId(alexa::value::HOME_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Bluetooth Page\n.createEndpoint(\"bluetoothPage\")\n.addAssetId(alexa::value::BLUETOOTH_PAGE)\n.addToggleController(\"bluetooth.screen\", false)\n.addAssetId(alexa::value::BLUETOOTH_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Radio Page\n.createEndpoint(\"radioPage\")\n.addAssetId(alexa::value::RADIO_PAGE)\n.addToggleController(\"radio.screen\", false)\n.addAssetId(alexa::value::RADIO_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Settings Page\n.createEndpoint(\"settingsPage\")\n.addAssetId(alexa::value::SETTINGS_PAGE)\n.addToggleController(\"settings.screen\", false)\n.addAssetId(alexa::value::SETTINGS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Controls Page\n.createEndpoint(\"controlsPage\")\n.addAssetId(alexa::value::CONTROLS_PAGE)\n.addToggleController(\"controls.screen\", false)\n.addAssetId(alexa::value::CONTROLS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Navigation Page\n.createEndpoint(\"navigationPage\")\n.addAssetId(alexa::value::NAVIGATION_PAGE)\n.addToggleController(\"navigation.screen\", false)\n.addAssetId(alexa::value::NAVIGATION_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// GPS Page\n.createEndpoint(\"gpsPage\")\n.addAssetId(alexa::value::GPS_PAGE)\n.addToggleController(\"gps.screen\", false)\n.addAssetId(alexa::value::GPS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Service Page\n.createEndpoint(\"servicePage\")\n.addAssetId(alexa::value::SERVICE_PAGE)\n.addToggleController(\"service.screen\", false)\n.addAssetId(alexa::value::SERVICE_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Satellite Radio Page\n.createEndpoint(\"satelliteRadioPage\")\n.addAssetId(alexa::value::SATELLITE_RADIO_PAGE)\n.addToggleController(\"satelliteRadio.screen\", false)\n.addAssetId(alexa::value::SATELLITE_RADIO_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Information Page\n.createEndpoint(\"informationPage\")\n.addAssetId(alexa::value::INFORMATION_PAGE)\n.addToggleController(\"information.screen\", false)\n.addAssetId(alexa::value::INFORMATION_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Vehicle Status Page\n.createEndpoint(\"vehicleStatusPage\")\n.addAssetId(alexa::value::VEHICLE_STATUS_PAGE)\n.addToggleController(\"vehicleStatus.screen\", false)\n.addAssetId(alexa::value::VEHICLE_STATUS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Multimedia Page\n.createEndpoint(\"multimediaPage\")\n.addAssetId(alexa::value::MULTIMEDIA_PAGE)\n.addAssetId(alexa::value::MUSIC_PAGE)\n.addToggleController(\"multimedia.screen\", false)\n.addAssetId(alexa::value::MULTIMEDIA_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Telephone Page\n.createEndpoint(\"telephonePage\")\n.addAssetId(alexa::value::TELEPHONE_PAGE)\n.addToggleController(\"telephone.screen\", false)\n.addAssetId(alexa::value::TELEPHONE_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Contacts Page\n.createEndpoint(\"contactsPage\")\n.addAssetId(alexa::value::CONTACTS_PAGE)\n.addToggleController(\"contacts.screen\", false)\n.addAssetId(alexa::value::CONTACTS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Alerts Page\n.createEndpoint(\"alertsPage\")\n.addAssetId(alexa::value::ALERTS_PAGE)\n.addToggleController(\"alerts.screen\", false)\n.addAssetId(alexa::value::ALERTS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// Notifications Page\n.createEndpoint(\"notificationsPage\")\n.addAssetId(alexa::value::NOTIFICATIONS_PAGE)\n.addToggleController(\"notifications.screen\", false)\n.addAssetId(alexa::value::NOTIFICATIONS_PAGE)\n.addActionTurnOff({action::CLOSE})\n.addActionTurnOn({action::OPEN})\n\n// 360 Camera\n.createEndpoint(\"360Camera\")\n.addAssetId(alexa::device::CAMERA_360)\n.addAssetId(alexa::device::AVM_CAMERA)\n.addPowerController(false)\n.addModeController(\"direction\", false, true)\n.addAssetId(alexa::setting::DIRECTION)\n.addValue(\"FRONT\")\n.addAssetId(alexa::location::FRONT)\n.addValue(\"REAR\")\n.addAssetId(alexa::location::REAR)\n.addValue(\"DRIVER\")\n.addAssetId(alexa::location::DRIVER)\n.addValue(\"PASSENGER\")\n.addAssetId(alexa::location::PASSENGER)\n.addValue(\"AUTO\")\n.addAssetId(alexa::setting::AUTO)\n\n// Steering Wheel\n.createEndpoint(\"steeringWheel\")\n.addAssetId(alexa::device::STEERING_WHEEL)\n.addToggleController(\"heater\", false)\n.addAssetId(alexa::device::HEATER)\n.addAssetId(alexa::setting::HEAT)\n\n// Hood\n.createEndpoint(\"hood\")\n.addAssetId(alexa::device::HOOD)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"OPEN\")\n.addAssetId(alexa::value::OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(alexa::value::CLOSED)\n.addActionSetMode({action::CLOSE}, \"CLOSED\")\n.addActionSetMode({action::OPEN}, \"OPEN\")\n\n// Trunk\n.createEndpoint(\"trunk\")\n.addAssetId(alexa::device::TRUNK)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"OPEN\")\n.addAssetId(alexa::value::OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(alexa::value::CLOSED)\n.addActionSetMode({action::CLOSE}, \"CLOSED\")\n.addActionSetMode({action::OPEN}, \"OPEN\")\n\n// Charge Door\n.createEndpoint(\"chargedoor\")\n.addAssetId(alexa::device::CHARGE_DOOR)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"OPEN\")\n.addAssetId(alexa::value::OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(alexa::value::CLOSED)\n.addActionSetMode({action::CLOSE}, \"CLOSED\")\n.addActionSetMode({action::OPEN}, \"OPEN\")\n\n// Gas Door\n.createEndpoint(\"gasdoor\")\n.addAssetId(alexa::device::GAS_DOOR)\n.addModeController(\"position\", false, false)\n.addAssetId(alexa::setting::POSITION)\n.addValue(\"OPEN\")\n.addAssetId(alexa::value::OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(alexa::value::CLOSED)\n.addActionSetMode({action::CLOSE}, \"CLOSED\")\n.addActionSetMode({action::OPEN}, \"OPEN\");\n\nconfiguration.push_back(config);\n</code></pre>"},{"location":"explore/features/car-control/#carcontrolconfiguration-java-sample-code","title":"CarControlConfiguration Java sample code","text":"<pre><code>import com.amazon.aace.carControl.CarControlAssets;\nimport com.amazon.aace.carControl.CarControlConfiguration;\nimport com.amazon.aace.core.config.EngineConfiguration;\n\n// Auto SDK Engine configuration\nList&lt;EngineConfiguration&gt; configuration = new ArrayList&lt;&gt;();\n\nCarControlConfiguration config = CarControlConfiguration.create();\n\nconfig.createZone(\"zone.default\")\n.addAssetId(CarControlAssets.Location.ALL)\n.addMembers(new String[] {\n\"climatecontrol\",\n\"default.ac\",\n\"default.fan\",\n\"default.vent\",\n\"default.heater\",\n\"default.light\",\n\"default.reading.light\",\n\"driver.cupholder\",\n\"driver.armrest\",\n\"driver.seat\",\n\"driver.window\",\n\"front.windshield\",\n\"front.foglight\",\n\"front.wipers\"\n});\nconfig.createZone(\"zone.driver\")\n.addAssetId(CarControlAssets.Location.DRIVER)\n.addAssetId(CarControlAssets.Location.FRONT_LEFT)\n.addMembers(new String[] {\n\"driver.fan\",\n\"driver.vent\",\n\"driver.heater\",\n\"driver.light\",\n\"driver.reading.light\",\n\"driver.cupholder\",\n\"driver.armrest\",\n\"driver.seat\",\n\"driver.window\"\n});\nconfig.createZone(\"zone.passenger\")\n.addAssetId(CarControlAssets.Location.PASSENGER)\n.addAssetId(CarControlAssets.Location.FRONT_RIGHT)\n.addMembers(new String[] {\n\"passenger.fan\",\n\"passenger.vent\",\n\"passenger.heater\",\n\"passenger.light\",\n\"passenger.reading.light\",\n\"passenger.cupholder\",\n\"passenger.armrest\",\n\"passenger.seat\",\n\"passenger.window\"\n});\nconfig.createZone(\"zone.front\")\n.addAssetId(CarControlAssets.Location.FRONT)\n.addMembers(new String[] {\n\"front.ac\",\n\"front.fan\",\n\"front.vent\",\n\"front.light\",\n\"front.reading.light\",\n\"front.cupholder\",\n\"front.armrest\",\n\"front.seat\",\n\"front.windshield\",\n\"front.foglight\",\n\"front.wipers\",\n\"front.window\"\n});\nconfig.createZone(\"zone.rear\")\n.addAssetId(CarControlAssets.Location.REAR)\n.addMembers(new String[] {\n\"rear.ac\",\n\"rear.fan\",\n\"rear.vent\",\n\"rear.light\",\n\"rear.reading.light\",\n\"rear.cupholder\",\n\"rear.armrest\",\n\"rear.seat\",\n\"rear.windshield\",\n\"rear.foglight\",\n\"rear.wipers\",\n\"rear.window\"\n});\nconfig.createZone(\"zone.left\")\n.addAssetId(CarControlAssets.Location.LEFT)\n.addMembers(new String[] {\n\"left.heater\",\n\"driver.seat\",\n\"driver.vent\"\n});\nconfig.createZone(\"zone.right\")\n.addAssetId(CarControlAssets.Location.RIGHT)\n.addMembers(new String[] {\n\"right.heater\",\n\"passenger.seat\",\n\"passenger.vent\"\n});\nconfig.createZone(\"zone.rear.driver\")\n.addAssetId(CarControlAssets.Location.REAR_DRIVER)\n.addAssetId(CarControlAssets.Location.REAR_LEFT)\n.addMembers(new String[] {\n\"rear.driver.fan\",\n\"rear.driver.vent\",\n\"rear.driver.light\",\n\"rear.driver.reading.light\",\n\"rear.driver.cupholder\",\n\"rear.driver.armrest\",\n\"rear.driver.seat\",\n\"rear.driver.window\"\n});\nconfig.createZone(\"zone.rear.passenger\")\n.addAssetId(CarControlAssets.Location.REAR_PASSENGER)\n.addAssetId(CarControlAssets.Location.REAR_RIGHT)\n.addMembers(new String[] {\n\"rear.passenger.fan\",\n\"rear.passenger.vent\",\n\"rear.passenger.light\",\n\"rear.passenger.reading.light\",\n\"rear.passenger.cupholder\",\n\"rear.passenger.armrest\",\n\"rear.passenger.seat\",\n\"rear.passenger.window\"\n});\nconfig.createZone(\"zone.secondRow\")\n.addAssetId(CarControlAssets.Location.SECOND_ROW)\n.addMembers(new String[] {\n\"secondRow.fan\",\n\"secondRow.vent\",\n\"secondRow.light\",\n\"secondRow.reading.light\",\n\"secondRow.cupholder\",\n\"secondRow.armrest\",\n\"secondRow.seat\",\n\"secondRow.window\",\n\"secondRow.heater\"\n});\nconfig.createZone(\"zone.thirdRow\")\n.addAssetId(CarControlAssets.Location.THIRD_ROW)\n.addMembers(new String[] {\n\"thirdRow.fan\",\n\"thirdRow.vent\",\n\"thirdRow.light\",\n\"thirdRow.reading.light\",\n\"thirdRow.cupholder\",\n\"thirdRow.armrest\",\n\"thirdRow.seat\",\n\"thirdRow.window\",\n\"thirdRow.heater\"\n});\nconfig.setDefaultZone(\"zone.default\");\n\n// \"Car\"\nconfig.createEndpoint(\"car\")\n.addAssetId(CarControlAssets.Device.CAR)\n.addToggleController(\"recirculate\", false)\n.addAssetId(CarControlAssets.Setting.AIR_RECIRCULATION)\n.addModeController(\"recirculatemode\", false, false)\n.addAssetId(CarControlAssets.Setting.AIR_RECIRCULATION)\n.addValue(\"INSIDE\")\n.addAssetId(CarControlAssets.Value.INSIDE_AIR)\n.addValue(\"OUTSIDE\")\n.addAssetId(CarControlAssets.Value.OUTSIDE_AIR)\n.addValue(\"AUTO\")\n.addAssetId(CarControlAssets.Setting.AUTO)\n.addToggleController(\"climate.sync\", false)\n.addAssetId(CarControlAssets.Setting.CLIMATE_SYNC)\n.addModeController(\"driveMode\", false, false)\n.addAssetId(CarControlAssets.Setting.DRIVE_MODE)\n.addValue(\"ECO\")\n.addAssetId(CarControlAssets.Setting.ECONOMY)\n.addValue(\"COMFORT\")\n.addAssetId(CarControlAssets.Value.COMFORT)\n.addValue(\"SPORT\")\n.addAssetId(CarControlAssets.Value.SPORT)\n.addValue(\"SPORTPLUS\")\n.addAssetId(CarControlAssets.Value.SPORT_PLUS)\n.addToggleController(\"towingMode\", false)\n.addAssetId(CarControlAssets.Setting.TOWING_MODE)\n.addToggleController(\"hillAssist\", false)\n.addAssetId(CarControlAssets.Setting.HILL_ASSIST)\n.addToggleController(\"windowLock\", false)\n.addAssetId(CarControlAssets.Setting.WINDOW_LOCK)\n.addToggleController(\"autoBrakeHold\", false)\n.addAssetId(CarControlAssets.Setting.AUTO_BRAKE_HOLD);\n\n// Ambient Light\nconfig.createEndpoint(\"ambient.light\")\n.addAssetId(CarControlAssets.Device.AMBIENT_LIGHT)\n.addPowerController(false)\n.addModeController(\"color\", false, false)\n.addAssetId(CarControlAssets.Setting.COLOR)\n.addAssetId(CarControlAssets.Setting.MODE)\n.addValue(\"RED\")\n.addAssetId(CarControlAssets.Color.RED)\n.addValue(\"BLUE\")\n.addAssetId(CarControlAssets.Color.BLUE)\n.addValue(\"GREEN\")\n.addAssetId(CarControlAssets.Color.GREEN)\n.addValue(\"WHITE\")\n.addAssetId(CarControlAssets.Color.WHITE)\n.addValue(\"ORANGE\")\n.addAssetId(CarControlAssets.Color.ORANGE)\n.addValue(\"YELLOW\")\n.addAssetId(CarControlAssets.Color.YELLOW)\n.addValue(\"INDIGO\")\n.addAssetId(CarControlAssets.Color.INDIGO)\n.addValue(\"VIOLET\")\n.addAssetId(CarControlAssets.Color.VIOLET);\n\n// Air Conditioner\nconfig.createEndpoint(\"default.ac\")\n.addAssetId(CarControlAssets.Device.AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(CarControlAssets.Setting.MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(CarControlAssets.Setting.ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(CarControlAssets.Setting.AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(CarControlAssets.Setting.MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(CarControlAssets.Setting.INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Front Air Conditioner\nconfig.createEndpoint(\"front.ac\")\n.addAssetId(CarControlAssets.Device.AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(CarControlAssets.Setting.MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(CarControlAssets.Setting.ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(CarControlAssets.Setting.AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(CarControlAssets.Setting.MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(CarControlAssets.Setting.INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Rear Air Conditioner\nconfig.createEndpoint(\"rear.ac\")\n.addAssetId(CarControlAssets.Device.AIR_CONDITIONER)\n.addPowerController(false)\n.addModeController(\"mode\", false, false)\n.addAssetId(CarControlAssets.Setting.MODE)\n.addValue(\"ECONOMY\")\n.addAssetId(CarControlAssets.Setting.ECONOMY)\n.addValue(\"AUTOMATIC\")\n.addAssetId(CarControlAssets.Setting.AUTO)\n.addValue(\"MANUAL\")\n.addAssetId(CarControlAssets.Setting.MANUAL)\n.addModeController(\"intensity\", false, true)\n.addAssetId(CarControlAssets.Setting.INTENSITY)\n.addValue(\"LOW\")\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Fan\nconfig.createEndpoint(\"default.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Driver Fan\nconfig.createEndpoint(\"driver.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Passenger Fan\nconfig.createEndpoint(\"passenger.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Front Fan\nconfig.createEndpoint(\"front.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Rear Fan\nconfig.createEndpoint(\"rear.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Rear Driver Fan\nconfig.createEndpoint(\"rear.driver.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Rear Passenger Fan\nconfig.createEndpoint(\"rear.passenger.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Second Row Fan\nconfig.createEndpoint(\"secondRow.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Third Row Fan\nconfig.createEndpoint(\"thirdRow.fan\")\n.addAssetId(CarControlAssets.Device.FAN)\n.addPowerController(false)\n.addRangeController(\"speed\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.FAN_SPEED)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Vent\nconfig.createEndpoint(\"default.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Driver Vent\nconfig.createEndpoint(\"driver.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Passenger Vent\nconfig.createEndpoint(\"passenger.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Front Vent\nconfig.createEndpoint(\"front.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Rear Vent\nconfig.createEndpoint(\"rear.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Rear Driver Vent\nconfig.createEndpoint(\"rear.driver.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Rear Passenger Vent\nconfig.createEndpoint(\"rear.passenger.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Second Row Vent\nconfig.createEndpoint(\"secondRow.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Third Row Vent\nconfig.createEndpoint(\"thirdRow.vent\")\n.addAssetId(CarControlAssets.Device.VENT)\n.addPowerController(false)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"BODY\")\n.addAssetId(CarControlAssets.Setting.BODY_VENTS)\n.addValue(\"FLOOR\")\n.addAssetId(CarControlAssets.Setting.FLOOR_VENTS)\n.addValue(\"WINDSHIELD\")\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS)\n.addValue(\"MIX\")\n.addAssetId(CarControlAssets.Setting.MIX_VENTS);\n\n// Climate Control\nconfig.createEndpoint(\"climatecontrol\")\n.addAssetId(CarControlAssets.Device.CLIMATE_CONTROL)\n.addAssetId(CarControlAssets.Setting.AUTO)\n.addPowerController(false);\n\n// Heater\nconfig.createEndpoint(\"default.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Driver Heater\nconfig.createEndpoint(\"driver.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Passenger Heater\nconfig.createEndpoint(\"passenger.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Left Heater\nconfig.createEndpoint(\"left.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Right Heater\nconfig.createEndpoint(\"right.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Second Row Heater\nconfig.createEndpoint(\"secondRow.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Third Row Heater\nconfig.createEndpoint(\"thirdRow.heater\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addPowerController(false)\n.addRangeController(\"temperature\", false, 60, 90, 1, CarControlAssets.Unit.FAHRENHEIT)\n.addAssetId(CarControlAssets.Setting.TEMPERATURE)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addPreset(60)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(75)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(90)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Light\nconfig.createEndpoint(\"default.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Driver Light\nconfig.createEndpoint(\"driver.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Passenger Light\nconfig.createEndpoint(\"passenger.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Front Light\nconfig.createEndpoint(\"front.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Rear Light\nconfig.createEndpoint(\"rear.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Rear Driver Light\nconfig.createEndpoint(\"rear.driver.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Rear Passenger Light\nconfig.createEndpoint(\"rear.passenger.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Second Row Light\nconfig.createEndpoint(\"secondRow.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Third Row Light\nconfig.createEndpoint(\"thirdRow.light\")\n.addAssetId(CarControlAssets.Device.LIGHT)\n.addAssetId(CarControlAssets.Device.DOME_LIGHT)\n.addAssetId(CarControlAssets.Device.CABIN_LIGHT)\n.addPowerController(false);\n\n// Reading Light\nconfig.createEndpoint(\"default.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Driver Reading Light\nconfig.createEndpoint(\"driver.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Passenger Reading Light\nconfig.createEndpoint(\"passenger.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Front Reading Light\nconfig.createEndpoint(\"front.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Rear Reading Light\nconfig.createEndpoint(\"rear.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Rear Driver Reading Light\nconfig.createEndpoint(\"rear.driver.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Rear Passenger Reading Light\nconfig.createEndpoint(\"rear.passenger.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Second Row Reading Light\nconfig.createEndpoint(\"secondRow.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Third Row Reading Light\nconfig.createEndpoint(\"thirdRow.reading.light\")\n.addAssetId(CarControlAssets.Device.READING_LIGHT)\n.addPowerController(false);\n\n// Driver Cupholder\nconfig.createEndpoint(\"driver.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Passenger Cupholder\nconfig.createEndpoint(\"passenger.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Front Cupholder\nconfig.createEndpoint(\"front.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Rear Cupholder\nconfig.createEndpoint(\"rear.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Rear Driver Cupholder\nconfig.createEndpoint(\"rear.driver.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Rear Passenger Cupholder\nconfig.createEndpoint(\"rear.passenger.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Second Row Cupholder\nconfig.createEndpoint(\"secondRow.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Third Row Cupholder\nconfig.createEndpoint(\"thirdRow.cupholder\")\n.addAssetId(CarControlAssets.Device.CUP_HOLDER)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addToggleController(\"cooler\", false)\n.addAssetId(CarControlAssets.Device.COOLER)\n.addAssetId(CarControlAssets.Setting.COOLING);\n\n// Driver Armrest\nconfig.createEndpoint(\"driver.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Passenger Armrest\nconfig.createEndpoint(\"passenger.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Front Armrest\nconfig.createEndpoint(\"front.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Rear Armrest\nconfig.createEndpoint(\"rear.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Rear Driver Armrest\nconfig.createEndpoint(\"rear.driver.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Rear Passenger Armrest\nconfig.createEndpoint(\"rear.passenger.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Second Row Armrest\nconfig.createEndpoint(\"secondRow.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Third Row Armrest\nconfig.createEndpoint(\"thirdRow.armrest\")\n.addAssetId(CarControlAssets.Device.ARMREST)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Driver Seat\nconfig.createEndpoint(\"driver.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Passenger Seat\nconfig.createEndpoint(\"passenger.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Front Seat\nconfig.createEndpoint(\"front.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Rear Seat\nconfig.createEndpoint(\"rear.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Rear Driver Seat\nconfig.createEndpoint(\"rear.driver.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Rear Passenger Seat\nconfig.createEndpoint(\"rear.passenger.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Second Row Seat\nconfig.createEndpoint(\"secondRow.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Third Row Seat\nconfig.createEndpoint(\"thirdRow.seat\")\n.addAssetId(CarControlAssets.Device.SEAT)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addRangeController(\"heaterintensity\", false, 1, 3, 1, \"\")\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT)\n.addAssetId(CarControlAssets.Device.SEAT_HEATER)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(2)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(3)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addToggleController(\"vent\", false)\n.addAssetId(CarControlAssets.Device.VENT)\n.addModeController(\"position\", false, true)\n.addAssetId(CarControlAssets.Setting.STORED_POSITION)\n.addValue(\"ONE\")\n.addAssetId(CarControlAssets.Value.POSITION_ONE)\n.addValue(\"TWO\")\n.addAssetId(CarControlAssets.Value.POSITION_TWO)\n.addValue(\"THREE\")\n.addAssetId(CarControlAssets.Value.POSITION_THREE);\n\n// Front Window\nconfig.createEndpoint(\"front.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Rear Window\nconfig.createEndpoint(\"rear.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Driver Window\nconfig.createEndpoint(\"driver.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Passenger Window\nconfig.createEndpoint(\"passenger.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Rear Driver Window\nconfig.createEndpoint(\"rear.driver.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Rear Passenger Window\nconfig.createEndpoint(\"rear.passenger.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Second Row Window\nconfig.createEndpoint(\"secondRow.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Third Row Window\nconfig.createEndpoint(\"thirdRow.window\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addRangeController(\"height\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.HEIGHT)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0);\n\n// Front Windshield\nconfig.createEndpoint(\"front.windshield\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addAssetId(CarControlAssets.Device.WINDSHIELD)\n.addToggleController(\"defroster\", false)\n.addAssetId(CarControlAssets.Setting.DEFROST)\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS);\n\n// Rear Windshield\nconfig.createEndpoint(\"rear.windshield\")\n.addAssetId(CarControlAssets.Device.WINDOW)\n.addAssetId(CarControlAssets.Device.WINDSHIELD)\n.addToggleController(\"defroster\", false)\n.addAssetId(CarControlAssets.Setting.DEFROST)\n.addAssetId(CarControlAssets.Setting.WINDSHIELD_VENTS);\n\n// Front Foglight\nconfig.createEndpoint(\"front.foglight\")\n.addAssetId(CarControlAssets.Device.FOG_LIGHT)\n.addPowerController(false);\n\n// Rear Foglight\nconfig.createEndpoint(\"rear.foglight\")\n.addAssetId(CarControlAssets.Device.FOG_LIGHT)\n.addPowerController(false);\n\n// Hazard Light\nconfig.createEndpoint(\"hazardlight\")\n.addAssetId(CarControlAssets.Device.HAZARD_LIGHTS)\n.addAssetId(CarControlAssets.Device.PARKING_LIGHTS)\n.addPowerController(false);\n\n// Front Wipers\nconfig.createEndpoint(\"front.wipers\")\n.addAssetId(CarControlAssets.Device.WINDSHIELD_WIPERS)\n.addPowerController(false)\n.addModeController(\"speed\", false, true)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addValue(\"LOW\")\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Rear Wipers\nconfig.createEndpoint(\"rear.wipers\")\n.addAssetId(CarControlAssets.Device.WINDSHIELD_WIPERS)\n.addPowerController(false)\n.addModeController(\"speed\", false, true)\n.addAssetId(CarControlAssets.Setting.SPEED)\n.addValue(\"LOW\")\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addValue(\"MEDIUM\")\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addValue(\"HIGH\")\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// Sunroof\nconfig.createEndpoint(\"sunroof\")\n.addAssetId(CarControlAssets.Device.SUNROOF)\n.addAssetId(CarControlAssets.Device.MOONROOF)\n.addRangeController(\"sunroof.position\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10);\n\n// Sunshade\nconfig.createEndpoint(\"sunshade\")\n.addAssetId(CarControlAssets.Device.SUNSHADE)\n.addRangeController(\"position\", false, 0, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.FULL)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addAssetId(CarControlAssets.Value.HALF)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.OPEN, CarControlConfiguration.Action.LOWER}, 0)\n.addActionSetRange(new String[] {CarControlConfiguration.Action.CLOSE, CarControlConfiguration.Action.RAISE}, 10);\n\n// HUD\nconfig.createEndpoint(\"hud\")\n.addAssetId(CarControlAssets.Device.HUD)\n.addToggleController(\"power\", false)\n.addAssetId(CarControlAssets.Device.HUD)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN})\n.addRangeController(\"brightness\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.BRIGHTNESS)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM);\n\n// IVI\nconfig.createEndpoint(\"ivi\")\n.addAssetId(CarControlAssets.Device.DISPLAY_SCREEN)\n.addAssetId(CarControlAssets.Device.INFO_SCREEN)\n.addToggleController(\"power\", false)\n.addAssetId(CarControlAssets.Device.DISPLAY_SCREEN)\n.addAssetId(CarControlAssets.Device.INFO_SCREEN)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN})\n.addRangeController(\"brightness\", false, 1, 10, 1, \"\")\n.addAssetId(CarControlAssets.Setting.BRIGHTNESS)\n.addPreset(1)\n.addAssetId(CarControlAssets.Value.LOW)\n.addAssetId(CarControlAssets.Value.MINIMUM)\n.addPreset(5)\n.addAssetId(CarControlAssets.Value.MEDIUM)\n.addPreset(10)\n.addAssetId(CarControlAssets.Value.HIGH)\n.addAssetId(CarControlAssets.Value.MAXIMUM)\n.addModeController(\"autobrightness\", false, false)\n.addAssetId(CarControlAssets.Setting.BRIGHTNESS)\n.addValue(\"OPTIMAL\")\n.addAssetId(CarControlAssets.Value.OPTIMAL)\n.addValue(\"AUTO\")\n.addAssetId(CarControlAssets.Setting.AUTO);\n\n// Dynamics Coordinator Page\nconfig.createEndpoint(\"dynamicsCoordinatorPage\")\n.addAssetId(CarControlAssets.Value.DYNAMIC_COORDINATOR_PAGE)\n.addToggleController(\"dynamicsCoordinator.screen\", false)\n.addAssetId(CarControlAssets.Value.DYNAMIC_COORDINATOR_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Performance Page\nconfig.createEndpoint(\"performancePage\")\n.addAssetId(CarControlAssets.Value.PERFORMANCE_PAGE)\n.addToggleController(\"performance.screen\", false)\n.addAssetId(CarControlAssets.Value.PERFORMANCE_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Home Page\nconfig.createEndpoint(\"homepage\")\n.addAssetId(CarControlAssets.Value.HOME_PAGE)\n.addToggleController(\"home.screen\", false)\n.addAssetId(CarControlAssets.Value.HOME_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Bluetooth Page\nconfig.createEndpoint(\"bluetoothPage\")\n.addAssetId(CarControlAssets.Value.BLUETOOTH_PAGE)\n.addToggleController(\"bluetooth.screen\", false)\n.addAssetId(CarControlAssets.Value.BLUETOOTH_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Radio Page\nconfig.createEndpoint(\"radioPage\")\n.addAssetId(CarControlAssets.Value.RADIO_PAGE)\n.addToggleController(\"radio.screen\", false)\n.addAssetId(CarControlAssets.Value.RADIO_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Settings Page\nconfig.createEndpoint(\"settingsPage\")\n.addAssetId(CarControlAssets.Value.SETTINGS_PAGE)\n.addToggleController(\"settings.screen\", false)\n.addAssetId(CarControlAssets.Value.SETTINGS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Controls Page\nconfig.createEndpoint(\"controlsPage\")\n.addAssetId(CarControlAssets.Value.CONTROLS_PAGE)\n.addToggleController(\"controls.screen\", false)\n.addAssetId(CarControlAssets.Value.CONTROLS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Navigation Page\nconfig.createEndpoint(\"navigationPage\")\n.addAssetId(CarControlAssets.Value.NAVIGATION_PAGE)\n.addToggleController(\"navigation.screen\", false)\n.addAssetId(CarControlAssets.Value.NAVIGATION_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// GPS Page\nconfig.createEndpoint(\"gpsPage\")\n.addAssetId(CarControlAssets.Value.GPS_PAGE)\n.addToggleController(\"gps.screen\", false)\n.addAssetId(CarControlAssets.Value.GPS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Service Page\nconfig.createEndpoint(\"servicePage\")\n.addAssetId(CarControlAssets.Value.SERVICE_PAGE)\n.addToggleController(\"service.screen\", false)\n.addAssetId(CarControlAssets.Value.SERVICE_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Satellite Radio Page\nconfig.createEndpoint(\"satelliteRadioPage\")\n.addAssetId(CarControlAssets.Value.SATELLITE_RADIO_PAGE)\n.addToggleController(\"satelliteRadio.screen\", false)\n.addAssetId(CarControlAssets.Value.SATELLITE_RADIO_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Information Page\nconfig.createEndpoint(\"informationPage\")\n.addAssetId(CarControlAssets.Value.INFORMATION_PAGE)\n.addToggleController(\"information.screen\", false)\n.addAssetId(CarControlAssets.Value.INFORMATION_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Vehicle Status Page\nconfig.createEndpoint(\"vehicleStatusPage\")\n.addAssetId(CarControlAssets.Value.VEHICLE_STATUS_PAGE)\n.addToggleController(\"vehicleStatus.screen\", false)\n.addAssetId(CarControlAssets.Value.VEHICLE_STATUS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Multimedia Page\nconfig.createEndpoint(\"multimediaPage\")\n.addAssetId(CarControlAssets.Value.MULTIMEDIA_PAGE)\n.addAssetId(CarControlAssets.Value.MUSIC_PAGE)\n.addToggleController(\"multimedia.screen\", false)\n.addAssetId(CarControlAssets.Value.MULTIMEDIA_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Telephone Page\nconfig.createEndpoint(\"telephonePage\")\n.addAssetId(CarControlAssets.Value.TELEPHONE_PAGE)\n.addToggleController(\"telephone.screen\", false)\n.addAssetId(CarControlAssets.Value.TELEPHONE_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Contacts Page\nconfig.createEndpoint(\"contactsPage\")\n.addAssetId(CarControlAssets.Value.CONTACTS_PAGE)\n.addToggleController(\"contacts.screen\", false)\n.addAssetId(CarControlAssets.Value.CONTACTS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Alerts Page\nconfig.createEndpoint(\"alertsPage\")\n.addAssetId(CarControlAssets.Value.ALERTS_PAGE)\n.addToggleController(\"alerts.screen\", false)\n.addAssetId(CarControlAssets.Value.ALERTS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// Notifications Page\nconfig.createEndpoint(\"notificationsPage\")\n.addAssetId(CarControlAssets.Value.NOTIFICATIONS_PAGE)\n.addToggleController(\"notifications.screen\", false)\n.addAssetId(CarControlAssets.Value.NOTIFICATIONS_PAGE)\n.addActionTurnOff(new String[] {CarControlConfiguration.Action.CLOSE})\n.addActionTurnOn(new String[] {CarControlConfiguration.Action.OPEN});\n\n// 360 Camera\nconfig.createEndpoint(\"360Camera\")\n.addAssetId(CarControlAssets.Device.CAMERA_360)\n.addAssetId(CarControlAssets.Device.AVM_CAMERA)\n.addPowerController(false)\n.addModeController(\"direction\", false, true)\n.addAssetId(CarControlAssets.Setting.DIRECTION)\n.addValue(\"FRONT\")\n.addAssetId(CarControlAssets.Location.FRONT)\n.addValue(\"REAR\")\n.addAssetId(CarControlAssets.Location.REAR)\n.addValue(\"DRIVER\")\n.addAssetId(CarControlAssets.Location.DRIVER)\n.addValue(\"PASSENGER\")\n.addAssetId(CarControlAssets.Location.PASSENGER)\n.addValue(\"AUTO\")\n.addAssetId(CarControlAssets.Setting.AUTO);\n\n// Steering Wheel\nconfig.createEndpoint(\"steeringWheel\")\n.addAssetId(CarControlAssets.Device.STEERING_WHEEL)\n.addToggleController(\"heater\", false)\n.addAssetId(CarControlAssets.Device.HEATER)\n.addAssetId(CarControlAssets.Setting.HEAT);\n\n// Hood\nconfig.createEndpoint(\"hood\")\n.addAssetId(CarControlAssets.Device.HOOD)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"OPEN\")\n.addAssetId(CarControlAssets.Value.OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(CarControlAssets.Value.CLOSED)\n.addActionSetMode(new String[] {CarControlConfiguration.Action.CLOSE}, \"CLOSED\")\n.addActionSetMode(new String[] {CarControlConfiguration.Action.OPEN}, \"OPEN\");\n\n// Trunk\nconfig.createEndpoint(\"trunk\")\n.addAssetId(CarControlAssets.Device.TRUNK)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"OPEN\")\n.addAssetId(CarControlAssets.Value.OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(CarControlAssets.Value.CLOSED)\n.addActionSetMode(new String[] {CarControlConfiguration.Action.CLOSE}, \"CLOSED\")\n.addActionSetMode(new String[] {CarControlConfiguration.Action.OPEN}, \"OPEN\");\n\n// Charge Door\nconfig.createEndpoint(\"chargedoor\")\n.addAssetId(CarControlAssets.Device.CHARGE_DOOR)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"OPEN\")\n.addAssetId(CarControlAssets.Value.OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(CarControlAssets.Value.CLOSED)\n.addActionSetMode(new String[] {CarControlConfiguration.Action.CLOSE}, \"CLOSED\")\n.addActionSetMode(new String[] {CarControlConfiguration.Action.OPEN}, \"OPEN\");\n\n// Gas Door\nconfig.createEndpoint(\"gasdoor\")\n.addAssetId(CarControlAssets.Device.GAS_DOOR)\n.addModeController(\"position\", false, false)\n.addAssetId(CarControlAssets.Setting.POSITION)\n.addValue(\"OPEN\")\n.addAssetId(CarControlAssets.Value.OPEN)\n.addValue(\"CLOSED\")\n.addAssetId(CarControlAssets.Value.CLOSED)\n.addActionSetMode(new String[] {CarControlConfiguration.Action.CLOSE}, \"CLOSED\")\n.addActionSetMode(new String[] {CarControlConfiguration.Action.OPEN}, \"OPEN\");\n\n\nconfiguration.add(config);\n</code></pre>"},{"location":"explore/features/car-control/#using-the-car-control-module-aasb-messages","title":"Using the Car Control Module AASB Messages","text":"<p>The Auto SDK Engine provides an AASB message interface with topic <code>CarControl</code> for you to handle the car control directives from Alexa. The messages include an <code>endpointId</code> to identify the connected endpoint that Alexa identified to match the user's intent. For directives targeting primitive capability instances, the message includes the <code>instanceId</code> as well. The <code>endpointId</code> and <code>instanceId</code> match the configured IDs from <code>aace.carControl.endpoints[i].endpointId</code> and <code>aace.carControl.endpoints[i].capabilities[j].instance</code>, respectively.</p>"},{"location":"explore/features/car-control/#changing-the-power-state-of-an-endpoint","title":"Changing the power state of an endpoint","text":"<p>When the user requests Alexa to turn an endpoint on or off, the Engine publishes a <code>SetControllerValue</code> message for power state. Your application must power on or off the endpoint and publish <code>SetControllerReply</code> message in response.</p> <p>Click to expand or collapse sequence diagram: Turning on AC </p> <p></p> <p>Click to expand or collapse sequence diagram: Turning off AC </p> <p></p>"},{"location":"explore/features/car-control/#toggling-an-endpoint-property","title":"Toggling an endpoint property","text":"<p>When the user requests Alexa to turn on or off a named property of an endpoint, the Engine publishes a <code>SetControllerValue</code> message for toggle of the setting. Your application must turn on or off the property and publish <code>SetControllerValueReply</code> message in response.</p> <p>Click to expand or collapse sequence diagram: Turning on the rear windshield defroster </p> <p></p> <p>Click to expand or collapse sequence diagram: Turning off the rear windshield defroster </p> <p></p>"},{"location":"explore/features/car-control/#changing-the-mode-of-an-endpoint-property","title":"Changing the mode of an endpoint property","text":"<p>When the user requests Alexa to set the mode of a named property of an endpoint to a specific value, the Engine publishes a <code>SetControllerValue</code> message for mode of the setting. Your application must set the mode of the property and publish SetControllerValueReply` message in response.</p> <p>Click to expand or collapse sequence diagram: Setting the AC intensity to minimum </p> <p></p> <p>When the user requests Alexa to increase or decrease the mode of a named property of an endpoint, the Engine publishes an <code>AdjustControllerValue</code> message for mode of the setting. Your application must adjust the mode of the property and publish <code>AdjustControllerValueReply</code> message in response.</p> <p>Click to expand or collapse sequence diagram: Increasing the AC intensity </p> <p></p>"},{"location":"explore/features/car-control/#changing-the-numeric-setting-of-an-endpoint-property","title":"Changing the numeric setting of an endpoint property","text":"<p>When the user requests Alexa to set the numeric setting of a named property of an endpoint to a specific value, the Engine publishes a <code>SetControllerValue</code> message for the range setting. Your application must set the value of the property and publish <code>SetControllerValueReply</code> message in response.</p> <p>Click to expand or collapse sequence diagram: Setting the temperature to 70 </p> <p></p> <p>When the user requests Alexa to adjust (increment or decrement) the numeric setting of a named property of an endpoint by a delta value, the Engine publishes a <code>AdjustControllerValue</code> message for the range setting. Your application must adjust the value of the property and publish <code>AdjustControllerValueReply</code> message in response.</p> <p>Click to expand or collapse sequence diagram: Increasing the temperature by 4 </p> <p></p>"},{"location":"explore/features/car-control/#integrating-the-car-control-module-into-your-application","title":"Integrating the Car Control Module Into Your Application","text":""},{"location":"explore/features/car-control/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to subscribe to \"CarControl\" AASB messages and publish replies.</p> <p>Click to expand or collapse C++ sample code</p> <pre><code>#include &lt;AACE/CarControl/CarControlConfiguration.h&gt;\n#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/CarControl/CarControl/AdjustControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/AdjustRangeControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/AdjustModeControllerValueMessage.h&gt;\n\n#include &lt;AASB/Message/CarControl/CarControl/SetControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/SetRangeControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/SetModeControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/SetPowerControllerValueMessage.h&gt;\n#include &lt;AASB/Message/CarControl/CarControl/SetToggleControllerValueMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyCarControlHandler {\n\nstatic const std::string AASB_TOPIC_CAR_CONTROL(\"CarControl\");\nstatic const std::string AASB_ACTION_SET_CONTROLLER_VALUE(\"SetControllerValue\");\nstatic const std::string AASB_ACTION_ADJUST_CONTROLLER_VALUE(\"AdjustControllerValue\");\n\n// Subscribe to \"CarControl\" messages from the Engine\nvoid MyCarControlHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleSetControllerValueMessage(message); },\nAASB_TOPIC_CAR_CONTROL,\nAASB_ACTION_SET_CONTROLLER_VALUE);\n\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleAdjustControllerValueMessage(message); },\nAASB_TOPIC_CAR_CONTROL,\nAASB_ACTION_ADJUST_CONTROLLER_VALUE);\n}\n\n// Handle the messages from the Engine for \"SetControllerValue\" action\nvoid MyCarControlHandler::handleSetControllerValueMessage(const std::string&amp; message) {\njson msgJson = json::parse(message);\n\nstd::string capabilityType = msgJson[\"payload\"][\"capabilityType\"];\nif (capabilityType.compare(\"POWER\") == 0) {\nSetPowerControllerValueMessage msg = json::parse(message);\nsetPowerControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.turnOn);\n} else if (capabilityType.compare(\"TOGGLE\") == 0) {\nSetToggleControllerValueMessage msg = json::parse(message);\nsetToggleControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.instanceId, msg.payload.turnOn);\n} else if (capabilityType.compare(\"RANGE\") == 0) {\nSetRangeControllerValueMessage msg = json::parse(message);\nsetRangeControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.instanceId, msg.payload.value);\n} else if (capabilityType.compare(\"MODE\") == 0) {\nSetModeControllerValueMessage msg = json::parse(message);\nsetModeControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.instanceId, msg.payload.value);\n} else {\n// Error. Unsupported controller type in message\n}\n}\n\nvoid MyCarControlHandler::setPowerControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nbool turnOn) {\nif (turnOn) {\n// Power on the endpoint represented by endpointId.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n} else {\n// Power off the endpoint represented by endpointId.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n}\n}\n\nvoid MyCarControlHandler::setToggleControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nconst std::string&amp; instanceId,\nbool turnOn) {\nif (turnOn) {\n// Turn on the endpoint property represented by endpointId and instanceId.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n} else {\n// Turn off the endpoint property represented by endpointId and instanceId.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n}\n}\n\nvoid MyCarControlHandler::setRangeControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nconst std::string&amp; instanceId,\ndouble value) {\n// Set the numeric setting of the property represented by endpointId and instanceId to the specified value.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n}\n\nvoid MyCarControlHandler::setModeControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nconst std::string&amp; instanceId,\nconst std::string&amp; value) {\n// Set the mode of the property represented by endpointId and instanceId to the specified value.\n// When complete, call sendSetControllerValueMessageReply() with messageId and the result\n}\n\nvoid MyCarControlHandler::sendSetControllerValueMessageReply(const std::string&amp; messageId, bool successful) {\nSetControllerValueMessageReply msg;\nmsg.header.messageDescription.replyToId = messageId;\nmsg.payload.success = successful;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// Handle the messages from the Engine for \"AdjustControllerValue\" action\nvoid MyCarControlHandler::handleAdjustControllerValueMessage(const std::string&amp; message) {\njson msgJson = json::parse(message);\n\nstd::string capabilityType = msgJson[\"payload\"][\"capabilityType\"];\nif (capabilityType.compare(\"RANGE\") == 0) {\nAdjustRangeControllerValueMessage msg = json::parse(message);\nadjustRangeControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.instanceId, msg.payload.delta);\n} else if (capabilityType.compare(\"MODE\") == 0) {\nAdjustModeControllerValueMessage msg = json::parse(message);\nadjustModeControllerValue(msg.header.id, msg.payload.endpointId, msg.payload.instanceId, msg.payload.delta);\n} else {\n// Error. Unsupported controller type in message\n}\n}\n\nvoid MyCarControlHandler::adjustRangeControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nconst std::string&amp; instanceId,\ndouble delta) {\n// Adjust the numeric setting of the property represented by endpointId and instanceId by the specified delta.\n// When complete, call sendAdjustControllerValueMessageReply() with messageId and the result\n}\n\nvoid MyCarControlHandler::adjustModeControllerValue(\nconst std::string&amp; messageId,\nconst std::string&amp; endpointId,\nconst std::string&amp; instanceId,\ndouble delta) {\n// Adjust the mode of the property represented by endpointId and instanceId by the specified delta.\n// When complete, call sendAdjustControllerValueMessageReply() with messageId and the result\n}\n\nvoid MyCarControlHandler::sendAdjustControllerValueMessageReply(const std::string&amp; messageId, bool successful) {\nAdjustControllerValueMessageReply msg;\nmsg.header.messageDescription.replyToId = messageId;\nmsg.payload.success = successful;\nm_messageBroker-&gt;publish(msg.toString());\n}\n</code></pre>"},{"location":"explore/features/cbl/","title":"Code-Based Linking (CBL) Module","text":""},{"location":"explore/features/cbl/#overview","title":"Overview","text":"<p>Every request to Alexa Voice Service (AVS) requires a Login with Amazon (LWA) access token. The Alexa Auto SDK CBL module implements the CBL mechanism of acquiring such tokens. Use the <code>Authorization</code> AASB message interface to start, cancel, and log out of CBL authorization. For more information about how the Engine manages authorization, see the <code>Authorization</code> interface documentation.</p> <p>Note that we use the following JSON-like notation to describe an AASB message:</p> <pre><code>Action {\n    field: value,\n    ...\n}\n</code></pre>"},{"location":"explore/features/cbl/#integrate-the-authorization-interface-for-cbl","title":"Integrate the Authorization interface for CBL","text":"<p>To use the Engine's implementation of CBL for for fetching and refreshing Alexa access tokens, use the <code>Authorization</code> interface according to the following specification. Use <code>\"alexa:cbl\"</code> for the service parameter in <code>Authorization</code> messages.</p>"},{"location":"explore/features/cbl/#start-the-authorization-flow","title":"Start the authorization flow","text":"<p>Use the <code>Authorization.StartAuthorization</code> message to start authorization on every Engine start. The <code>data</code> field in the message payload has the following JSON structure:</p> <pre><code>{\n\"refreshToken\":\"{STRING}\"\n}\n</code></pre> <p>If the user is not signed in to their Amazon account, use an empty string as the data parameter. For example,</p> <pre><code>    StartAuthorizationMessage msg;\nmsg.payload.service = \"alexa:cbl\";\nmsg.payload.data = \"\";\nm_messageBroker-&gt;publish(msg);\n</code></pre> <p>The Engine uses the absence of refresh token in the message to trigger the code pair request that fetches a URL and one-time code to display to the user.</p> <p>If the user has already signed in on a previous Engine cycle, the application should already have a stored refresh token. Include the refresh token in the <code>SetAuthorizationData</code> message using the key <code>\"refreshToken\"</code>. For example,</p> <pre><code>    StartAuthorizationMessage msg;\nmsg.payload.service = \"alexa:cbl\";\nmsg.payload.data = \"{\"refreshToken\":\u201cAtzr|IQEBLzAtAhRP\u201d}\";\nm_messageBroker-&gt;publish(msg);\n</code></pre> <p>The Engine uses the presence of the refresh token in the message to request a new access token for the user without requiring the user to complete any steps.</p>"},{"location":"explore/features/cbl/#receive-data-from-the-engine","title":"Receive data from the Engine","text":"<p>This section describes the protocol for getting the code pair and user profile data by using the <code>EventReceived</code> message.</p> <p>After <code>StartAuthorization</code> in the sign-in flow, the Engine publishes an <code>EventReceived</code> message including the URL and one-time code pair. The <code>event</code> parameter in the message payload is a serialized JSON string with the following structure:</p> <pre><code>{\n\"type\": \"cbl-code\",\n\"payload\": {\n\"code\": \"{STRING}\",\n\"url\": \"{STRING}\"\n}\n}\n</code></pre> <p>The following <code>EventReceived</code> message example provides the application with a CBL code and URL:</p> <pre><code>EventReceived {\n    service: \"alexa:cbl\",\n    event: \"{\\\"type\\\":\\\"cbl-code\\\", \\\"payload\\\":{\\\"code\\\":\\\"OC2EFA\\\",\\\"url\\\":\\\"some-url\\\"}}\"\n}\n</code></pre> <p>Your application should display the URL and code to the user as text or a QR code following the Alexa Auto Design Guidelines.</p> <p>If your application configured the Engine to enable CBL user profile data, the Engine's request to Login with Amazon will include user email and name in the request scope. After the user has signed in, the Engine will publish an <code>EventReceived</code> message. The <code>event</code> parameter in the message payload is a serialized JSON string with the following structure:</p> <pre><code>{\n\"type\": \"user-profile\",\n\"payload\": {\n\"name\": \"{STRING}\",\n\"email\": \"{STRING}\"\n}\n}\n</code></pre> <p>The following <code>EventReceived</code> message example provides the user profile data for an application to display the signed-in user's name and email:</p> <pre><code>EventReceived {\n    service: \"alexa:cbl\",\n    event: \"{\\\"type\\\":\\\"user-profile\\\",\\\"payload\\\":{\\\"name\\\":\\\"some-name\\\",\\\"email\\\":\\\"some-email\\\"}}\"\n}\n</code></pre>"},{"location":"explore/features/cbl/#store-the-refresh-token","title":"Store the refresh token","text":"<p>The Engine requires the application to securely store authorization data on the device when requested. Once the Engine fetches a refresh token during a new sign-in flow, the Engine will publish a <code>SetAuthorizationData</code> message that includes the token for your application to store.</p> <p>The <code>data</code> parameter in the message payload is a serialized JSON string with the following structure:</p> <pre><code>{\n\"refreshToken\": \"{STRING}\"\n}\n</code></pre> <p>For example,</p> <pre><code>SetAuthorizationData {\n    service: \"alexa:cbl\",\n    key: \"refreshToken\",\n    data: \"{\\\"refreshToken\\\":\\\"Atzr|IQEBLzAtAhRP\\\"}\"\n}\n</code></pre> <p>Your application must securely store the token and provide it any time the Engine requests the refresh token with a <code>GetAuthorizationData</code> message. The <code>key</code> parameter in the message payload is a serialized JSON string with the following structure:</p> <pre><code>{\n\"refreshToken\":\"{STRING}\"\n}\n</code></pre> <p>For example,</p> <pre><code>GetAuthorizationData {\n    service: \"alexa:cbl\",\n    key: \"refreshToken\"\n}\n</code></pre> <p>The application returns the refresh token in a reply message like the following example:</p> <pre><code>GetAuthorizationDataReply {\n    data: \"{\\\"refreshToken\\\":\\\"Atzr|IQEBLzAtAhRP\\\"}\"\n}\n</code></pre>"},{"location":"explore/features/cbl/#cancel-ongoing-authorization","title":"Cancel ongoing authorization","text":"<p>If the application needs to stop the CBL flow, for example, if the user cancels sign-in while the application is waiting for the user to sign in and enter the code, publish the  <code>CancelAuthorization</code> message. If the device is already authorized, the <code>CancelAuthorization</code> message cancels the token refreshing process. Canceling authorization does not affect the device authorization state.</p>"},{"location":"explore/features/cbl/#sign-out","title":"Sign out","text":"<p>Publish the <code>Logout</code> message if the user signs out of the application.</p>"},{"location":"explore/features/cbl/#handle-errors","title":"Handle errors","text":"<p>This section describes the errors reported by the Engine.</p> <p>The following list describes possible errors during authorization:</p> <ul> <li><code>UNKNOWN_ERROR</code> is an unrecoverable error in the authorization process.</li> <li><code>TIMEOUT</code> happens when the application's attempt to get the code pair from the LWA Service times out.</li> <li><code>CODE_PAIR_EXPIRED</code> is caused by an expired code pair. The application must restart the authorization process and request a new code pair.</li> <li><code>AUTHORIZATION_EXPIRED</code> is caused by an expired or a revoked refresh token.</li> <li><code>LOGOUT_FAILED</code> happens when a logout attempt fails.</li> <li><code>START_AUTHORIZATION_FAILED</code> happens when the authorization flow cannot start.</li> </ul> <p>The Engine notifies the application about any error during authorization by publishing an <code>AuthorizationError</code> message. The following example shows how the Engine notifies the application when a code pair expires:</p> <pre><code>AuthorizationError{service: \"alexa:cbl\", error: \"CODE_PAIR_EXPIRED\", message: \"\"}\n</code></pre>"},{"location":"explore/features/cbl/#enable-user-profile","title":"Enable user profile","text":"<p>If you want the Engine to provide information about the signed-in user to the application, include the following object in the Engine configuration file:</p> <pre><code>{\n\"aace.cbl\": {\n\"enableUserProfile\": true\n}\n}\n</code></pre> <p>Alternatively, you can generate the configuration programmatically by using the <code>createCBLUserProfileConfig</code> method:</p> <pre><code>auto userProfileConfig = aace::cbl::config::CBLConfiguration::createCBLUserProfileConfig( true );\nengine-&gt;configure( { //other config objects..., userProfileConfig, ... } );\n</code></pre> <p>The user profile is passed via the <code>eventReceived</code> API as described in this section.</p>"},{"location":"explore/features/cbl/#sequence-diagrams-for-cbl","title":"Sequence Diagrams for CBL","text":"<p>The following diagram illustrates the flow when authorization starts.</p> <p>Note that we use the following notation to represent an AASB message:</p> <pre><code>Action{value, ...}\n</code></pre> <p></p> <p>The following diagram illustrates how the Authorization platform interface handles a refresh token.</p> <p></p> <p>The following diagram illustrates the flow when authorization is canceled.</p> <p></p> <p>The following diagram illustrates the flow when the application logs out of the authorization.</p> <p></p>"},{"location":"explore/features/connectivity/","title":"Connectivity Module","text":""},{"location":"explore/features/connectivity/#overview","title":"Overview","text":"<p>The <code>Connectivity</code> module for the Alexa Auto SDK creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. This module allows the automaker to create tiered access to Alexa for customers and offer up-sell opportunities to subscribe to a full connectivity plan.</p> <p>A customer who purchases an Alexa-enabled vehicle typically has to subscribe to the automaker\u2019s connectivity plans and accept the automaker's and network provider's terms and conditions to access Alexa. Without the <code>Connectivity</code> module, if the customer declines the terms and conditions, or does not have a data plan (for example, due to plan expiration), the customer loses access to Alexa. The <code>Connectivity</code> module, however, provides an option that allows the automaker to offer a reduced set of Alexa functionality and limited bandwidth consumption for little or no cost. In this low data consumption mode, utterances sent to the cloud are filtered by feature, because the <code>Connectivity</code> module offers a restricted set of features. For example, when a user accesses Alexa through the <code>Connectivity</code> module, an utterance requesting music streaming does not start the streaming but turns on the FM radio station that was last played. Features such as weather and traffic remain accessible.</p> <p>Your application's <code>Connectivity</code> module integration is responsible for:</p> <ul> <li>Providing the network identifier for Alexa to send to the mobile network operator (MNO)</li> <li>Providing the vehicle's connection properties and configurations to Alexa</li> </ul>"},{"location":"explore/features/connectivity/#configuring-the-connectivity-module","title":"Configuring the Connectivity Module","text":"<p>The <code>Connectivity</code> module does not require Engine configuration.</p>"},{"location":"explore/features/connectivity/#using-the-connectivity-aasb-messages","title":"Using the Connectivity AASB Messages","text":""},{"location":"explore/features/connectivity/#providing-the-network-identifier","title":"Providing the Network Identifier","text":"<p>The network identifier is agnostic of the data plan and is assigned when initially integrated into the vehicle. It links the device with the network provider and enables the network provider to identify and provide device connectivity. Examples of the network identifier are the Embedded SIM ID (eSIM ID) and a globally unique ID (GUID). Which ID to use depends on the implementation determined in agreement with Amazon, OEM, and MNO.</p> <p>During device discovery the Engine publishes the <code>GetIdentifier</code> message. To report the network identifier to Alexa, publish the <code>GetIdentifierReply</code> message.</p> <p>Click to expand or collapse sequence diagram: Providing the Network Identifier </p> <p></p> <p></p>"},{"location":"explore/features/connectivity/#providing-the-connectivity-status","title":"Providing the Connectivity Status","text":"<p>When a client application initiates connection with Alexa or when Alexa requests a report of the current connectivity state, publish the <code>ConnectivityStateChange</code> message. In response, the Engine will publish the <code>GetConnectivityState</code> message to which your application must publish the <code>GetConnectivityStateReply</code> message containing the connectivity state. The Engine will then publish the <code>ConnectivityStateChangeReply</code> message to indicate if the connectivity state was processed successfully.</p> <p>Alexa parses the internet connectivity information from the vehicle and determines whether the customer is eligible for the full or partial Alexa experience. The connectivityState obtained in the <code>GetConnectivityState</code> reply payload has the following schema:</p> <pre><code> {\n    \"managedProvider\": {\n        \"type\": \"{{STRING_ENUM}}\",\n        \"id\": \"{{STRING}}\"\n    },\n    \"termStatus\": \"{{STRING_ENUM}}\",\n    \"termsVersion\": \"{{STRING}}\",\n    \"dataPlan\": {\n        \"type\": \"{{STRING_ENUM}}\",\n        \"endDate\": \"{{STRING}}\"\n    },\n    \"dataPlansAvailable\": [\"{{STRING}}\", \"{{STRING}}\", ...]\n}\n</code></pre> <p>Click to expand or collapse details about the objects in the payload</p> Property Type Description Required <code>dataPlan</code> Object It provides the active data plan type and end date. Yes (only when <code>managedProvider.type</code> is <code>MANAGED</code>) <code>dataPlan.type</code> String Accepted values: <ul><li><code>PAID</code> indicates that the device has an active data plan paid for by the customer.<li><code>TRIAL</code> indicates that the device has an active data plan which has been provided to the customer as a promotional event.<li><code>AMAZON_SPONSORED</code> indicates that the customer has not paid for a data plan or signed up for a free trial. The customer can connect to the internet via a plan sponsored by Amazon and can access a limited number of Alexa features. A customer with either of <code>PAID</code> or <code>TRIAL</code> data plan has unrestricted access to all Alexa features. Yes <code>dataPlan.endDate</code> String It specifies the date on which the trial data plan ends. If it is not set, there is no end date for the plan. The value is in the RFC 3339 format. Yes (only when <code>dataPlan.type</code> is <code>TRIAL</code>) <code>termsStatus</code> String It indicates whether the customer has accepted the terms and conditions of the OEM and MNO. If it is not set, the behavior is the same as when it is set to <code>DECLINED</code>. Accepted values:<ul><li><code>ACCEPTED</code> means that the customer has agreed to receive voice messages from Alexa, which enable the customer to use voice to purchase a data plan.<li><code>DECLINED</code> means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade.<li><code>DEFERRED</code> means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. However, Alexa might remind the user to respond to the terms and conditions again. No, but recommended <code>termsVersion</code> String It indicates the version of the terms and conditions presented to the user. Do not use <code>termsVersion</code> if you do not use <code>termsStatus</code>. Maximum length is 250 characters. Note: If you implemented Auto SDK 3.1 with the Connectivity module, a default value is automatically assigned to <code>termsVersion</code>. For Auto SDK 3.2 or later, be sure to specify <code>termsVersion</code>. Otherwise, the MNO is not notified of the correct version of the terms and conditions presented to the user. Yes (only when <code>termsStatus</code> is provided) <code>dataPlansAvailable</code> String array It indicates the data plans that can be activated. Accepted values are <code>PAID</code>, <code>AMAZON_SPONSORED</code>, and <code>TRIAL</code>. For example, if the array is <code>[\"TRIAL\", \"AMAZON_SPONSORED\", \"PAID\"]</code>, Alexa encourages the user to upgrade from an AMAZON_SPONSORED plan to a TRIAL plan or from a TRIAL plan to a PAID plan. No <code>managedProvider</code> Object It provides information about the type of network connectivity that the device has. Yes <code>managedProvider.type</code> String Accepted Values:<ul><li><code>MANAGED</code> means the device's internet connectivity is managed by a provider. The only possible provider that manages connectivity is Amazon. The Alexa experience is affected by the current connectivity state in the following ways:<ul><li>If the customer is on a paid or trial data plan, <code>MANAGED</code> has no effect on the customer's Alexa experience. <li>If the customer does not have a paid or trial data plan, the customer, through the AlexaConnectivity platform interface, can access a limited number of Alexa features.<li><code>NOT_MANAGED</code> means the device's internet connectivity is not managed by a provider. For example, assign this value if the customer accesses the internet via a WiFi network or mobile hotspot. The customer can access all Alexa features, regardless of the current connectivity state. Yes <code>managedProvider.id</code> String It specifies the name of the provider that manages connectivity. The only accepted value is <code>AMAZON</code>. Yes (only when <code>managedProvider.type</code> is <code>MANAGED</code>) <p></p> <p>Click to expand or collapse sequence diagram: Connectivity Report </p> <p></p> <p></p>"},{"location":"explore/features/connectivity/#activating-voice-up-sell-conversation","title":"Activating Voice Up-Sell Conversation","text":"<p>To activate the voice up-sell conversation with Alexa (e.g., to activate the trial or paid plan subscription), publish the <code>SendConnectivityEvent</code> message. The Engine publishes the <code>SendConnectivityEventReply</code> message specifying the delivery status of the event. The event sent in the <code>SendConnectivityEvent</code> message payload has the following schema:</p> <pre><code>  {\n    \"type\": \"{{STRING}}\"\n  }\n</code></pre> <p>Note: Alexa requires the customer to have accepted the OEM and network provider's terms and conditions before starting the voice conversation.</p> <p>Click to expand or collapse details about the objects in the payload</p> Property Type Description Required <code>type</code> String Represents the type of the connectivity event to Alexa. Accepted Values:<ul><li><code>ACTIVATE_TRIAL</code> for Alexa to begin the trial data plan activation (if available). Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation.  Note: If the platform implementation cannot determine the data plan type, use this event type. Alexa would first check the trial eligibility. If the customer is not eligible, Alexa begins the paid plan voice conversation. <li> <code>ACTIVATE_PAID_PLAN</code> for Alexa to begin the paid data plan activation. Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Yes <p></p> <p>Click to expand or collapse sequence diagram: Send Connectivity Event </p> <p></p> <p></p>"},{"location":"explore/features/connectivity/#integrating-the-connectivity-module-into-your-application","title":"Integrating the Connectivity Module Into Your Application","text":""},{"location":"explore/features/connectivity/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to publish \"Connectivity\" AASB messages and subscribe to their replies.</p> <p>Click to expand or collapse C++ sample code</p> <p></p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/Connectivity/AlexaConnectivity/StatusCode.h&gt;\n\n#include &lt;AASB/Message/Connectivity/AlexaConnectivity/ConnectivityStateChangeMessage.h&gt;\n#include &lt;AASB/Message/Connectivity/AlexaConnectivity/GetConnectivityStateMessage.h&gt;\n#include &lt;AASB/Message/Connectivity/AlexaConnectivity/GetIdentifierMessage.h&gt;\n#include &lt;AASB/Message/Connectivity/AlexaConnectivity/SendConnectivityEventMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyAlexaConnectivityHandler {\n\n// Subscribe to messages from the Engine\nvoid MyAlexaConnectivityHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetConnectivityStateMessage(message); },\nGetConnectivityStateMessage::topic(),\nGetConnectivityStateMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetIdentifierMessage(message); },\nGetIdentifierMessage::topic(),\nGetIdentifierMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleConnectivityStateChangeReplyMessage(message); },\nConnectivityStateChangeMessageReply::topic(),\nConnectivityStateChangeMessageReply::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleSendConnectivityEventReplyMessage(message); },\nSendConnectivityEventMessageReply::topic(),\nSendConnectivityEventMessageReply::action());\n}\n\n// Handle the ConnectivityStateChange reply message from the Engine\nvoid MyAlexaConnectivityHandler::handleConnectivityStateChangeReplyMessage(const std::string&amp; message) {\nConnectivityStateChangeMessageReply msg = json::parse(message);\nstd::string messageId = msg.header.messageDescription.replyToId;\n\n// ...Handle change in the connectivity state...\n}\n\n// Handle the SendConnectivityEvent reply message from the Engine\nvoid MyAlexaConnectivityHandler::handleSendConnectivityEventReplyMessage(const std::string&amp; message) {\nSendConnectivityEventMessageReply msg = json::parse(message);\n\nstd::string messageId = msg.header.messageDescription.replyToId;\nStatusCode statusCode = msg.payload.statusCode;\n\n// ...Handle delivery status of the event...\n}\n\n// Handle the GetConnectivityState message from the Engine and publish the reply message to the Engine\nvoid MyAlexaConnectivityHandler::handleGetConnectivityStateMessage(const std::string&amp; message) {\nGetConnectivityStateMessage msg = json::parse(message);\nGetConnectivityStateMessageReply replyMsg;\nreplyMsg.header.messageDescription.replyToId = msg.header.id;\nreplyMsg.payload.connectivityState = getConnectivityState();\nm_messageBroker-&gt;publish(replyMsg.toString());\n}\n\n// Handle the GetIdentifier message from the Engine and publish the reply message to the Engine\nvoid MyAlexaConnectivityHandler::handleGetIdentifierMessage(const std::string&amp; message) {\nGetIdentifierMessage msg = json::parse(message);\nGetIdentifierMessageReply replyMsg;\nreplyMsg.header.messageDescription.replyToId = msg.header.id;\nreplyMsg.payload.identifier = getIdentifier();\nm_messageBroker-&gt;publish(replyMsg.toString());\n}\n\n// To report a connectivity status change to Alexa, publish a ConnectivityStateChange message to the Engine\nbool MyAlexaConnectivityHandler::connectivityStateChange() {\nConnectivityStateChangeMessage msg;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the ConnectivityStateChangeReply message\n// Return the success status from reply message payload\n}\n\n// To activate a voice up-sell conversation with Alexa, publish a SendConnectivityEvent message to the Engine\nStatusCode MyAlexaConnectivityHandler::sendConnectivityEvent(const std::string&amp; event) {\nSendConnectivityEventMessage msg;\nmsg.payload.event = event;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the SendConnectivityEventReply message\n// Return the statusCode from reply message payload\n}\n\n// Implement to retrieve the connectivity state\nstd::string MyAlexaConnectivityHandler::getConnectivityState();\n\n// Implement to retrieve the identifier\nstd::string MyAlexaConnectivityHandler::getIdentifier();\n\n};\n</code></pre> <p></p>"},{"location":"explore/features/core/","title":"Core Module","text":""},{"location":"explore/features/core/#overview","title":"Overview","text":"<p>The <code>Core</code> module is the heart of the Alexa Auto SDK. The <code>Core</code> module provides the following elements that are the foundation for all Auto SDK features:  - Defining core API for your application to access the features of Auto SDK\u2014 <code>Core</code> defines the <code>Engine</code> and <code>MessageBroker</code> components. Alongside the Alexa Auto Services Bridge (AASB) messages defined by each Auto SDK module, these components comprise the core API for your application to access the features of Auto SDK. To learn about the API, see Auto SDK Core API Overview.</p> <ul> <li> <p>Providing an infrastructure to other modules\u2014 <code>Core</code> provides the base infrastructure of the Engine, which each Auto SDK module extends to add module-specific features. </p> </li> <li> <p>Providing core services to other modules\u2014 <code>Core</code> defines the common Engine services and corresponding AASB message interfaces for logging, audio I/O, authorization, device settings, network info, and more. Each module uses these Engine services to provide its own module-specific features.</p> </li> </ul>"},{"location":"explore/features/core/#configure-the-core-module","title":"Configure the Core module","text":"<p>The <code>Core</code> module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions.</p>"},{"location":"explore/features/core/#required-vehicle-info-configuration","title":"(Required) Vehicle info configuration","text":"<p>Your application must provide the <code>aace.vehicle</code> configuration specified below. Amazon uses the vehicle configuration properties for analytics and metrics.</p> <p><pre><code>\"aace.vehicle\": {\n    \"deviceInfo\": {\n        \"manufacturer\": \"${DEVICE_MANUFACTURER}\",\n        \"model\": \"${DEVICE_MODEL}\",\n        \"platform\": \"${DEVICE_PLATFORM}\",\n        \"osVersion\": \"${DEVICE_OS_VERSION}\",\n        \"hardwareArch\": \"${DEVICE_HARDWARE_ARCH}\",\n        \"serialNumber\":  \"${DEVICE_SERIAL_NUMBER}\"\n    },\n    \"appInfo\": {\n        \"softwareVersion\": \"${APP_VERSION}\"\n    },\n    \"vehicleInfo\": {\n        \"make\": \"${VEHICLE_MAKE}\",\n        \"model\": \"${VEHICLE_MODEL}\",\n        \"year\": \"${VEHICLE_YEAR}\",\n        \"trim\": \"${VEHICLE_TRIM}\",\n        \"microphoneType\": \"${VEHICLE_MICROPHONE}\",\n        \"operatingCountry\": \"${VEHICLE_COUNTRY}\",\n        \"vehicleIdentifier\": \"${VEHICLE_IDENTIFIER}\",\n        \"engineType\": \"${VEHICLE_ENGINE_TYPE}\",\n        \"rseEmbeddedFireTvs\": \"${RSE_EMBEDDED_FIRE_TV_COUNT}\"\n    }\n}\n</code></pre> The following table describes the properties in the configuration:</p> Property Type Required Description Example deviceInfo.manufacturer String Yes The manufacturer of the head unit hardware \"Alpine\", \"Pioneer\" deviceInfo.model String Yes The model name of the head unit hardware \"Coral\" deviceInfo.platform String Yes The head unit software platform or operating system name \"Android\", \"Ubuntu\" deviceInfo.osVersion String Yes The version of the head unit operating system \"12\", \"18.04.6 LTS\" deviceInfo.hardwareArch String Yes The hardware architecture of the head unit or CPU+instruction set \"arm64-v8a\", \"x86_64\", \"armv7hf\", \"armv8\" deviceInfo.serialNumber String Yes The serial number of the head unit \"A01BCDEFGH2I\" appInfo.softwareVersion String Yes The version of the Auto SDK client application \"1.0.1\" vehicleInfo.make String Yes The make of the vehicle \"BMW\", \"Ford\" vehicleInfo.model String Yes The model of the vehicle \"MDX\", \"Q5\", \"Accord\" vehicleInfo.year String Yes The model year of the vehicle. The value must be an integer in the range 1900-2100 expressed as a string \"2023\" vehicleInfo.trim String No The trim package of the vehicle, identifying the vehicle's level of equipment or special features \"Limited\", \"Base package\", \"Type S\" vehicleInfo.microphoneType String No The type and arrangement of microphone used in the vehicle \"7 mic array centrally mounted\" vehicleInfo.operatingCountry String Yes The current (or intended, if current is not available) operating country for the vehicle. The value must be an ISO 3166 Alpha-2 country code \"US\", \"MX\", \"JP\" vehicleInfo.vehicleIdentifier String Yes The automaker's identifier for the vehicle. The value should not be the vehicle identification number (VIN). \"12345ABCDE\" vehicleInfo.engineType String No The type of engine in the vehicle. Accepted values:<ul><li><code>\"GAS\"</code></li><li><code>\"ELECTRIC\"</code></li><li><code>\"HYBRID\"</code></li></ul> \"ELECTRIC\" vehicleInfo.rseEmbeddedFireTvs String No The number of Rear Seat Entertainment embedded Fire TVs in the vehicle, expressed as a string \"2\" Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory functions <p>Auto SDK provides the <code>VehicleConfiguration</code> factory functions to generate the configuration programmatically. </p> <pre><code>#include &lt;AACE/Vehicle/VehicleConfiguration.h&gt;\n\nstd::vector&lt;aace::vehicle::config::VehicleConfiguration::VehicleInfoProperty&gt; vehicleProperties = {\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::MAKE, \"SampleMake\"},\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::MODEL, \"SampleModel\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::YEAR, \"2020\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::TRIM, \"Sport\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::OPERATING_COUNTRY, \"US\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::MICROPHONE_TYPE, \"7 mic array, centrally mounted\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::VEHICLE_IDENTIFIER, \"1234abcd\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::ENGINE_TYPE, \"GAS\" },\n{ aace::vehicle::config::VehicleConfiguration::VehicleInfoPropertyType::RSE_EMBEDDED_FIRE_TVS, \"2\" }\n};\n\nauto vehicleConfig = aace::vehicle::config::VehicleConfiguration::createVehicleInfoConfig(vehicleProperties);\n\nstd::vector&lt;aace::vehicle::config::VehicleConfiguration::DeviceInfoProperty&gt; deviceProperties = {\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::MANUFACTURER, \"SampleManufacturer\"},\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::MODEL, \"SampleModel\" },\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::SERIAL_NUMBER, \"A01BCDEFGH2I\" },\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::PLATFORM, \"Android\" },\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::OS_VERSION, \"12\" },\n{ aace::vehicle::config::VehicleConfiguration::DeviceInfoPropertyType::HARDWARE_ARCH, \"arm64-v8a\" }\n};\n\nauto deviceConfig = aace::vehicle::config::VehicleConfiguration::createDeviceInfoConfig(deviceProperties);\n\nstd::vector&lt;aace::vehicle::config::VehicleConfiguration::AppInfoProperty&gt; appProperties = {\n{ aace::vehicle::config::VehicleConfiguration::AppInfoPropertyType::SOFTWARE_VERSION, \"1.0.1\"}\n};\n\nauto appConfig = aace::vehicle::config::VehicleConfiguration::createAppInfoConfig(appProperties);\n\nengine-&gt;configure(\n{\n// ...other config objects...,\nvehicleConfig,\ndeviceConfig,\nappConfig\n}\n);\n</code></pre>"},{"location":"explore/features/core/#required-storage-configuration","title":"(Required) Storage configuration","text":"<p>Your application must provide the <code>aace.storage</code> configuration specified below. The Engine uses the configured path to create a database to persist data across device reboots.</p> <pre><code>{\n    \"aace.storage\": {\n        \"localStoragePath\": {{STRING}},\n        \"storageType\": \"sqlite\"\n    }\n}\n</code></pre> <p>The following table describes the properties in the configuration:</p> Property Type Required Description Example localStoragePath String Yes The absolute path where the Engine will create the local storage database, including the database name \"/opt/AAC/data/aace-storage.db\" storageType String Yes The type of storage to use \"sqlite\" <p>Note: This database is not the only one used by the Engine. For example, components in the <code>Alexa</code> module have similar configuration to store feature-specific data. See Configure the Alexa module for details.</p> Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function <p>Auto SDK provides the <code>StorageConfiguration::createLocalStorageConfig()</code> factory function to generate the configuration programmatically. </p> <pre><code>#include &lt;AACE/Storage/StorageConfiguration.h&gt;\n\nauto storageConfig = aace::storage::config::StorageConfiguration::createLocalStorageConfig(\"/opt/AAC/data/storage.db\");\n\nengine-&gt;configure(\n{\n// ...other config objects...,\nstorageConfig\n}\n);\n</code></pre>"},{"location":"explore/features/core/#required-curl-configuration","title":"(Required) cURL configuration","text":"<p>The Auto SDK uses cURL for network connections. Your application can provide Engine configuration to specify the cURL configuration:</p> <pre><code>{\n    \"aace.alexa\": {\n        \"avsDeviceSDK\": {\n            \"libcurlUtils\" {\n                \"CURLOPT_CAPATH\": {{STRING}},\n                \"CURLOPT_INTERFACE\": {{STRING}},\n                \"CURLOPT_PROXY\": {{STRING}}\n\n            }\n        }\n    }\n}\n</code></pre> <p>The following table describes the properties in the configuration:</p> Property Type Required Description Example CURLOPT_CAPATH String Yes The path to the directory containing the CA certificates \"/opt/AAC/certs\" CURLOPT_INTERFACE String Yes The outgoing network interface. Can be a network interface name, an IP address, or a host name \"wlan0\" CURLOPT_PROXY String No The address of the HTTP proxy \"http://127.0.0.1:8888\" <p>Note: If the HTTP proxy requires credentials in HTTP headers to authenticate a user agent, you can specify the headers at runtime with the <code>PropertyManager</code> interface by using the <code>aace.network.httpProxyHeaders</code> property name. You can also change the network interface at runtime with the <code>aace.network.networkInterface</code> property name.</p> Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function <p>Auto SDK provides the <code>AlexaConfiguration::createCurlConfig()</code> factory function to generate the configuration programmatically. </p> <pre><code>#include &lt;AACE/Alexa/AlexaConfiguration.h&gt;\n\nauto curlConfig = aace::alexa::config::AlexaConfiguration::createCurlConfig(\"/opt/AAC/etc/certs\");\n\nengine-&gt;configure(\n{\n// ...other config objects...,\ncurlConfig\n}\n);\n</code></pre>"},{"location":"explore/features/core/#required-metrics-configuration","title":"(Required) Metrics configuration","text":"<p>Your application must provide the <code>aace.metrics</code> configuration specified below. The Engine uses the configured values for uploading metrics to Amazon metric services.</p> <pre><code>{\n    \"aace.metrics\": {\n        \"metricStoragePath\": ${METRIC_STORAGE_PATH,\n        \"metricDeviceIdTag\": \"${METRIC_TAG}\"\n    }\n}\n</code></pre> <p>The following table describes the properties in the configuration:</p> Property Type Required Description Example metricStoragePath String Yes An absolute path to a directory where metrics may be stored prior to upload. The directory must exist and should not be used for any other purpose. \"/opt/AAC/data/metrics\" metricDeviceIdTag String Yes A tag that Auto SDK Engine will use in combination with DSN to generate a unique anonymous device identifier. Neither Alexa nor Auto SDK will store this tag and hence cannot reverse the hash to identify a single DSN from an individual metric. The metricDeviceIdTag may be any nonempty alphanumeric string that does not change across device reboots, factory resets, app data reset, or software updates. The recommended value is a 32 character string that is not the DSN or VIN. The value may be unique to an individual vehicle, provided it is stable, but it is not required to be unique. \"yXGO5U1ylqauXa5LwSx2ppQPFTQbFtu4\" Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory functions <p>Auto SDK provides the <code>MetricsConfiguration</code> factory functions to generate the configuration programmatically. </p> <pre><code>#include &lt;AACE/Metrics/MetricsConfiguration.h&gt;\n\nauto metricTag = aace::metrics::config::MetricsConfiguration::createMetricsTagConfig(\"yXGO5U1ylqauXa5LwSx2ppQPFTQbFtu4\");\n\nauto metricPath = aace::metrics::config::MetricsConfiguration::createMetricsStorageConfig(\"/opt/AAC/data/metrics\");\n\nengine-&gt;configure(\n{\n// ...other config objects...,\nmetricTag,\nmetricPath\n}\n);\n</code></pre>"},{"location":"explore/features/core/#optional-logger-configuration","title":"(Optional) Logger configuration","text":"<p>By default, the Engine writes Auto SDK logs to the following places:</p> <ul> <li>The console, for C++ native applications</li> <li>Logcat, for Android applications</li> </ul> <p>You can configure the Engine to save logs to a file with the <code>aace.logger</code> configuration:</p> <pre><code>{\n  \"aace.logger\": {\n    \"sinks\": [\n        {\n            \"id\": {{STRING}},\n            \"type\": \"aace.logger.sink.file\",\n            \"config\": {\n                \"path\": {{STRING}},\n                \"prefix\": {{STRING}},\n                \"maxSize\": {{INTEGER}},\n                \"maxFiles\": {{INTEGER}},\n                \"append\": {{BOOLEAN}}\n            },\n            \"rules\": [\n                {\n                    \"level\": {{STRING}}\n                }\n            ]\n        }\n    ]\n}\n</code></pre> <p>The following table describes the properties in the configuration:</p> Property Type Required Description Example aace.logger.sinks[i].id String Yes A unique identifier for the log sink. \"debug-logs\" aace.logger.sinks[i].type String Yes The type of the log sink. Use \"aace.logger.sink.file\" to write logs to a file. \"aace.logger.sink.file\" aace.logger.sinks[i].config.path String Yes An absolute path to a directory where the Engine creates the log file. \"/opt/AAC/data\" aace.logger.sinks[i].config.prefix String Yes The prefix for the log file. \"auto-sdk-logs\" aace.logger.sinks[i].config.maxSize Integer Yes The maximum size of the log file in bytes. 5242880 aace.logger.sinks[i].config.maxFiles Integer Yes The maximum number of log files. 5 aace.logger.sinks[i].config.append Boolean Yes Whether the Engine should overwrite log files.Use true to append logs to the existing file. Use false to overwrite the log files. false aace.logger.sinks[i].rules[j].level Enum string Yes The log level filter the Engine uses when writing logs to the sink. Accepted values:<ul><li><code>\"VERBOSE\"</code></li><li><code>\"INFO\"</code></li><li><code>\"WARN\"</code></li><li><code>\"ERROR\"</code></li><li><code>\"CRITICAL\"</code></li><li><code>\"METRIC\"</code></li></ul> \"VERBOSE\" Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function <p>Auto SDK provides the <code>LoggerConfiguration::createFileSinkConfig()</code> factory function to generate the configuration programmatically. </p> <pre><code>#include \"AACE/Logger/Logger.h\"\n#include \"AACE/Logger/LoggerConfiguration.h\"\n\n\nauto fileSinkConfig = aace::logger::config::LoggerConfiguration::createFileSinkConfig(\n\"debug-logs\",\naace::logger::LoggerEngineInterface::Level::VERBOSE,\n\"opt/AAC/data\",\n\"auto-sdk-logs\",\n5242880,\n5,\nfalse);\n\nengine-&gt;configure(\n{\n// ...other config objects...,\nfileSinkConfig\n}\n);\n</code></pre>"},{"location":"explore/features/core/#optional-aasb-and-messagebroker-configuration","title":"(Optional) AASB and MessageBroker configuration","text":""},{"location":"explore/features/core/#configure-enabled-interfaces","title":"Configure enabled interfaces","text":"<p>When you use a module, the Engine services of that module enable every interface the module defines. This means that for every interface in a module you use, if your application does not subscribe to the AASB messages of the interface, the Engine performs default handling (typically no-op) for the messages you do not handle.</p> <p>To disable this setting, provide the following <code>aace.messageBroker</code> configuration object in your Engine configuration:</p> <pre><code>{\n    \"aace.messageBroker\": {\n        \"autoEnableInterfaces\": false\n    }\n}\n</code></pre> <p>You can also configure the enablement on a per-interface basis. If you don't want the Engine to provide a default handler for a particular interface, you can disable the interface using the following configuration that specifies the name of the interface and the Engine service that owns it:</p> <pre><code>{\n    \"aasb.&lt;engine_service_ID&gt;\": {\n        \"&lt;interface_name&gt;\": {\n            \"enabled\": {{BOOLEAN}}\n        }\n    }\n}\n</code></pre> <p>For example, the following configuration disables the <code>TemplateRuntime</code> interface from the <code>Alexa</code> module's <code>alexa</code> Engine service and the <code>LocationProvider</code> interface from <code>Core</code> module's <code>location</code> Engine service: </p> <pre><code>{\n    \"aasb.alexa\": {\n        \"TemplateRuntime\": {\n            \"enabled\": false\n        }\n    },\n   \"aasb.location\": {\n      \"LocationProvider\": {\n         \"enabled\": false\n      }\n   }\n}\n</code></pre>"},{"location":"explore/features/core/#configure-the-synchronous-message-timeout","title":"Configure the synchronous message timeout","text":"<p>All the messages published by the Engine through the Message Broker are asynchronous; however, certain messages require your application to respond with a special synchronous-style <code>Reply</code> message. Your application must publish the reply quickly because the Engine blocks its execution thread while waiting for the response, and the Message Broker cannot dispatch more messages while waiting. The following messages are examples of the <code>LocationProvider.GetLocation</code> message and its reply message:</p> <p><code>LocationProvider.GetLocation</code> message: <pre><code>{\n  \"header\": {\n    \"id\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\",\n    \"messageType\": \"Publish\",\n    \"version\": \"4.0\",\n    \"messageDescription\": {\n        \"topic\": \"LocationProvider\",\n        \"action\": \"GetLocation\"\n    }\n  }\n}\n</code></pre> <code>LocationProvider.GetLocation</code> reply message: <pre><code>{\n  \"header\": {\n    \"id\": \"4c4d13b6-6a8d-445b-931a-a3feb0878311\",\n    \"messageType\": \"Reply\",\n    \"version\": \"4.0\",\n    \"messageDescription\": {\n      \"topic\": \"LocationProvider\",\n      \"action\": \"GetLocation\",\n      \"replyToId\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\"\n    }\n  },\n  \"payload\": {\n    \"location\": {\n      \"latitude\": 37.410,\n      \"longitude\": -122.025\n    }\n  }\n}\n</code></pre> The AASB message documentation for each interface specifies whether the interface requires any <code>Reply</code> messages. However, not every <code>Reply</code> message is synchronous-style.</p> <p>To avoid waiting indefinitely for \"synchronous\" replies, the Engine uses a timeout when waiting for these reply messages. If your application does not publish a reply before the timeout elapses, the Message Broker proceeds to avoid waiting, but the relevant Engine operation won't execute properly. The default timeout value for reply messages is 500 milliseconds. In a busy system, the default timeout might not be long enough. You can configure this value by adding the optional field <code>defaultMessageTimeout</code> to the <code>aace.messageBroker</code> JSON object in your Engine configuration. The following example configuration sets the reply timeout to 1000 ms: <pre><code>{\n    \"aace.messageBroker\": {\n        \"defaultMessageTimeout\": 1000\n    }\n}\n</code></pre></p> <p>Important! Since increasing the timeout increases the Engine's message processing time, use this configuration carefully. Consult with your Amazon Solutions Architect (SA) as needed.</p>"},{"location":"explore/features/core/#use-the-core-module-interfaces","title":"Use the Core module interfaces","text":"<p>The following list describes the AASB message interfaces provided by the <code>Core</code> module:</p>"},{"location":"explore/features/core/#required-provide-access-tokens-with-authorization","title":"(Required) Provide access tokens with Authorization","text":"<p>The <code>Authorization</code> interface specifies messages for your application to initiate device authorization, terminate device authorization, or provide authorization data, such as Alexa access tokens, to the Engine.</p> <p>&gt;&gt; Authorization interface</p>"},{"location":"explore/features/core/#required-provide-audio-channels-with-audioinput-and-audiooutput","title":"(Required) Provide audio channels with AudioInput and AudioOutput","text":"<p>The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each component that requests an audio channel specifies its audio channel type so your application can provide different microphone and media player implementations for each channel.</p> <p>&gt;&gt; AudioInput interface</p> <p>&gt;&gt; AudioOutput interface</p>"},{"location":"explore/features/core/#required-manage-runtime-properties-with-propertymanager","title":"(Required) Manage runtime properties with PropertyManager","text":"<p>Different Auto SDK modules define properties based on their supported features. For example, the <code>Alexa</code> module requires a locale setting to notify Alexa which language to use when interacting with the user. The <code>Core</code> module provides a mechanism for Engine services to register properties they manage and listen to changes in properties managed by other modules. The <code>PropertyManager</code> interface specifies messages for your application and the Engine to query and update these properties.</p> <p>&gt;&gt; PropertyManager interface</p>"},{"location":"explore/features/core/#optional-report-location-with-locationprovider","title":"(Optional) Report location with LocationProvider","text":"<p>For an accurate and personalized user experience, the Engine uses the vehicle's location from <code>LocationProvider</code>.</p> <p>&gt;&gt; LocationProvider interface</p>"},{"location":"explore/features/core/#optional-report-network-status-changes-with-networkinfoprovider","title":"(Optional) Report network status changes with NetworkInfoProvider","text":"<p>To adapt the Engine behavior dynamically based on the state of the head unit's network connection, provide network connection reporting through <code>NetworkInfoProvider</code>.</p> <p>&gt;&gt; NetworkInfoProvider interface</p>"},{"location":"explore/features/core/#optional-report-data-usage-with-deviceusage","title":"(Optional) Report data usage with DeviceUsage","text":"<p>Report metrics about the head unit's data usage with <code>DeviceUsage</code>.</p> <p>&gt;&gt; DeviceUsage interface</p>"},{"location":"explore/features/core/#optional-manage-multiple-voice-assistants-dialog-requests-and-status","title":"(Optional) Manage multiple voice assistants dialog requests and status","text":"<p>The Arbitrator interface manages the voice assistant agents for both Alexa and 3rd parties. You can control how arbitration is handled for multiple voice assistant requests based on the rules you configure at the system level or at agent registration.</p> <p>&gt;&gt; Arbitrator interface</p>"},{"location":"explore/features/core/#optional-provide-3rd-party-wakeword-support","title":"(Optional) Provide 3rd Party Wakeword Support","text":"<p>The Wakeword interface manages the voice assistant agents for both Alexa and 3rd party assistants. Using the Wakeword module, OEM partners can simultaneously support multiple voice assistant wake words like Siri on the same in-vehicle infotainment system. </p> <p>&gt;&gt; Wakeword interface</p>"},{"location":"explore/features/core/Arbitrator/","title":"Arbitrator Module","text":""},{"location":"explore/features/core/Arbitrator/#overview","title":"Overview","text":"<p>The Arbitrator module has interfaces to manage multiple agents (aka voice assistants like Alexa, Siri, etc) and their dialog states. This module is responsible for determining if an agent\u2019s request for dialog is granted or denied, and if an active agent\u2019s dialog can be interrupted. This arbitration between agents is done based on rules configured both at the system level, and when registering the agent with the Arbitrator. </p> <p>The Arbitrator interface provides messages to * Register agents - both Alexa and external 3rd Party * Allow registered agents to request dialog to become the active agent * Allow registered agents to update their dialog state * Enforce wakeword interruption (barge-in) rules * Enforce gesture interruption for immediate agent invocation (Push-To-Talk/Tap-To-Talk) rules</p>"},{"location":"explore/features/core/Arbitrator/#configuration-the-arbitrator-module","title":"Configuration the Arbitrator Module","text":"<p>The following changes are added in config.json for the Arbitrator module to specify system-level wake word barge-in settings across all agents. </p> <pre><code>\"aace.arbitrator\": {\n    \"Arbitrator\": {\n        \"WakewordInterruption\": \"ACTIVE_AGENT_ONLY\" \n        \"GestureInterruption\": \"ANY_AGENT\" \n        }\n}\n</code></pre> <p>For WakewordInterruption</p> <ul> <li>ACTIVE_AGENT_ONLY: Barge-in via only the speaking agent's wake word,</li> <li>ANY_AGENT: Barge-in via any agent's wake word</li> </ul> <p>This setting depends on the 3rd Party VA platform - (For example the OEM can set this value to <code>ACTIVE_AGENT_ONLY</code> to satisfy CarPlay Enahnced Siri Requrement\")</p> <p>For GestureInterruption</p> <p>For example \"Button Down\" in ESR.</p> <ul> <li>ACTIVE_AGENT_ONLY: Interruption via only the active agent's PTT/TTT,</li> <li>ANY_AGENT: Interruption via any agent's PTT/TTT</li> </ul> <p>This setting depends on the 3rd Party VA platform -  (For example the OEM can set this value to <code>AGENT_ONLY</code> to satisfy CarPlay Enahnced Siri Requrement\")</p> <p>NOTE: If no configuration is provided for this module at Engine start, the default values for both the settings are ACTIVE_AGENT_ONLY</p>"},{"location":"explore/features/core/Arbitrator/#sequence-diagrams","title":"Sequence Diagrams","text":"Click to expand or collapse AgentRegistration sequence diagram.  Click to expand or collapse AlexaInvocation sequence diagram.  <p>An example of Alexa Invocation when no agent is active </p> Click to expand or collapse 3rd Party Invocation with no agent is active sequence diagram. <p>Example of 3rd Party Invocation when no agent is active </p> Click to expand or collapse Barge-in of non-active agent sequence diagram  <p>Example of Barge-in of non-active agent when Alexa is active </p> Click to expand or collapse Barge-in of active agent sequence diagram. <p>Example of Barge-in of active agent when agent is speaking </p>"},{"location":"explore/features/core/AudioInput/","title":"AudioInput Interface","text":""},{"location":"explore/features/core/AudioInput/#overview","title":"Overview","text":"<p>The core audio Engine service provides a mechanism for Engine components of any module to open audio input channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a microphone implementation specific to the channel type. The <code>AudioInput</code> interface provides AASB messages for your application to share audio data with the Engine when the Engine needs it.</p>"},{"location":"explore/features/core/AudioInput/#understand-audioinput","title":"Understand AudioInput","text":"<p>Your application subscribes to the outgoing <code>AudioInput</code> AASB messages published by the Engine. When some Engine component requests audio input (for example, when the user presses the tap-to-talk button from <code>SpeechRecognizer</code>), the Engine publishes a <code>StartAudioInput</code> message that specifies the <code>audioType</code> and <code>streamId</code>. The Engine defines the following audio types for which it requests <code>AudioInput</code> streams:</p> <ul> <li> <p>VOICE\u2014 This audio input type provides user speech audio data.</p> </li> <li> <p>COMMUNICATION\u2014 This audio input type provides user speech audio data specific to Alexa-to-Alexa calling. For example, the <code>Alexa Comms</code> module Engine components request audio input with this type.</p> </li> <li> <p>LOOPBACK\u2014 This audio input type provides audio data recorded from the device's own speakers. For example, the <code>Loopback Detector</code> module Engine components request audio input with this type to detect Alexa saying her own name in the audio output.</p> </li> </ul> <p>Regardless of the audio type, your application writes audio data to the stream with the specified ID until the Engine publishes a <code>StopAudioInput</code> message for the same stream ID. The audio data you provide must use the following format:</p> <ul> <li>16bit Linear PCM</li> <li>16kHz sample rate</li> <li>Single channel</li> <li>Signed, little endian byte order</li> </ul> <p>The core audio Engine service enables multiple Engine components to share single producer, multi-consumer audio input in two key ways:</p> <ul> <li> <p>Multiple Engine components might request audio input of the same type. For example, the <code>Alexa</code> module and <code>Amazonlite</code> module Engine components both want <code>VOICE</code> audio input. When the first component requests to open a <code>VOICE</code> stream, your application receives a <code>StartAudioInput</code> message requesting to open a stream for the <code>VOICE</code> type. When the second Engine component needs the voice audio type, the Engine won't ask your application for voice audio again because your application is already providing it. The Engine takes care of providing the same audio data to both consumers. Similarly, your application will only receive a <code>StopAudioInput</code> message for the voice stream when the last Engine component has canceled its request to receive this type of audio.</p> </li> <li> <p>Multiple Engine components might request audio input of \"different\" types that your application considers the same. For example, the <code>Alexa</code> module and <code>Alexa Comms</code> module want <code>VOICE</code> and <code>COMMUNICATION</code> audio input, respectively. Your application's specific integration might have one implementation for producing the user speech audio data. In this case, your application takes care of providing the same audio data to both consumers in different streams opened by the Engine.</p> </li> </ul>"},{"location":"explore/features/core/AudioInput/#use-the-audioinput-interface-in-a-native-c-application","title":"Use the AudioInput interface in a native C++ application","text":"<p>To write the audio data to the Engine after receiving a <code>StartAudioInput</code> message, use the <code>MessageBroker::openStream()</code> function, specifying the same <code>streamId</code> from the <code>StartAudioInput</code> message and the operation mode <code>MessageStream::Mode::WRITE</code>. The <code>openStream()</code> call returns a <code>MessageStream</code> object. Provide audio data in repeated calls to <code>MessageStream::write()</code> until the Engine publishes a <code>StopAudioInput</code> message for the stream ID.</p> <p>The following C++ example code demonstrates how your application subscribes to <code>AudioInput</code> AASB messages, opens an input stream to provide audio when requested, and stops providing audio when requested.</p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n#include &lt;AASB/Message/Audio/AudioInput/StopAudioInputMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioInput/StartAudioInputMessage.h&gt;\n\nclass MyAudioInputHandler {\n\n// Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle\nvoid MyAudioInputHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStartAudioInputMessage(message); },\nStartAudioInputMessage::topic(),\nStartAudioInputMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStopAudioInputMessage(message); },\nStopAudioInputMessage::topic(),\nStopAudioInputMessage::action());\n}\n\nvoid MyAudioInputHandler::handleStartAudioInputMessage(const std::string&amp; message) {\nStartAudioInputMessage msg = json::parse(message);\n// open the stream for writing\nauto streamId = msg.payload.streamId;\nauto stream = m_messageBroker-&gt;openStream(\nstreamId,\nMessageStream::Mode::WRITE);\nif (stream == nullptr) {\n// handle the error condition\nreturn;\n}\n\nstartAudioInput(streamId, stream)\n}\n\nvoid startAudioInput(const std::string&amp; streamId, std::shared_ptr&lt;MessageStream&gt; stream) {\n// On another thread, write data to the stream until\n// you receive a StopAudioInput message with the same \"streamId\"\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\nreturn;\n}\n\nvoid MyAudioInputHandler::handleStopAudioInputMessage(const std::string&amp; message) {\nStopAudioInputMessage msg = json::parse(message);\nauto streamId = msg.payload.streamId;\nstopAudioInput(streamId);\n}\n\nvoid stopAudioInput(const std::string&amp; streamId) {\n// Stop writing audio data to the stream identified by \"streamId\"\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\nreturn;\n}\n}\n</code></pre>"},{"location":"explore/features/core/AudioOutput/","title":"AudioOutput Interface","text":""},{"location":"explore/features/core/AudioOutput/#overview","title":"Overview","text":"<p>The core audio Engine service provides a mechanism for Engine components of any module to open audio output channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a media player implementation specific to the channel type. The <code>AudioOutput</code> interface provides AASB messages for the Engine to request your application to play or perform other operations on audio output data.</p>"},{"location":"explore/features/core/AudioOutput/#understand-audiooutput","title":"Understand AudioOutput","text":"<p>Your application subscribes to the outgoing <code>AudioOutput</code> AASB messages published by the Engine. When some Engine component needs to play audio, the Engine publishes <code>AudioOutput</code> messages that specify content to play with a <code>token</code> uniquely identifying the content.</p> <p>To set up content for playback, the Engine includes an <code>audioType</code> in an <code>AudioOutput.Prepare</code> message. The Engine defines the following audio types for which it requests playback via <code>AudioOutput</code>:</p> <ul> <li> <p>TTS\u2014 This audio output type plays speech audio data. For example, Alexa's speech responses from the <code>SpeechSynthesizer</code> interface</p> </li> <li> <p>MUSIC\u2014 This audio output type plays media. For example, Amazon Music or other streaming content from the <code>AudioPlayer</code> interface</p> </li> <li> <p>NOTIFICATION\u2014 This audio output type plays notification audio cues. For example, short cues from the <code>Notifications</code> interface</p> </li> <li> <p>ALARM\u2014 This audio output type plays alerts or alarms.</p> </li> </ul> <p>Note: Auto SDK does not have any features that play audio streams using the ALARM audio output type.</p> <ul> <li> <p>EARCON\u2014 This audio output type plays Alexa attention state audio cues. For example, the audio cue to indicate Alexa started listening</p> </li> <li> <p>COMMUNICATION\u2014 This audio output type plays the audio for Alexa-to-Alexa calling. For example, the \"other side\" of the user's Alexa-to-Alexa call placed using the <code>Alexa Comms</code> module.</p> </li> <li> <p>RINGTONE\u2014 This audio output type plays ringtones. For example, the inbound or outbound ringing tone of the user's Alexa-to-Alexa call placed using the <code>Alexa Comms</code> module.</p> </li> </ul> <p>Your application determines how to handle each different audio type. The simplest integration, for example, might play all audio output types with multiple instances of the same underlying media player implementation. A more sophisticated integration might provide different media player implementations depending on the audio type\u2014 for example, using a low-level audio implementation for <code>NOTIFICATION</code> and <code>EARCON</code> types, and a high-level implementation for <code>TTS</code> and <code>MUSIC</code>. The best approach depends on your system-specific use cases.</p> <p>Important! Even though your application might use the same media player implementation for multiple audio output types, the actual integration must be able to handle the Engine having multiple channels open at the same time; for example, there might be music buffered in the <code>MUSIC</code> channel media player while the user makes a quick Alexa-to-Alexa call using the <code>RINGTONE</code> and <code>COMMUNICATION</code> channels. The Engine is agnostic to how you buffer and control the audio, but it does require your integration to be capable of keeping the right state of all channels that are active at the same time. I.e., starting <code>RINGTONE</code> audio playback is not allowed to override your active <code>MUSIC</code> playback buffer.</p> <p>After preparing an appropriate media player implementation with content specified in a <code>Prepare</code> message, the Engine will publish additional messages with the same <code>token</code> instructing your application to perform additional operations on the content, such as starting playback, pausing, stopping, or querying data about the content. Messages that request data require your application to publish a synchronous-style reply message, and messages that request playback operations require your application to asynchronously respond with a message when the media state has changed. See the AudioOutput AASB message reference for complete details about which messages require which responses.</p>"},{"location":"explore/features/core/AudioOutput/#enable-music-ducking","title":"Enable music ducking","text":"<p>The <code>AudioOutput</code> interface allows audio ducking for the <code>MUSIC</code> audio type. Your application can duck music playback when a higher priority Alexa audio channel acquires foreground focus or when any external application's audio channel acquires foreground focus. To enable music audio ducking, provide the following JSON in your Engine configuration:</p> <p><pre><code>{\n\"aace.alexa\" : {\n\"audio\": {\n\"audioOutputType.music\": {\n\"ducking\": {\n\"enabled\" : true\n}\n}\n}\n}\n}\n</code></pre> Alternatively, use the <code>AlexaConfiguration::createDuckingConfig()</code> factory function to generate the <code>EngineConfiguration</code> object.</p> <pre><code>auto audioDuckingConfig = aace::alexa::config::AlexaConfiguration::createDuckingConfig(true);\n</code></pre> <p>This Engine configuration is required in order for you to use the <code>AudioFocusEvent</code> message to report externally-initiated audio ducking events on the music channel. The configuration is also required to enable the Engine to publish <code>StartDucking</code> and <code>StopDucking</code> messages to your application. See Duck audio for additional details about using these messages.</p>"},{"location":"explore/features/core/AudioOutput/#use-the-audiooutput-interface-in-a-native-c-application","title":"Use the AudioOutput interface in a native C++ application","text":"<p>This section describes how to integrate the AudioOutput AASB messages in your application.</p>"},{"location":"explore/features/core/AudioOutput/#prepare-content-for-playback","title":"Prepare content for playback","text":"<p>When your application receives a <code>Prepare</code> message, use the <code>audioType</code> value in the payload to determine which of your media player implementations will handle the content (if your application manages multiple player types). There are two flavors of content that a <code>Prepare</code> message might use:</p> <ol> <li> <p>If the <code>Prepare</code> message includes a <code>url</code> in its payload, begin downloading the content at the URL and preparing your media player for playback when the Engine requests it. URL-based content is used by the Alexa module's <code>AudioPlayer</code> interface, for example, to specify content provided by Amazon Music, Flash Briefing, Audible, TuneIn, and other media streaming skills.</p> </li> <li> <p>If the <code>Prepare</code> message includes a <code>streamId</code>, the Engine will write the audio data directly to a <code>MessageStream</code> object that you retrieve through <code>MessageBroker</code>. Call <code>MessageBroker::openStream()</code>, specifying the <code>streamId</code> from the <code>Prepare</code> message and the operation mode <code>MessageStream::Mode::READ</code>. To retrieve the audio data for your buffer, repeatedly call <code>MessageStream::read()</code> on the stream object until <code>MessageStream::isClosed()</code> returns true, indicating the Engine has no more data to add to the stream.</p> </li> </ol> <p>Important!: Your application should use a separate thread to read the content from the stream into your media player's buffer. For some types of audio, the Engine can continuously write data to the stream for a long time and may request operations on the content playback in parallel. Your application may not block MessageBroker's outgoing thread or block operations on the content (such as play or pause) from happening immediately when requested.</p> <p>Keep track of the <code>token</code> and <code>channel</code> from the <code>Prepare</code> message since these values are used in further messages to and from the Engine for the content.</p> <p>After publishing a <code>Prepare</code> message, the Engine can optionally publish a <code>MayDuck</code> message to indicate if your application is allowed to duck this particular audio item during its playback (for example, when an external application temporarily takes foreground audio focus but allows your Alexa app audio to play at a ducked volume). If you receive this message, your player is allowed to duck the audio during its playback any time the system requests it and report the ducking as outlined in Duck audio. If you do not receive a <code>MayDuck</code> message before receiving a <code>Play</code> message for the audio item, your application is not allowed to duck this audio content.</p>"},{"location":"explore/features/core/AudioOutput/#start-playback","title":"Start playback","text":"<p>Begin playback of the buffered content only after you receive a <code>Play</code> message with matching <code>token</code>. Your media player might take a moment to start playback (for instance, if there is not enough content buffered), so publish the asynchronous <code>MediaStateChanged</code> message with <code>state</code> set to <code>PLAYING</code> when your player begins to play. Specify the cached <code>token</code> and <code>channel</code> for the content in this message.</p> <p>Unless you receive another message with matching <code>token</code>, such as a request from the Engine to pause or stop the playback, your player should continue to play back all of the content for this audio item until there is no more content to play. Publish the <code>MediaStateChanged</code> message with <code>state</code> set to <code>STOPPED</code> to tell the Engine when the content is finished. The Engine will not send any further AASB messages for this particular audio item (identified by the <code>token</code>), and it may or may not tell your player to prepare new content (such as another track in a playlist) with a fresh <code>Prepare</code> message.</p>"},{"location":"explore/features/core/AudioOutput/#set-the-playback-position","title":"Set the playback position","text":"<p>If the Engine needs your player to seek to a particular position in the media stream, your application receives a <code>SetPosition</code> message. Your player must update its playback position to the offset specified in the <code>position</code> parameter.</p>"},{"location":"explore/features/core/AudioOutput/#respond-to-queries-about-the-playback","title":"Respond to queries about the playback","text":"<p>The Engine might need to query your implementation for information about the active playback. Publish the reply messages quickly so you don't delay the user's interactions with Alexa.</p> <p>If you receive a <code>GetPosition</code> message, use the synchronous-style reply message to notify the Engine of the current playback offset in the media stream (or the most recent offset if the stream isn't currently playing). The Engine will query the position any time the user makes a request to Alexa as well as various other times during playback.</p> <p>If you receive a <code>GetNumBytesBuffered</code> message, use the synchronous-style reply message to notify the Engine how many bytes your player has buffered for the current audio item.</p> <p>If you receive a <code>GetDuration</code> message, use the synchronous-style reply message to notify the Engine of the duration of the current audio item</p>"},{"location":"explore/features/core/AudioOutput/#handle-a-buffer-underrun-during-playback","title":"Handle a buffer underrun during playback","text":"<p>If your player encounters a buffer underrun during playback (i.e., your playback buffer has run out and is refilling slower than the rate needed for playback), you can notify the Engine by publishing a <code>MediaStateChanged</code> message with <code>state</code> set to <code>BUFFERING</code>. Publish another <code>MediaStateChanged</code> message with <code>state</code> set to <code>PLAYING</code> when the buffer is refilled.</p>"},{"location":"explore/features/core/AudioOutput/#handle-an-error-during-playback","title":"Handle an error during playback","text":"<p>If your player encounters an error during playback, notify the Engine by publishing a <code>MediaError</code> message. Publishing this message indicates to the Engine that the player has stopped playback due to an error and cannot resume, so ensure you do not begin playback for this audio item after publishing a <code>MediaError</code> message.</p> <p>After receiving <code>MediaError</code> for an audio item, the Engine will not request any more playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type.</p>"},{"location":"explore/features/core/AudioOutput/#pause-and-resume-playback","title":"Pause and resume playback","text":"<p>The Engine can request your player to pause the content playback by publishing a <code>Pause</code> message. When you receive this message, you must pause playback and preserve the state of the audio in the buffer. Publish a <code>MediaStateChanged</code> message with <code>state</code> set to <code>STOPPED</code> to indicate to the Engine that your player has paused as requested. Your player will remain paused until you receive a <code>Resume</code> message for the same audio item. Publish a <code>MediaStateChanged</code> message with <code>state</code> set to <code>PLAYING</code> to indicate to the Engine that your player has resumed as requested.</p> <p>Note: The Engine uses the <code>Pause</code> and <code>Resume</code> messages for temporary operations, typically related to higher priority Alexa channels taking over. For example, the Engine will temporarily pause audio playing from the <code>AudioPlayer</code> channel when the <code>SpeechSynthesizer</code> channel needs to play Alexa speech. The Engine resumes the <code>AudioPlayer</code> audio when the <code>SpeechSynthesizer</code> audio is finished. For cases in which a user presses a pause button or makes a voice request to pause <code>AudioPlayer</code> streaming content, the Engine typically uses the <code>Stop</code> message for this sort of pause operation. When the user resumes the playback with the button or voice, the Engine will <code>Prepare</code> and <code>Play</code> a new audio item even though the content is the same.</p> <p>Important! Do not publish a <code>MediaStateChanged</code> message with <code>state</code> set to <code>STOPPED</code> in an attempt to notify the Engine of some locally-initiated pause or stop operation. The <code>STOPPED</code> state has three interpretations in the Engine, and which one the Engine uses depends on its state prior to receiving the <code>STOPPED</code> state from your application.</p> <ol> <li> <p>If you publish the <code>STOPPED</code> state after the Engine published <code>Pause</code> for the audio item, the Engine interprets the <code>STOPPED</code> as a successful pause. The Engine will <code>Resume</code> the audio when it needs to.</p> </li> <li> <p>If you publish the <code>STOPPED</code> state after the Engine published <code>Stop</code> for the audio item, the Engine interprets the <code>STOPPED</code> as a successful stop. The Engine considers this media item complete and flushed from the buffer. The audio item is not resumable any more.</p> </li> <li> <p>If you publish the <code>STOPPED</code> state proactively (i.e., not after a <code>Pause</code> or <code>Stop</code> request from the Engine), the Engine interprets this as meaning that the content is finished playing. If the Engine has more content in its queue, such as a subsequent track in a playlist, the Engine will continue to <code>Prepare</code> and <code>Play</code> the next item automatically.</p> </li> </ol> <p>If you need to pause or stop audio playback for the <code>MUSIC</code> audio type due to a user button press or some system audio focus event, you must use the <code>PlaybackController</code> interface from the Alexa module to request the Engine to halt the playback. There is no AASB message to pause other audio types.</p>"},{"location":"explore/features/core/AudioOutput/#stop-playback","title":"Stop playback","text":"<p>The Engine can request your player to stop the content playback by publishing a <code>Stop</code> message. When you receive this message, you must stop playback and publish a <code>MediaStateChanged</code> message with <code>state</code> set to <code>STOPPED</code> to indicate to the Engine that your player has stopped as requested. The Engine considers this media item complete and non-operable any more, so you will not receive further requests for playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type.</p>"},{"location":"explore/features/core/AudioOutput/#duck-audio","title":"Duck audio","text":""},{"location":"explore/features/core/AudioOutput/#engine-initiated","title":"Engine-initiated","text":"<p>If your application has enabled audio ducking for the music channel, the Engine can request your application to duck audio playback when a higher priority Alexa audio source temporarily needs the foreground audio focus rather than using the default behavior in which the Engine pauses and resumes the content.</p> <p>For example, sometimes the <code>AudioPlayer</code> channel is streaming media when the user interrupts to ask Alexa a question. Without ducking enabled, the Engine requests your application to pause the active audio output on the music channel. When the user and Alexa finish their interaction, the Engine requests your application to resume the audio. With ducking enabled, the Engine requests your application to start ducking the music channel content for the duration of the user's interaction with Alexa and then restores the original volume of the music when the interaction is over.</p> <p>When the Engine needs your application to duck the volume of the music content, the Engine publishes the <code>StartDucking</code> message. When you receive this message, you must reduce the playback volume, preserve the state of the audio, and continue playback. When you receive a <code>StopDucking</code> message, restore the audio playback to its original volume prior to ducking and continue playback.</p>"},{"location":"explore/features/core/AudioOutput/#externally-initiated","title":"Externally-initiated","text":"<p>If audio is active on the music channel and the Engine permitted the audio source to duck with the <code>MayDuck</code> message (see Prepare content for playback), your application is allowed to duck audio when external audio sources on the system overtake foreground audio focus. If this happens, you must report to the Engine that your media player implementation proactively ducked its own audio by publishing an <code>AudioFocusEvent</code> message with <code>focusAction</code> set to <code>REPORT_DUCKING_STARTED</code>. When your implementation regains foreground audio focus on the system and restores the volume to the original level, publish another <code>AudioFocusEvent</code> message with <code>focusAction</code> set to <code>REPORT_DUCKING_STOPPED</code>.</p>"},{"location":"explore/features/core/AudioOutput/#mute-audio","title":"Mute audio","text":"<p>The Engine can request your player to mute or unmute the content playback by publishing a <code>MutedStateChanged</code> message. When you receive a <code>MutedStateChanged</code> message with <code>state</code> set to <code>MUTED</code>, you must mute the playback volume, preserving the state of the audio and continuing playback. When you receive a <code>MutedStateChanged</code> message with <code>state</code> set to <code>UNMUTED</code>, you must restore the playback volume, preserving the state of the audio and continuing playback.</p>"},{"location":"explore/features/core/AudioOutput/#change-audio-volume","title":"Change audio volume","text":"<p>The Engine can request your player to change the volume of the content playback by publishing a <code>VolumeChanged</code> message. When you receive a <code>VolumeChanged</code> message, use the value of the <code>volume</code> parameter to adjust the volume of the audio source. The volume is a float in the range 0-1, so you can use it as a scaling factor for the actual volume range used by your media player.</p>"},{"location":"explore/features/core/AudioOutput/#example-code","title":"Example code","text":"<p>The following example code demonstrates how your application subscribes to the <code>AudioOutput</code> AASB messages.</p> <p> Click to expand or collapse C++ sample code</p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/GetDurationMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/GetNumBytesBufferedMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/GetPositionMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/MayDuckMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/MediaErrorMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/MediaStateChangedMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/MutedStateChangedMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/PauseMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/PlayMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/PrepareStreamMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/PrepareURLMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/ResumeMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/SetPositionMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/StartDuckingMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/StopDuckingMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/StopMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioOutput/VolumeChangedMessage.h&gt;\n\nclass MyAudioOutputHandler {\n\n// Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle\nvoid MyAudioOutputHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleMutedStateChangedMessage(message); },\nMutedStateChangedMessage::topic(),\nMutedStateChangedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePauseMessage(message); },\nPauseMessage::topic(),\nPauseMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePlayMessage(message); },\nPlayMessage::topic(), PlayMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePrepareStreamMessage(message); },\nPrepareStreamMessage::topic(),\nPrepareStreamMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePrepareURLMessage(message); },\nPrepareURLMessage::topic(),\nPrepareURLMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleMayDuckMessage(message); },\nMayDuckMessage::topic(),\nMayDuckMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleResumeMessage(message); },\nResumeMessage::topic(),\nResumeMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleSetPositionMessage(message); },\nSetPositionMessage::topic(),\nSetPositionMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStopMessage(message); },\nStopMessage::topic(),\nStopMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleVolumeChangedMessage(message); },\nVolumeChangedMessage::topic(),\nVolumeChangedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStartDuckingMessage(message); },\nStartDuckingMessage::topic(),\nStartDuckingMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStopDuckingMessage(message); },\nStopDuckingMessage::topic(),\nStopDuckingMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetDurationMessage(message); },\nGetDurationMessage::topic(),\nGetDurationMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetNumBytesBufferedMessage(message); },\nGetNumBytesBufferedMessage::topic(),\nGetNumBytesBufferedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetPositionMessage(message); },\nGetPositionMessage::topic(),\nGetPositionMessage::action());\n}\n\nvoid MyAudioOutputHandler::handleMutedStateChangedMessage(const std::string&amp; message) {\n// Implement this stub to mute the audio\n}\n\nvoid MyAudioOutputHandler::handlePauseMessage(const std::string&amp; message) {\n// Implement this stub to pause the audio\n}\n\nvoid MyAudioOutputHandler::handlePlayMessage(const std::string&amp; message) {\n// Implement this stub to play the audio\n}\n\nvoid MyAudioOutputHandler::handlePrepareStreamMessage(const std::string&amp; message) {\nPrepareStreamMessage msg = json::parse(message);\nauto stream = m_messageBroker-&gt;openStream(msg.payload.streamId, MessageStream::Mode::READ);\n\n// Implement this stub to read the stream content into the media player buffer\n// Use a separate thread!\n}\n\nvoid MyAudioOutputHandler::handlePrepareURLMessage(const std::string&amp; message) {\n// Implement this stub to download the URL contents into the media player buffer\n// Use a separate thread!\n}\n\nvoid MyAudioOutputHandler::handleMayDuckMessage(const std::string&amp; message) {\n// Implement this stub to set the prepared content as duck-able\n}\n\nvoid MyAudioOutputHandler::handleResumeMessage(const std::string&amp; message) {\n// Implement this stub to resume the audio\n}\n\nvoid MyAudioOutputHandler::handleSetPositionMessage(const std::string&amp; message) {\n// Implement this stub to set the audio playback position\n}\n\nvoid MyAudioOutputHandler::handleStopMessage(const std::string&amp; message) {\n// Implement this stub to stop the audio playback\n}\n\nvoid MyAudioOutputHandler::handleVolumeChangedMessage(const std::string&amp; message) {\n// Implement this stub to change the volume of the audio stream\n}\n\nvoid MyAudioOutputHandler::handleStartDuckingMessage(const std::string&amp; message) {\n// Implement this stub to duck the audio stream volume\n// Alternatively, you can pause the audio stream if more suitable - just don't publish MediaStateChanged in this case\n}\n\nvoid MyAudioOutputHandler::handleStopDuckingMessage(const std::string&amp; message) {\n// Implement this stub to restore the audio stream volume from the ducked state\n// You can resume the playback if you paused instead of ducking - just don't publish MediaStateChanged in this case\n}\n\nvoid MyAudioOutputHandler::handleGetDurationMessage(const std::string&amp; message) {\nGetDurationMessage msg = json::parse(message);\n\n// Implement this stub to get the duration\n// Perform this operation quickly and publish the sync-style reply message\n}\n\nvoid MyAudioOutputHandler::handleGetNumBytesBufferedMessage(const std::string&amp; message) {\nGetNumBytesBufferedMessage msg = json::parse(message);\n\n// Implement this stub to get the number of bytes buffered\n// Perform this operation quickly and publish the sync-style reply message\n}\n\nvoid MyAudioOutputHandler::handleGetPositionMessage(const std::string&amp; message) {\nGetPositionMessage msg = json::parse(message);\n\n// Implement this stub to get the current playback offset (or the most recent offset if nothing is playing)\n// Perform this operation quickly and publish the sync-style reply message\n}\n\n// Call this function when you need to publish a MediaError message\nvoid MyAudioOutputHandler::publishMediaError(\nconst std::string&amp; token,\nMediaError error,\nconst std::string&amp; description) {\nMediaErrorMessage msg;\nmsg.payload.token = token;\nmsg.payload.error = error;\nmsg.payload.description = description;\n\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// Call this function when you need to publish a MediaStateChanged message\nvoid MyAudioOutputHandler::publishMediaStateChanged(\nconst std::string&amp; channel,\nconst std::string&amp; token,\nMediaState state) {\nMediaStateChangedMessage msg;\nmsg.payload.channel = channel;\nmsg.payload.token = token;\nmsg.payload.state = state;\n\nm_messageBroker-&gt;publish(msg.toString());\n}\n}\n</code></pre>"},{"location":"explore/features/core/AudioOutput/#sequence-diagrams","title":"Sequence diagrams","text":"<p>Note: The following diagrams show sequences using the deprecated <code>AudioOutput</code> platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analogous <code>AudioOutput</code> AASB messages with the MessageBroker. The concepts are the same between the two interfaces.</p>"},{"location":"explore/features/core/AudioOutput/#duck-music-volume-when-alexa-dialog-or-alerts-take-foreground-focus","title":"Duck music volume when Alexa dialog or alerts take foreground focus","text":""},{"location":"explore/features/core/AudioOutput/#duck-music-volume-when-an-external-audio-source-takes-foreground-focus","title":"Duck music volume when an external audio source takes foreground focus","text":""},{"location":"explore/features/core/AudioOutput/#play-drm-protected-audio","title":"Play DRM-protected audio","text":"<p>Digital Rights Management (DRM) uses encryption to secure music on the device. To play DRM-protected audio, your media player implementation generally has to make a key request, fetch a manifest, and download audio segments. Auto SDK 4.3 adds a <code>PlaybackContext</code> field in the <code>AudioOutput.Prepare</code> message to provide additional headers necessary for requesting DRM-related resources. Your media player implementation must include any headers from <code>PlaybackContext</code> as HTTP request headers in the HTTP request to download the media.</p> <p>To receive DRM-protected audio, configure Auto SDK with an allowed-listed media player fingerprint:</p> <pre><code>{\n\"aace.alexa\": {\n\"mediaPlayerFingerprint\": {\n\"package\": \"&lt;package&gt;\",\n\"buildType\": \"&lt;buildType&gt;\",\n\"versionNumber\": \"&lt;versionNumber&gt;\"\n}\n}\n}\n</code></pre> <ul> <li><code>package</code> is the unique identifier for the audio player software loaded on the device.</li> <li><code>buildType</code> is the audio player build type, for example, \"DEBUG\" or \"RELEASE\".</li> <li><code>versionNumber</code> identifies the version of the audio player loaded on your device.</li> </ul> <p>Contact your Amazon SA partner to allow-list your fingerprint configuration.</p>"},{"location":"explore/features/core/Authorization/","title":"Authorization Interface","text":""},{"location":"explore/features/core/Authorization/#overview","title":"Overview","text":"<p>To make requests to services such as Alexa, the Auto SDK Engine requires authorization. For example, the Engine includes a Login with Amazon (LWA) access token in every request to Alexa. The access token authorizes the Engine to interact with Alexa on behalf of the user. A service that requires authorization might have more than one method of performing the authorization; for instance, there are multiple methods to acquire an LWA token that authorizes access to Alexa. See the Authorize an AVS Device for details of each method.</p> <p>The Auto SDK <code>Core</code> module provides an Engine service and <code>Authorization</code> interface for your application to initiate, terminate, or provide data for an authorization session with an authorization provider. The following sections describe the Auto SDK <code>Authorization</code> interface and details to use the <code>Authorization</code> interface for LWA Alexa authorization in your application.</p>"},{"location":"explore/features/core/Authorization/#understand-the-authorization-interface","title":"Understand the Authorization interface","text":"<p>The <code>Authorization</code> interface specifies generic messages to support authorization to any cloud service using any valid authorization method for that service. The actions the Engine takes in response to an <code>Authorization</code> message from your application depend on the provider to which the message corresponds, as well as the specific responsibilities of each software component involved in the authorization method. For example, in your Alexa integration, your application might use the method in which the Engine acquires LWA Alexa access tokens, so at first time user sign-in, your application requests the Engine to fetch a code for your application UI to display to the user. Alternatively, you might use the method in which your application provides its own implementation to acquire LWA Alexa access tokens, so at first time user sign-in, your application notifies the Engine that your application will will soon provide an access token that it acquires on its own. In either case, your application interacts with the same <code>Authorization</code> interface messages; only the protocol in the message payload varies.</p> <p>Each authorization provider that the Engine supports corresponds to a protocol that your application uses in <code>Authorization</code> message payloads. See the <code>Authorization</code> message reference for details about the messages and provider-specific documentation for details about the specific protocol to use with the messages. Regardless of the authorization provider you choose, your application does the following general steps:</p> <p>Before starting the Engine, subscribe to the following messages:</p> <ul> <li> <p>SetAuthorizationData\u2014 Requests your application to store provider-specific data.</p> </li> <li> <p>GetAuthorizationData\u2014 Requests your application to share provider-specific data. Your application publishes the synchronous-style reply message in response.</p> </li> <li> <p>EventReceived\u2014 Notifies your application of provider-specific events during the authorization flow.</p> </li> <li> <p>AuthorizationStateChanged\u2014 Notifies your application of status changes during the authorization flow.</p> </li> <li> <p>AuthorizationError\u2014 Notifies your application of errors during the authorization flow.</p> </li> </ul> <p>At runtime, publish the following messages:</p> <ul> <li> <p>StartAuthorization\u2014 Tells the Engine to start the authorization flow. Depending on the provider in use, this could be a request to the Engine to start fetching authorization data or a notification that your application is ready for authorization and will fetch or refresh authorization data on its own.</p> </li> <li> <p>SendEvent\u2014 Notifies the Engine about a provider-specific event.</p> </li> <li> <p>CancelAuthorization\u2014 Tells the Engine to cancel the authorization flow. Depending on the provider in use, this could be a request to the Engine to cancel fetching authorization data while in progress or a notification that your application is canceling its own data fetching.</p> </li> <li> <p>Logout\u2014 Notifies the Engine that the user signed out of your application.</p> </li> </ul>"},{"location":"explore/features/core/Authorization/#authorize-for-alexa","title":"Authorize for Alexa","text":"<p>To simplify your Alexa authorization implementation, the Engine provides an implementation of the code-based linking (CBL) LWA authorization method, which you can use in your application by integrating with the CBL module. Alternatively, your application can provide the implementation to fetch access tokens through any method you choose. </p> <p>The different authorization providers for Alexa access tokens are mutually exclusive, so the Engine only allows one active provider session at a time. If your application has an active authorization session using the CBL module, for example, and switches to an application-provided authorization implementation, the Engine terminates the session with the CBL module provider prior to accepting further updates from the application-provided provider.</p> <p>Important!: Logging out from the CBL module or application-provided authorization clears the Auto SDK databases that store user data, such as alerts and settings. For example, when the user logs out, the Alexa module Engine components clear pending alerts in the alerts database to ensure that the next user who logs in does not receive any alerts set by another user. However, the Alexa module Engine components also clear the locale setting at log out and reset the setting to the default value from the Engine configuration. Therefore, if the device locale setting is different from the default locale when the next user signs in, you must set the locale before starting an authorization flow.</p>"},{"location":"explore/features/core/Authorization/#use-the-cbl-module","title":"Use the CBL module","text":"<p>The Engine provides an implementation of the code-based linking method of acquiring LWA access tokens. To use the implementation, build the Auto SDK with the <code>CBL</code> module, link the library in your application, and follow the <code>Authorization</code> protocol specified in the <code>CBL</code> module documentation. </p>"},{"location":"explore/features/core/Authorization/#use-an-application-provided-method","title":"Use an application-provided method","text":"<p>If you want your application to provide the implementation for fetching and refreshing Alexa access tokens, use the application-provided authorization method according to the following specification. Use <code>alexa:auth-provider</code> for the <code>service</code> parameter in <code>Authorization</code> messages.</p>"},{"location":"explore/features/core/Authorization/#initialize-the-active-authorization-provider","title":"Initialize the active authorization provider","text":"<p>When your application is ready to start an authorization session for <code>alexa:auth-provider</code>, publish the <code>StartAuthorization</code> message with empty <code>data</code> parameter. This <code>StartAuthorization</code> message notifies the Engine that your application-provided component is the active authorization provider. This allows the Engine to clear any previously active authorization provider sessions and ready itself to expect further state change notifications and access tokens from your application.</p> Click to expand or collapse example StartAuthorization message <pre><code>{\n   \"header\": {\n      \"id\": \"7b388b36-6843-4f63-b3ad-ec69c16a518e\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"StartAuthorization\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"data\": \"\",\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>In response to the <code>StartAuthorization</code> message that requests to initialize <code>alexa:auth-provider</code>, the Engine will publish one or more <code>AuthorizationStateChanged</code> messages. The <code>state</code> parameter indicates the Engine's internal view of the authorization state for the provider specified in the <code>service</code> parameter. If a different provider was used more recently than <code>alexa:auth-provider</code>, the Engine un-initializes that provider and sets its state to <code>UNAUTHORIZED</code>.</p> Click to expand or collapse example AuthorizationStateChanged message <pre><code>{\n   \"header\": {\n      \"id\": \"56f4fdb1-2174-44ba-850e-e46ae10488e6\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"AuthorizationStateChanged\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:cbl\",\n      \"state\": \"UNAUTHORIZED\"\n   }\n}\n</code></pre> <p>Once any previously active authorization session is cleared, the Engine notifies your application that <code>alexa:auth-provider</code> is <code>AUTHORIZING</code>. The Engine does not consider your application-provided authorization component to be the active authorization provider until you receive this message.</p> Click to expand or collapse example AuthorizationStateChanged message <pre><code>{\n   \"header\": {\n      \"id\": \"5d163203-2ebc-4169-ac45-e840fc125ad2\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"AuthorizationStateChanged\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:auth-provider\",\n      \"state\": \"AUTHORIZING\"\n   }\n}\n</code></pre> <p>Once <code>alexa:auth-provider</code> reaches the <code>AUTHORIZING</code> state, the Engine needs to know whether there is an access token. It publishes the <code>EventReceived</code> message to request your application to publish its authorization state. The <code>data</code> parameter is a serialized JSON string with the following structure:</p> <pre><code>{\n    \"type\": \"requestAuthorization\"\n}\n</code></pre> Click to expand or collapse example EventReceived message <pre><code>{\n   \"header\": {\n      \"id\": \"9fac0f24-779b-4e69-91db-317c8988eedc\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"EventReceived\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"data\": \"{\\\"type\\\":\\\"requestAuthorization\\\"}\",\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>The Engine can also publish this <code>EventReceived</code> message at any point later in the application run time. Publish the <code>SendEvent</code> message in response to this <code>EventReceived</code> message. The <code>event</code> parameter is a serialized JSON string with the following structure:</p> <pre><code>{\n    \"type\":\"authStateChangeEvent\",\n    \"payload\": {\n        \"state\": {{STRING}}\n    }\n}\n</code></pre> <p>The accepted values for <code>state</code> are <code>AUTHORIZED</code> and <code>UNAUTHORIZED</code>. Set <code>state</code> to <code>AUTHORIZED</code> if your application has an access token or <code>UNAUTHORIZED</code> if it does not have an access token yet.</p> Click to expand or collapse example SendEvent message <pre><code>{\n   \"header\": {\n      \"id\": \"6f6baa3c-0de7-439d-aa67-c9b7ad858894\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"SendEvent\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"data\": \"{\\\"type\\\":\\\"authStateChangeEvent\\\",\\\"payload\\\":{\\\"state\\\":\\\"AUTHORIZED\\\"}}\",\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>Your application can also proactively publish this <code>SendEvent</code> message when its authorization state changes. For example, if the state was initially <code>AUTHORIZED</code> but later your application fails to refresh an expired token, publish <code>SendEvent</code> as specified above and use the state <code>UNAUTHORIZED</code>. If the application later recovers and acquires a new token, publish another <code>SendEvent</code>  message with state <code>AUTHORIZED</code>.</p> <p>The Engine acknowledges the authorization state from your application by publishing an <code>AuthorizationStateChanged</code> message with its updated internal state.</p> Click to expand or collapse example AuthorizationStateChanged message <pre><code>{\n   \"header\": {\n      \"id\": \"1a91c0ab-053e-4884-a275-ff5caf3207b8\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"AuthorizationStateChanged\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:auth-provider\",\n      \"state\": \"AUTHORIZED\"\n   }\n}\n</code></pre> <p>The following diagram illustrates the sequence for your application to set the application-provided component as the active authorization provider.</p> <p></p>"},{"location":"explore/features/core/Authorization/#provide-an-access-token","title":"Provide an access token","text":"<p>When your application is in the <code>AUTHORIZED</code> state, the Engine will request your application to provide the access token by publishing a <code>GetAuthorizationData</code> message with the <code>key</code> parameter set to <code>accessToken</code>. The Engine will publish <code>GetAuthorizationData</code> messages throughout the application run time, such as when the user invokes Alexa.</p> Click to expand or collapse example GetAuthorizationData message <pre><code>{\n   \"header\": {\n      \"id\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"GetAuthorizationData\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"key\": \"accessToken\",\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>Your application includes the access token in the synchronous-style <code>GetAuthorizationData</code> reply message. The <code>data</code> parameter is a serialized JSON string with the following structure: <pre><code>{\n    \"accessToken\": {{STRING}}\n}\n</code></pre></p> Click to expand or collapse example GetAuthorizationData reply message <pre><code>{\n   \"header\": {\n      \"id\": \"a680da01-8046-4401-9ab6-a8d6120f0814\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"GetAuthorizationData\",\n         \"replyToId\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\"  \n      },\n      \"messageType\": \"Reply\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"data\": \"{\\\"accessToken\\\":\\\"Atza|AAAAAABBBBBBCCCCCC\\\"}\"      \n    }\n}\n</code></pre> <p>The following diagram illustrates an example sequence for your application to provide an access token to the Engine.</p> <p></p>"},{"location":"explore/features/core/Authorization/#cancel-authorization","title":"Cancel authorization","text":"<p>If your application needs to cancel an in-progress authorization initialization, you can publish a <code>CancelAuthorization</code> message prior to publishing <code>SendEvent</code> containing an access token. The Engine acknowledges this message from your application by publishing an <code>AuthorizationStateChanged</code> message with its updated internal state.</p> Click to expand or collapse example CancelAuthorization message <pre><code>{\n   \"header\": {\n      \"id\": \"329ac412-82e2-46be-8c67-fd965dfe3dc6\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"CancelAuthorization\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>Note: If you need to terminate the authorization session when the auth state is <code>AUTHORIZED</code>, use the <code>Logout</code> message instead. </p> <p>The following diagram illustrates an example sequence for your application to cancel authorization.</p> <p></p>"},{"location":"explore/features/core/Authorization/#log-out","title":"Log out","text":"<p>When the user signs out of your application, publish a <code>Logout</code> message and delete any stored access or refresh tokens. The user must sign in to their Amazon account in order to use Alexa with your application again.</p> Click to expand or collapse example Logout message <pre><code>{\n   \"header\": {\n      \"id\": \"a9e28b9a-6f9d-45b5-999a-19a421431af4\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"Logout\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:auth-provider\"\n   }\n}\n</code></pre> <p>The Engine acknowledges the <code>Logout</code> message from your application by publishing an <code>EventReceived</code> message with <code>type</code> set to <code>logout</code> and an <code>AuthorizationStateChanged</code> message with its updated internal state.</p> <p>The following diagram illustrates an example sequence when the user signs out of your application.</p> <p></p>"},{"location":"explore/features/core/Authorization/#handle-errors","title":"Handle errors","text":"<p>If the Engine encounters an error during the authorization flow, it publishes an <code>AuthorizationError</code> message to your application. The <code>error</code> parameter specifies which issue the Engine encountered. The following list describes the values:</p> <ul> <li><code>START_AUTHORIZATION_FAILED</code>: The Engine could not start the authorization flow.</li> <li><code>LOGOUT_FAILED</code>: The Engine could not complete the logout flow.</li> <li><code>AUTH_FAILURE</code>: The application provided an invalid or expired access token.</li> <li><code>UNKNOWN_ERROR</code>: The Engine encountered any other type of unrecoverable error in the authorization flow.</li> </ul> Click to expand or collapse example AuthorizationError message <pre><code>{\n   \"header\": {\n      \"id\": \"c7e93ab5-2509-4f0e-b421-32d0b5991279\",\n      \"messageDescription\": {\n         \"topic\": \"Authorization\",\n         \"action\": \"AuthorizationError\"\n      },\n      \"messageType\": \"Publish\",\n      \"version\": \"4.0\"\n   },\n   \"payload\": {\n      \"service\": \"alexa:auth-provider\",\n      \"error\": \"UNKNOWN_ERROR\",\n      \"message\": \"\"\n   }\n}\n</code></pre> <p>The following diagram illustrates an example error scenario in which the user de-registers their car from their Alexa account using the Alexa companion app while the car's Alexa application is running.</p> <p></p>"},{"location":"explore/features/core/Authorization/#optional-configure-the-engine-for-multiple-providers","title":"(Optional) Configure the Engine for multiple providers","text":"<p>By default, the Engine supports one application-provided authorization provider. However, if your application supports more than one, include the following JSON object in your Engine configuration:</p> <pre><code>{\n    \"aace.alexa\" : {\n        \"authProvider\" : {\n           \"providers\" : [&lt;LIST_OF_PROVIDER_NAME_STRINGS&gt;]\n        }\n    }\n}\n</code></pre> <p>For example, if your application supports providers \"serviceA\" and \"serviceB,\" provide the following configuration:</p> <pre><code>{\n    \"aace.alexa\" : {\n        \"authProvider\" : {\n           \"providers\" : [\"serviceA\" , \"serviceB\"]\n        }\n    }\n}\n</code></pre> <p>With this configuration, the Engine uses the <code>service</code> names <code>serviceA</code> and <code>serviceB</code> with the <code>Authorization</code> interface messages instead of using the default <code>service</code> name <code>alexa:auth-provider</code>. The rest of the sequence is the same as <code>alexa:auth-provider</code>.</p>"},{"location":"explore/features/core/DeviceUsage/","title":"DeviceUsage Interface","text":"<p>Periodically publish the <code>DeviceUsage.ReportNetworkDataUsage</code> message (for example, at five minute intervals) to report network data usage to the Engine. If your application uses the <code>Device Client Metrics (DCM)</code> extension, the Engine records metrics with this information.</p> <p>The <code>usage</code> field in the payload is a JSON object as a string. The format of the JSON is the following:</p> <pre><code>{\n  \"startTimeStamp\" : {{LONG}},\n  \"endTimeStamp\" : {{LONG}},\n  \"networkInterfaceType\": \"{{STRING}}\",\n  \"dataPlanType\" : \"{{STRING}}\",\n  \"bytesUsage\" :{\n      \"rxBytes\" : {{LONG}},\n      \"txBytes\" : {{LONG}}\n   }\n}\n</code></pre> <p>The following table describes the properties in the JSON:</p> Property Type Required Description Example startTimeStamp Long Yes The starting timestamp in milliseconds for this network usage datapoint \u2014 endTimeStamp Long Yes The ending timestamp in milliseconds for this network usage datapoint \u2014 networkInterfaceType String Yes The name of the network interface over which the data is recorded \"WIFI\",\"MOBILE\" dataPlanType String No The type of data plan the device is subscribed to. This is an optional field and should be provided if your application uses the <code>AlexaConnectivity</code> module. See <code>AlexaConnectivity</code> bytesUsage.rxBytes Long Yes The number of bytes received over the network interface during the time range represented by this datapoint \u2014 bytesUsage.txBytes Long Yes The number of bytes transmitted over the network interface during the time range represented by this datapoint \u2014"},{"location":"explore/features/core/LocationProvider/","title":"LocationProvider Interface","text":"<p>Sometimes the user asks Alexa a question that requires she know the location in order to answer properly. For example, a user in San Francisco, California might say \"Alexa, what's the weather?\". This user probably wants to hear Alexa say something like \"The weather in San Francisco is sixty-five degrees and overcast...\" rather than something like \"I can't find your exact location right now...\". Similarly, the user might say \"Alexa, take me to the nearest Whole Foods\" and wants Alexa to start navigation to a Whole Foods that is actually nearby.</p> <p>To provide the user with accurate responses to local search commands, weather questions, and more, obtain the user's consent to share their location with Alexa and use the <code>LocationProvider</code> interface.</p> <p>Your application should subscribe to the <code>LocationProvider.GetLocation</code> and <code>LocationProvider.GetCountry</code> messages to provide location data, such as geographic coordinates and vehicle operating country, when the Engine requests it. These messages are synchronous-style and require your application to send the corresponding reply messages right away. To avoid blocking the MessageBroker outgoing thread and delaying user requests to Alexa, your application should keep the location data in a cache that you update frequently. Pull the location from the cache when the Engine requests it.</p> <p>The Engine won't publish the <code>GetLocation</code> message if it knows your application has lost access to the location data. Keep the Engine in sync with the state of your application's location provider availability by proactively publishing the <code>LocationServiceAccessChanged</code> message at startup and each time the state changes. For example, your application might publish this message with <code>access</code> set to <code>DISABLED</code> if the system revokes your application's access to location or if GPS turns off.</p> <p>Note: The Engine does not persist this state across device reboots. To ensure the Engine always knows the initial state of location availability, publish a <code>LocationServiceAccessChanged</code> message each time you start the Engine. This includes notifying the Engine that <code>access</code> is <code>ENABLED</code>.</p> Click to expand or collapse C++ example code <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/Location/LocationProvider/GetCountryMessage.h&gt;\n#include &lt;AASB/Message/Location/LocationProvider/GetLocationMessage.h&gt;\n#include &lt;AASB/Message/Location/LocationProvider/LocationServiceAccessChangedMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyLocationProviderHandler {\n\n// Call before you start the Engine\nvoid MyLocationProviderHandler::subscribeToAASBMessages() {\nmessageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetCountryMessage(message); },\nGetCountryMessage::topic(),\nGetCountryMessage::action());\nmessageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetLocationMessage(message); },\nGetLocationMessage::topic(),\nGetLocationMessage::action());\n}\n\nvoid MyLocationProviderHandler::handleGetCountryMessage(const std::string&amp; message) {\nGetCountryMessage msg = json::parse(message);\n\n// Quickly publish the GetCountry reply message\nauto country = getCountryFromCache(); // implement this stub\nGetCountryMessageReply replyMsg;\nreplyMsg.header.messageDescription.replyToId = msg.header.id;\nreplyMsg.payload.country = country;\nmessageBroker-&gt;publish(replyMsg.toString());\n}\n\nvoid MyLocationProviderHandler::handleGetLocationMessage(const std::string&amp; message) {\nGetLocationMessage msg = json::parse(message);\n\n// Quickly publish the GetCountry reply message\nauto location = getLocationFromCache(); // implement this stub\nGetLocationMessageReply replyMsg;\nreplyMsg.header.messageDescription.replyToId = msg.header.id;\n\n// parse \"location\" and populate the fields of the reply message\naasb::message::location::locationProvider::Location replyLocation;\nreplyLocation.latitude = ... ; // the latitude from \"location\";\nreplyLocation.longitude =  ... ; // the longitude from \"location\";\nreplyMsg.payload.location = replyLocation;\nmessageBroker-&gt;publish(replyMsg.toString());\n}\n\n// Call when the application access to location data changes\n// and after starting the Engine\nvoid MyLocationProviderHandler::locationServiceAccessChanged(bool hasAccess) {\nLocationServiceAccessChangedMessage msg;\nif (hasAccess) {\nmsg.payload.access = aasb::message::location::locationProvider::LocationServiceAccess::ENABLED;\n} else {\nmsg.payload.access = aasb::message::location::locationProvider::LocationServiceAccess::DISABLED;\n}\nmessageBroker-&gt;publish(msg.toString());\n}\n}\n</code></pre>"},{"location":"explore/features/core/NetworkInfoProvider/","title":"NetworkInfoProvider Interface","text":"<p>Your application should monitor the internet connection and notify the Engine of changes in the status using the <code>NetworkInfoProvider</code> interface. The Engine uses this information to adjust its behavior, including tearing down the connection to Alexa cloud when your application reports that it has no connection to the internet. Although using <code>NetworkInfoProvider</code> is optional, you should use it so the Engine can avoid undesirable behavior; for instance, attempting to send events to Alexa when the lack of connectivity means the events are bound to fail.</p> <p>Note: You must use the <code>NetworkInfoProvider</code> interface if your application uses the Local Voice Control (LVC) extension.</p> <p>Various Engine components want the initial network status at startup so they can adapt their initial behavior accordingly. Your application should subscribe to the <code>NetworkInfoProvider.GetNetworkStatus</code> and <code>NetworkInfoProvider.GetWifiSignalStrength</code> messages to answer the initial query from the Engine. These messages are synchronous-style and require your application to send the corresponding reply messages right away.</p> <p>At runtime, publish the <code>NetworkInfoProvider.NetworkStatusChanged</code> message to notify the Engine of any status changes.</p>"},{"location":"explore/features/core/PropertyManager/","title":"PropertyManager Interface","text":""},{"location":"explore/features/core/PropertyManager/#overview","title":"Overview","text":"<p>Certain modules in the Auto SDK define constants (for example <code>FIRMWARE_VERSION</code> and <code>LOCALE</code>) that are used to get and set the values of runtime properties in the Engine. Changes to property values may also be initiated from the Alexa Voice Service (AVS). For example, the <code>TIMEZONE</code> property may be changed through AVS when the user changes the timezone setting in the Alexa Companion App.</p> <p>The Auto SDK <code>Core</code> module provides the Property Manager service with corresponding AASB interface <code>PropertyManager</code>. Property Manager maintains the runtime properties by storing properties and listeners to the properties and delegating the <code>SetProperty</code> and <code>GetProperty</code> messages calls from your application to the respective Engine services. The Engine also publishes <code>PropertyChanged</code> and <code>PropertyStateChanged</code> messages to notify your application about property value changes originating in the Engine.</p>"},{"location":"explore/features/core/PropertyManager/#use-the-property-manager-aasb-messages","title":"Use the Property Manager AASB messages","text":"<p>To change a property value, publish a <code>SetProperty</code> message. The Engine publishes a <code>PropertyStateChanged</code> message indicating the success or failure of the request.</p> <p>To retrieve a property value, publish a <code>GetProperty</code> message. The Engine publishes synchronous-style a <code>GetProperty</code> reply with the value of the property.</p> <p>When a change in a property value occurs in the Engine that is not initiated by your application, the Engine publishes a <code>PropertyChanged</code> message. </p> Click to expand or collapse C++ example code <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/PropertyManager/PropertyManager/GetPropertyMessage.h&gt;\n#include &lt;AASB/Message/PropertyManager/PropertyManager/PropertyChangedMessage.h&gt;\n#include &lt;AASB/Message/PropertyManager/PropertyManager/SetPropertyMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyPropertyManagerHandler {\n\n// Subscribe to messages from the engine\nvoid MyPropertyManagerHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePropertyChangedMessage(message); },\nPropertyChangedMessage::topic(),\nPropertyChangedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePropertyStateChangedMessage(message); },\nPropertyStateChangedMessage::topic(),\nPropertyStateChangedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetPropertyReplyMessage(message); },\nGetPropertyMessage::topic(),\nGetPropertyMessage::action());\n}\n\nvoid MyPropertyManagerHandler::handlePropertyChangedMessage(const std::string&amp; message) {\nPropertyChangedMessage msg = json::parse(message);\n\nstd::string name = msg.payload.name;\nstd::string newValue = msg.payload.newValue;\n\n// ...Handle property changed...\n}\n\nvoid MyPropertyManagerHandler::handlePropertyStateChangedMessage(const std::string&amp; message) {\nPropertyStateChangedMessage msg = json::parse(message);\n\nstd::string name = msg.payload.name;\nstd::string value = msg.payload.value;\nstd::string state = msg.payload.state\n\n// ...Handle property state changed...\n}\n\n\nvoid MyPropertyManagerHandler::handleGetPropertyReplyMessage(const std::string&amp; message) {\nGetPropertyMessageReply msg = json::parse(message);\n\nstd::string messageId = msg.header.messageDescription.replyToId;\nstd::string value = msg.payload.value;\n\n// ...Handle the value for the message...\n}\n\n// Call to set a property\nvoid MyPropertyManagerHandler::setProperty(const std::string&amp; name, const std::string&amp; value) {\n]        SetPropertyMessage msg;\nmsg.payload.name = name;\nmsg.payload.value = value;\n\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// Call to get a property\nstd::string MyPropertyManagerHandler::getProperty(const std::string&amp; name) {\nGetPropertyMessage msg;\nmsg.payload.name = name;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the GetProperty reply message\n// Return the value from reply message payload\n}\n}\n</code></pre>"},{"location":"explore/features/core/PropertyManager/#property-definitions","title":"Property Definitions","text":"<p>The definitions of the properties used with the <code>SetProperty</code> and <code>GetProperty</code> messages are defined by the Auto SDK modules that manage the properties.</p>"},{"location":"explore/features/core/PropertyManager/#alexa","title":"Alexa","text":"<p>The <code>Alexa</code> module provides the following properties:</p> <ul> <li> <p>\"aace.alexa.wakewordSupported\" This read-only property is used with <code>GetProperty</code> to check if wake word support is enabled in the Engine. If wake word is not supported in the Engine, attempts to enable wake word with the <code>SpeechRecognizer</code> will fail.</p> </li> <li> <p>\"aace.alexa.system.firmwareVersion\" This property is used with <code>SetProperty</code> to change the firmware version that is reported to AVS. The value must be a positive, 32-bit signed integer represented as a string.</p> </li> <li> <p>\"aace.alexa.setting.locale\" This property is used with <code>SetProperty</code> to change the current locale setting for Alexa. The value must be one of the following:</p> <ul> <li>A valid locale accepted by AVS as a string. E.g. \"en-US\"</li> <li>A valid locale pair. The format is a string containing two valid locales separated with a forward slash. E.g. \"en-US/es-US\"</li> </ul> <p>Note: For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation</p> </li> <li> <p>\"aace.alexa.countrySupported\" This read-only property is used with <code>GetProperty</code> to check if the vehicle's country is supported.</p> </li> <li> <p>\"aace.alexa.wakewordEnabled\" This property is used with <code>SetProperty</code> to change the current wake word enabled setting. The value must be a boolean represented as a string, i.e. \"true\" or \"false\". Use <code>GetProperty</code> with this property to check whether wake word is enabled.</p> <ul> <li> <p>Note: The Engine does not persist this setting across device reboots.</p> </li> </ul> </li> <li> <p>\"aace.alexa.timezone\" This property is used with <code>SetProperty</code> to change the current timezone setting of the device. The value must be a valid timezone accepted by AVS. Use <code>GetProperty</code>to get the Engine's current timezone setting.</p> </li> </ul>"},{"location":"explore/features/core/PropertyManager/#core","title":"Core","text":"<p>The <code>Core</code> module provides the following properties:</p> <ul> <li> <p>\"aace.core.version\" This property is used with <code>GetProperty</code> to return the Auto SDK version.</p> </li> <li> <p>\"aace.vehicle.operatingCountry\" This property is used with <code>SetProperty</code> to change the current operating country. The value must be a valid 2-letter ISO country code.</p> </li> <li> <p>\"aace.network.networkInterface\" This property is used with <code>SetProperty</code> to set the network interface for the network connection. The value must be an IP address or network interface name.</p> </li> <li> <p>\"aace.network.httpProxyHeaders\" This property is used with <code>SetProperty</code> to set the custom HTTP header to pass in the HTTP request sent to a proxy.      The headers should be <code>\\n</code> separated. For example,      <code>\"Proxy-Authorization: Bearer 1234\"</code> (should not be CRLF-terminated)</p> <p>Note: To apply the custom headers you are required to specify the <code>CURLOPT_PROXY</code> in the Engine configuration. The specified headers will be applied to all subsequent requests sent to a proxy.</p> </li> </ul>"},{"location":"explore/features/core/Wakeword/","title":"Wakeword Module","text":""},{"location":"explore/features/core/Wakeword/#overview","title":"Overview","text":"<p>The <code>Wakeword</code> module has interfaces to manage 3rd Party agent\u2019s wakeword detection. This module manages 3rd party agent's wakeword detection via amazonlite supported wakeword engine in auto sdk\" to indicate that it only manages the 3rd party agent's detection through its own Wakeword extension and not external. </p> <p>The WakewordManager interface provides messages to</p> <ul> <li>Enable or Disable 3rd Party wakeword</li> <li>Notify the application when their wakeword is detected</li> </ul>"},{"location":"explore/features/core/Wakeword/#configuring-the-wakeword-module","title":"Configuring the Wakeword Module","text":"<p>The following changes are added in config.json for the Wakeword module to supply the list of supported 3rd Party wakewords. This configuration is manadatory to specify when supporting 3rd Party wakewords. If this is not provided as a part of the config when using a Amazonlite WWE that supports 3rd Party Wakewords any 3rd Party wakeword detections can result in undesired behavior</p> <pre><code>\"aace.wakewordManager\": {\n    \"WakewordManager\": {\n        \"3PWakewords\": [\"SIRI\"]\n    }\n}\n</code></pre>"},{"location":"explore/features/custom-domain/","title":"Custom Domain Module","text":""},{"location":"explore/features/custom-domain/#overview","title":"Overview","text":"<p>The Alexa Auto SDK <code>Custom Domain</code> module creates a bi-directional communication channel between your device and your cloud custom skills, allowing you to build customized experience with your in-vehicle Alexa Custom Assistant. By using this module, you can instruct Auto SDK to send data (in Events and Contexts) from your device to your cloud custom skills that can consume the data, and also receive the data (in Directives) dispatched by the skills to the device.</p> <p><code>Custom Domain</code> provides an AASB message interface that you can integrate with to enable the bi-directional communication between your device and your custom skills in the cloud. Since Auto SDK is built on top of Alexa Voice Service (AVS) Device SDK which utilizes directives and events to achieve the communication with Alexa Cloud, this module enables your device to receive custom directives from your skills and send custom events, contexts to your skills that can process them.</p>"},{"location":"explore/features/custom-domain/#prerequisites","title":"Prerequisites","text":"<p>To use Custom Domain module, please contact your Solution Architect to onboard your device type, vendor ID, custom skill IDs, custom interface names, etc.</p>"},{"location":"explore/features/custom-domain/#auto-sdk-custom-domain-sequence-diagrams","title":"Auto SDK Custom Domain Sequence Diagrams","text":"<p>This diagram illustrates the sequence of receiving custom directives and sending custom events.</p> <p></p> <p>This diagram illustrates the sequence of providing custom states in the context when required. The event that requires context could be from the device, Auto SDK, or AVS itself and it could be custom or non-custom ones. For any AVS event, as long as it requires context, which is queried by the <code>ContextManager</code>, the Auto SDK Engine publishes <code>GetContext</code> message, and the registered custom states should be provided by replying the message.</p> <p></p>"},{"location":"explore/features/custom-domain/#required-engine-configuration","title":"Required Engine Configuration","text":"<p>The Custom Domain module requires proper Engine Configuration for your custom interfaces. Below is the expected configuration format.</p> <p>Sample JSON Object <pre><code>\"aace.customDomain\" : {\n    \"interfaces\": [\n        {\n            \"namespace\": \"{{String}}\",\n            \"version\": \"{{String}}\"\n            \"states\": [\"{{String}}\", \"{{String}}\", ...]\n        },\n        {\n            \"namespace\": \"{{String}}\",\n            \"version\": \"{{String}}\",\n            \"states\": [\"{{String}}\", \"{{String}}\", ...]\n        },\n        ...\n    ]\n}\n</code></pre> Object Parameters</p> Field Type Required Description aace.customDomain.interfaces list Yes The list of custom interfaces for the communication between your device and skills. aace.customDomain.interfaces[i].namespace string Yes The namespace of the custom interface. The string must follow the convention <code>Custom.&lt;vendorId&gt;.&lt;customInterfaceName&gt;</code>, where the <code>vendorId</code> must match your actual vendorId that should be onboarded and allow-listed, and the <code>customInterfaceName</code> is a string of your own choice based on the responsibility of the interface. The namespace must match with the one you specified in your Skill Manifest. aace.customDomain.interfaces[i].version string Yes The version of the custom interface in string. The version should follow the versioning convention <code>&lt;major&gt;.&lt;minor&gt;</code>. e.g. \"1.0\". aace.customDomain.interfaces[i].states list No Optional. The list of the custom state names for a custom interface. It must be provided if custom states are available for this interface. The custom state names must match with the ones you specified in your Skill Manifest."},{"location":"explore/features/custom-domain/#using-the-custom-domain-module-aasb-messages","title":"Using the Custom Domain Module AASB Messages","text":""},{"location":"explore/features/custom-domain/#receiving-and-handling-a-custom-directive","title":"Receiving and handling a custom directive","text":"<p>Custom directives carry the information from your custom skills to the device. When a new directive arrives, the Engine publishes <code>HandleDirective</code> message with directive metadata including namespace, name, payload, etc. Only directives with custom namespaces configured in the Engine Configuration will be received.</p>"},{"location":"explore/features/custom-domain/#reporting-a-directive-handling-result","title":"Reporting a directive handling result","text":"<p>After handling a directive, your application is responsible for reporting the directive handling result by publishing <code>ReportDirectiveHandlingResult</code> message with the necessary directive metadata.</p>"},{"location":"explore/features/custom-domain/#when-a-directive-is-cancelled","title":"When a directive is cancelled","text":"<p>It is possible that the arrived directive is cancelled by AVS due to associated directives (e.g. a Speak directive) is not handled properly or an error occurs. In this case, the Engine publishes <code>CancelDirective</code> message to inform your application that a directive is cancelled. Depending on the use case, your application might need to process the cancellation accordingly and inform the user that a previous directive is cancelled.</p>"},{"location":"explore/features/custom-domain/#sending-a-custom-event","title":"Sending a custom event","text":"<p>Custom events carry the information from your application to your skills. Your application can inform the Engine to send a custom event to the Alexa cloud by publishing <code>SendEvent</code> message with required event metadata. Only custom events with configured custom namespaces in the Engine Configuration will be sent to the Alexa cloud, and only events with custom namespaces registered and onboarded with the cloud services can be received by your skill. If the custom event should be sent with context, set <code>requiresContext</code> to true in the AASB message payload. Optionally, you can also include the custom context (if available) for the custom event's namespace in the <code>SendEvent</code> message, and it's recommended to do so to avoid the unnecessary <code>GetContext</code> messages from the Engine. If the custom event is in response to a custom directive, make sure the <code>correlationToken</code> for the event matches with the one the directive has. Your application can also send proactive events, which can trigger a skill session without user interaction. <code>correlationToken</code> is not required for proactive events.</p>"},{"location":"explore/features/custom-domain/#providing-custom-states-in-context","title":"Providing custom states in Context","text":"<p>Context communicates the state of the device client components to AVS. A context object reflects the state of client components immediately before its associated event is sent. Please refer to AVS documentation for more information on Context. The Engine publishes <code>GetContext</code> message to query the custom context with a specific configured custom namespace. Your device is expected to reply back the custom context quickly, and should provide the custom context in a String representation of a JSON object in <code>GetContextReply</code> message. Below is the expected JSON structure for the custom context, which needs to be serialized to a single String to be included in the <code>GetContext</code> message reply. The context states should match the ones specified in the Custom Domain Engine Configuration.</p> <p><pre><code>{\n    \"context\": [\n        {\n            \"name\": \"{{String}}\",\n            \"value\": {{Object}} | \"{{String}}\" | {{Long}},\n            \"timeOfSample\": \"{{String}}\",\n            \"uncertaintyInMilliseconds\": {{Long}}\n        },\n        {\n            \"name\": \"{{String}}\",\n            \"value\": {{Object}} | \"{{String}}\" | {{Long}},\n            \"timeOfSample\": \"{{String}}\",\n            \"uncertaintyInMilliseconds\": {{Long}}\n        },\n        ...\n    ]\n}\n</code></pre> Object Parameters</p> Field Type Required Description context list Yes List of custom states to be reported. context[i].name string Yes The name of the custom context property state. context[i].value string/object/number Yes The value of the context property state. context[i].timeOfSample string No The time at which the property value was recorded in ISO-8601 representation. If omitted, the default value is the current time recorded when AVS constructs the context. context[i].uncertaintyInMilliseconds integer No The number of milliseconds that have elapsed since the property value was last confirmed. If omitted, the default value is 0."},{"location":"explore/features/loopback-detector/","title":"Loopback Detector Module","text":""},{"location":"explore/features/loopback-detector/#overview","title":"Overview","text":"<p>The <code>Loopback Detector</code> module enables your Alexa Auto SDK client application to monitor wake word detection to cancel out self references.</p> <p>In some environments where acoustic echo cancellation capabilities are limited, the microphone may pick up the wake word from speakers, which will cause false wake word detection. For example, if the user says \"Alexa, what's your name?\", Alexa responds with \"My name is Alexa\", which may cause false wake word detection and interrupt the current speech output.</p> <p>The <code>Loopback Detector</code> module solves this issue by capturing speaker reference \"loopback\" audio and trying to detect the wake word at the same time.</p>"},{"location":"explore/features/loopback-detector/#configuring-the-loopback-detector-module","title":"Configuring the Loopback Detector Module","text":"<p>The <code>Loopback Detector</code> module can be optionally configured with the following configuration structure:</p> <pre><code>{\n\"aace.loopbackDetector\" : {\n\"wakewordEngine\" : \"&lt;WAKEWORD ENGINE NAME&gt;\"\n}\n}\n</code></pre>"},{"location":"explore/features/loopback-detector/#setting-up-the-loopback-detector-module","title":"Setting up the Loopback Detector Module","text":""},{"location":"explore/features/loopback-detector/#providing-audio","title":"Providing Audio","text":"<p>The <code>Loopback Detector</code> module requests audio through the <code>StartAudioInput</code> AASB message. The <code>StartAudioInput</code> message payload contains a field <code>audioType</code> set to <code>LOOPBACK</code>. The <code>StopAudioInput</code> AASB message is sent to request that audio input be stopped. The example below shows how to handle the <code>StartAudioInput</code> and <code>StopAudioInput</code> messages.</p> <pre><code>#include &lt;AASB/Message/Audio/AudioInput/StartAudioInputMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioInput/StopAudioInputMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\n// Loopback stream id\nstd::string m_streamId;\n\n// subscribe to the StartAudioInput message\nmessageBroker-&gt;subscribe([=](const std::string&amp; msg) {\n// parse the json message\nStartAudioInputMessage _msg = json::parse(msg);\nm_streamId = _msg.payload.streamId;\nauto audioType = _msg.payload.audioType;\nif (audioType == \"LOOPBACK\") {\n// open the stream for writing\nauto stream = messageBroker-&gt;openStream(\nm_streamId,\nMessageStream::Mode::WRITE);\nif (stream != nullptr) startAudioInput(m_streamId, stream)\n}\n}),\nStartAudioInputMessage::topic(),\nStartAudioInputMessage::action());\n\n// subscribe to the StopAudioInput message\nmessageBroker-&gt;subscribe([=](const std::string&amp; msg) {\n// parse the json message\nStopAudioInputMessage _msg = json::parse(msg);\nauto streamId = _msg.payload.streamId;\nif (streamId == m_streamId) {\nstopAudioInput(streamId);\nm_streamId = \"\";\n} }),\nStopAudioInputMessage::topic(),\nStopAudioInputMessage::action());    void startAudioInput(const std::string&amp; streamId, std::shared_ptr&lt;MessageStream&gt; stream) {\n// On another thread, write data to the stream until\n// you receive a StopAudioInput message with the same streamId\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\n} void stopAudioInput(const std::string&amp; streamId) {\n// Stop writing audio data to the stream\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\n}\n</code></pre> <p>This audio source should be the final mix of audio output (i.e. speaker reference/monitor).</p> <p>Note: If you are using the System Audio module, see the <code>System Audio</code> module documentation for details about how to specify <code>LOOPBACK</code> audio input provider.</p>"},{"location":"explore/features/loopback-detector/#building-with-the-loopback-detector-module","title":"Building with the Loopback Detector Module","text":"<p>To build the Alexa Auto SDK with the Loopback Detector module, simply include the module when running the Auto SDK builder:</p> <pre><code>$ builder/build.py -m loopback-detector\n</code></pre> <p>Note: Additionally include any other modules you want to use in the same command. </p>"},{"location":"explore/features/loopback-detector/#example-setup-in-ubuntu-linux","title":"Example Setup in Ubuntu Linux","text":"<p>Here is an example of how to provide loopback audio into the Alexa Auto SDK.</p> <p>You will need the following software running on a Linux system:</p> <ul> <li>PulseAudio</li> <li>GStreamer</li> <li>Advanced Linux Sound Architecture (ALSA) <code>snd_aloop</code> module</li> </ul> <p>If you are using the <code>System Audio</code> module, the Auto SDK (and all other applications on Linux) will use PulseAudio to output audio by default. PulseAudio mixes all audio then plays it through a hardware device. We need to capture this \"final mix result\" into the GStreamer pipeline and pass it through directly into the ALSA loopback device so the Auto SDK can capture this audio. To do this, follow these steps:</p> <ol> <li>Make sure the <code>snd_aloop</code> module is loaded into kernel by running <code>sudo modprobe snd_aloop</code>.</li> <li> <p>Use this command to launch the GStreamer pipeline:     <pre><code>gst-launch-1.0 -v autoaudiosrc ! audio/x-raw,format=S16LE,channels=1,rate=16000,layout=interleaved ! audioconvert ! audioresample ! alsasink device=hw:Loopback,0,0\n</code></pre></p> <p>Note: You need to keep this process throughout the testing.</p> </li> <li> <p>Open the PulseAudio control panel (<code>pavucontrol</code>), and go to the Recording panel.</p> </li> <li>You will see that the gst-launch-1.0 process is capturing the audio. Change the audio source to Monitor of Built-in Audio Analog Stereo.</li> <li>Set the SampleApp Record Stream to microphone device.</li> </ol> <p>At this point, all speaker outputs (through PulseAudio) will be eventually routed to the ALSA loopback device.</p> <p>If you are using the System Audio module, ensure the <code>LOOPBACK</code> type and <code>loopback</code> device are configured correctly.</p> <pre><code>\"aace.systemAudio\": {\n  \"AudioInputProvider\": {\n    \"devices\": {\n      \"default\": {\n        \"module\": \"GStreamer\"\n      },\n      \"loopback\": {\n        \"module\": \"GStreamer\",\n        \"card\": \"hw:Loopback,1,0\",\n        \"shared\": true\n      }\n    },\n    \"types\": {\n      \"LOOPBACK\": \"loopback\"\n    }\n  },\n  \"AudioOutputProvider\": {\n    \"devices\": {\n      \"default\": {\n        \"module\": \"GStreamer\"\n      }\n    }\n  }\n}\n</code></pre> <p>After this, the Auto SDK can capture audio loopback from the <code>hw:Loopback,1,0</code> device.</p> <p>The following diagram illustrates how the audio output data is routed to the Loopback Detector on Linux:</p> <p></p>"},{"location":"explore/features/messaging/","title":"Messaging Module","text":""},{"location":"explore/features/messaging/#overview","title":"Overview","text":"<p>The Alexa Auto SDK <code>Messaging</code> module enables your Alexa Auto SDK client application to use the Short Message Service (SMS) capabilities of Alexa, independent of the messaging device's connection mechanism. The SMS features of this module include reading messages, sending messages, and replying to messages as they are read.</p> <p>The user must connect their device and consent to allow Alexa to read and send SMS messages through the messaging device. The Messaging feature can use phone numbers directly or use phone contacts uploaded via the <code>Address Book</code> module.</p>"},{"location":"explore/features/messaging/#managing-messaging-sessions","title":"Managing Messaging Sessions","text":"<p>The application is responsible for managing the life cycle of the messaging session, including enhancing the end user experience by:</p> <ul> <li>Uploading unread SMS messages when the messaging device is connected, so they are ready for readout.</li> <li>Uploading new SMS messages when they are received on the messaging device.</li> <li>Updating the status of messages when notified to do so.</li> <li>Responding to messaging requests with appropriate successful or failure responses.</li> </ul> <p>Alexa will not notify the user when new SMS messages are available, your implementation is responsible for providing new message notifications.</p>"},{"location":"explore/features/messaging/#configuring-the-messaging-module","title":"Configuring the Messaging Module","text":"<p>The <code>Messaging</code> module does not require Engine configuration.</p>"},{"location":"explore/features/messaging/#using-the-messaging-module-aasb-messages","title":"Using the Messaging Module AASB Messages","text":""},{"location":"explore/features/messaging/#sending-messages","title":"Sending Messages","text":"<p>When Alexa sends a request to the Engine to deliver a message, the Engine publishes the <code>SendMessage</code> message including the text and URL for the audio from which the message was created. Publish either the <code>SendMessageSucceeded</code> message or <code>SendMessageFailed</code> message indicating either the success or failure of the request.</p> <p>Click to expand or collapse sequence diagram: Sending Messages </p> <p></p> <p></p>"},{"location":"explore/features/messaging/#reading-messages","title":"Reading Messages","text":"<p>When a user requests for Alexa to read messages, your application's <code>Messaging</code> module integration must upload a conversation report containing all unread messages. Once Alexa requests a conversation report upload, the Engine publishes the <code>UploadConversations</code> message. Publish the <code>ConversationsReport</code> message to notify the Engine to upload a conversation report to the cloud.</p> <p>Note: Messages are grouped by conversation, each given a unique identifier. Conversations also have unique identifiers and contain the list of recipient phone numbers included in the conversation, but not the phone number of the messaging device.</p> <p>After Alexa reads a message, it notifies the application that the message was read and should exclude the read message in subsequent conversation report uploads. The Engine publishes the <code>UpdateMessagesStatus</code> message to update the status of the SMS messages. Publish either the <code>UpdateMessagesStatusSucceeded</code> message or <code>UpdateMessageStatusFailed</code> message indicating the success of the message status update. After Alexa reads all messages, or if message readout is interrupted, Alexa requests the upload of a new conversation report. In this way, Alexa stays in sync with unread messages on the messaging device.</p> <p>Note: Unread messages are stored in the cloud for 12 hours before being deleted. By design Alexa will read a limited number of unread messages with a 'read messages' utterance. Therefore, it may be necessary to issue additional read messages requests to head all messages.</p> <p>Click to expand or collapse sequence diagram: Reading Messages and Replying </p> <p></p> <p></p>"},{"location":"explore/features/messaging/#replying-to-message","title":"Replying to Message","text":"<p>The user can request to reply to a message after Alexa reads the message or as it is being read. Replying is always done within the context of the currently read message.</p> <p>Click to expand or collapse sequence diagram: Replying to Message </p> <p></p> <p></p>"},{"location":"explore/features/messaging/#updating-messaging-endpoint-state","title":"Updating Messaging Endpoint State","text":"<p>When connection to a calling device is established or broken and/or the user grants or denies permissions to read and send messages, publish the <code>UpdateMessagingEndpointState</code> message to update Alexa with the state of the messaging device.</p> <p>Click to expand or collapse sequence diagram: Connecting/Disconnecting Calling Device </p> <p></p> <p>Click to expand or collapse sequence diagram: Granting/Denying Permissions to Read and Send Messages </p> <p></p> <p></p>"},{"location":"explore/features/messaging/#integrating-the-messaging-module-into-your-application","title":"Integrating the Messaging Module Into Your Application","text":""},{"location":"explore/features/messaging/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to subscribe to and publish \"Messaging\" AASB messages.</p> <p>Click to expand or collapse C++ sample code</p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/Messaging/Messaging/ConnectionState.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/ErrorCode.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/PermissionState.h&gt;\n\n#include &lt;AASB/Message/Messaging/Messaging/ConversationsReportMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/SendMessageMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/SendMessageFailedMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/SendMessageSucceededMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/UpdateMessagesStatusMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/UpdateMessagesStatusFailedMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/UpdateMessagesStatusSucceededMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/UpdateMessagingEndpointStateMessage.h&gt;\n#include &lt;AASB/Message/Messaging/Messaging/UploadConversationsMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyMessagingHandler {\n\n// Subscribe to messages from the Engine\nvoid MyMessagingHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleSendMessageMessage(message); },\nSendMessageMessage::topic(),\nSendMessageMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleUpdateMessagesStatusMessage(message); },\nUpdateMessagesStatusMessage::topic(),\nUpdateMessagesStatusMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleUploadConversationsMessage(message); },\nUploadConversationsMessage::topic(),\nUploadConversationsMessage::action());\n}\n\n// Handle the SendMessage message from the Engine\nvoid MyMessagingHandler::handleSendMessageMessage(const std::string&amp; message) {\nSendMessageMessage msg = json::parse(message);\nsendMessage(msg.payload.token, msg.payload.message, msg.payload.recipients);\n}\n\n// Handle the UpdateMessagesStatus message from the Engine\nvoid MyMessagingHandler::handleUpdateMessagesStatusMessage(const std::string&amp; message) {\nUpdateMessagesStatusMessage msg = json::parse(message);\nupdateMessagesStatus(msg.payload.token, msg.payload.conversationId, msg.payload.status);\n}\n\n// Handle the UploadConversations message from the Engine\nvoid MyMessagingHandler::handleUploadConversationsMessage(const std::string&amp; message) {\nUploadConversationsMessage msg = json::parse(message);\nuploadConversations(msg.payload.token);\n}\n\n// To upload a conversations report to Alexa, publish a ConversationsReport message to the Engine\nvoid MyMessagingHandler::conversationsReport(\nconst std::string&amp; token,\nconst std::string&amp; conversations) {\nConversationsReportMessage msg;\nmsg.payload.token = token;\nmsg.payload.conversations = conversations;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the message fails to send, publish a SendMessageFailed message to the Engine\nvoid MyMessagingHandler::sendMessageFailed(\nconst std::string&amp; token,\nErrorCode code,\nconst std::string&amp; message) {\nSendMessageFailedMessage msg;\nmsg.payload.token = token;\nmsg.payload.code = code;\nmsg.payload.message = message;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the message is successfully sent, publish a SendMessageSucceeded message to the Engine\nvoid MyMessagingHandler::sendMessageSucceeded(const std::string&amp; token) {\nSendMessageSucceededMessage msg;\nmsg.payload.token = token;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the message status update fails, publish a UpdateMessagesStatusFailed message to the Engine\nvoid MyMessagingHandler::updateMessagesStatusFailed(\nconst std::string&amp; token,\nErrorCode code,\nconst std::string&amp; message) {\nUpdateMessagesStatusFailedMessage msg;\nmsg.payload.token = token;\nmsg.payload.code = code;\nmsg.payload.message = message;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the message status update succeeds, publish an UpdateMessagesStatusSucceeded message to the Engine\nvoid MyMessagingHandler::updateMessagesStatusSucceeded(const std::string&amp; token) {\nUpdateMessagesStatusSucceededMessage msg;\nmsg.payload.token = token;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// To update the messaging endpoint state, publish an UpdateMessagingEndpointState message to the Engine\nvoid MyMessagingHandler::updateMessagingEndpointState(\nConnectionState connectionState,\nPermissionState sendPermission,\nPermissionState readPermission) {\nUpdateMessagingEndpointStateMessage msg;\nmsg.payload.connectionState = connectionState;\nmsg.payload.sendPermission = sendPermission;\nmsg.payload.readPermission = readPermission;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\nvoid MyMessagingHandler::sendMessage(\nconst std::string&amp; token,\nconst std::string&amp; message,\nconst std::string&amp; recipients) {\n// Parse list of recipients to extract the phone number(s)\n// Send message using the connected messaging device\n// Send response of the result using the received token\n\n// If message was sent successfully then call\nsendMessageSucceeded(token);\n// Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message\nsendMessageFailed(token, ErrorCode::GENERIC_FAILURE, \"Unable to send message\");\n\n}\n\nvoid MyMessagingHandler::updateMessagesStatus(\nconst std::string&amp; token,\nconst std::string&amp; conversationId,\nconst std::string&amp; status) {\n// Remove unread messages specified in 'status' from the conversation that matches the 'conversationId'\n// Send response of the result using the received token\n\n// If messages status was updated successfully then call\nupdateMessagesStatusSucceeded(token);\n// Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message\nupdateMessagesStatusFailed(token, ErrorCode::GENERIC_FAILURE, \"Unable to update message status\");\n}\n\n// Alexa is requesting that a conversation report is uploaded so it can sync up the\n// status of messages on the cloud\nvoid MyMessagingHandler::uploadConversations(const std::string&amp; token) {\nconversationsReport(token, storedConversations);\n}\n\n};\n</code></pre> <p></p>"},{"location":"explore/features/mobile-bridge/","title":"Mobile Bridge","text":""},{"location":"explore/features/mobile-bridge/#overview","title":"Overview","text":"<p>Alexa Auto Mobile Bridge (AAMB) aims to help vehicle drivers use Alexa in the car via their phone's data plan. After provisioning the AAMB feature, the head unit is able to use user's phone as a proxy to forward all network requests made by Alexa or other allow-listed apps.</p> <p>The Mobile Bridge module provides platform-agnostic implementation of AAMB in Auto SDK and exposes platform interfaces for the app based on Auto SDK to provide platform-specific implementations.</p>"},{"location":"explore/features/mobile-bridge/#prerequisites","title":"Prerequisites","text":"<ul> <li>C++ toolchain supporting C++14 standard</li> <li>libtins 4.4 and libevent 2.1.12 as Conan dependency</li> </ul>"},{"location":"explore/features/mobile-bridge/#implementation","title":"Implementation","text":"<p>The Mobile Bridge modules provides the following two core components:</p> <ul> <li>Session Manager: a C++ implementation to parse IP packets and generate the corresponding proxy requests to the Transport Manager.</li> <li>Transport Manager: a C++ implementation to serve as a local proxy and forward the network traffic to the active transport.</li> </ul>"},{"location":"explore/features/mobile-bridge/#transport-manager","title":"Transport Manager","text":"<p>Transport Manager listens on a few local TCP/UDP ports to provide a local TCP/UDP proxy.</p>"},{"location":"explore/features/mobile-bridge/#session-manager","title":"Session Manager","text":"<p>Session Manager requires the platform to provide a file descriptor for TUN interface while starting the Mobile Bridge feature. On Android, obtain the file descriptor by creating a VpnService.</p> <p>Currently Session Manager ignores IP v6 packets and only IP v4 is supported.</p>"},{"location":"explore/features/mobile-bridge/#configuring-the-mobile-bridge-module","title":"Configuring the Mobile Bridge Module","text":"<p>The Mobile Bridge module allows customization of the following configuration:</p> <ul> <li>Transport Manager<ul> <li>TCP proxy port number</li> <li>UDP proxy port number</li> </ul> </li> </ul> <p>The following JSON object illustrates the list of supported configuration settings and their default values:</p> <pre><code>{\n\"aace.mobileBridge\": {\n\"tcp-proxy-port\": 9876,\n\"udp-proxy-port\": 9877\n}\n}\n</code></pre> <p>See Configure the Engine for onfiguring Auto SDK Engine with the preceding JSON configuration.</p>"},{"location":"explore/features/mobile-bridge/#platform-implementation","title":"Platform Implementation","text":"<p>AAMB expects the platform to provide the following implementations:</p> <ul> <li>Get the list of available transports</li> <li>Connect/Disconnect a transport</li> <li>Get notified about a device has complete hand-shaking and authorize it for Internet connectivity</li> </ul> <p>See the following sequence diagram for how mobile bridge engine interacts with platform implementation:</p> <p></p> <p>App can provide the platform implementation by subscribing message handlers or sending messages with MessageBroker API.</p>"},{"location":"explore/features/navigation/","title":"Navigation Module","text":""},{"location":"explore/features/navigation/#overview","title":"Overview","text":"<p>The <code>Navigation</code> module enables your Alexa Auto SDK client application to use the navigation capabilities of Alexa and provides support for Alexa to interface with the onboard navigation system.</p> <p>Your integration is responsible for handling navigation actions when notified to do so by the Engine. How these requests are handled is based on your navigation provider.</p>"},{"location":"explore/features/navigation/#configuring-the-navigation-module","title":"Configuring the Navigation Module","text":"<p>To inform Alexa which navigation provider is used on the head unit, configure the <code>Navigation</code> module. Sometimes Alexa needs to query a cloud navigation provider API to fulfill a user request. Knowing which provider is used on the device allows for better customer experience because Alexa's results can more closely match what the user sees on the screen in the navigation app.</p> <p>To configure the <code>Navigation</code> module, use the \"aace.navigation\" JSON object specified below in your Engine configuration:</p> <pre><code>{\n    \"aace.navigation\": {\n        \"providerName\": \"{{STRING}}\"\n    }\n}\n</code></pre> Property Type Required Description Example aace.navigation.providerName string No The navigation service provider name.  Accepted values: <ul> <li> <code>\"HERE\"</code> (default) </li> <li> <code>\"TOMTOM\"</code></li> <li> <code>\"TELENAV\"</code> </li> </ul> <code>\"HERE\"</code> <p>Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an <code>EngineConfiguration</code> from that file, or you can use the provided configuration factory function <code>aace::navigation::config::NavigationConfiguration::createNavigationConfig</code> to programmatically construct the <code>EngineConfiguration</code> in the proper format.</p> <p>Click to expand or collapse NavigationConfiguration C++ sample code</p> <pre><code>#include &lt;AACE/Navigation/NavigationConfiguration.h&gt;\n\nstd::vector&lt;std::shared_ptr&lt;aace::core::config::EngineConfiguration&gt;&gt; configurations;\n\nauto navigationConfig = aace::navigation::config::NavigationConfiguration::createNavigationConfig(\"HERE\");\nconfigurations.push_back(navigationConfig);\n\n// ... create other EngineConfiguration objects and add them to configurations...\n\nm_engine-&gt;configure(configurations);\n</code></pre> <p></p>"},{"location":"explore/features/navigation/#using-the-navigation-aasb-messages","title":"Using the Navigation AASB Messages","text":""},{"location":"explore/features/navigation/#providing-the-current-navigation-state","title":"Providing the Current Navigation State","text":"<p>The navigation state context informs Alexa whether the device is navigating and provides Alexa with the user's routing information or the destination set by the user. Such information is necessary for Alexa to respond to route-based utterances, allowing the user to use the following features:</p> <ul> <li>Adding or removing waypoints</li> <li>Obtaining Estimated Time of Arrival (ETA)</li> <li>Obtaining Distance To Arrival (DTA)</li> </ul> <p>When the user requests navigation information based on the current route, the Engine publishes the <code>GetNavigationState</code> message. The implementation should respond with the <code>GetNavigationStateReply</code> message containing the navigation state passed as a JSON string payload.</p> <p>Note: Returning the navigation state must be quick. If querying the navigation provider for state information takes significant time, Amazon recommends that the application periodically query the provider to update the state in a cache. Then the application can obtain the information each time the Engine requests the navigation state.</p> <p>The following table explains the properties in the JSON.</p> Property Type Required Description state String Yes The navigation device state. Accepted values: <ul><li><code>\"NAVIGATING\"</code>: Navigation engine is navigating to a predefined destination set. </li> <li><code>\"NOT_NAVIGATING\"</code>: Navigation is not in progress.</li></ul> shapes Array of double arrays Yes The array contains an ordered list of coordinates depicting the route from the source to the destination. The coordinate is a latitude-longitude pair (in that order) specified as an array of doubles. The array can be empty. The maximum number of coordinates is 100. Special considerations: <ul><li>The set of coordinates might not represent the complete route.</li><li>Shapes are provider specific. The shape of a route can correspond to one of these versions: a complete route, a route for a viewport, or a route defined for a certain distance.</li><li>One mile spacing between each coordinate in the shapes array is recommended.</li><li>The coordinates in the array are ordered in the same direction as the user is driving.</li></ul> waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. Expand the section below for more information.  Note: Can be empty except when <code>state</code> is <code>\"NAVIGATING\"</code>. <p>Click to expand or collapse the properties of <code>waypoints</code> object</p> <p></p> Property Type Required Description type String Yes Type of the location on the route. Accepted values: <ul><li><code>SOURCE</code>: The location from which the user starts driving.</li><li><code>DESTINATION</code>: Final location to which the user wants to navigate to.</li><li><code>INTERIM</code>: Intermediate stop where the user wants to navigate to before reaching the destination. estimatedTimeOfArrival Object Yes (Applicable only if <code>type</code> is <code>\"DESTINATION\"</code> or <code>\"INTERIM\"</code>.) Time of arrival at the waypoint, specified in the ISO-8601 time format. estimatedTimeOfArrival.ideal String No Expected arrival time without considering traffic, diversions, etc. estimatedTimeOfArrival.predicted String Yes Expected arrival time, after considering traffic conditions. If the ideal ETA and predicted ETA match, only the predicted ETA will be populated. address Object No Address of the waypoint specified in multiple string fields, such as <code>addressLine1</code>, <code>city</code>, etc. Note: <code>countryCode</code> is a 3-letter country code in ISO 3166-1 alpha-3 format. name String No Name of the waypoint (e.g., \"work\" or \"Starbucks\"). coordinate Array Yes An array consisting of the waypoint's latitude and longitude (in that order). The data type of latitude and longitude is double. pointOfInterest Object No Information about the waypoint if the waypoint is also a point of interest (POI). Expand the section below for more information. <p>Click to expand or collapse the properties of <code>pointOfInterest</code> object</p> <p></p> Property Type Required Description id String No (recommended if available) ID for the POI known to Alexa. If <code>id</code> is provided, you can omit other properties of <code>pointOfInterest</code>. If the waypoint is added by the user via the navigation app, omit <code>id</code> because Alexa cannot recognize any ID assigned by the app. You can specify the ID if the waypoint is added by Alexa (e.g., by the utterance \"Alexa, navigate to Whole Foods along the way\"). It is specified in the <code>StartNavigation</code> message payload received from Alexa. hoursOfOperation Array No Hours of operation for the POI. hoursOfOperation.dayOfWeek String Y Day of week for this day. Accepted values: <code>\"MONDAY\"</code>, <code>\"TUESDAY\"</code>, <code>\"WEDNESDAY\"</code>, <code>\"THURSDAY\"</code>, <code>\"FRIDAY\"</code>, <code>\"SATURDAY\"</code>, <code>\"SUNDAY\"</code>. hoursOfOperation.hours Array Yes List of times when the POI is open or closed for the day, specified in ISO 8601 format with the timezone offset (time difference from UTC). Properties in the array are:<ul><li><code>open</code>: Time at which the POI is open.</li><li><code>close</code>: Time at which the POI is closed.</li></ul>Timezone considerations:<ul><li>If the user and the POI are in different timezones, hours are converted to the timezone of the POI.</li><li>If timezone offset is omitted, the time is assumed to be a UTC time and then converted to the POI's timezone.</li></ul>Note: Hours for the next 7 days are provided by the data provider. hoursOfOperation.type String Yes Status of the current operation. Accepted values: <code>\"OPEN_DURING_HOURS\"</code>, <code>\"OPEN_24_HOURS\"</code>, <code>\"CLOSED\"</code>, <code>\"UNKNOWN\"</code>, <code>\"HOLIDAY\"</code>. phoneNumber String No Phone number of the POI in E.164 format. <p></p>"},{"location":"explore/features/navigation/#examples-of-navigation-state-payload","title":"Examples of Navigation State Payload","text":"<p>Click to expand or collapse example Navigation State payload when navigation is in progress</p> <p></p> <pre><code>{\n\"state\": \"NAVIGATING\",\n\"waypoints\": [\n{\n\"type\": \"SOURCE\",\n\"address\": {\n\"addressLine1\": \"2795 Augustine Drive\",\n\"addressLine2\": \"\",\n\"addressLine3\": \"\",\n\"city\": \"Santa Clara\",\n\"districtOrCounty\": \"\",\n\"stateOrRegion\": \"CA\",\n\"countryCode\": \"USA\",\n\"postalCode\": \"95054\"\n},\n\"name\": \"work\",\n\"coordinate\": [\n37.3809462,\n-121.9794846\n]\n},\n{\n\"type\": \"INTERIM\",\n\"estimatedTimeOfArrival\": {\n\"ideal\": \"2019-12-09T17:00:00-08:00\",\n\"predicted\": \"2019-12-09T17:10:00-08:00\"\n},\n\"address\": {\n\"addressLine1\": \"750 Castro Street\",\n\"addressLine2\": \"\",\n\"addressLine3\": \"\",\n\"city\": \"Mountain View\",\n\"districtOrCounty\": \"\",\n\"stateOrRegion\": \"CA\",\n\"countryCode\": \"USA\",\n\"postalCode\": \"94041\"\n},\n\"name\": \"Starbucks\",\n\"coordinate\": [\n37.3809461,\n-122.0830221\n],\n\"pointOfInterest\": {\n\"id\": \"AlexaLocalSearch:eyJpZCI6InllbHA6OnRGV01ySS1VWERGa09FcnZ6eXJ0clEiLCJjb3ZlcnMiOnsiUExBQ0VTX1JFUE8iOiJ5ZWxwOjp0RldNckktVVhERmtPRXJ2enlydHJRIn0sInF1ZXJ5SWQiOiItNjYxMzI1NTYxIiwiZGRiVGFibGVOYW1lIjoiZXMtbHNzLTIwMjEwNjE2Iiwid2VibGFiQWxsb2NhdGlvbnMiOnsiQUxTU19XRUJMQUJfT05CT0FSRF9URVNUSU5HXzI4MDI4NiI6IlQxIiwiQUxFWEFfTE9DQUxTRUFSQ0hfUExBQ0VUWVBFX0NMQVNTSUZJRVJfMzA4MTY5IjoiQyIsIkFMRVhBX0xPQ0FMX1NFQVJDSF9MMlJfRU5USVRZX1NIQURPV18yOTA5MDUiOiJDIiwiQUxFWEFfTE9DQUxfU0VBUkNIX1RSSUdHRVJfQU1CSUdVT1VTX1FVRVJZX0lERU5USUZJQ0FUSU9OXzMyNjMxNSI6IlQxIn19\",\n\"phoneNumber\": \"+14084968523\"\n}\n},\n{\n\"type\": \"DESTINATION\",\n\"estimatedTimeOfArrival\": {\n\"ideal\": \"2019-12-09T17:30:00-08:00\",\n\"predicted\": \"2019-12-09T17:40:00-08:00\"\n},\n\"address\": {\n\"addressLine1\": \"4800 El Camino Real\",\n\"addressLine2\": \"\",\n\"addressLine3\": \"\",\n\"city\": \"Los Altos\",\n\"districtOrCounty\": \"\",\n\"stateOrRegion\": \"CA\",\n\"countryCode\": \"\",\n\"postalCode\": \"94022\"\n},\n\"name\": \"Whole Foods Market\",\n\"coordinate\": [\n37.3991897,\n-122.1106268\n],\n\"pointOfInterest\": {\n\"hoursOfOperation\": [\n{\n\"dayOfWeek\": \"MONDAY\",\n\"hours\": [\n{\n\"open\": \"08:00:00-08:00\",\n\"close\": \"22:00:00-08:00\"\n}\n],\n\"type\": \"OPEN_DURING_HOURS\"\n}\n]\n}\n}\n],\n\"shapes\": [\n[\n37.380946,\n-121.9794846\n],\n[\n37.380545,\n-122.073252\n],\n...\n]\n}\n</code></pre> <p>Click to expand or collapse example Navigation State payload when navigation no navigation is in progress</p> <p></p> <pre><code>{\n\"state\": \"NOT_NAVIGATING\",\n\"waypoints\":[],\n\"shapes\":[]\n}\n</code></pre> <p></p>"},{"location":"explore/features/navigation/#starting-navigation","title":"Starting Navigation","text":"<p>To start navigation, the Engine publishes the <code>StartNavigation</code> message passing a JSON string payload containing the destination information.</p> <p>The following table explains the properties in the JSON.</p> Property Type Required Description transportationMode String No The mode of transportation.  Accepted Values: <ul> <li><code>\"BIKING\"</code></li> <li><code>\"DRIVING\"</code></li> <li><code>\"TRANSIT\"</code></li> <li><code>\"WALKING\"</code></li> </ul> waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. The properties use the same schema used for state reporting. See the Providing the Current Navigation State section. <p>Click to expand or collapse the <code>StartNavigation</code> message payload schema</p> <p></p> <pre><code>{\n    \"transportationMode\": \"DRIVING\",\n    \"waypoints\":[\n       {\n          \"type\":\"{{STRING}}\",\n          \"estimatedTimeOfArrival\":{\n             \"ideal\":\"{{STRING}}\",\n             \"predicted\":\"{{STRING}}\"\n          },\n          \"address\": {\n               \"addressLine1\": \"{{STRING}}\",\n               \"addressLine2\": \"{{STRING}}\",\n               \"addressLine3\": \"{{STRING}}\",\n               \"city\": \"{{STRING}}\",\n               \"districtOrCounty\": \"{{STRING}}\",\n               \"stateOrRegion\": \"{{STRING}}\",\n               \"countryCode\": \"{{STRING}}\",\n               \"postalCode\": \"{{STRING}}\"\n          },\n          \"coordinate\":[\n             {{LATITUDE_DOUBLE}},\n             {{LONGITUDE_DOUBLE}}\n          ],\n          \"name\":\"{{STRING}}\"\n       },\n       {\n          \"type\":\"{{STRING}}\",\n          \"estimatedTimeOfArrival\":{\n             \"ideal\":\"{{STRING}}\",\n             \"predicted\":\"{{STRING}}\"\n          },\n          \"address\":\"{{STRING}}\",\n          \"coordinate\":[\n             {{LATITUDE_DOUBLE}},\n             {{LONGITUDE_DOUBLE}}\n          ],\n          \"name\":\"{{STRING}}\",\n          \"pointOfInterest\":{\n             \"id\":\"{{STRING}}\",\n             \"hoursOfOperation\":[\n                {\n                   \"dayOfWeek\":\"{{STRING}}\",\n                   \"hours\":[\n                      {\n                         \"open\":\"{{STRING}}\",\n                         \"close\":\"{{STRING}}\"\n                      }\n                   ],\n                   \"type\":\"{{STRING}}\"\n                }\n             ],\n             \"phoneNumber\":\"{{STRING}}\"\n        }\n      }\n    ]\n  }\n}\n</code></pre> <p></p> <p>Note: The waypoints in the route are determined by Alexa either through a proximity search or by resolving the user's uploaded navigation favorite name to its location. Your implementation should calculate the route from the <code>SOURCE</code> waypoint to the <code>DESTINATION</code> waypoint, with stops along the way at <code>INTERIM</code> waypoints in the order in which they appear in the payload. If there are multiple routes, your implementation should either pick the fastest route if no user interaction is possible, or let the user choose the route. After the route is chosen, your implementation should start navigation.</p> <p>If navigation starts successfully, your implementation should publish the <code>NavigationEvent</code> message with a <code>NAVIGATION_STARTED</code> event. Otherwise, it should publish the <code>NavigationError</code> message with the  <code>NAVIGATION_START_FAILED</code> type, and <code>INTERNAL_SERVICE_ERROR</code> or <code>ROUTE_NOT_FOUND</code> code.</p> <p>Click to expand or collapse sequence diagram: Starting Navigation </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#stopping-navigation","title":"Stopping Navigation","text":"<p>To stop navigation, the Engine publishes the <code>CancelNavigation</code> message. Consequently, when the Engine publishes the next <code>GetNavigationState</code> message the state should be <code>NOT_NAVIGATING</code>.</p> <p>Click to expand or collapse sequence diagram: Stopping Navigation </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#adding-a-waypoint","title":"Adding a Waypoint","text":"<p>If the user wants to add a waypoint, the Engine publishes the <code>StartNavigation</code> message.</p> <p>If navigation is in progress or route is present, the route to the final destination is changed by including the additional waypoint. Your implementation should calculate or re-calculate the route with the information of the waypoint.</p> <p>If the waypoint is added successfully, your implementation should publish the <code>NavigationEvent</code> message with a <code>NAVIGATION_STARTED</code> event. Otherwise, it should publish the <code>NavigationError</code> message with the  <code>NAVIGATION_START_FAILED</code> type, and <code>INTERNAL_SERVICE_ERROR</code> or  <code>ROUTE_NOT_FOUND</code> code.</p> <p>Click to expand or collapse sequence diagram: Adding a Waypoint </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#canceling-a-waypoint","title":"Canceling a Waypoint","text":"<p>If the user wants to cancel a waypoint, the Engine publishes the <code>StartNavigation</code> message after receiving the directive from Alexa with the updated waypoints. Your implementation should start navigation using the updated waypoints.</p> <p>If navigation is started successfully, your implementation should publish the <code>NavigationEvent</code> message with a <code>NAVIGATION_STARTED</code> event. Otherwise, it should publish the <code>NavigationError</code> message with the  <code>NAVIGATION_START_FAILED</code> type, and <code>INTERNAL_SERVICE_ERROR</code> or  <code>ROUTE_NOT_FOUND</code> code.</p> <p>Click to expand or collapse sequence diagram: Canceling a Waypoint </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#showing-previous-waypoints","title":"Showing Previous Waypoints","text":"<p>If the user wants to display previous waypoints, the Engine publishes the <code>ShowPreviousWaypoints</code> message. Each waypoint displayed includes at least the address.</p> <p>If the device can successfully display the previous waypoints, your implementation should publish the <code>NavigationEvent</code> message with a  <code>PREVIOUS_WAYPOINTS_SHOWN</code> event. Otherwise, it should publish the <code>NavigationError</code> message with the <code>SHOW_PREVIOUS_WAYPOINTS_FAILED</code> type, and <code>INTERNAL_SERVICE_ERROR</code> or <code>NO_PREVIOUS_WAYPOINTS</code> code.</p> <p>Note: It is the responsibility of the navigation provider to store and provide the previous destination list to the user.</p> <p>Click to expand or collapse sequence diagram: Showing Previous Waypoints </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#navigating-to-a-previous-waypoint","title":"Navigating to a Previous Waypoint","text":"<p>If the user wants to  navigate to a previous waypoint, the Engine publishes the <code>NavigateToPreviousWaypoint</code> message.</p> <p>The navigation app retrieves the most recently used destination, calculates a route from the current location, selects the fastest route or a route preferred by the user, and starts navigation.</p> <p>If the device can successfully display the previous waypoints, your implementation should publish the <code>NavigationEvent</code> message with a <code>PREVIOUS_NAVIGATION_STARTED</code> event. Otherwise, it should publish the <code>NavigationError</code> message with the <code>PREVIOUS_NAVIGATION_START_FAILED</code> type, and <code>INTERNAL_SERVICE_ERROR</code> or <code>NO_PREVIOUS_WAYPOINTS</code> code.</p> <p>Click to expand or collapse sequence diagram: Navigating to a Previous Waypoint </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#getting-turn-and-lane-guidance-information","title":"Getting Turn and Lane Guidance Information","text":"<p>If the user wants to get turn and lane guidance, the Engine publishes the <code>AnnounceManeuver</code> message, passing a JSON string payload containing the manueuver information.</p> <p>The following table explains the properties in the JSON.</p> Property Type Required Description type String Yes Specifies the type of information requested. Accepted values: <ul><li><code>\"TURN\"</code>:  The user asks about a turn. (e.g., \"What's my next turn?\")</li><li><code>\"EXIT\"</code>: The user asks about a freeway exit. (e.g., \"What's my next exit?\")</li><li><code>\"ENTER\"</code>: The user asks about how to get onto a street. (e.g., \"Which lane should I be to get onto the US-101?\")</li><li><code>\"MERGE\"</code>: The user asks about the merge onto a street. (e.g., \"Alexa, which lane do i need to merge onto the highway?\")</li><li><code>\"LANE\"</code>: The user asks for lane guidance. (e.g., \"Alexa, which lane to take?\")</li></ul> targetLocation Object No Describes the location for which maneuver information is requested. If the target location is a POI, user place, or street address, Alexa provides at least one field in this object. If the utterance does not include a location (e.g., \"Alexa, what's my next turn?\"), <code>targetLocation</code> is omitted. targetLocation.name String No Specifies the name of the location (e.g., \"HOME\" or \"WORK\") for which the user requests the maneuver instruction. targetLocation.address Object No Specifies the address for which the user requests the maneuver instruction. The object contains multiple string fields, which together form the complete address. targetLocation.coordinate Array No The array value specifies the latitude and longitude of the target location. Data type for the values in the array is double. <p>Click to expand or collapse the <code>AnnounceManeuver</code> message schema</p> <p></p> <pre><code>{\n  \"type\": \"{{STRING}}\",\n  \"targetLocation\" : {\n        \"name\": \"{{STRING}}\",\n        \"address\": {\n            \"addressLine1\": \"{{STRING}}\",\n            \"addressLine2\": \"{{STRING}}\",\n            \"addressLine3\": \"{{STRING}}\",\n            \"city\": \"{{STRING}}\",\n            \"districtOrCounty\": \"{{STRING}}\",\n            \"stateOrRegion\": \"{{STRING}}\",\n            \"countryCode\": \"{{STRING}}\",\n            \"postalCode\": \"{{STRING}}\"\n        },\n        \"coordinate\": [\n            {{LATITUDE_DOUBLE}},\n            {{LONGITUDE_DOUBLE}}\n        ]\n  }\n}\n</code></pre> <p></p> <p>Your implementation should provide the navigation instruction as follows:</p> <ul> <li>If <code>targetLocation</code> is omitted, announce the next maneuver along the route.</li> <li>If <code>targetLocation</code> is specified and the location is along the route, announce the maneuver about the location. If <code>targetLocation</code> is specified but the location is not along the route, calculate the route to the location, announce maneuver from the user's current location to the target location, and inform the user the target location is NOT along the current route.</li> </ul> <p>If the device can provide the maneuver instruction successfully, your implementation should publish the <code>NavigationEvent</code> message with one of the following events:</p> <p>events: <code>TURN_GUIDANCE_ANNOUNCED</code>, <code>EXIT_GUIDANCE_ANNOUNCED</code>, <code>ENTER_GUIDANCE_ANNOUNCED</code>, <code>MERGE_GUIDANCE_ANNOUNCED</code>, <code>LANE_GUIDANCE_ANNOUNCED</code></p> <p>Otherwise, your implementation should publish the <code>NavigationError</code> message with a type and code from the following:</p> <p>types: <code>TURN_GUIDANCE_FAILED</code>, <code>EXIT_GUIDANCE_FAILED</code>, <code>ENTER_GUIDANCE_FAILED</code>, <code>MERGE_GUIDANCE_FAILED</code>, <code>LANE_GUIDANCE_FAILED</code></p> <p>codes: <code>INTERNAL_SERVICE_ERROR</code>, <code>ROUTE_NOT_FOUND</code>, <code>NOT_SUPPORTED</code>, <code>NOT_NAVIGATING</code></p> <p>Click to expand or collapse sequence diagram: Getting Turn and Lane Guidance Information </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#getting-road-regulation-information","title":"Getting Road Regulation Information","text":"<p>If the user wants to get road regulation information, the Engine publishes the <code>AnnounceRoadRegulation</code> message, which passes a payload with the following schema:</p> <pre><code>{\n  \"type\": \"{{STRING}}\"\n}\n</code></pre> Property Type Required Description type String Yes Type of road regulation requested.  Accepted values: <ul> <li><code>\"SPEED_LIMIT\"</code> specifies the speed limit at the current position (e.g., when the user asks, \"Alexa, what is the speed limit?\").</li> <li><code>\"CARPOOL_RULES\"</code> specifies the carpool regulations on the current highway (e.g., when the user asks, \"Alexa, is carpool free now?\").</li> </ul> <p>If the device can provide the road regulation information successfully, your implementation should publish the <code>NavigationEvent</code> message with a <code>SPEED_LIMIT_REGULATION_ANNOUNCED</code> or <code>CARPOOL_RULES_REGULATION_ANNOUNCED</code> event. Otherwise, it should publish the <code>NavigationError</code> message with a type and code from the following:</p> <p>types: <code>SPEED_LIMIT_REGULATION_FAILED</code>, <code>CARPOOL_RULES_REGULATION_FAILED</code></p> <p>codes: <code>INTERNAL_SERVICE_ERROR</code>, <code>ROUTE_NOT_FOUND</code>, <code>NOT_SUPPORTED</code>, <code>NOT_NAVIGATING</code></p> <p>Click to expand or collapse sequence diagram: Getting Road Regulation Information </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#controlling-the-display","title":"Controlling the Display","text":"<p>If the user wants to control the map display on the screen, the Engine publishes the <code>ControlDisplay</code> message.</p> <p>If the device can adjust the display successfully, your implementation should publish the <code>NavigationEvent</code> message with one of the following event:</p> <p>events: <code>ROUTE_OVERVIEW_SHOWN</code>, <code>DIRECTIONS_LIST_SHOWN</code>, <code>ZOOMED_IN</code>, <code>ZOOMED_OUT</code>, <code>MAP_CENTERED</code>, <code>ORIENTED_NORTH</code>, <code>SCROLLED_NORTH</code>, <code>SCROLLED_UP</code>, <code>SCROLLED_EAST</code>, <code>SCROLLED_RIGHT</code>, <code>SCROLLED_SOUTH</code>, <code>SCROLLED_DOWN</code>, <code>SCROLLED_WEST</code>, <code>SCROLLED_LEFT</code>, <code>ROUTE_GUIDANCE_MUTED</code>, <code>ROUTE_GUIDANCE_UNMUTED</code></p> <p>Otherwise, your implementation should publish the <code>NavigationError</code> message with a type and code from the following:</p> <p>types: <code>ROUTE_OVERVIEW_FAILED</code>, <code>DIRECTIONS_LIST_FAILED</code>, <code>ZOOMED_IN_FAILED</code>, <code>ZOOMED_OUT_FAILED</code>, <code>MAP_CENTERED_FAILED</code>, <code>ORIENTED_NORTH_FAILED</code>, <code>SCROLLED_NORTH_FAILED</code>, <code>SCROLLED_UP_FAILED</code>, <code>SCROLLED_EAST_FAILED</code>, <code>SCROLLED_RIGHT_FAILED</code>, <code>SCROLLED_SOUTH_FAILED</code>, <code>SCROLLED_DOWN_FAILED</code>, <code>SCROLLED_WEST_FAILED</code>, <code>SCROLLED_LEFT_FAILED</code>, <code>ROUTE_GUIDANCE_MUTED_FAILED</code>, <code>ROUTE_GUIDANCE_UNMUTED_FAILED</code></p> <p>codes: <code>INTERNAL_SERVICE_ERROR</code>, <code>NOT_NAVIGATING</code>, <code>NOT_SUPPORTED</code>, <code>NOT_ALLOWED</code></p> <p>Click to expand or collapse sequence diagram: Controlling the Display </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#showing-alternative-routes","title":"Showing Alternative Routes","text":"<p>If the user wants to display alternative routes, the Engine publishes the <code>ShowAlternativeRoutes</code> message, which passes the type of alternate route to be displayed.</p> <p>If the device can display the alternative route successfully, your implementation should publish the <code>ShowAlternativeRoutesSucceeded</code> message with a payload containing information about the alternative route.</p> <p>The following table explains the properties in the JSON.</p> Property Type Required Description inquiryType String Yes The type of alternative routes based on the user's preference. Accepted values: <ul><li><code>\"DEFAULT\"</code>, which means there is no preference as to whether the alternate route saves time or distance.</li><li><code>\"SHORTER_TIME\"</code>, which means the alternate route saves time.</li><li><code>\"SHORTER_DISTANCE\"</code>, which means the alternate route saves distance.</li></ul> alternateRoute Object Yes Information about the best route that matches the preference specified by <code>inquiryType</code>. alternateRoute.labels Array of strings Yes Unique names within a route (e.g., names of highways) used to distinguish between alternative routes. Each label might contain the direction of the route. alternateRoute.savings Array No List of savings achieved by the route. alternateRoute.savings.type String Yes The type of savings. Accepted values: <code>\"DISTANCE\"</code> or <code>\"TIME\"</code>. alternateRoute.savings.amount Float Yes The amount of savings achieved by the route. Alexa uses prescribed unit to convert the amount of savings to improve user experience, if needed. alternateRoute.savings.unit String Yes Measurement unit of the savings. Accepted values: <code>\"MINUTE\"</code>, <code>\"HOUR\"</code>, <code>\"YARD\"</code>, <code>\"FOOT\"</code>, <code>\"MILE\"</code>, <code>\"METER\"</code>, or <code>\"KILOMETER\"</code>. <p>Click to expand or collapse the <code>ShowAlternativeRoutesSucceeded</code> message schema</p> <p></p> <pre><code>{\n  \"inquiryType\": \"{{STRING}}\",\n  \"alternateRoute\":\n  {\n      \"labels\": [\"{{STRING}}\"],\n      \"savings\": [\n          {\n              \"type\": \"{{STRING}}\",\n              \"amount\": {{FLOAT}},\n              \"unit\": \"{{STRING}}\"\n          }\n      ]\n  }\n}\n</code></pre> <p></p> <p>Otherwise, your implementation should publish the <code>NavigationError</code> message with a type and code from the following:</p> <p>types: <code>DEFAULT_ALTERNATE_ROUTES_FAILED</code>, <code>SHORTER_TIME_ROUTES_FAILED</code>, <code>SHORTER_DISTANCE_ROUTES_FAILED</code></p> <p>codes: <code>INTERNAL_SERVICE_ERROR</code>, <code>ROUTE_NOT_FOUND</code>, <code>NOT_SUPPORTED</code>, <code>NOT_NAVIGATING</code></p> <p>Click to expand or collapse sequence diagram: Showing Alternative Routes </p> <p></p> <p></p>"},{"location":"explore/features/navigation/#integrating-the-navigation-module-into-your-application","title":"Integrating the Navigation Module Into Your Application","text":""},{"location":"explore/features/navigation/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the Engine's <code>MessageBroker</code> to subscribe to and publish \"Navigation\" AASB messages.</p> <p>Click to expand or collapse C++ sample code</p> <p></p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/Navigation/Navigation/AlternateRouteType.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ControlDisplay.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ErrorCode.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ErrorType.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/EventName.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/RoadRegulation.h&gt;\n\n#include &lt;AASB/Message/Navigation/Navigation/AnnounceManeuverMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/AnnounceRoadRegulationMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/CancelNavigationMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ControlDisplayMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/GetNavigationStateMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/NavigationErrorMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/NavigationEventMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/NavigateToPreviousWaypointMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ShowAlternativeRoutesMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ShowAlternativeRoutesSucceededMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/ShowPreviousWaypointsMessage.h&gt;\n#include &lt;AASB/Message/Navigation/Navigation/StartNavigationMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyNavigationHandler {\n\nvoid MyNavigationHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleAnnounceManeuverMessage(message); },\nAnnounceManeuverMessage::topic(),\nAnnounceManeuverMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleAnnounceRoadRegulationMessage(message); },\nAnnounceRoadRegulationMessage::topic(),\nAnnounceRoadRegulationMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleCancelNavigationMessage(message); },\nCancelNavigationMessage::topic(),\nCancelNavigationMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleControlDisplayMessage(message); },\nControlDisplayMessage::topic(),\nControlDisplayMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetNavigationStateMessage(message); },\nGetNavigationStateMessage::topic(),\nGetNavigationStateMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleNavigateToPreviousWaypointMessage(message); },\nNavigateToPreviousWaypointMessage::topic(),\nNavigateToPreviousWaypointMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleShowAlternativeRoutesMessage(message); },\nShowAlternativeRoutesMessage::topic(),\nShowAlternativeRoutesMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleShowPreviousWaypointsMessage(message); },\nShowPreviousWaypointsMessage::topic(),\nShowPreviousWaypointsMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStartNavigationMessage(message); },\nStartNavigationMessage::topic(),\nStartNavigationMessage::action());\n}\n\n// Handle the AnnounceManeuver message from the Engine\nvoid MyNavigationHandler::handleAnnounceManeuverMessage(const std::string&amp; message) {\nAnnounceManeuverMessage msg = json::parse(message);\nannounceManeuver(msg.payload.payload);\n}\n\n// Handle the AnnounceRoadRegulation message from the Engine\nvoid MyNavigationHandler::handleAnnounceRoadRegulationMessage(const std::string&amp; message) {\nAnnounceRoadRegulationMessage msg = json::parse(message);\nannounceRoadRegulation(msg.payload.roadRegulation);\n}\n\n// Handle the CancelNavigation message from the Engine\nvoid MyNavigationHandler::handleCancelNavigationMessage(const std::string&amp; message) {\ncancelNavigation();\n}\n\n// Handle the ControlDisplay message from the Engine\nvoid MyNavigationHandler::handleControlDisplayMessage(const std::string&amp; message) {\nControlDisplayMessage msg = json::parse(message);\ncontrolDisplay(msg.payload.controlDisplay);\n}\n\n// Handle the GetNavigationState message from the Engine and publish the\n// reply message containing the current navigation state\nvoid MyNavigationHandler::handleGetNavigationStateMessage(const std::string&amp; message) {\nGetNavigationStateMessage msg = json::parse(message);\nGetNavigationStateMessageReply replyMsg;\nreplyMsg.header.messageDescription.replyToId = msg.header.id;\nreplyMsg.payload.navigationState = getNavigationState();\nm_messageBroker-&gt;publish(replyMsg.toString());\n}\n\n// Handle the NavigateToPreviousWaypoint message from the Engine\nvoid MyNavigationHandler::handleNavigateToPreviousWaypointMessage(const std::string&amp; message) {\nnavigateToPreviousWaypoint();\n}\n\n// Handle the ShowAlternativeRoutes message from the Engine\nvoid MyNavigationHandler::handleShowAlternativeRoutesMessage(const std::string&amp; message) {\nShowAlternativeRoutesMessage msg = json::parse(message);\nshowAlternativeRoutes(msg.payload.alternateRouteType);\n}\n\n// Handle the ShowPreviousWaypoints message from the Engine\nvoid MyNavigationHandler::handleShowPreviousWaypointsMessage(const std::string&amp; message) {\nshowPreviousWaypoints();\n}\n\n// Handle the StartNavigation message from the Engine\nvoid MyNavigationHandler::handleStartNavigationMessage(const std::string&amp; message) {\nStartNavigationMessage msg = json::parse(message);\nstartNavigation(msg.payload.payload);\n}\n\nvoid MyNavigationHandler::navigationError(\nErrorType type,\nErrorCode code,\nconst std::string&amp; description) {\nNavigationErrorMessage msg;\nmsg.payload.type = type;\nmsg.payload.code = code;\nmsg.payload.description = description;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\nvoid MyNavigationHandler::navigationEvent(EventName event) {\nNavigationEventMessage msg;\nmsg.payload.event = event;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\nvoid MyNavigationHandler::showAlternativeRoutesSucceeded(const std::string&amp; payload) {\nShowAlternativeRoutesSucceededMessage msg;\nmsg.payload.payload = payload;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\nvoid MyNavigationHandler::startNavigation(const std::string&amp; payload) {\n// Update the previous destinations list\n\n// Call navigationEvent(EventName::NAVIGATION_STARTED)\n// If error occurs call navigationError() with ErrorType::NAVIGATION_START_FAILED and the ErrorCode describing the type of failure\n}\n\nvoid MyNavigationHandler::navigateToPreviousWaypoint() {\n// Call navigationEvent(EventName::PREVIOUS_NAVIGATION_STARTED)\n// If any error occurs call navigationError() with ErrorType::PREVIOUS_NAVIGATION_START_FAILED and the ErrorCode describing the type of failure\n}\n\nvoid NavigationHandler::showPreviousWaypoints() {\n// Call navigationEvent(EventName::PREVIOUS_WAYPOINTS_SHOWN)\n// If error occurs call navigationError() with ErrorType::SHOW_PREVIOUS_WAYPOINTS_FAILED and the ErrorCode describing the type of failure\n}\n\nvoid NavigationHandler::showAlternativeRoutes(AlternateRouteType alternateRouteType) {\n// Based on the AlternativeRouteType obtain the alternative route information\n\n// Call showAlternativeRoutesSucceeded()\n// If error occurs call navigationError() with ErrorType and ErrorCode describing failure\n}\n\nvoid NavigationHandler::controlDisplay(ControlDisplay controlDisplay) {\n// Call navigationEvent() for the requested map control request\n// If error occurs call navigationError() with ErrorType and ErrorCode describing failure\n}\n\nvoid NavigationHandler::announceManeuver(const std::string&amp; payload) {\n// Call navigationEvent() for the requested manueuver instruction\n// If error occurs call navigationError() with ErrorType and ErrorCode describing failure\n}\n\nvoid NavigationHandler::announceRoadRegulation(RoadRegulation roadRegulation) {\n// Call navigationEvent() for the requested road regulation\n// If error occurs call navigationError() with ErrorType and ErrorCode describing failure\n}\n\nbool NavigationHandler::cancelNavigation() {\n// Clear the navigation state\n}\n\nstd::string NavigationHandler::getNavigationState() {\n// Return current navigation state\n}\n\n};\n</code></pre> <p></p>"},{"location":"explore/features/phone-control/","title":"Phone Control Module","text":""},{"location":"explore/features/phone-control/#overview","title":"Overview","text":"<p>The <code>Phone Control</code> module enables your Alexa Auto SDK client application to use the phone call control capabilities of Alexa, independent of the connection mechanism to the calling device. By using the <code>PhoneCallController</code> interface in your application, you allow the end user to interact with new or ongoing calls using Alexa, and you provide Alexa with the state of the calling device. The <code>Phone Control</code> module uses phone contacts uploaded via the <code>Address Book</code> module.</p> <p>Your application's <code>PhoneCallController</code> integration is responsible for managing the lifecycle of the call session, including enhancing the end user experience by:</p> <ul> <li>Preventing Alexa Text To Speech (TTS) from being fed back into the microphone when the user triggers Alexa during a call. To accomplish this, your implementation should stop feeding the microphone input into the call channel until Alexa returns to the idle state, and it should also specify strong echo cancellation.</li> <li>Lowering the audio level of previous media in response to an incoming call until the call is answered or declined (if ducking is supported) and pausing the media if the call is answered.</li> <li>Maintaining the last dialed number to support redialing.</li> </ul>"},{"location":"explore/features/phone-control/#configuring-the-phone-control-module","title":"Configuring the Phone Control Module","text":"<p>The <code>Phone Control</code> module does not require Engine configuration.</p>"},{"location":"explore/features/phone-control/#using-the-phone-call-controller-aasb-messages","title":"Using the Phone Call Controller AASB Messages","text":""},{"location":"explore/features/phone-control/#changing-connection-state","title":"Changing Connection State","text":"<p>When connection to a calling device is established or terminated, publish the <code>ConnectionStateChanged</code> message.</p> <p>Click to expand or collapse sequence diagram: Connection State Changed </p> <p></p> <p></p>"},{"location":"explore/features/phone-control/#updating-device-configuration","title":"Updating Device Configuration","text":"<p>To update the device configuration of the connected calling device, publish the <code>DeviceConfigurationUpdated</code> message.</p> <p>Note: The Auto SDK only supports updates to <code>DTMF_SUPPORTED</code> to enable or disable <code>SendDTMF</code>.</p> <p>Click to expand or collapse sequence diagram: Device Configuration Updated </p> <p></p> <p></p>"},{"location":"explore/features/phone-control/#calling","title":"Calling","text":"<p>Whether the call is initiated by Alexa or by the user, during the call session your application is responsible for publishing <code>CallStateChanged</code> messages to inform the Engine of the progression of the call (e.g., call is answered, call ended) while the Engine publishes messages to the application in order to handle user interactions with the call (e.g., answer, dial, stop).</p> <p>Regardless of whether the call is inbound or outbound:</p> <ul> <li>During a call if the user asks Alexa to press the keypad, the Engine publishes the <code>SendDTMF</code> message. Your application must handle this message and publish either the <code>SendDTMFSucceeded</code> message or <code>SendDTMFFailed</code> message to indicate its completion or failure, respectively.</li> <li>If an error occurrs during an active call or call setup, publish the <code>CallFailed</code> message specifying the error.</li> <li>When the user asks Alexa to hang up a call, cancel a call setup, or decline an incoming call the Engine publishes the <code>Stop</code> message.</li> </ul>"},{"location":"explore/features/phone-control/#inbound-calling","title":"Inbound Calling","text":"<p>When an inbound call is detected, publish the <code>CreateCallId</code> message. In response, the Engine will publish the <code>CreateCallId</code> reply containing a unique identifier for the call. Once an inbound call alert is received, your application must publish the <code>CallStateChanged</code> message indicating the call is now in the CALL_RECEIVED state. When the inbound call begins ringing, publish the <code>CallStateChanged</code> message, this time specifying the INBOUND_RINGING call state.</p> <p>If the user asks Alexa to answer the inbound call, the Engine publishes the <code>Answer</code> message. Publish the <code>CallStateChanged</code> message indicating the call is now ACTIVE.</p> <p>Whenever the user asks Alexa to end the call, the Engine publishes the <code>Stop</code> message. Publish the <code>CallStateChanged</code> message to indicate that the call is now IDLE.</p> <p>Note: When a caller id is received for an inbound call, publish the <code>CallerIdReceived</code> message.</p> <p>Click to expand or collapse sequence diagram: Inbound Calling </p> <p></p> <p></p>"},{"location":"explore/features/phone-control/#outbound-calling","title":"Outbound Calling","text":"<p>When a user asks Alexa to dial a number or call an uploaded contact, the Engine publishes the <code>Dial</code> message. Alternatively, if the user asks Alexa to redial the last dialed number, the Engine publishes the <code>Redial</code> message. In both cases, your application must publish the <code>CallStateChanged</code> message indicating the call is now in the DIALING state. Once the outgoing call setup is complete and outbound ringing has started, publish the <code>CallStateChanged</code> message specifying the OUTBOUND_RINGING call state.</p> <p>If the call is answered and in progress, publish the <code>CallStateChanged</code> message indicating the call is now ACTIVE.</p> <p>Whenever the user asks Alexa to end the call, the Engine publishes the <code>Stop</code> message. Publish the <code>CallStateChanged</code> message to indicate that the call is now IDLE.</p> <p>Note: It is possible for the connection state to become <code>DISCONNECTED</code> after the user asks Alexa to dial or redial a number. Therefore, the application must ensure to check the connection state when the <code>Dial</code> or <code>Redial</code> message is received. If the call cannot be placed, publish the <code>CallFailed</code> message specifying an appropriate error code and message.</p> <p>Click to expand or collapse sequence diagram: Outbound Calling </p> <p></p> <p></p>"},{"location":"explore/features/phone-control/#integrating-the-phone-call-controller-module-into-your-application","title":"Integrating the Phone Call Controller Module Into Your Application","text":"<p>Use the <code>MessageBroker</code> to subscribe to and publish <code>PhoneCallController</code> AASB messages.</p> <p>Click to expand or collapse C++ sample code</p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallError.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallState.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallingDeviceConfigurationProperty.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/ConnectionState.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/DTMFError.h&gt;\n\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/AnswerMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallerIdReceivedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallFailedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CallStateChangedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/ConnectionStateChangedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/CreateCallIdMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/DeviceConfigurationUpdatedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/DialMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/RedialMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/SendDTMFMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/SendDTMFFailedMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/SendDTMFSucceededMessage.h&gt;\n#include &lt;AASB/Message/PhoneCallController/PhoneCallController/StopMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyPhoneCallControllerHandler {\n\n// Subscribe to messages from the Engine\nvoid MyPhoneCallControllerHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleAnswerMessage(message); },\nAnswerMessage::topic(),\nAnswerMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleDialMessage(message); },\nDialMessage::topic(),\nDialMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleRedialMessage(message); },\nRedialMessage::topic(),\nRedialMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleSendDMTFMessage(message); },\nSendDTMFMessage::topic(),\nSendDTMFMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleStopMessage(message); },\nStopMessage::topic(),\nStopMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleCreateCallIdReplyMessage(message); },\nCreateCallIdMessageReply::topic(),\nCreateCallIdMessageReply::action());\n}\n\n// Handle the Answer message from the Engine\nvoid MyPhoneCallControllerHandler::handleAnswerMessage(const std::string&amp; message) {\nAnswerMessage msg = json::parse(message);\nanswer(msg.payload.payload);\n}\n\n// Handle the Dial message from the Engine\nvoid MyPhoneCallControllerHandler::handleDialMessage(const std::string&amp; message) {\nAnswerMessage msg = json::parse(message);\nstd::string payload = msg.payload.payload;\ndial(msg.payload.payload);\n}\n\n// Handle the Redial message from the Engine\nvoid MyPhoneCallControllerHandler::handleRedialMessage(const std::string&amp; message) {\nAnswerMessage msg = json::parse(message);\nredial(msg.payload.payload);\n}\n\n// Handle the SendDTMF message from the Engine\nvoid MyPhoneCallControllerHandler::handleSendDMTFMessage(const std::string&amp; message) {\nSendDTMFMessage msg = json::parse(message);\nsendDTMF(msg.payload.payload);\n}\n\n// Handle the Stop message from the Engine\nvoid MyPhoneCallControllerHandler::handleStopMessage(const std::string&amp; message) {\nStopMessage msg = json::parse(message);\nstop(msg.payload.payload);\n}\n\n// Handle the CreateCallId reply message from the Engine\nvoid MyPhoneCallControllerHandler::handleCreateCallIdReplyMessage(const std::string&amp; message) {\nCreateCallIdMessageReply msg = json::parse(message);\nstd::string messageId = msg.header.messageDescription.replyToId;\nstd::string callId = msg.payload.callId;\n\n// ...Handle the generated call id...\n}\n\n// When an error occurrs during an active call or call setup, publish a CallFailed\n// message to the Engine\nvoid MyPhoneCallControllerHandler::callFailed(\nconst std::string&amp; callId,\nCallError code,\nconst std::string&amp; message) {\nCallFailedMessage msg;\nmsg.payload.callId = callId;\nmsg.payload.code = code;\nmsg.payload.message = message;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the call state changes, publish a CallStateChanged message to the Engine\nvoid MyPhoneCallControllerHandler::callStateChanged(\nCallState state,\nconst std::string&amp; callId,\nconst std::string&amp; callerId) {\nCallStateChangedMessage msg;\nmsg.payload.state = state;\nmsg.payload.callId = callId;\nmsg.payload.callerId = callerId;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When a caller id is received for an inbound call, publish a CallerIdReceived\n// message to the Engine\nvoid MyPhoneCallControllerHandler::callerIdReceived(const std::string&amp; callId, const std::string&amp; callerId) {\nCallerIdReceivedMessage msg;\nmsg.payload.callId = callId;\nmsg.payload.callerId = callerId;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When connection to a calling device is established or broken, publish a\n// ConnectionStateChanged message to the Engine\nvoid MyPhoneCallControllerHandler::connectionStateChanged(ConnectionState state) {\nConnectionStateChangedMessage msg;\nmsg.payload.state = state;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// To generate an identifier for a call, publish a CreateCallId message to the Engine\nstd::string MyPhoneCallControllerHandler::createCallId() {\nCreateCallIdMessage msg;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the CreateCallIdReply message\n// Return the unique identifier from reply message payload\n}\n\n// When a feature of the calling device changes, publish a\n// DeviceConfigurationUpdated message to the Engine\nvoid MyPhoneCallControllerHandler::deviceConfigurationUpdated(\nstd::unordered_map&lt;CallingDeviceConfigurationProperty, bool&gt; configurationMap) {\njson configuration;\nfor (auto it: configurationMap) {\nconfiguration[configurationFeatureToString(it.first)] = it.second;\n}\n\nDeviceConfigurationUpdatedMessage msg;\nmsg.payload.configurationMap = configuration.dump();\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When the DTMF signal is delivered, publish a SendDTMFSucceeded message to the Engine\nvoid MyPhoneCallControllerHandler::sendDTMFSucceeded(const std::string&amp; callId) {\nSendDTMFSucceededMessage msg;\nmsg.payload.callId = callId;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// When sending the DTMF signal failed, publish a SendDTMFFailed message to the Engine\nvoid MyPhoneCallControllerHandler::sendDTMFFailed(\nconst std::string&amp; callId,\nDTMFError code,\nconst std::string&amp; message) {\nSendDTMFFailedMessage msg;\nmsg.payload.callId = callId;\nmsg.payload.code = code;\nmsg.payload.message = message;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\nvoid MyPhoneCallControllerHandler::answer(const std::string&amp; payload) {\n// Answer the inbound call\n}\n\nvoid MyPhoneCallControllerHandler::dial(const std::string&amp; payload) {\n// Initiate an outbound call\n}\n\nvoid MyPhoneCallControllerHandler::redial(const std::string&amp; payload) {\n// Initiate an outbound call\n}\n\nvoid MyPhoneCallControllerHandler::stop(const std::string&amp; payload) {\n// Stop the call\n}\n\nvoid MyPhoneCallControllerHandler::sendDTMF(const std::string&amp; payload) {\n// Send a DTMF signal\n}\n\n// Implement to convert CallingDeviceConfigurationProperty to string\nstd::string MyPhoneCallControllerHandler::configurationFeatureToString(CallingDeviceConfigurationProperty feature);\n\n};\n</code></pre>"},{"location":"explore/features/system-audio/","title":"Alexa Auto SDK System Audio Module","text":"<p>The <code>System Audio</code> module provides the default audio capturing and playback functionality for macOS, Linux, and QNX.</p>"},{"location":"explore/features/system-audio/#whats-included","title":"What's Included","text":"<p>The <code>System Audio</code> module contains the platform implementations of:</p> <ul> <li><code>aace::audio::AudioOutput</code> and <code>aace::audio::AudioOutputProvider</code> for audio playback capability</li> <li><code>aace::audio::AudioInput</code> and <code>aace::audio::AudioInputProvider</code> for audio capturing capability</li> </ul>"},{"location":"explore/features/system-audio/#supported-audio-backends","title":"Supported Audio Backends","text":"<p>Currently the <code>System Audio</code> module supports:</p> <ul> <li> <p>GStreamer tested on:</p> <ul> <li> <p>Ubuntu Linux (18.04 and 20.04)</p> <p>Note: Ensure installing at least <code>gstreamer1.0-plugins-base</code> and <code>gstreamer1.0-plugins-good</code>. It is recommended to install <code>gstreamer1.0-plugins-bad</code> for playing content from Amazon Music (which uses HLS) and other Music Service Providers. Refer to https://gstreamer.freedesktop.org/documentation/installing/on-linux.html for instructions.</p> <p>Note: GStreamer on Poky Linux for iMX8 does not support Audible or Amazon Music playback.</p> </li> <li> <p>Automotive Grade Linux with 4A framework support (FF or GG)</p> </li> <li> <p>Poky Linux armv7hf and armv8</p> </li> <li> <p>macOS x86_64 with GStreamer installed by Homebrew</p> </li> </ul> </li> <li> <p>OpenMAX AL (Encoded audio playback only) tested with:</p> <ul> <li>QNX Multimedia Suite 2.0 on QNX 7.0.0 armv8</li> </ul> </li> <li> <p>QNX Sound Architecture (QSA) (Raw audio only) tested with:</p> <ul> <li> <p>QNX 7.0.0 armv8</p> <p>Note: You'll need a QNX Multimedia Suite license to use OpenMAX AL, and both OpenMAX AL and QSA are required in order to enable full functionality on QNX.</p> </li> </ul> </li> </ul>"},{"location":"explore/features/system-audio/#getting-started","title":"Getting Started","text":""},{"location":"explore/features/system-audio/#prerequisites","title":"Prerequisites","text":"<p>You'll need GStreamer development packages such as <code>libgstreamer1.0-dev</code> and <code>libgstreamer-plugins-base1.0-dev</code>.</p>"},{"location":"explore/features/system-audio/#building-the-alexa-auto-sdk-with-the-system-audio-module","title":"Building the Alexa Auto SDK with the System Audio Module","text":"<p>The Alexa Auto SDK Builder Tool automatically includes the <code>System Audio</code> module when you build the C++ sample app. You can include it explicitly by specifying <code>-o aac_modules=aac-module-system-audio,...</code> to the build command.</p>"},{"location":"explore/features/system-audio/#running-the-c-sample-app-with-the-audio-configuration","title":"Running the C++ Sample App with the Audio Configuration","text":"<p>When you run the C++ Sample App, a <code>config-system-audio.json</code> file with default audio settings for Linux platforms is provided under <code>shared/system-audio/config</code>.</p>"},{"location":"explore/features/system-audio/#changing-the-default-audio-settings-for-linux-required-for-poky-32","title":"Changing the Default Audio Settings for Linux (required for Poky 32)","text":"<p>If you need to modify the configuration defined in the <code>config-system-audio.json</code> file for your Linux platform, follow these steps:</p> <ol> <li> <p>Edit the <code>config-system-audio.json</code> file (located in the <code>aac-sdk/modules/system-audio/configs/linux</code> directory) as necessary.</p> <p>Note: For Poky 32 boards, you must set <code>\"shared\"</code> to <code>\"true\"</code> in the <code>\"default\"</code> node.</p> </li> <li> <p>Save the <code>config-system-audio.json</code> file to the same directory other config files reside.</p> </li> <li> <p>Include a  <code>--config path/to/config-system-audio.json</code> line when you run the C++ Sample App.</p> </li> </ol>"},{"location":"explore/features/system-audio/#changing-the-default-audio-settings-for-qnx-required","title":"Changing the Default Audio Settings for QNX (required)","text":"<p>The default audio settings will not work for QNX. To modify the configuration defined in the <code>config-system-audio.json</code> file for your QNX platform, follow these steps:</p> <ol> <li>Edit the <code>config-system-audio.json</code> file (located in the <code>aac-sdk/modules/system-audio/configs/neutrino</code> directory) as necessary. See the default QNX configuration for guidance.</li> <li>Save the <code>config-system-audio.json</code> file to the same directory other config files reside.</li> <li>Include a <code>--config /opt/AAC/etc/config-system-audio.json</code> line when you run the C++ Sample App.</li> </ol> <p>Note: You may need to set the <code>AAL_CAPATH</code> system environment value to specify which path should OpenMAX AL used for <code>CURLOPT_CAPATH</code> internally. If you don't set the <code>AAL_CAPATH</code> system environment variable, <code>/etc/ssl/certs</code> will be used by default.</p>"},{"location":"explore/features/system-audio/#configuring-system-audio","title":"Configuring System Audio","text":"<p>For complex audio setup, you may need to write your own config file. To use this file, save it as <code>config-system-audio.json</code> and include a <code>--config path/to/config-system-audio.json</code> line when you run the C++ Sample App.</p> <p>Here is the config file template:</p> <pre><code>{\n  \"aace.systemAudio\": {\n    \"&lt;provider&gt;\": {\n      \"enabled\": {{BOOLEAN}},\n      \"devices\": {\n        \"&lt;device-name&gt;\": {\n          \"module\": \"&lt;module-name&gt;\",\n          \"card\": \"&lt;id&gt;\",\n          \"rate\": \"&lt;sample-rate&gt;\",\n          \"shared\": {{BOOLEAN}}\n        }\n      },\n      \"types\": {\n        \"&lt;type&gt;\": \"&lt;device-name&gt;\"\n      }\n    }\n  }\n}\n</code></pre> <ul> <li><code>aace.systemAudio.&lt;provider&gt;</code>: Set to <code>AudioInputProvider</code> or <code>AudioOutputProvider</code>. You can write a configuration for each <code>&lt;provider&gt;</code>, depending on the direction (input or output).</li> <li><code>aace.systemAudio.&lt;provider&gt;.enabled</code>: Set to <code>true</code> or <code>false</code>. Setting this parameter to <code>false</code> disables the registration of the <code>&lt;provider&gt;</code> platform implementation. The default setting is <code>true</code>.</li> <li><code>aace.systemAudio.&lt;provider&gt;.devices.&lt;device-name&gt;</code>: Set to any <code>\"&lt;device-name&gt;\"</code> or to <code>default</code>. If you set the <code>\"&lt;device-name&gt;\"</code> to <code>\"default\"</code> audio will be routed by default if there is no explicit <code>\"&lt;device-name&gt;</code>\" available for the configured <code>\"&lt;type&gt;\"</code>. You can configure multiple devices, depending on your platform.<ul> <li><code>\"module\"</code>: Specify a <code>\"&lt;module-name&gt;\"</code> to explicitly define which audio backend to use. By default, <code>\"module\"</code> is set to an empty string, which configures the system audio module to use whatever backend is available.</li> <li><code>\"card\"</code>: Specify the card id for the specific audio backend you defined with the <code>\"&lt;module-name&gt;\"</code> parameter. By default, <code>\"card\"</code> is set to an empty string since by default <code>\"&lt;module-name&gt;\"</code> is not defined.</li> <li><code>\"rate\"</code>: Specify the sample rate of audio input. By default the <code>\"rate\"</code> is set to <code>0</code>.</li> <li><code>\"shared\"</code> (AudioInputProvider only): Set to <code>true</code> or <code>false</code>. Set <code>\"shared\"</code> to <code>true</code> for Poky 32 boards or in cases where the device should be shared within the Auto SDK Engine; otherwise, the System Audio module will try to open the device for every audio input type. The <code>\"shared\"</code> option is useful when the underlying backend doesn't support the input splitter. By default <code>\"shared\"</code> is set to <code>false</code>.</li> </ul> </li> <li><code>aace.systemAudio.&lt;provider&gt;.types.&lt;type&gt;</code>: Use the <code>\"type\"</code> option to specify which device should be used for various types of audio. If you do not explicitly specify a device, the <code>default</code> type is used. See <code>aace::audio::AudioInputProvider::AudioInputType</code> and <code>aace::audio::AudioOutputProvider::AudioOutputType</code> for the possible <code>\"&lt;type&gt;\"</code> values.</li> </ul>"},{"location":"explore/features/system-audio/#default-qnx-configuration","title":"Default QNX Configuration","text":"<p>Here is the default configuration for QNX platforms:</p> <pre><code>{\n\"aace.systemAudio\": {\n\"AudioInputProvider\": {\n\"devices\": {\n\"default\": {\n\"module\": \"QSA\",\n\"shared\": true\n}\n}\n},\n\"AudioOutputProvider\": {\n\"devices\": {\n\"default\": {\n\"module\": \"OpenMAX AL\"\n},\n\"raw\": {\n\"module\": \"QSA\"\n}\n},\n\"types\": {\n\"COMMUNICATION\": \"raw\"\n}\n}\n}\n}\n</code></pre> <p>If you use this configuration:</p> <ul> <li>The audio capturing for all types will use <code>QSA</code>, but it will be shared. This means that only a single PCM channel will be opened by the Engine.</li> <li>The audio playback for all types except <code>COMMUNICATION</code> will use <code>OpenMAX AL</code>. <code>COMMUNICATION</code> audio will use <code>QSA</code> instead. Note that the multiple PCM channels will be opened for each types.</li> </ul>"},{"location":"explore/features/system-audio/#linux-configuration-example","title":"Linux Configuration Example","text":"<p>Here is a configuration example for Linux platforms:</p> <pre><code>{\n\"aace.systemAudio\": {\n\"AudioInputProvider\": {\n\"devices\": {\n\"default\": {\n\"module\": \"GStreamer\"\n},\n\"loopback\": {\n\"module\": \"GStreamer\",\n\"card\": \"hw:Loopback,1,0\",\n\"shared\": true\n}\n},\n\"types\": {\n\"LOOPBACK\": \"loopback\"\n}\n},\n\"AudioOutputProvider\": {\n\"devices\": {\n\"default\": {\n\"module\": \"GStreamer\"\n}\n}\n}\n}\n}\n</code></pre> <p>The above example shows how you could provide \"Speaker reference\" into the engine.</p>"},{"location":"explore/features/system-audio/#specifying-input-and-output-device","title":"Specifying Input and Output Device","text":"<p>The <code>card</code> field specifies the audio input source and audio output sink.</p> <p>For devices using module <code>GStreamer</code>, the <code>card</code> field can be one of the following values:</p> <ul> <li>If the <code>card</code> field is an empty string or not specified at all, the input device will be decided by GStreamer <code>autoaudiosrc</code> plugin and the output device will be decided by GStreamer <code>autoaudiosink</code> plugin automatically.</li> <li>If the the <code>card</code> field starts with <code>bin:</code>, the input and output device can be specified with a GStreamer bin description. For example, setting <code>card</code> of an audio input device to <code>bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay</code> will receive audio from local UDP port 5000. See Pipeline Description for details.</li> <li>If the <code>card</code> field starts with <code>element:</code>, the input and output device can be specified with a GStreamer element. For example, setting <code>card</code> of an audio output device to <code>element:pulsesink</code> will deliver the output audio to the PulseAudio server. See Plugins for the list of GStreamer plugins.</li> <li>If none of the above matches, the string will be treated as an Advanced Linux Sound Architecture (ALSA) device name. You can use <code>aplay -L</code> or <code>arecord -L</code> to list available audio output and input devices.</li> </ul> <p>One practical use of the <code>card</code> field is to specify virtual audio input/output for the following devices:</p> <ul> <li>The target device does not have audio input/output hardware.</li> <li>The target device is remotely located.</li> </ul> <p>Here is an example to use local microphone and speaker and run C++ sample app on a remote device:</p> <ul> <li>Local macOS/Linux device<ul> <li>Deliver audio from local microphone to remote UDP port 5000 by running <code>gst-launch-1.0 -v autoaudiosrc ! \"audio/x-raw, format=(string)S16LE, channels=(int)1, layout=(string)interleaved\" ! audioresample ! audio/x-raw, rate=16000 ! audioconvert ! rtpL16pay ! udpsink host=your.remote.device port=5000</code>.</li> <li>Build a reverse SSH tunnel by running <code>ssh -R 24713:localhost:4713 your.remote.device</code>.</li> <li>Play audio output received from remote device by running <code>pulseaudio --load=module-native-protocol-tcp --exit-idle-time=-1 --daemon</code>.</li> </ul> </li> <li>Remote device<ul> <li>Receive audio input from UDP port 5000 by specifying <code>card</code> of audio input device to <code>bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay</code>.</li> <li>Send audio output to local device by specifying <code>card</code> of audio output device to <code>element:pulsesink</code> and export <code>PULSE_SERVER</code> environment variable to <code>tcp:localhost:24713</code> before running C++ sample app.</li> </ul> </li> </ul>"},{"location":"explore/features/system-audio/#playlist-url-support","title":"Playlist URL Support","text":"<p>The System Audio module supports playback of playlist URL from media streaming services (such as TuneIn) based on <code>PlaylistParser</code> provided by AVS Device SDK. The current supported formats include M3U and PLS. Note that only the first playable entry will be played in the current implementation. Choosing a variant based on stream information or continuing playback of the second or later entry is not supported right now.</p> <p>After the user asks Alexa to play on TuneIn, if Alexa acknowledges the request but says TuneIn is not available, the parser displays the following error:</p> <pre><code>2021-03-02 05:04:25.745 [AVS] E PlaylistParser:doDepthFirstSearch:url=http\\://www.podtrac.com/pts/redirect.mp3/chtbl.com/track/5899E/traffic.megaphone.fm/HSW1953246087.mp3:getHeaderFailed\n</code></pre> <p>To avoid this error, provide a valid <code>cacert.pem</code> to <code>CURLOPT_CAINFO</code> in the Auto SDK configuration. Download the <code>cacert.pem</code> file from here.</p> <pre><code>      \"libcurlUtils\": {\n        \"CURLOPT_CAPATH\": \"/path/to/certs\",\n        \"CURLOPT_CAINFO\": \"/path/to/cacert.pem\"\n      }\n</code></pre>"},{"location":"explore/features/text-to-speech/","title":"Text-To-Speech (TTS) Module","text":""},{"location":"explore/features/text-to-speech/#overview","title":"Overview","text":"<p>The <code>Text-To-Speech</code> module enables your Alexa Auto SDK client application to synthesize Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. To synthesize speech, this module uses the <code>Text-To-Speech-Provider</code> module. The Auto SDK does not provide any speech-playing APIs. Your application's TTS module integration is responsible for playing the synthesized speech to deliver a unified Alexa experience to the user.</p> <p>Note: This feature may only be used with voice-guided turn-by-turn navigation.</p> <p>Important! The <code>Text-To-Speech</code> module requires the Local Voice Control extension.</p>"},{"location":"explore/features/text-to-speech/#configuring-the-text-to-speech-module","title":"Configuring the Text-To Speech-Module","text":"<p>The <code>Text-To-Speech</code> module does not require Engine configuration.</p>"},{"location":"explore/features/text-to-speech/#using-the-text-to-speech-aasb-messages","title":"Using the Text-To-Speech AASB Messages","text":""},{"location":"explore/features/text-to-speech/#prepare-speech","title":"Prepare Speech","text":"<p>To request speech synthesis from a text or SSML input, your application must publish the <code>PrepareSpeech</code> message. The Engine publishes either the <code>PrepareSpeechCompleted</code> message or <code>PrepareSpeechFailed</code> message to indicate success or failure, respectively.</p> <p>Click to expand or collapse sequence diagram: Prepare Speech </p> <p></p> <p>Note: The <code>prepareSpeechFailed</code> API contains the <code>reason</code> parameter that specifies the error string for failure. Refer to the TTS provider errors for more information on errors defined by the TTS provider.</p> <p>TThe TTS module defines the <code>REQUEST_TIMED_OUT</code> error that occurs when the TTS provider sends no response, causing the speech request to time out. The timeout value is 1000 milliseconds.</p> <p></p>"},{"location":"explore/features/text-to-speech/#get-capabilities","title":"Get Capabilities","text":"<p>To request the capabilities of the TTS provider being used, your application must publish the <code>GetCapabilities</code> message. The Engine publishes the <code>GetCapabilitiesReply</code> message reply with the capabilities of the TTS provider.</p> <p>Click to expand or collapse sequence diagram: Get Capabilities </p> <p></p> <p></p>"},{"location":"explore/features/text-to-speech/#integrating-the-text-to-speech-module-into-your-application","title":"Integrating the Text-To-Speech Module Into Your Application","text":""},{"location":"explore/features/text-to-speech/#c-messagebroker-integration","title":"C++ MessageBroker Integration","text":"<p>Use the <code>MessageBroker</code> to subscribe to and publish <code>TextToSpeech</code> AASB messages.</p> <p>Click to expand or collapse C++ sample code</p> <pre><code>#include &lt;AACE/Core/MessageBroker.h&gt;\n\n#include &lt;AASB/Message/TextToSpeech/TextToSpeech/GetCapabilitiesMessage.h&gt;\n#include &lt;AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechCompletedMessage.h&gt;\n#include &lt;AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechFailedMessage.h&gt;\n#include &lt;AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechMessage.h&gt;\n\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n\nclass MyTextToSpeechHandler {\n\n// Subscribe to messages from the Engine\nvoid MyTextToSpeechHandler::subscribeToAASBMessages() {\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePrepareSpeechCompletedMessage(message); },\nPrepareSpeechCompletedMessage::topic(),\nPrepareSpeechCompletedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handlePrepareSpeechFailedMessage(message); },\nPrepareSpeechFailedMessage::topic(),\nPrepareSpeechFailedMessage::action());\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetCapabilitiesReplyMessage(message); },\nGetCapabilitiesMessageReply::topic(),\nGetCapabilitiesMessageReply::action());\n}\n\n// Handle the PrepareSpeechCompleted message from the Engine\nvoid MyTextToSpeechHandler::handlePrepareSpeechCompletedMessage(const std::string&amp; message) {\nPrepareSpeechCompletedMessage msg = json::parse(message);\nstd::string speechId = msg.payload.speechId;\nstd::string streamId = msg.payload.streamId;\nstd::string metadata = msg.payload.metadata;\n\nprepareSpeechCompleted(speechId, streamId, metadata);\n}\n\n// Handle the PrepareSpeechFailed message from the Engine\nvoid MyTextToSpeechHandler::handlePrepareSpeechFailedMessage(const std::string&amp; message) {\nPrepareSpeechFailedMessage msg = json::parse(message);\nstd::string speechId = msg.payload.speechId;\nstd::string reason = msg.payload.reason;\n\nprepareSpeechFailed(speechId, reason);\n}\n\n// Handle the GetCapabilities reply message from the Engine\nvoid MyTextToSpeechHandler::handleGetCapabilitiesReplyMessage(const std::string&amp; message) {\nGetCapabilitiesMessageReply msg = json::parse(message);\nstd::string messageId = msg.header.messageDescription.replyToId;\nstd::string capabilities = msg.payload.capabilities;\n\n// ...Handle capabilities of the TTS provider...\n}\n\n// To prepare speech, publish the PrepareSpeech message to the Engine\nvoid MyTextToSpeechHandler::prepareSpeech(\nconst std::string&amp; speechId,\nconst std::string&amp; text,\nconst std::string&amp; provider,\nconst std::string&amp; options) {\nPrepareSpeechMessage msg;\nmsg.payload.speechId = speechId;\nmsg.payload.text = text;\nmsg.payload.provider = provider;\nmsg.payload.options = options;\nm_messageBroker-&gt;publish(msg.toString());\n}\n\n// To get capabilities, publish the GetCapabilities message to the Engine\nstd::string MyTextToSpeechHandler::getCapabilities(\nconst std::string&amp; requestId,\nconst std::string&amp; provider) {\nGetCapabilitiesMessage msg;\nmsg.header.id = requestId;\nmsg.payload.provider = provider;\nm_messageBroker-&gt;publish(msg.toString());\n\n// The Engine will send the GetCapabilitiesReply message\n// Return the capabilities from reply message payload\n}\n\nvoid MyTextToSpeechHandler::prepareSpeechCompleted(\nconst std::string&amp; speechId,\nconst std::string&amp; streamId,\nconst std::string&amp; metadata) {\n// Use MessageBroker openStream API to get the MessageStream\nstd::shared_ptr&lt;MessageStream&gt; preparedAudio =\nm_messageBroker-&gt;openStream(msg.payload.streamId, MessageStream::Mode::READ);\n\n// Follow the UX guidelines in order to play the audio stream\n}\n\n// Notification of a failed speech synthesis\nvoid TextToSpeechHandler::prepareSpeechFailed(\nconst std::string&amp; speechId,\nconst std::string&amp; reason) {\n// Use the speechId to correlate the synthesis request to the result\n// Access the reason for failure\n}\n\n};\n</code></pre>"},{"location":"explore/features/text-to-speech-provider/","title":"Text-Speech Provider Module","text":""},{"location":"explore/features/text-to-speech-provider/#overview","title":"Overview","text":"<p>The <code>Text-To-Speech Provider</code> module synthesizes Alexa speech on demand. Auto SDK supports one text-to-speech provider, which uses Alexa's voice as the default voice for speech synthesis.</p> <p>The <code>Text-To-Speech Provider</code> module performs the following functions:</p> <ul> <li>Generating speech from a text or SSML document to provide the speech to the TTS module.</li> <li>Providing capabilities based on the properties of the TTS provider, such as available locales.</li> </ul> <p>The TTS Provider module follows the existing AVS (Alexa Voice Service) protocol to carry out speech synthesis and requires connection to the Local Voice Control (LVC) service. If the device is disconnected from LVC, speech synthesis fails.</p> <p>Note: The module can synthesize speech only in the current locale as set by the application. </p>"},{"location":"explore/features/text-to-speech-provider/#configuring-the-tts-provider-module","title":"Configuring the TTS Provider Module","text":"<p>The <code>Text-To-Speech Provider</code> module does not require Engine configuration.</p>"},{"location":"explore/features/text-to-speech-provider/#specifying-the-tts-provider-in-aasb-messages","title":"Specifying the TTS Provider in AASB Messages","text":"<p>In all of the text-to-speech AASB messages that involve the provider parameter, use the string, \"text-to-speech-provider\", to specify the TTS provider.</p>"},{"location":"explore/features/text-to-speech-provider/#using-tts-provider-module-with-different-input-types","title":"Using TTS Provider Module with Different Input Types","text":"<p>How the TTS Provider module synthesizes speech depends on the input type and the <code>requestPayload</code> field in the options parameter of the <code>PrepareSpeech</code> message published to the Engine when request speech synthesis. The <code>requestPayload</code> structure is as follows:</p> <pre><code>{\n        \"requestPayload\" : {\n            \"voiceId\" : {VOICE_IDENTIFIER},\n            \"locale\" : {LOCALE_STRING}\n        }\n}\n</code></pre> <p>Note: You do not need to specify the <code>requestPayload</code> in the options parameter because currently only the default voice (Alexa\u2019s voice) is supported. Therefore, you can leave the options parameter unspecified or supply an empty string for it.</p> <p>The following list explains how the TTS Provider module synthesizes speech depending on the input type and <code>requestPayload</code>:</p> <ul> <li>If input is text and <code>requestPayload</code> is empty, the text is synthesized to speech with Alexa's voice and the current locale.</li> <li>If input is text and <code>requestPayload</code> specifies the voice and locale, the text is synthesized to speech in the specified voice and locale. The locale must be the current locale. </li> <li> <p>If input is text and <code>requestPayload</code> contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error <code>VOICE_NOT_SUPPORTED</code> or <code>LOCALE_NOT_SUPPORTED</code>, depending on the unsupported parameter.</p> </li> <li> <p>If input is SSML and contains all the supported tags and <code>requestPayload</code> specifies voice and locale, the SSML document is synthesized to speech in the specified voice and locale. The locale must be the current locale.</p> </li> <li>If input is SSML and contains all the supported tags, <code>requestPayload</code> is empty, the SSML document is synthesized to speech with Alexa's voice and current locale.</li> <li>If input is SSML and contains all the supported tags, and <code>requestPayload</code> contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error <code>VOICE_NOT_SUPPORTED</code> or <code>LOCALE_NOT_SUPPORTED</code>, depending on the unsupported parameter.</li> <li>If input is SSML and contains one or more unsupported tags, speech is synthesized but the unsupported tag is ignored. The text within the tag is synthesized normally.</li> </ul>"},{"location":"explore/features/text-to-speech-provider/#tts-capability-returned","title":"TTS Capability Returned","text":"<p>To request the capabilities of the TTS provider being used, your application publishes the <code>GetCapabilities message</code>. The Engine publishes the <code>GetCapabilitiesReply</code> message with the following payload structure:</p> <pre><code>\"text-to-speech-provider\" : {\n\n    \"voices\" : [    \n            {\n                 \"voiceId\": \"Alexa\",\n                 \"locales\": [CURRENT_LOCALE]\n             }\n    ]\n}\n</code></pre> <p>NOTE: The locale returned is always the current locale because you can load only one locale model at a time, which is the current locale.</p>"},{"location":"explore/features/text-to-speech-provider/#ssml-examples","title":"SSML Examples","text":"<ul> <li><code>&lt;speak&gt; ETA &lt;break time=\\\"3s\\\"/&gt; three hours &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Turn right &lt;emphasis level=\\\"strong\\\"&gt;in twenty feet&lt;/emphasis&gt; &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Turn right on&lt;lang xml:lang=\\\"fr-CA\\\"&gt;Moulin Rouge street.&lt;/lang&gt; &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; &lt;p&gt;Turn left in 500ft.&lt;/p&gt; &lt;p&gt;Then turn right.&lt;/p&gt; &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt;Turn left on, &lt;phoneme alphabet=\\\"ipa\\\" ph=\\\"Bo.fort\\\"&gt;Beaufort&lt;/phoneme&gt;&lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Turn right onto &lt;phoneme alphabet='nt-sampa' ph='*\\\"stAk|t@n \\\"strit'&gt;Stockton Street&lt;/phoneme&gt; &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Your ETA is 5 minutes on &lt;say-as interpret-as=\\\"date\\\" format=\\\"dmy\\\"&gt;12-10-2020&lt;/say-as&gt;. &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Take a &lt;prosody volume=\\\"-6dB\\\"&gt;U turn.&lt;/prosody&gt; &lt;/speak&gt;</code></li> <li><code>&lt;speak&gt; Take the next left onto &lt;sub alias=\\\"John Doe\\\"&gt;JD&lt;/sub&gt; street &lt;/speak&gt;</code></li> </ul>"},{"location":"explore/features/text-to-speech-provider/#errors","title":"Errors","text":"<p>The TTS provider defines its set of error strings or codes. The <code>PrepareSpeechFailed</code> message payload uses the <code>reason</code> parameter to send the error strings to the application.</p> <p>The following list describes the error strings used by the Local TTS provider:</p> <ul> <li> <p><code>LOCALE_NOT_SUPPORTED</code> occurs in any of the following situations:</p> <ul> <li>The language model for the current locale is missing. </li> <li>The locale specified in <code>requestPayload</code> is not the current locale.</li> <li>The locale specified is invalid.</li> </ul> </li> <li> <p><code>VOICE_NOT_SUPPORTED</code> occurs when the application specifies in <code>requestPayload</code> an invalid voice or is not Alexa.</p> </li> <li> <p><code>INTERNAL_ERROR</code> is an internal error that signifies an error when the TTS or TTS Provider module processes a request.</p> </li> <li> <p><code>PROVIDER_NOT_CONNECTED</code> occurs when the provider is not connected to LVC and a speech synthesis request is made.</p> </li> </ul> <p>NOTE: If a speech synthesis request is made during an ongoing Alexa dialog, the speech is synthesized after the current Alexa dialog ends.</p>"},{"location":"native/","title":"Auto SDK Native C++ Developer Guide","text":""},{"location":"native/#overview","title":"Overview","text":"<p>This guide outlines how to set up, build, and integrate Auto SDK into your native C++ application. Use this guide if you develop for a head unit running a Linux or QNX operating system.</p>"},{"location":"native/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Follow the steps in the general Get Started with Auto SDK guide to set up an Amazon developer account, access to the Auto SDK source code, and understand the core API and features.</p> </li> <li> <p>Read the Build Alexa Auto SDK guide to learn about how the Auto SDK build system works and understand how to build the SDK for your host and target hardware combination.</p> </li> </ol>"},{"location":"native/#optional-try-the-sample-app","title":"(Optional) Try the sample app","text":"<p>Auto SDK provides a C++ sample app that you can run on a Linux, QNX, or macOS machine to try sample utterances that exercise the Auto SDK APIs. See the C++ sample app documentation for more information about building and using the sample app.</p>"},{"location":"native/#build-auto-sdk-libraries","title":"Build Auto SDK libraries","text":"<p>Follow the instructions in Build Alexa Auto SDK to build the Auto SDK for your target platform. The output of your build command will be an archive in the <code>${AUTO_SDK_HOME}/builder/deploy/</code> directory. Extract the archive contents to find the Auto SDK libraries and headers. For example, <pre><code>aac-dev-macos_x86_64-release-220111103523/\n  \u251c\u2500 docs/\n  \u251c\u2500 include/\n  \u2502   \u251c\u2500\u2500 AACE\n  \u2502   \u2514\u2500\u2500 AASB\n  \u251c\u2500 lib/\n  |  \u251c\u2500 libAACECore.so\n  |  \u2514\u2500 ...\n  \u251c\u2500 share/\n  \u2514\u2500 aac-buildinfo.txt\n</code></pre> Link the libraries from <code>lib</code> to your application, and include the headers from <code>include</code>.</p>"},{"location":"native/#manage-the-engine-lifecycle-in-your-application","title":"Manage the Engine lifecycle in your application","text":"<p>To use Auto SDK features, your application must instantiate and manage the lifecycle of the Engine.</p>"},{"location":"native/#create-the-engine","title":"Create the Engine","text":"<p>During the launch sequence of your application, create an instance of the Engine using the static function <code>Engine::create()</code>:</p> <p><pre><code>#include &lt;AACE/Core/Engine.h&gt;\n\nstd::shared_ptr&lt;aace::core::Engine&gt; engine = aace::core::Engine::create();\n</code></pre> A typical application creates the Engine once when the user turns on the vehicle ignition and uses the instance until the user turns off the vehicle ignition.</p>"},{"location":"native/#configure-the-engine","title":"Configure the Engine","text":"<p>After creating the Engine instance, configure the Engine with the required Engine configurations for every module that you use. Engine configuration uses serialized JSON strings, but you pass the configurations to the Engine in one or more <code>aace::core::config::EngineConfiguration</code> wrapper objects. Auto SDK provides two options to generate <code>EngineConfiguration</code> objects:</p> <ul> <li>Specify your Engine configuration in a JSON file and construct an <code>EngineConfiguration</code> from a path to the file</li> <li>Build the configuration programmatically using one of the configuration factory functions.</li> </ul> <p>You can choose either option or a combination of both. I.e., you can generate a single <code>EngineConfiguration</code> object that includes all configuration data for the Engine components you use, or you can break up the configuration data into logical sections and generate multiple <code>EngineConfiguration</code> objects. For example, you might generate one <code>EngineConfiguration</code> object for each module.</p> <p>To configure the Engine, call the <code>Engine::configure()</code> function, passing in the <code>EngineConfiguration</code> object(s): </p> <ul> <li> <p>For a single <code>EngineConfiguration</code> object:</p> <pre><code>engine-&gt;configure( config );\n</code></pre> </li> <li> <p>For multiple <code>EngineConfiguration</code> objects:     <pre><code>engine-&gt;configure( { xConfig, yConfig, zConfig } );\n</code></pre>     replacing <code>xConfig</code>, <code>yConfig</code>, <code>zConfig</code> with logical names to identify the <code>EngineConfiguration</code> objects you generated.</p> </li> </ul> <p>See the documentation for individual module features to see the format of each module's respective JSON configuration.</p> <p>Note: For one Engine instance, you can call the <code>configure()</code> function only once, and you must call it before you subscribe to AASB messages or start the Engine.</p>"},{"location":"native/#specify-configuration-in-a-file","title":"Specify configuration in a file","text":"<p>Auto SDK provides the <code>ConfigurationFile</code> class that reads the JSON configuration from a specified file path and creates an <code>EngineConfiguration</code> object from the configuration:</p> <pre><code>#include &lt;AACE/Core/EngineConfiguration.h&gt;\n\naace::core::config::ConfigurationFile::create( \"&lt;/path/to/filename.json&gt;\" )\n</code></pre> <p>You can include all the configuration data in a single JSON file to create a single <code>EngineConfiguration</code> object. For example,</p> <pre><code>auto config = aace::core::config::ConfigurationFile::create( \"/opt/AAC/config/config.json\" );\n\nengine-&gt;configure(config);\n</code></pre> <p>Alternatively, you can break the configuration data into multiple JSON files to create multiple <code>EngineConfiguration</code> objects. For example,</p> <pre><code>auto coreConfig = aace::core::config::ConfigurationFile::create( \"/opt/AAC/data/core-config.json\" );\nauto alexaConfig = aace::core::config::ConfigurationFile::create( \"/opt/AAC/data/alexa-config.json\" );\nauto navigationConfig = aace::core::config::ConfigurationFile::create( \"/opt/AAC/data/navigation-config.json\" );\n\nengine-&gt;configure({coreConfig, alexaConfig, navigationConfig});\n</code></pre>"},{"location":"native/#specify-configuration-programmatically","title":"Specify configuration programmatically","text":"<p>Each Auto SDK module that defines configuration provides a factory class with functions that return <code>EngineConfiguration</code> objects. The values a function puts in the configuration it creates correspond to the function parameters. For example, you can configure the <code>Alexa</code> module's <code>notificationsCapabilityAgent</code> settings by using the <code>AlexaConfiguration::createNotificationsConfig()</code> function:</p> <pre><code>auto notificationConfig = aace::alexa::config::AlexaConfiguration::createNotificationsConfig(\"&lt;/some/directory/path/for/databases/notifications.db&gt;\" );\n</code></pre>"},{"location":"native/#register-for-aasb-messages","title":"Register for AASB Messages","text":"<p>After you configure the Engine, get the <code>MessageBroker</code> instance from the <code>Engine</code> instance:</p> <pre><code>std::shared_ptr&lt;aace::core::MessageBroker&gt; messageBroker = engine-&gt;getMessageBroker();\n</code></pre> <p>Use <code>MessageBroker</code> to subscribe to any AASB messages that your application will handle. See Understand how to use MessageBroker for further information. </p> <p>Note: For one Engine instance, you must subscribe to messages after configuring the Engine and before starting the Engine.</p>"},{"location":"native/#start-the-engine","title":"Start the Engine","text":"<p>After configuring the Engine and subscribing to AASB messages, start the Engine by calling the <code>Engine::start()</code> function:</p> <p><pre><code>engine-&gt;start();\n</code></pre> Engine start initializes the internal Engine components for each Engine service your application uses. With respect to Alexa, <code>start</code> initiates the connection to Alexa if there is an internet connection and an Alexa access token. Wait to publish AASB messages to the Engine until after <code>start()</code> returns.</p> <p>Your application can start the Engine more than once in its lifetime, if needed, by stopping the Engine and starting it again. However, you cannot start the Engine again after shutting it down.</p>"},{"location":"native/#stop-the-engine","title":"Stop the Engine","text":"<p>When your application needs to halt the operations of the Engine, stop the Engine by calling the <code>Engine::stop()</code> function:</p> <p><pre><code>engine-&gt;stop();\n</code></pre> With respect to Alexa, stopping the Engine tears down the Alexa connection. Typically, Engine stop is a cleanup step before Engine shutdown. However, if you stopped the Engine at runtime and need to start it again, calling <code>start()</code> resumes Engine operations. With respect to Alexa, this includes reestablishing the Alexa connection.</p>"},{"location":"native/#shut-down-the-engine","title":"Shut down the Engine","text":"<p>When your application is ready to exit, shut down the Engine by calling the Engine's <code>shutdown()</code> function.</p> <pre><code>engine-&gt;shutdown();\n</code></pre> <p>Make sure you also stop the Engine prior to shutting it down. After shutdown completes, you can safely dispose of the pointer to your Engine instance. You cannot use this instance of the Engine again.</p>"},{"location":"native/#understand-how-to-use-messagebroker","title":"Understand how to use MessageBroker","text":"<p>As outlined in Auto SDK Core API Overview, your application will use <code>MessageBroker</code> to interface with the Engine by exchanging AASB messages. The Message Broker uses AASB messages as serialized JSON strings; however, Auto SDK provides C++ wrapper classes for each message that help with the serialization and de-serialization. The Auto SDK build system generates these wrapper classes as part of the build. For example, if the build output archive file is <code>aac-dev-macos_x86_64-release-220111103523.tgz</code>, the extracted archive contains the AASB messages for each interface in a directory structure like the following example:</p> <p><pre><code>aac-dev-macos_x86_64-release-220111103523\n    \u251c\u2500\u2500 aac-buildinfo.txt\n    \u251c\u2500\u2500 bin\n    \u251c\u2500\u2500 docs\n    \u251c\u2500\u2500 include\n    \u2502   \u251c\u2500\u2500 AACE\n    \u2502   \u2514\u2500\u2500 AASB\n    \u2502       \u2514\u2500\u2500 Message\n    \u2502           \u251c\u2500\u2500 Alexa\n    \u2502           \u2502   \u251c\u2500\u2500 ...directory for other interface in Alexa module...\n    \u2502           \u2502   \u2502   \u251c\u2500\u2500 ...message header 1 for this other interface...\n    \u2502           \u2502   \u2502   \u2514\u2500\u2500 ...message header 2 for this other interface...\n    \u2502           \u2502   \u251c\u2500\u2500 SpeechRecognizer\n    \u2502           \u2502   \u2502   \u251c\u2500\u2500 EndOfSpeechDetectedMessage.h\n    \u2502           \u2502   \u2502   \u251c\u2500\u2500 Initiator.h\n    \u2502           \u2502   \u2502   \u251c\u2500\u2500 StartCaptureMessage.h\n    \u2502           \u2502   \u2502   \u251c\u2500\u2500 StopCaptureMessage.h\n    \u2502           \u2502   \u2502   \u2514\u2500\u2500 WakewordDetectedMessage.h\n    \u2502           \u2502   \u2514\u2500\u2500 ...directory for other interface in Alexa module...\n    \u2502           \u251c\u2500\u2500 ...directory for other module...\n    \u2502           \u2502   \u251c\u2500\u2500 ...directory for other interface in this module...\n    \u2502           \u2514\u2500\u2500 ...directory for other module...\n    \u251c\u2500\u2500 lib\n    \u2514\u2500\u2500 share\n</code></pre> The header file <code>StartCaptureMessage.h</code>, for example, represents the incoming <code>SpeechRecognizer.StartCapture</code> AASB message, and the header contains a class your application can use to build the message in the correct format and then convert it to a string to publish with <code>MessageBroker</code>. Similarly, the <code>WakewordDetectedMessage.h</code> header file contains a class your application can use to easily subscribe to the <code>SpeechRecognizer.WakewordDetectedMessage</code> message and de-serialize the message when you receive it from the Engine.</p> <p>The following example code uses the AASB message wrapper classes for the <code>SpeechRecognizer</code> interface to subscribe to messages from the Engine with <code>SpeechRecognizer</code> topic:</p> <pre><code>#include &lt;AASB/Message/Alexa/SpeechRecognizer/EndOfSpeechDetectedMessage.h&gt;\n#include &lt;AASB/Message/Alexa/SpeechRecognizer/WakewordDetectedMessage.h&gt;\n\n// call this function before starting the Engine\nvoid SpeechRecognizerHandler::subscribeToAASBMessages() {\nmessageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleEndOfSpeechDetectedMessage(message); },\nEndOfSpeechDetectedMessage::topic(),   // equivalent to \"SpeechRecognizer\"\nEndOfSpeechDetectedMessage::action()); // equivalent to \"EndOfSpeechDetected\"\n\nmessageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleWakewordDetectedMessage(message); },\nWakewordDetectedMessage::topic(),      // equivalent to \"SpeechRecognizer\"\nWakewordDetectedMessage::action());    // equivalent to \"WakewordDetected\"\n}\n\nvoid SpeechRecognizerHandler::handleEndOfSpeechDetectedMessage(const std::string&amp; message) {\n// Your application defines this handling function.\n// MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message.\n\n// Per the AASB message documentation, this message has no payload.\n\n// Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread.\n}\n\nvoid SpeechRecognizerHandler::handleWakewordDetectedMessage(const std::string&amp; message) {\n// Your application defines this handling function.\n// MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.WakewordDetected message.\n\n// You can use the WakewordDetectedMessage class to deserialize the message.\n// The payload of this message is simple, but other messages may contain more complex payloads.\nWakewordDetectedMessage msg = json::parse(message);\nstd::string ww = msg.payload.wakeword; // This string contains the wake word that the Engine detected\n\n// Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread.\n}\n</code></pre> <p>For every AASB message interface that you wish to handle, your application will define code like the above example in which you define a function to handle each \"outgoing\" message (or one function to handle all outgoing messages) and subscribe the function to <code>MessageBroker</code> by specifying the topic and action combination that the function will handle. In the implementation of the handling functions, you must return quickly and delegate any time-consuming handling to a worker thread.</p> <p>When you need to publish an \"incoming\" message to the Engine, you can construct the message JSON string directly or, preferably because it's simpler, use the AASB message helper class to construct the message and convert it to a string. Then use <code>MessageBroker</code> to publish the message to the Engine. For example,</p> <pre><code>#include &lt;AASB/Message/Alexa/SpeechRecognizer/Initiator.h&gt;\n#include &lt;AASB/Message/Alexa/SpeechRecognizer/StartCaptureMessage.h&gt;\n\n\n// call this function when the user tapped the Alexa invocation button to initiate an interaction\nvoid SpeechRecognizerHandler::tapToTalk(Initiator initiator) {\nStartCaptureMessage msg;\nmsg.payload.initiator = Initiator::TAP_TO_TALK;\nm_messageBroker-&gt;publish(msg.toString());\n}\n</code></pre> <p>Only publish messages to the Engine after the Engine was started successfully (i.e., after <code>Engine::start()</code> returned <code>true</code>).</p>"},{"location":"native/#implement-features","title":"Implement features","text":"<p>The Auto SDK feature documentation provides detailed documentation for each individual Auto SDK module and explains the Engine configuration and AASB messages you must implement in order to use the features the module provides. Follow the feature documentation as you integrate features into your application.</p>"},{"location":"native/#tip-to-get-started-quickly","title":"Tip to get started quickly","text":"<p>To get your application up and running as quickly as possible if you wish to develop features incrementally, you can start by integrating only the <code>Core</code>, <code>Alexa</code>, <code>CBL</code>, and <code>System Audio</code> modules. In particular, follow these high level guidelines:</p> <ul> <li>Implement the Engine lifecycle management described above.</li> <li>Read the documentation for each of these four modules.</li> <li>Provide the required Engine configuration for each of these modules.</li> <li>Integrate the AASB messages for the following interfaces:<ul> <li><code>Authorization</code><ul> <li>Note: <code>CBL</code> completes most of the implementation for you.</li> </ul> </li> <li><code>AudioInput</code> and <code>AudioOutput</code><ul> <li>Note: <code>System Audio</code> completes the implementation for you.</li> </ul> </li> <li><code>PropertyManager</code><ul> <li>Note: You can start by handling only the properties defined by the modules you initially use</li> </ul> </li> <li><code>SpeechRecognizer</code> with <code>TAP_TO_TALK</code> initiation.</li> </ul> </li> </ul> <p>After you have completed this bare minimum integration, you should be able to start the Engine in your application and invoke Alexa by button press to ask a simple question such as \"What's the weather?\"</p>"},{"location":"native/building/","title":"Build Alexa Auto SDK","text":""},{"location":"native/building/#supported-platforms-and-architectures","title":"Supported platforms and architectures","text":"<p>Auto SDK can be built for the following supported target platforms and hardware architectures:</p> <ul> <li>Android 5.1 Lollipop API Level 22 or higher.<ul> <li>ARM 64-bit</li> <li>x86 64-bit</li> </ul> </li> <li>QNX 7.0<ul> <li>ARM 64-bit</li> <li>x86 64-bit</li> </ul> </li> <li>Generic Linux<ul> <li>x86 64-bit</li> </ul> </li> <li>Poky Linux<ul> <li>ARMv7a (+NEON)</li> <li>AArch64</li> </ul> </li> <li>macOS<ul> <li>x86 64-bit</li> </ul> </li> </ul> <p>To build Auto SDK for other platforms or architectures, see Build with a custom toolchain.</p>"},{"location":"native/building/#general-build-requirements","title":"General build requirements","text":"<p>You can build the Alexa Auto SDK natively on a Linux or macOS host, or you can use Docker. For specific information about Docker, see Build in a Docker container.</p> <p>The following list describes the supported host configurations:</p> <ul> <li>Operating system:<ul> <li>macOS Sierra</li> <li>Ubuntu 18.04 LTS (Bionic) or Ubuntu 20.04 LTS (Focal)</li> </ul> </li> <li>Processor: 2.5 GHz</li> <li>Memory: 16 Gb</li> <li>Storage: 1 Gb+ available to use</li> </ul>"},{"location":"native/building/#build-dependencies","title":"Build dependencies","text":"<p>To build Auto SDK, you must install the following dependencies on your host machine:</p>"},{"location":"native/building/#general","title":"General","text":"<ul> <li>Python 3.7</li> <li>Conan 1.45</li> <li>CMake 3.12</li> </ul>"},{"location":"native/building/#linux","title":"Linux","text":"<ul> <li>GCC</li> <li>GStreamer (see Install GStreamer)</li> </ul>"},{"location":"native/building/#macos","title":"macOS","text":"<ul> <li>Xcode</li> </ul>"},{"location":"native/building/#understand-the-build-system","title":"Understand the build system","text":"<p>Building software for multiple platforms can be complex because specific toolchains might vary depending on the build system and target platform. In general, there are two flavors of builds: native and cross-compiled. In a native build, the build system uses its own toolchain and libraries to build the software, so the compiled software can run on the platform that built it. In cross-compilation, the build system typically uses an installed toolchain to compile the software for a different target platform. It's possible that more than one toolchain is installed on a system, so extra steps are typically needed to cross-compile to those targets. Auto SDK uses Conan, along with other tools and scripts described in this section, to manage the complexities required to implement a complete build system.</p>"},{"location":"native/building/#conan","title":"Conan","text":"<p>The Auto SDK build system uses Conan as its underlying package manager and build configuration tool. For every Conan package, there is a recipe that defines the dependencies of the package and specifies how to download and build the package source code. After building a package, Conan copies the binaries and other artifacts into a cache directory so other recipes that depend on that package can use the prebuilt binaries without rebuilding them. When a Conan recipe defines a dependency, Conan finds and builds the dependency as required, taking care of complexities such as transitive requirements, package version conflicts, and managing multiple versions of a package built with different configurations.</p> <p>Before using a package, Conan must export or download the package into the local cache. When a package recipe exists in the same local repository as the source code it builds, as is the case when you download Auto SDK, you must run <code>conan create</code> or <code>conan export</code> before other recipes can build the package. Community servers such as Conan Center host some popular third party libraries, however, so Conan automatically downloads them to the local cache as needed. Auto SDK requires a combination of Conan packages including local recipes for Auto SDK modules and tools, local recipes for third party packages, and third party packages hosted on the Conan Center server.</p> <p>Once Conan copies a package into the local cache, a recipe can build or consume the package based on the specified build configuration. Conan will build a new package version if the package version is required and missing from the cache. For example, if you build Auto SDK for Linux, Conan will build all of the required packages for the specified Linux target. If you then build for an Android target, Conan will rebuild all of the required packages for the Android target and cache both the Linux and Android versions. In addition to target platform, any option or setting that you specify when building a recipe affects the package version.</p>"},{"location":"native/building/#auto-sdk-modules","title":"Auto SDK modules","text":"<p>Auto SDK includes a base Conan recipe class that all Auto SDK modules extend. This is defined in <code>conan/recipes/aac-sdk-tools</code>, and must be exported before other modules since it is required by each module's recipe definition. The base recipe defines common build options, and relies on specific conventions in the module's directory structure to find source files and headers, and to generate other artifacts that are needed at build time. A simple Conan recipe is required for each module to override abstract values in the base class (such as the module name), and to define any module specific dependencies or options that are required. A module can also define it's own CMake files, unique configuration, or even custom build steps as needed.</p> <p>For each module, the base recipe defines common options that are used to specify which components are included in the library. The default values provided in the base recipe should be used in most cases when you are building release libraries for production. For some cases, however, you may want to enabled features such as <code>with_sensitive_logs</code> or <code>with_unit_tests</code>, to add additional information when debugging issues with the libraries. To find out which options are defined for a specific module, you can use the <code>conan inspect</code> command to display information about any Conan recipe. This command will display all of options and default values for a recipe, including any options that are inherited from the base module recipe. See the Specify build settings and options section in this guide, for more information.</p> <p>Applications integrate with Auto SDK using the <code>MessageBroker</code> API by publishing and subscribing to specific message topics and actions (see Understand the Auto SDK API). Most modules provide interfaces that require these messages to be defined, in which case they will include one or more message definition files in the <code>aasb/messages</code> directory of the module. The model created by the message definitions are used when building Auto SDK to generate message headers that are required to build the module, and are also used to create documentation for each message interface.</p>"},{"location":"native/building/#third-party-dependencies","title":"Third party dependencies","text":"<p>Auto SDK has dependencies on several third party packages (libraries and build tools for example), which may themselves have dependencies on other packages. In general, managing these types of build requirements can be very complex for a large project. Conan helps by providing community hosted recipes for many common packages, as well as by allowing developers to create there own package recipes. It is important to understand that some of the packages used by Auto SDK are pulled from the Conan Center remote server, while others are defined locally in the <code>conan/recipes</code> directory of Auto SDK. Local recipes are typically required when the package does not already exist on Conan Center, or there are specific patches or changes to the recipe that are needed for Auto SDK.</p>"},{"location":"native/building/#builder-tool","title":"Builder Tool","text":"<p>The Builder Tool is a script that can be used to build Auto SDK libraries for supported platforms. It improves the build process by wrapping underlying Conan commands and options with a simple command line interface. Although it is possible to use Conan by itself to build Auto SDK\u2014see Build with Conan directly\u2014it is recommended to use the Builder Tool for common build tasks.</p>"},{"location":"native/building/#build-with-builder-tool","title":"Build with Builder Tool","text":"<p>The Builder Tool script, <code>build.py</code> is located in the <code>builder</code> directory of the SDK. It wraps underlying Conan commands, and simplifies building libraries for Auto SDK modules on supported platforms. Individual modules, components, and dependencies in the SDK are described as packages in the builder. Each package has a corresponding Conan recipe that is used to build and deploy the package to the cache located in the builder's home directory. An archive containing all of the specified build artifacts is created from the cache, and written to the <code>deploy</code> directory of the builder, after the build has completed. This section describes the most common commands used to build Auto SDK. For a complete reference to the Builder Tool command line interface, see Builder Tool command reference.</p> <p>Auto SDK supports native builds for Ubuntu Linux (x86_64) and MacOS, and building for each platform follows the same steps. After cloning the Auto SDK git repository on your system, the following examples should be run with <code>alexa-auto-sdk</code> as the working directory.</p> <p>The following command will build all of the modules that are included in the Auto SDK repository, along with any dependencies that are required for the target platform:</p> <pre><code>$ ./builder/build.py\n</code></pre> <p>When you run the build command, the builder tool will export and configure any new build artifacts, such as package recipes or configuration files, that are discovered in the search path. The first time you run (or after cleaning the build cache), you'll see several log messages indicating that the build recipes are being exported to the local cache:</p> <pre><code>[BUILDER] INFO: Python version: 3.7.3\n[BUILDER] INFO: Cleaning cached builder data\n[BUILDER] INFO: Builder home: ../aac-sdk/builder/.builder\n[BUILDER] INFO: Conan home: ../aac-sdk/builder/.builder/.conan\n[BUILDER] INFO: Gradle home: ../aac-sdk/builder/.builder/.gradle\n[BUILDER] INFO: Configuring Conan...\n[BUILDER] INFO: Installing Conan configuration: ../aac-sdk/conan/config\n[BUILDER] INFO: Exporting recipe: aac-sdk-tools\n[BUILDER] INFO: Exporting recipe: aac-module-core\n[BUILDER] INFO: Exporting recipe: aac-module-alexa\n[BUILDER] INFO: Exporting recipe: aac-module-cbl\n[BUILDER] INFO: Exporting recipe: android-sdk-tools\n[BUILDER] INFO: Exporting recipe: avs-device-sdk\n...\n</code></pre> <p>The builder keeps track of which recipes have already been added to the cache, so that the next time you run the build command only new recipes will be exported. It is possible, however, to tell the builder to force re-exporting a recipe (using the <code>-f</code> or <code>--force</code> option), and build it if necessary. The following command will force all Auto SDK module recipes to be re-exported:</p> <pre><code>$ ./builder/build.py -f \"aac-module-*\"\n</code></pre> <p>To explicitly force one or more recipes to be exported, you can specify the name of the module (or explicit package name) that you want. The following example will force the builder to re-export and build only the <code>alexa</code> and <code>cbl</code> modules.</p> <pre><code>$ ./builder/build.py -f alexa cbl\n</code></pre> <p>Each time the builder is run, it will also attempt to re-configure Conan settings by initializing the Conan configuration and installing any config files found in the search path. This happens every time because it is possible, using Docker for example, to re-use the Conan home path when building with a different build system configuration. This step ensures that the Conan configuration will match the build system currently being used. In the case that you want to skip the configuration step for some reason (maybe you have overridden configuration settings in the Conan home manually), you can tell the builder to skip the configuration step using the <code>--skip-config</code> option:</p> <pre><code>$ ./builder/build.py --skip-config\n</code></pre>"},{"location":"native/building/#specify-the-build-target","title":"Specify the build target","text":"<p>Auto SDK can be cross-compiled for supported target systems by specifying the platform and architecture with the build command. Android and QNX targets can be built on either Linux or macOS, and Poky must be built using Linux. For information about specific build target requirements, see the Platform-specific build information section of this guide. To set the target platform using the Builder Tool, specify the <code>--platform,-p &lt;platform&gt;</code> option when doing a build:</p> <pre><code>$ ./builder/build.py -p android\n</code></pre> <p>You can also set the target architecture by specifying the  <code>--arch,-a &lt;architecture&gt;</code> option:</p> <pre><code>$ ./builder/build.py -p android -a x86_64\n</code></pre> <p>The following table defines the supported platforms and architectures.</p> platform arch android armv8, x86_64 qnx armv8, x86_64 poky armv8, armv7hf, x86_64, x86"},{"location":"native/building/#specify-which-modules-to-build","title":"Specify which modules to build","text":"<p>If you are using a subset of modules in Auto SDK, you can specify which modules to build on the command line using the <code>-m</code> or <code>--modules</code> option followed by a list of modules names. Dependent modules and libraries will be included transitively when specifying which modules to build. The following example will build the <code>core</code>, <code>alexa</code>, and <code>cbl</code> modules, and package them into the output archive:</p> <pre><code>$ ./builder/build.py -m core alexa cbl\n</code></pre> <p>You can verify which modules were specified in the build by looking at the <code>[requires]</code> section or <code>pkg_modules</code> option value in the <code>aac-buildinfo.txt</code> file:</p> <pre><code>[requires]\n    aac-module-alexa/dev\n    aac-module-cbl/dev\n    aac-module-core/dev\n\n[options]\n    ...\n    pkg_modules=aac-module-core/dev,aac-module-alexa/dev,aac-module-cbl/dev\n</code></pre> <p>You could also build the same modules by specifying the following on the command line:</p> <pre><code>$ ./builder/build.py -m cbl\n</code></pre> <p>This works because the <code>cbl</code> module depends on the <code>alexa</code> module, which depends on the <code>core</code> module, so even though they are not specified on the command line, <code>core</code> and <code>alexa</code> are transitively included. The <code>aac-buildinfo.txt</code> file will only show the <code>cbl</code> module under the <code>[requires]</code> section, however, the full list of included dependencies can be found under the <code>[full_requires]</code> section in the build info:</p> <pre><code>[full_requires]\n    aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5\n    aac-module-cbl/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c\n    aac-module-core/dev:fe4587e72f3350cdb9dab53b293dfee0d5575a0a\n    ...\n</code></pre>"},{"location":"native/building/#clean-build-artifacts","title":"Clean build artifacts","text":"<p>Conan caches binaries and artifacts for each package after it is built, so they can be used as dependencies by other packages without having to be re-built each time. If you make changes to the source code in the SDK, however, you must either explicitly force the builder to re-export and build the package (using the <code>--force,-f &lt;pattern&gt;</code> option of the builder), or remove the package entirely from the cache. To remove packages from the cache using the Builder Tool, you can use the <code>clean</code> command:</p> <pre><code>$ ./builder/build.py clean &lt;pattern&gt;\n</code></pre> <p>You must specify the package name or regex-style pattern to clean. For example, to remove all of the packages from the cache, you can use the following command:</p> <pre><code>$ ./builder/build.py clean \"*\"\n</code></pre> <p>To remove a specific module, you can either specify the package name or just the module's name:</p> <pre><code>$ ./builder/build.py clean alexa\n</code></pre> <p>Since the convention used by Auto SDK is to specify the module's package name as <code>aac-module-&lt;name&gt;</code>, you can also use the full package name as part of the pattern. One way to remove all Auto SDK modules from the cache would be to use the following command:</p> <pre><code>$ ./builder/build.py clean \"aac-module-*\"\n</code></pre> <p>If a package has been removed from the cache, the Builder Tool will automatically detect that it needs to be re-exported and built the next time you do a build, and it is not necessary to specify the package using the <code>--force</code> option.</p>"},{"location":"native/building/#build-debug-libraries","title":"Build debug libraries","text":"<p>Building debug libraries for Auto SDK can be specified by using the <code>--debug</code> or <code>-g</code> option when doing a build:</p> <pre><code>$ ./builder/build.py -g\n</code></pre> <p>When this option is used, debug libraries for all of the Auto SDK modules and dependencies will be built if required, and exported to the build archive. If you want more specific control over which debug libraries to use, you can specify the <code>build_type</code> option as a Conan setting instead, using the <code>--conan-setting,-s &lt;name&gt;=&lt;value&gt;</code> build option. For example, to use debug libraries only for Auto SDK modules, you can use the following build command:</p> <pre><code>$ ./builder/build.py -s \"aac-module-*\":build_type=Debug\n</code></pre> <p>This is a less common use case, however, that requires you to be familiar with some of the underlying Conan build architecture. To learn more about some of the Conan specific options for building Auto SDK, see the Build with Conan directly section of this guide.</p>"},{"location":"native/building/#locate-the-build-output","title":"Locate the build output","text":"<p>When you run the builder tool, all of the shared libraries and dependencies will be saved in an archive file in the <code>builder/deploy</code> directory by default. The name of the archive file is displayed in the console when the build is completed:</p> <pre><code>[BUILDER] INFO: Created output archive: ../aac-dev-macos_x86_64-release-210706140415.tgz\n</code></pre> <p>The default name of the archive indicates the following information that is used to build the SDK:</p> <pre><code>aac-&lt;version&gt;-&lt;os&gt;_&lt;arch&gt;-&lt;build-type&gt;-&lt;datetime&gt;.tgz\n</code></pre> <p>Sometimes it is helpful to tag a build with an identifier, for example, if you want to indicate a build was made for a specific purpose. If you want to add an additional identifier to the archive name, you can use <code>--name</code> option when running the build tool:</p> <pre><code>$ ./builder/build.py --name test\n...\n[BUILDER] INFO: Created output archive: ../aac-dev-test-macos_x86_64-release-210706142403.tgz\n</code></pre> <p>It is also possible to completely override the output file name and path by specifying the <code>-o</code> or <code>--output</code> option on the command line:</p> <pre><code>$ ./builder/build.py --output /mypath/custom-output.tgz\n...\n[BUILDER] INFO: Created output archive: /mypath/custom-output.tgz\n</code></pre> <p>If you don't want the builder to generate an output archive at all, you can specify the <code>--no-output</code> option on the command line. This is helpful if you just want to re-build one or more module, for example, to run unit tests or inspect the package libraries:</p> <pre><code>$ ./builder/build.py --no-output\n</code></pre>"},{"location":"native/building/#archive-contents","title":"Archive contents","text":"<p>The output archive created by the Builder Tool includes all of the build artifacts from the modules and dependencies specified by the build command. You can extract the archive with the following command (the exact filename will be slightly different for your build):</p> <pre><code>$ tar -xvzf builder/deploy/aac-dev-linux_x86_64-release.tgz\n</code></pre> <p>After you can extract the contents of the archive, there should be a directory with contents similar to the following file structure:</p> <pre><code>aac-dev-linux_x86_64-release/\n  \u251c\u2500 docs/\n  \u251c\u2500 include/\n  \u251c\u2500 lib/\n  |  \u251c\u2500 libAACECore.so\n  |  \u2514\u2500 ...\n  \u251c\u2500 share/\n  \u2514\u2500 aac-buildinfo.txt\n</code></pre> <p>You can get additional information about the archive contents from a description file in the archive named <code>aac-buildinfo.txt</code>. The build description file can be used to identify which modules, settings, and options were used to generate the libraries by the build. The following is an example of the information found in the build description file:</p> <pre><code>[settings]\n    arch=x86_64\n    build_type=Release\n    compiler=apple-clang\n    compiler.libcxx=libc++\n    compiler.version=11.0\n    os=Macos\n\n[requires]\n    aac-module-aasb/dev\n    aac-module-address-book/dev\n    aac-module-alexa/dev\n    aac-module-car-control/dev\n    aac-module-cbl/dev\n    aac-module-connectivity/dev\n    aac-module-core/dev\n    aac-module-messaging/dev\n    aac-module-navigation/dev\n    aac-module-phone-control/dev\n    aac-module-text-to-speech/dev\n\n[options]\n    aac_version=dev\n    with_sensitive_logs=False\n    pkg_modules=aac-module-aasb/dev,aac-module-address-book/dev,aac-module-alexa/dev,...\n    with_aasb=False\n\n[full_settings]\n    arch=x86_64\n    build_type=Release\n    compiler=apple-clang\n    compiler.libcxx=libc++\n    compiler.version=11.0\n    os=Macos\n\n[full_requires]\n    aac-module-aasb/dev:4990d7e4c95bbcae311c6d13cb0e71a09ecd2f43\n    aac-module-address-book/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c\n    aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5\n    ...\n</code></pre>"},{"location":"native/building/#build-with-conan-directly","title":"Build with Conan directly","text":"<p>Conan can be used directly to build Auto SDK components and other package dependencies, or to use Auto SDK libraries in other Conan recipes. It's helpful to have a good general understanding of how Conan works first, and also to understand the basic Auto SDK build system. The examples in this section should be run with <code>aac-sdk</code> as the working directory.</p>"},{"location":"native/building/#export-conan-recipes","title":"Export Conan recipes","text":"<p>The following script will find all of the Conan recipes in Auto SDK and export them to the local cache. Package binaries won't actually be built until they are required by another recipe during a build operation, or explicitly built by running the <code>conan create</code> command. This is a convenience script and is not required if you want to export or create packages individually.</p> <pre><code>$ ./conan/setup.py\n</code></pre> <p>If you want to export a single package individually, you can run the <code>conan export</code> command. For example, to export the alexa module to the local cache:</p> <pre><code>$ conan export modules/alexa\n</code></pre> <p>It is important to understand that exporting a module using the <code>conan export</code> command does not automatically find and export any of the dependent packages specified in the recipe. Attempting to build the alexa module would fail, unless all of the requirements can be resolved in the local cache. Running the <code>conan/setup.py</code> script is usually the safest option to ensure all required packages are copied to the cache, however, exporting a package individually can save time after you make changes, if you have previously exported all of the packages.</p>"},{"location":"native/building/#build-modules","title":"Build modules","text":"<p>In most cases it shouldn't be necessary to manually build Auto SDK modules, since Conan can build missing dependencies when required by another recipe. It is possible, however, to create/build a package independently using Conan if needed. The following example shows how to create the Alexa module package from the command line:</p> <pre><code>$ conan create modules/alexa --build missing\n</code></pre> <p>The <code>conan create</code> command tells conan to create a new binary package from a recipe file and install it in the local cache. In the example above, <code>modules/alexa</code> refers to the parent directory in Auto SDK (<code>aac-sdk/modules/alexa</code>), where the <code>conanfile.py</code> recipe is located for the Alexa module.</p> <p>By specifying the <code>--build missing</code> option, Conan will automatically build dependencies where a binary package is missing for the specified build configuration. If the dependency has already been created it will not be built again.</p> <p>Using the <code>--build</code> flag without any additional options will force all of the dependencies to be rebuilt, even if the binary for the specified configuration already exists.</p>"},{"location":"native/building/#specify-build-settings-and-options","title":"Specify build settings and options","text":"<p>When you build a Conan package, you can specify settings and options that result in different binaries when the source code is built. Conan <code>settings</code> are project-wide configurations, such as <code>os</code>, <code>compiler</code>, <code>build_type</code>, and <code>arch</code>. These settings should be applied to each package when selecting the correct binary. Most of the time, settings will be applied based on the selected (or default) profile. To view or modify a profile, you can use the <code>conan profile</code> command. To show the default profile values, you can enter the following command:</p> <pre><code>$ conan profile show default\n\nConfiguration for profile default:\n\n[settings]\nos=Macos\nos_build=Macos\narch=x86_64\narch_build=x86_64\ncompiler=apple-clang\ncompiler.version=11.0\ncompiler.libcxx=libc++\nbuild_type=Release\n[options]\n[build_requires]\n[env]\n</code></pre> <p>You usually don't need to change settings specified in the profile, but if needed, you can override any setting value when running a Conan command. For example, to build a debug version of the alexa module, you can add <code>-s build_type=Debug</code> to the <code>conan create</code> command:</p> <pre><code>$ conan create modules/alexa -b missing -s build_type=Debug\n</code></pre> <p>Individual packages can also define <code>options</code> which are specific to it's own build requirements. One common option that most packages define is <code>shared</code>, which is used to build either the static or dynamic library. Options can also be used to specify conditional features which should be included in the build, for example, <code>libcurl</code> defines an option called <code>with_nghttp2</code> to specify that the build should include support for <code>http2</code>.</p>"},{"location":"native/building/#inspect-package-recipes","title":"Inspect package recipes","text":"<p>To see which options a recipe has defined, you can use the <code>conan inspect</code> command:</p> <pre><code>$ conan inspect modules/alexa/conanfile.py\n\nname: aac-module-alexa\nversion: dev\nurl: https://github.com/alexa/alexa-auto-sdk\nhomepage: None\nlicense: Apache-2.0\nauthor: None\ndescription: Auto SDK module: alexa\ntopics: None\ngenerators: cmake\nexports: None\nexports_sources: *\nshort_paths: False\napply_env: True\nbuild_policy: None\nrevision_mode: hash\nsettings: ('os', 'compiler', 'build_type', 'arch')\noptions:\n    message_version: ANY\n    shared: [True, False]\nwith_aasb: [True, False]\nwith_address_sanitizer: [True, False]\nwith_android_libs: [True, False]\nwith_coverage_tests: [True, False]\nwith_docs: [True, False]\nwith_engine: [True, False]\nwith_jni: [True, False]\nwith_metrics: [True, False]\nwith_messages: [True, False]\nwith_platform: [True, False]\nwith_sensitive_logs: [True, False]\nwith_unit_tests: [True, False]\ndefault_options:\n    message_version: 4.0\n    shared: True\n    with_aasb: True\n    with_address_sanitizer: False\n    with_android_libs: True\n    with_coverage_tests: False\n    with_docs: True\n    with_engine: True\n    with_jni: True\n    with_metrics: True\n    with_messages: True\n    with_platform: True\n    with_sensitive_logs: False\n    with_unit_tests: False\ndeprecated: None\n</code></pre> <p>This command shows different attributes of the package, including its <code>options</code> and the default values for each option specified in <code>default_options</code>. To override a default option when building a package, you can add <code>-o [option]=[value]</code>. If you want to override an option for a specific package, then you can specify the package name as well, <code>-o [pkg]:[option]=[value]</code>. For example, to build and run unit tests for the alexa module, you can add <code>-o with_unit_tests=True</code> to the <code>conan create</code> command:</p> <pre><code>$ conan create modules/alexa -b missing -o with_unit_tests=True\n</code></pre>"},{"location":"native/building/#remove-packages-from-the-cache","title":"Remove packages from the cache","text":"<p>Packages can be removed from the local cache if needed by using the <code>conan remove</code> command. For example, the following command can be used to remove the alexa module from the cache:</p> <pre><code>$ conan remove aac-module-alexa -f\n</code></pre> <p>The <code>-f</code> option is used to remove the package without confirmation. To remove all Auto SDK modules from the cache, you can specify the following pattern <code>aac-module-*</code> in place of a package name, or specify <code>*</code> to remove all packages:</p> <pre><code>$ conan remove \"aac-module-*\" -f\n$ conan remove \"*\"\n</code></pre> <p>Note: when specifying a wildcard in the package name, you must surround the pattern with quotes.</p>"},{"location":"native/building/#use-auto-sdk-in-other-recipes","title":"Use Auto SDK in other recipes","text":"<p>If you have your own project that uses Conan, to build an application or library for example, you can include Auto SDK packages in the requirements section of your Conan recipe. The following example shows how you can include Auto SDK modules that are built on the same development machine, in a <code>conanfile.txt</code> recipe:</p> <pre><code>[requires]\naac-module-core/dev\naac-module-alexa/dev\naac-module-cbl/dev\naac-module-system-audio/dev\n...\n</code></pre> <p>When you build your package, as long as the Auto SDK packages have been exported to the local cache, Conan will include the specified modules when building your project. It is important to note the convention used by Auto SDK, where all module packages are named <code>aac-module-&lt;module_name&gt;</code>, and the default package version when building locally will be <code>dev</code> unless overridden at build time.</p> <p>You can add Auto SDK modules as a requirement to <code>conanfile.py</code> recipes as well, by specifying them using the <code>requires</code> attribute in the recipe:</p> <pre><code>class ConanRecipe(ConanFile):\n    requires =\n        [\"aac-module-core/dev\",\"aac-module-alexa\",\"aac-module-cbl/dev\",\"aac-module-system-audio/dev\"]\n    ...\n</code></pre>"},{"location":"native/building/#platform-specific-build-information","title":"Platform-specific build information","text":""},{"location":"native/building/#android","title":"Android","text":"<p>Android can be cross-compiled on either MacOS or Linux, using the NDK toolchain build requirement specified in the <code>aac-android</code> profile. To build Android compatible binaries with the Builder Tool, simply use the <code>--platform</code> or <code>-p</code> option to specify the <code>android</code> platform.</p> <pre><code>$ ./builder/build.py -p android\n</code></pre> <p>By default the android configuration used to build the SDK is defined in the <code>aac-android</code> Conan profile:</p> <pre><code>[settings]\nos=Android\nos.api_level=26\narch=armv8\nbuild_type=Release\ncompiler=clang\ncompiler.libcxx=libc++\ncompiler.version=8\n\n[build_requires]\nandroid-sdk-tools/4.0@aac-sdk/stable\n</code></pre> <p>You can override default target architecture to build either the <code>armv8</code>, or <code>x86_64</code> version of the binaries by specifying the <code>--arch</code> or <code>-a</code> option on the command line:</p> <pre><code>$ ./builder/build.py -p android --arch=x86_64\n</code></pre> <p>The first time you build Auto SDK for Android, the Android SDK must be downloaded and installed. This is handled by the <code>android-sdk-tools</code> recipe in Auto SDK when you build, however, several license agreements must be manually accepted before any of the Android tools can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying <code>-y</code> or <code>--accept-licenses</code> when running the builder from the command line.</p> <p>If you are using Conan directly to build Auto SDK libraries, you must specify the <code>--profile:host,-pr:b</code> and <code>--profile:build,-pr:b</code> options as part of the build command. In this case for Android, you would specify <code>aac-android</code> as the host (target) profile in your build command, in addition to explicitly specifying <code>default</code> as the build profile:</p> <pre><code>$ conan create modules/alexa -pr:h aac-android -pr:b default -b missing\n</code></pre> <p>You can override any setting for the target platform on the command line, for example, to build the <code>x86_64</code> version of the Android libraries you can specify <code>-s:h arch=x86_64</code> as an option:</p> <pre><code>$ conan create modules/alexa -pr:h aac-android -pr:b default -b missing -s:h arch=x86_64\n</code></pre>"},{"location":"native/building/#ubuntu","title":"Ubuntu","text":"<p>Building Auto SDK for Linux on Ubuntu requires installing some additional dependencies, such as GStreamer if you are using the <code>system-audio</code> module.</p>"},{"location":"native/building/#install-gstreamer","title":"Install GStreamer","text":"<p>The <code>system-audio</code> module uses GStreamer to implement the core audio interfaces, and must be installed prior to building. The following command will install the dependencies required to build with GStreamer:</p> <pre><code>$ apt install -y \\\npkg-config libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\\nlibgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base \\\ngstreamer1.0-plugins-good gstreamer1.0-plugins-bad \\\ngstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc \\\ngstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl \\\ngstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio\n</code></pre>"},{"location":"native/building/#update-the-default-conan-profile","title":"Update the default Conan profile","text":"<p>You might run into an issue on Ubuntu where Conan does not detect the default <code>libstdc++11</code> setting properly, so it is recommended to check this when setting up your host environment. You can run the following command to update the default Conan profile to use the <code>libstdc++11</code> compiler option:</p> <pre><code>$ conan profile new default --detect\n$ conan profile update settings.compiler.libcxx=libstdc++11 default\n</code></pre>"},{"location":"native/building/#poky","title":"Poky","text":"<p>Poky can be cross compiled on Linux using the host Poky SDK toolchain. To build Poky compatible binaries with the Builder Tool, simple use the <code>--platform</code> or <code>-p</code> option to specify the <code>poky</code> platform.</p> <pre><code>$ ./builder/build.py -p poky\n</code></pre> <p>By default the poky configuration used to build the Auto SDK is defined in the aac-poky Conan profile:</p> <pre><code>[settings]\ncompiler.version=8.2\narch=armv7hf\nbuild_type=Release\nos=Linux\ncompiler.libcxx=libstdc++11\n\n[build_requires]\npoky-sdk/2.6.1\n</code></pre> <p>You can override default target architecture to build either the <code>armv7hf</code>, or <code>armv8</code> version of the binaries by specifying the <code>--arch</code> or <code>-a</code> option on the command line:</p> <pre><code>$ ./builder/build.py -p poky --arch=armv8\n</code></pre> <p>The first time you build Auto SDK for Poky, the Poky SDK must be downloaded and installed. This is handled by the <code>poky-sdk</code> recipe in Auto SDK when you build, however, several license agreements must be manually accepted before the Poky SDK can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying <code>-y</code> or <code>--accept-licenses</code> when running the builder from the command line.</p> <p>If you are using Conan directly to build Auto SDK libraries, you must specify the <code>--profile:host,-pr:h</code> and <code>--profile:build,-pr:b</code> options as part of the build command. In this case for Poky, you would specify <code>aac-poky</code> as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile:</p> <pre><code>$ conan create modules/alexa -pr:h aac-poky -pr:b default -b missing\n</code></pre> <p>You can override any setting for the target platform on the command line, for example, to build the <code>armv8</code> version of the Poky libraries you can specify <code>-s:h arch=armv8</code> as an option:</p> <pre><code>$ conan create modules/alexa -pr:h aac-poky -pr:h default -b missing -s:h arch=armv8\n</code></pre>"},{"location":"native/building/#qnx","title":"QNX","text":"<p>QNX can be cross compiled on Linux or MacOS using the host QNX SDP tools. To build QNX, you must install the QNX 7.0 SDP on your host as a prerequisite. To build QNX compatible binaries with the Builder Tool, simply use the <code>--platform</code> or <code>-p</code> option to specify the <code>qnx</code> platform:</p> <pre><code>$ ./builder/build.py -p qnx\n</code></pre> <p>By default the QNX configuration used to build the Alexa Auto SDK is defined in the <code>aac-qnx</code> Conan profile:</p> <pre><code>[settings]\nos=Neutrino\nos.version=7.0\narch=armv8\ncompiler=qcc\ncompiler.version=5.4\ncompiler.libcxx=cxx\ncompiler.cppstd=None\n\n[build_requires]\nqnx-cross-compiling/7.0.0\n[options]\n[env]\n</code></pre> <p>You can override default target architecture to build either the <code>armv8</code>, or <code>x86_64</code> version of the binaries by specifying the <code>--arch</code> or <code>-a</code> option on the command line:</p> <pre><code>$ ./builder/build.py -p qnx --arch=x86_64\n</code></pre> <p>The Conan recipe assumes that the QNX SDP is installed in your home director: <code>~/qnx700</code>, but you can override this by setting the <code>qnx7sdp_path</code> option using the <code>--conan-option</code> or <code>-o</code> argument on the command line:</p> <pre><code>$ ./builder/build.py -p qnx -o qnx7-sdp:qnx7sdp_path=/path/to/qnx7sdp\n</code></pre>"},{"location":"native/building/#macos_1","title":"macOS","text":"<p>macOS can be used as a build host for cross-compiled Android and QNX targets, as well and target for native development and testing.</p>"},{"location":"native/building/#windows","title":"Windows","text":"<p>Windows is not currently supported as a build host or target.</p>"},{"location":"native/building/#build-with-a-custom-toolchain","title":"Build with a custom toolchain","text":"<p>You can cross-compile Auto SDK for platforms or architectures other than the officially supported targets using the cross-compilation support provided by Conan.</p> <p>To build Auto SDK with a custom toolchain, you need to create a new Conan profile, Conan recipe, and CMake toolchain file. The following example demonstrates building Auto SDK for ARMv8 Linux using the CodeSourcery toolchain.</p> <p>1. Create a new Conan profile</p> <p>Create a new Conan profile file at <code>${AUTO_SDK_HOME}/conan/config/profiles/aac-codesourcery</code> with the following content:</p> <pre><code>include(default)\n\n[settings]\ncompiler.version=7.5\narch=armv8\nbuild_type=Release\nos=Linux\ncompiler.libcxx=libstdc++11\n\n[build_requires]\ncodesourcery/1.0.0\n\n[options]\n\n[env]\n</code></pre> <p>2. Create a new Conan recipe</p> <p>Create a new Conan profile at <code>${AUTO_SDK_HOME}/conan/recipes/codesourcery/conanfile.py</code> with the following content:</p> <pre><code>import os, logging\n\nfrom conans import ConanFile, tools\nfrom conans.errors import ConanInvalidConfiguration\n\n\nclass CodeSourceryConan(ConanFile):\n    name = \"codesourcery\"\n    version = \"1.0.0\"\n    description = \"Cross-compiling with CodeSourcery toolchain\"\n\n    settings = {\"os\": [\"Linux\", \"Macos\"], \"arch\": [\"x86\", \"x86_64\", \"armv7hf\", \"armv8\"]}\n\n    exports = \"*.cmake\"\n\n    def configure(self):\n        if self.settings_target.arch not in [\"armv7hf\", \"armv8\"]:\n            raise ConanInvalidConfiguration(f\"Invalid arch {self.settings_target.arch}\")\n\n    def _check_toolchain_override(self, force=True):\n        var = f\"CODESOURCERY_TOOLCHAIN_{self.settings_target.arch}\"\n        toolchain_override = os.getenv(var)\n        if force and not toolchain_override:\n            raise ConanInvalidConfiguration(f\"{var} is not exported\")\n        if toolchain_override and not os.path.exists(toolchain_override):\n            raise ConanInvalidConfiguration(f\"{toolchain_override} does not exist\")\n        return toolchain_override\n\n    def _check_sysroot_override(self, force=True):\n        var = f\"CODESOURCERY_SYSROOT_{self.settings_target.arch}\"\n        sysroot_override = os.getenv(var)\n        if force and not sysroot_override:\n            raise ConanInvalidConfiguration(f\"{var} is not exported\")\n        if sysroot_override and not os.path.exists(sysroot_override):\n            raise ConanInvalidConfiguration(f\"{sysroot_override} does not exist\")\n        return sysroot_override\n\n    def source(self):\n        pass\n\n    def build(self):\n        pass\n\n    def package(self):\n        toolchain = self._check_toolchain_override(True)\n        self.copy(\"*.cmake\", src=self.recipe_folder, dst=self.package_folder)\n\n    def map_arch_string(self, arch):\n        return {\n            \"armv8\": (\"aarch64\", \"gnu\"),\n            \"armv7hf\": (\"arm\", \"gnueabihf\"),\n        }[arch]\n\n    def _append_path(self, var, path):\n        if os.path.isdir(path):\n            var.append(path)\n\n    def package_info(self):\n        toolchain = self._check_toolchain_override(True)\n        sysroot = self._check_sysroot_override(False)\n\n        self._append_path(self.env_info.PATH, os.path.join(toolchain, \"bin\"))\n        arch, abi = self.map_arch_string(str(self.settings_target.arch))\n\n        # Specify toolchain executables\n        prefix = f\"{arch}-linux-{abi}\"\n        self.env_info.CC = f\"{prefix}-gcc\"\n        self.env_info.CFLAGS = f\"--sysroot {sysroot}\" if sysroot else \"\"\n        self.env_info.CXX = f\"{prefix}-g++\"\n        self.env_info.CXXFLAGS = self.env_info.CFLAGS\n        self.env_info.CPP = f\"{prefix}-cpp\"\n        self.env_info.AR = f\"{prefix}-ar\"\n        self.env_info.RANLIB = f\"{prefix}-ranlib\"\n        self.env_info.LD = f\"{prefix}-ld\"\n        self.env_info.LDFLAGS = f\"\"\n        self.env_info.AS = f\"{prefix}-as\"\n        self.env_info.STRIP = f\"{prefix}-strip\"\n        self.env_info.OBJCOPY = f\"{prefix}-objcopy\"\n        self.env_info.OBJDUMP = f\"{prefix}-objdump\"\n        self.env_info.READELF = f\"{prefix}-readelf\"\n        self.env_info.NM = f\"{prefix}-nm\"\n\n        # Specify CMake toolchain file and environment variables it expects to use.\n        self.env_info.CONAN_CMAKE_TOOLCHAIN_FILE = os.path.join(self.package_folder, \"codesourcery_toolchain.cmake\")\n        self.env_info.CODESOURCERY_TOOLCHAIN_PREFIX = prefix\n        if sysroot:\n            self.env_info.CODESOURCERY_SYSROOT = sysroot\n</code></pre> <p>The new Conan recipe sets the required build context. This example recipe performs the following setup:</p> <ul> <li>Checks the environment variables <code>CODESOURCERY_TOOLCHAIN_armv8</code> and <code>CODESOURCERY_SYSROOT_armv8</code> to find the location of the custom toolchain and sysroot.</li> <li>Exports <code>CC</code>, <code>CXX</code>, <code>CFLAGS</code>, <code>CXXFLAGS</code> and other environment variables for GNU Make and CMake to use the specified compiler and flags.</li> <li>Exports <code>CONAN_CMAKE_TOOLCHAIN_FILE</code> to specify the toolchain configuration for CMake.</li> </ul> <p>3. Create a CMake toolchain file</p> <p>The Conan recipe in the previous step references a CMake toolchain file at <code>${AUTO_SDK_HOME}/conan/recipes/codesourcery/codesourcery_toolchain.cmake</code>. Create this file with the following content:</p> <pre><code>set(CMAKE_SYSTEM_NAME Linux)\nset(CMAKE_SYSTEM_VERSION 1)\n\nif(\"$ENV{CODESOURCERY_TOOLCHAIN_PREFIX}\" STREQUAL \"\")\nmessage(FATAL_ERROR \"Define the CODESOURCERY_TOOLCHAIN_PREFIX environment variable to specify toolchain prefix, e.g aarch64-none-linux-gnu.\")\nelse()\nset(CODESOURCERY_TOOLCHAIN_PREFIX \"$ENV{CODESOURCERY_TOOLCHAIN_PREFIX}\")\nset(CMAKE_C_COMPILER   ${CODESOURCERY_TOOLCHAIN_PREFIX}-gcc)\nset(CMAKE_CXX_COMPILER ${CODESOURCERY_TOOLCHAIN_PREFIX}-g++)\nendif()\n\nif(\"$ENV{CODESOURCERY_SYSROOT}\" STREQUAL \"\")\nmessage(WARNING \"Define the CODESOURCERY_SYSROOT environment variable to point to the sysroot.\")\nelse()\nset(CODESOURCERY_SYSROOT \"$ENV{CODESOURCERY_SYSROOT}\")\nmessage(STATUS \"Using sysroot path: ${CODESOURCERY_SYSROOT}\")\n\n# Specify where compiler/linker looks for system include files and libraries\nset(CMAKE_SYSROOT \"${CODESOURCERY_SYSROOT}\")\n\n# Specify where cmake find_xxx looks for files\nset(CMAKE_FIND_ROOT_PATH \"${CMAKE_SYSROOT}\")\nset(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)\nset(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)\nset(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)\nset(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)\nendif()\n</code></pre> <p>See cmake-toolchains(7) for more detailed information about further customization.</p> <p>4. Build Auto SDK with the custom toolchain</p> <p>Run the setup script to export your new Conan recipe before building Auto SDK:</p> <pre><code>$ ./conan/setup.py\n</code></pre> <p>Specify your Conan profile and target platform when running the Auto SDK Builder Tool:</p> <pre><code>$ ./builder/build.py build -p codesourcery --arch armv8\n</code></pre>"},{"location":"native/building/#build-in-a-docker-container","title":"Build in a Docker container","text":"<p>You can use Docker for native Linux builds, or any cross-compiler target that is supported with Linux, as long as the Docker container has the required build dependencies installed. For convenience, you can use the <code>aac-ubuntu-bionic</code> or <code>aac-ubuntu-focal</code> containers provided in the <code>conan/docker</code> directory of the SDK. The following commands should be run with <code>aac-sdk</code> as the working directory.</p> <p>Create the <code>aac-ubuntu-bionic</code> docker image:</p> <pre><code>$ docker build -t aac/ubuntu-bionic conan/docker/aac-ubuntu-bionic\n</code></pre> <p>Build Auto SDK using the Builder Tool:</p> <pre><code>$ docker run -it -v$(pwd):/home/conan/aac-sdk --rm \\\naac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py\"\n</code></pre> <p>The option <code>-v$(pwd):/home/conan/aac-sdk</code> specifies that we want to mount the current directory on the host machine (which should be the Auto SDK root), to <code>/home/conan/aac-sdk</code> in the Docker container file system. After starting the container, you will be able to build Auto SDK using Conan with the same commands used on your host machine.</p> <p>When the build is complete, the output archive file will be saved to the mounted <code>aac-sdk/builder/deploy</code> directory of your host machine. If you inspect <code>aac-buildinfo.txt</code> in the archive, you should see that the libraries were built for <code>os=Linux, arch=x86_64</code>:</p> <pre><code>[settings]\n    arch=x86_64\n    build_type=Release\n    compiler=gcc\n    compiler.libcxx=libstdc++11\n    compiler.version=7\n    os=Linux\n</code></pre>"},{"location":"native/building/#optimize-build-performance","title":"Optimize build performance","text":"<p>When you build Auto SDK using a Docker container it can take much longer to build than it would natively on your host computer. This is because the Builder Tool home directory is specified as <code>aac-sdk/builder</code> by default, which is a directory on the host file system. File operations in general are much slower when running on a mounted volume, so this will impact the build performance. One option is to specify a different home directory on the container's volume when running the build command instead. This will greatly improve the build time, however, you should be aware that when you remove the container the cached build artifacts may be lost. The Builder Tool will still write the output archive to <code>aac-sdk/builder/deploy</code> on the mounted volume by default, even if the home directory is changed.</p> <p>The following example shows how you can set the home directory using the <code>--home</code> option, when doing a build using Docker:</p> <pre><code>$ docker run -it -v$(pwd):/home/conan/aac-sdk --rm \\\naac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py --home /home/conan\"\n</code></pre>"},{"location":"native/api/","title":"C++ API Reference","text":""},{"location":"native/api/#aasb-message-reference","title":"AASB Message Reference","text":"<p>See the AASB Message Reference for detailed information about each AASB message interface.</p>"},{"location":"native/api/#c-class-reference","title":"C++ Class Reference","text":"<p>See the C++ Class Reference for detailed information about the C++ API including the <code>Engine</code>, <code>MessageBroker</code>, and configuration factory classes.</p>"},{"location":"native/sample-app/","title":"Alexa Auto SDK C++ Sample App","text":""},{"location":"native/sample-app/#overview","title":"Overview","text":"<p>The purpose of the C++ Sample App is to provide useful example code to help you integrate your implementation with the Alexa Auto SDK. The C++ Sample App provides an example of creating and configuring an instance of the Engine, and using the MessageBroker API to subscribe to messages from the Engine. It also provides examples of handling audio and stream based interfaces with the MessageStream API, and replying to messages from the Engine. The C++ Sample App also includes detailed logs for interactions with the Alexa Auto SDK, as well as UI elements relevant to the implementation.</p>"},{"location":"native/sample-app/#prerequisites","title":"Prerequisites","text":""},{"location":"native/sample-app/#amazon-developer-account","title":"Amazon developer account","text":"<p>To use the C++ Sample App, you need an Amazon Developer account.</p>"},{"location":"native/sample-app/#register-product-and-security-profile","title":"Register product and security profile","text":"<p>After creating an Amazon developer account, you'll need to register a product and create a security profile on the AVS developer portal.</p> <p>When you follow the instructions to fill in the product information:</p> <ul> <li>Use your own custom information, taking note of the Product ID, as this information is required to configure the Sample App.</li> <li>Be sure to select Automotive from the Product category pull-down.</li> </ul> <p>When you follow the instructions to set up your security profile, generate a Client ID and take note of it, as this information is required to configure the Sample App.</p>"},{"location":"native/sample-app/#optional-device-capabilities","title":"Optional device capabilities","text":"<p>In order to use certain optional Alexa Auto SDK functionality (for example, AmazonLite Wake Word, Alexa Communications, and Local Voice Control (LVC)) with the Sample App, your product must be placed on the allow list by Amazon. Copy the product's Amazon ID from the Developer Console and follow the directions on the Need Help? page.</p> <p>Note: Most of the commands that follow are meant to be run from this <code>alexa-auto-sdk</code> directory.</p>"},{"location":"native/sample-app/#build-and-run-the-sample-app","title":"Build and Run the Sample App","text":"<p>Before you build and run the Sample App, it is recommended that you first review and understand how to build Auto SDK. The Sample App can be built by using the Auto SDK Builder Tool, or by using Conan to build the Auto SDK and Sample App packages directly. Each option is described in more detail in this section.</p>"},{"location":"native/sample-app/#build-using-builder-tool","title":"Build using Builder Tool","text":"<p>The C++ Sample App can be built using the Auto SDK Builder Tool by specifying the <code>--with-sampleapp</code> or <code>--sampleapp</code> option when doing a build. The following examples should be run with <code>alexa-auto-sdk</code> as the working directory.</p> <p>To build Auto SDK and Sample App with all modules included:</p> <pre><code>$ ./builder/build.py --with-sampleapp\n</code></pre> <p>The build archive is created in the <code>builder/deploy</code> directory, and will include the Sample App binary, along with all of the required libs and configuration files needed to run the application. The name of the archive will depend on your build settings, but in general will match the following pattern:</p> <pre><code>aac-&lt;version&gt;-&lt;os&gt;_&lt;arch&gt;-&lt;build-type&gt;-&lt;datetime&gt;.tgz\n</code></pre> <p>You can extract the contents of the build archive to any location on your target device, with the following command:</p> <pre><code>$ tar -xvzf &lt;archive&gt;.tgz\n</code></pre> <p>After extracting the contents, the directory structure should look something like the following:</p> <pre><code>aac-dev-linux_x86_64-release/\n  \u251c\u2500 bin/\n  |  \u2514\u2500 SampleApp \n  \u251c\u2500 docs/\n  \u251c\u2500 include/\n  \u251c\u2500 lib/\n  |  \u251c\u2500 libAACECore.so \n  |  \u2514\u2500 ... \n  \u251c\u2500 share/\n  |  \u251c\u2500 sampleapp/\n  |  |  \u251c\u2500 certs/\n  |  |  \u251c\u2500 config/\n  |  |  |  \u2514\u2500 config.json \n  |  |  \u251c\u2500 inputs/\n  |  |  \u251c\u2500 menu/\n  |  |  |  \u2514\u2500 menu.json \n  |  |  \u2514\u2500 sampledata/\n  |  \u2514\u2500 ... \n  \u2514\u2500 aac-buildinfo.txt\n</code></pre>"},{"location":"native/sample-app/#run-the-sample-app","title":"Run the Sample App","text":"<p>Before running the Sample App, you are required to configure the settings defined in the <code>share/sampleapp/config/config.json</code> file, including setting up your unique client ID and product information. This is described in more detail in the Configure the Sample App section of this document. Once the configuration changes have been made, you can run the Sample App from the root directory of the extracted archive using the following command:</p> <pre><code>$ DYLD_LIBRARY_PATH=lib:+:${DYLD_LIBRARY_PATH} \\\nLD_LIBRARY_PATH=lib:+:${LD_LIBRARY_PATH} \\\n./bin/SampleApp -c share/sampleapp/config/config.json -m share/sampleapp/menu/menu.json\n</code></pre>"},{"location":"native/sample-app/#build-using-conan","title":"Build using Conan","text":"<p>The Auto SDK C++ Sample App can be configured using the provided Conan recipe, and then built with CMake. The Conan recipe requires packages that are defined as part of Auto SDK, which must first be installed into the local cache (see Build Alexa Auto SDK for instructions about how to install Auto SDK Conan packages). If you are specifying any additional dependencies, such as extra modules for Auto SDK, those packages must also be installed in the Conan cache before configuring the Sample App.</p> <p>If the required dependencies are already installed, the following commands can be used to quickly configure, build and run the Sample App.</p> <pre><code># export auto sdk conan dependencies\n$ python conan/setup.py\n\n# configure the sample app and install it in a build directory\n$ conan install samples/cpp -if=build-sampleapp -b missing\n\n# build the sample app in the build directory\n$ conan build samples/cpp -bf=build-sampleapp\n\n# run the sample app from the build directory\n$ cd build-sampleapp\n$ DYLD_LIBRARY_PATH=lib:+:${DYLD_LIBRARY_PATH} \\\nLD_LIBRARY_PATH=lib:+:${LD_LIBRARY_PATH} \\\n./bin/SampleApp -c ./config/config.json -m ./menu/menu.json\n</code></pre> <p>Note: These examples assume your working directory is set to the root <code>alexa-auto-sdk</code> directory.</p>"},{"location":"native/sample-app/#specify-build-options","title":"Specify build options","text":"<p>You can use the following command line options with the Conan install command. The options are defined in the Conan recipe:</p> <p><code>aac_modules</code> - Specify default Auto SDK modules to build with the Sample App. This is a comma separated list of modules that must be installed in the Conan local cache before building. If this option is not overridden, the default value will be <code>core, alexa, cbl, system-audio</code>.</p> <p><code>extra_modules</code> - Specify additional modules to build with the Sample App. This is a comma separated list of modules that must be installed in the Conan local cache before building. This is a useful option if you want to specify modules to build in addition to the default modules, rather than replacing the default modules entirely.</p> <p>You can specify the options above using <code>-o</code> when running the Conan command. For example, to specify additional modules that are included when building the Sample App, you can us the following option:</p> <pre><code>$ conan install samples/cpp -if=build-sampleapp -b missing \\ \n-o extra_modules=\"navigation,phone-control\"\n</code></pre>"},{"location":"native/sample-app/#specify-environment-variables-for-configuration-values","title":"Specify environment variables for configuration values","text":"<p>For convenience, a config file template has been included for the core Auto SDK modules with well-known tokens (e.g. <code>CLIENT_ID</code>, <code>PRODUCT_ID</code>) for various configuration values. You can set environment variables for these tokens; when building the Sample App, they will be replaced in the configuration file.</p> <p>For example you can set an environment variable when running <code>conan install</code> like this:</p> <pre><code>$ CLIENT_ID=xxxx \\\nPRODUCT_ID=xxxx \\\nconan install ...\n</code></pre>"},{"location":"native/sample-app/#configure-the-sample-app","title":"Configure the Sample App","text":"<p>You can pass one or more configuration files to the Sample App using the <code>--config &lt;config-file-path&gt;</code> flag. When you build additional modules with the sample app, you may need to pass module-specific configuration. Please refer to the <code>README</code> file within each module to get this configuration information. </p> <p>For convenience, a config file template has been included for the core Auto SDK modules. You must customize this template with values specific to your implementation. You can either edit the configuration file manually or specify environment variables that can be used to override the configuration values when building the Sample App with Conan, see how to specify environment variables for configuration values.</p> <p>To change the config file manually, follow these steps:</p> <ol> <li> <p>Edit the config file template and save it.</p> </li> <li> <p>Replace the <code>${YOUR_CLIENT_ID}</code>, <code>${YOUR_PRODUCT_ID}</code>, and <code>${YOUR_DEVICE_SERIAL_NUMBER}</code> placeholders with your values as follows:</p> <ul> <li>Replace <code>${YOUR_CLIENT_ID}</code> with the Client ID, which you can find in your device's Security Profile under the Other devices and platforms tab.</li> <li>Replace <code>${YOUR_PRODUCT_ID}</code> with the Product ID, which you can find under the Products tab on the AVS Developer Console. (It is different from the Amazon ID.)</li> <li>Replace <code>${YOUR_DEVICE_SERIAL_NUMBER}</code> with an arbitrary value that must not contain spaces and must be unique.</li> </ul> <p>Note: The Client ID and Product ID must correspond to a development device profile that you created as an automotive product by selecting the <code>Automotive</code> product category when you filled in the product information.  </p> </li> <li> <p>Replace the <code>${DATA_PATH}</code> and <code>${CERTS_PATH}</code> with paths to your database and certificates, respectively. You must ensure that the directories exist and have write permissions.</p> <p>Note: The Auto SDK engine will fail to start if the database directory path does not exist or does not have write permissions.</p> </li> <li> <p>Modify the vehicle information (<code>aace.vehicle</code>) to match your vehicle specifics.</p> </li> </ol>"},{"location":"native/sample-app/#use-the-sample-app","title":"Use the Sample App","text":""},{"location":"native/sample-app/#authenticate-with-avs-using-code-based-linking-cbl","title":"Authenticate with AVS using Code-Based Linking (CBL)","text":"<p>Every request to AVS requires an Login with Amazon (LWA) access token. Code-Based Linking (CBL) is the recommended method to acquire access tokens and is demonstrated by the C++ Sample App. After the Sample App launches, you will see the Main Menu. Follow these steps to authorize your device with AVS using CBL.</p>"},{"location":"native/sample-app/#start-the-cbl-authorization","title":"Start the CBL authorization","text":"<ol> <li>Press <code>A</code>, the Sample App displays the below message:</li> </ol> <p><pre><code>################################################################################\n#                                                                              #\n#                              Authorization Menu                              #\n#                                                                              #\n################################################################################\n\n[ 1 ]    Start CBL Authorization\n    [ esc ]  Go back\n    ```\n\n2. Press `1` to start the CBL authorization. The Sample App displays messages, including a code and a URL in a format similar to the following:\n</code></pre>     ###########################               123456        ############################################          url: http://www.amazon.com/us/code      ############################################     ```    </p> <p>Note: You may have to scroll up to see the code and URL.</p> <ol> <li>Open a browser and navigate to the URL displayed in the Sample App.</li> <li>In the browser, enter the code displayed in the Sample App.</li> <li>Click Continue and follow the instructions in the browser to complete the authentication.</li> </ol>"},{"location":"native/sample-app/#cancel-the-authorization","title":"Cancel the authorization","text":"<p>After you start the authorization, the <code>Authorization</code> menu displays option [1] for you to cancel the authorization that is in progress. Press <code>1</code> to cancel the authorization.</p> <pre><code>################################################################################\n#                                                                              #\n#                              Authorization Menu                              #\n#                                                                              #\n################################################################################\n\n[ 1 ]    Cancel CBL Authorization\n [ esc ]  Go back\n</code></pre>"},{"location":"native/sample-app/#log-out-of-the-cbl-authorization","title":"Log out of the CBL authorization","text":"<p>After the device is registered successfully, the Sample App displays option [1] in the <code>Authorization</code> menu for you to log out of CBL authorization. Press <code>1</code> to log out from the authorization.</p> <pre><code>################################################################################\n#                                                                              #\n#                              Authorization Menu                              #\n#                                                                              #\n################################################################################\n\n[ 1 ]    Logout CBL Authorization\n [ esc ]  Go back\n</code></pre>"},{"location":"native/sample-app/#multimedia-support-for-qnx","title":"Multimedia support for QNX","text":"<p>The C++ Sample App supports the BlackBerry QNX Multimedia Suite for live audio input and output on QNX platforms. </p> <p>Note: The SHOUTcast/lcecast streaming format is not supported.</p> <p>See the System Audio module documentation for details about configuring audio input and output on QNX platforms.</p>"},{"location":"native/sample-app/#audiofile-menu","title":"AudioFile menu","text":"<p>The C++ Sample App provides an AudioFile menu to send pre-recorded utterances. Responses are saved as MP3 audio files within the current directory where the app was run. Refer to the C++ Sample App Menu System documentation for information on how to extend the AudioFile menu with custom audio files. However, this menu is only available if there is no default audio provider specified during the build. By default the Auto SDK Builder will build the C++ Sample App with the <code>System Audio</code> configuration defined in the <code>config-system-audio.json</code> file.</p> <p>Note: The AudioFile menu appears on platforms that do not provide built-in audio support (such as platforms that are under development). On platforms that provide built-in audio support, the AudioFile menu does not appear. </p>"},{"location":"native/sample-app/#handle-unknown-locations-for-navigation-use-cases","title":"Handle unknown locations for navigation use-cases","text":"<p>Your platform implementation should handle cases where a GPS location cannot be obtained by returning the <code>UNDEFINED</code> value provided by the Auto SDK. In these cases, the Auto SDK does not report the location in the context, and your platform implementation should return a localization object initialized with <code>UNDEFINED</code> values for latitude and longitude ((latitude,longitude) = (<code>UNDEFINED</code>,<code>UNDEFINED</code>)) in the context object of every SpeechRecognizer event. </p>"},{"location":"native/sample-app/#enable-siriusxm-as-a-local-media-source","title":"Enable SiriusXM as a local media source","text":"<p>The Sample App does not configure SiriusXM as a local media source by default. If you need the SiriusXM local media source, you must enable and build it. To do this, add the following line to the list of local media sources in the <code>Application.cpp</code> class then rebuild the Sample App:</p> <p><code>{ aace::alexa::LocalMediaSource::Source::SIRIUS_XM, nullptr }</code></p> <p>Note: When SiriusXM is present as a local media source, the cloud defaults to local SiriusXM only and blocks any use of the cloud SiriusXM service even if the local implementation/service is unavailable or not enabled. </p>"},{"location":"native/sample-app/#using-sample-app-with-3rd-party-wakewords","title":"Using Sample App with 3rd Party Wakewords","text":"<p>The C++ Sample App provides a reference implementation to help OEMs integrate with Siri and Apple CarPlay. The app demonstrates how OEMs can use CarPlay in Voice Activity Detection (VAD) and Keyword Detection (KWD) modes. In the VAD mode, the sample app integrates with Amazon's PryonLite VAD APIs to showcase voice activity detection and time stamp calculations</p>"},{"location":"native/sample-app/#building-sample-app","title":"Building Sample App","text":"<p>To use the sample app with 3P CarPlay capabilities, build with the following flag: <pre><code>$ builder/build.py -o aac-sampleapp:with_3pva=True --with-sampleapp\n</code></pre></p> <p>The sample app will include the <code>AgentHandler</code> and supporting files needed to demonstrate the CarpPlay features. You will also need to include the Amazonlite Extension in your build.  Contact your Amazon Solutions Architect (SA) or Partner Manager to obtain the correct Pryonlite package for Amazonlite to support VAD and corresponding Amazonlite Extension.</p>"},{"location":"native/sample-app/#features-for-carplay","title":"Features for CarPlay","text":"<p>To access the CarPlay features, select Car Play or \u201cC\u201d from the main menu</p> <p>[ C ]  Car Play Menu</p> <p>The Car Play features allows you to: </p> <ol> <li>Register/Deregister Siri as the 3P agent</li> <li>Trigger Siri interactions</li> <li>Set CarPlay modes (VAD, Keyword detection, Deactivated)</li> </ol> <pre><code>################################################################################\n#                                                                              #\n#                              Car Play Menu                                   #\n#                                                                              #\n################################################################################\n[A]    Agent registration\n[S]    SIRI Interaction\n[M]    Car Play Mode\n[esc]  Go back\n</code></pre>"},{"location":"native/sample-app/#agent-registration","title":"Agent Registration","text":"<pre><code>################################################################################\n#                                                                              #\n#                              Agent registration Menu                         #\n#                                                                              #\n################################################################################\n[ 1 ]    Register SIRI Agent\n [ 2 ]    Deregister SIRI Agent\n [ esc ]  Go back\n</code></pre>"},{"location":"native/sample-app/#siri-interaction","title":"Siri Interaction","text":"<p>Once Siri is registered and in CarPlay Keyword mode (see CarPlay Modes section below), you can invoke Siri with the wake word or use the \u201cButton Down\u201d option to simulate a gesture (Push-to-talk/Tap-to-talk) in this Siri interaction menu</p> <pre><code>################################################################################\n#                                                                              #\n#                            SIRI Interaction Menu                             #\n#                                                                              #\n################################################################################\n\n[ 1 ]    Button Down\n [ 2 ]    Set State to SPEAKING\n [ 3 ]    Set State to NONE\n [ esc ]  Go back\n ```\nWhen Siri is granted dialog, you can also use this menu to simulate dialog state changes on behalf of Siri. (*Note*: In an actual integration, the device will send dialog state changes to your application. Your application must publish the messages for setting the dialog states in Auto SDK).\n\n### CarPlay Modes\n\nYou can use the following menu to set CarPlay in one of the three modes.\n```shell\n\n################################################################################\n#                                                                              #\n#                              Car Play Mode Menu                              #\n#                                                                              #\n################################################################################\n\n[ 1 ]    VAD\n [ 2 ]    Keyword\n [ 3 ]    Deactivated\n [ esc ]  Go back\n</code></pre> <p>The OEM application integrates with CarPlay APIs, handles the different modes, and communicates with the device (iPhone). The sample app demonstrates the following:</p> <p>In VAD mode, the sample app demonstrates how to:</p> <ol> <li>Create an instance of PryonLite VAD/SRD with parameters for SRD config and register for VAD detection callback.</li> <li>Feed audio to the PryonLite VAD/SRD instance (in 10 ms chunks), keep track of (save) the timestamps and the offsets of the chunks and calculate the Start Of Speech (SoS) timestamp using the offset given by the PryonLite instance and the saved timestamps.</li> <li>Create a requestSiri event with the SoS timestamp to send to the device.</li> </ol>"},{"location":"native/sample-app/#vad-mode-voice-activity-detection","title":"VAD Mode - Voice Activity Detection","text":"<pre><code>There are 2 options to enable VAD feature.\n* Mic Audio \n* Audio File\n</code></pre> <p><pre><code>################################################################################\n#                                                                              #\n#                              VAD Mode Menu                                   #   \n#                                                                              #\n################################################################################\n\n[ 1 ]    Mic Audio\n    [ 2 ]    Audio File Input\n    [ esc ]  Go back\n</code></pre> In order to enable this feature, a config for PryonLiteVAD which is given below should be added in the SampleApp Config, to provide path to Pryonlite models which are copied over to the <code>share/amazonlite/models</code> folder, after untarring the <code>.tgz</code> file. In future if in Amazonlite package, model file inside Pryonlite package, update this file name <code>(.bin)</code> as well in this config. (name of model file can be found inside <code>share/amazonlite/models</code> folder).</p> <pre><code>    \"pryonLiteVAD\": {\n\"rootPath\": \"${PATH_TO_WW_LOCALE_MODELS}\",\n        \"models\": \"H.ar-SA+de-DE+en-AU+en-CA+en-GB+en-IN+en-US+es-MX+es-US+fr-CA+fr-FR+hi-IN+it-IT+ja-JP+pt-BR.alexa+siri.bin\"\n}\n</code></pre> <p>If the Keyword Detection mode, the app demonstrates how to:</p> <ol> <li>Stop the instance of PryonLite VAD/SRD if previously running.</li> <li>Publish AASB message to Auto SDK to enable \"Siri\" wakeword.</li> <li>Handle \"Siri\" keyword detected messages from Auto SDK.</li> <li>Publish message to Auto SDK (Arbitrator) to request dialog.</li> <li>If the dialog is granted, calculate the start of the keyword time stamp with the indices sent in the keyword detected callback.</li> <li>Create a requestSiri event with the start of the keyword timestamp to send to the device.</li> </ol>"},{"location":"native/sample-app/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>When interacting with Alexa, if the Dialog State goes from <code>LISTENING</code> immediately to <code>IDLE</code>, you might not be logged in. Try logging into your account via CBL by tapping <code>A</code> from the Main Menu.</p> <p>Note: For security reasons, authentication is not persisted if you quit the Sample App.  Upon relaunch, you must re-authenticate via CBL.  Restarting the app using the menu system, however, preserves authentication.</p> </li> <li> <p>If the device serial number is not unique, the authentication state bounces between <code>PENDING</code> and <code>CONNECTED</code> states:</p> <pre><code>Auth state changed: REFRESHED ( NO_ERROR )\nConnection status changed: PENDING ( ACL_CLIENT_REQUEST )\nConnection status changed: CONNECTED ( ACL_CLIENT_REQUEST )\nConnection status changed: PENDING ( SERVER_SIDE_DISCONNECT )\nstatus changed: CONNECTED ( ACL_CLIENT_REQUEST )\nConnection status changed: PENDING ( SERVER_SIDE_DISCONNECT )\n...\n</code></pre> </li> </ul> <p>To resolve this, edit the <code>samples/cpp/assets/config.json</code> file and choose a unique serial number.</p>"},{"location":"releases/","title":"Auto SDK Release Notes","text":""},{"location":"releases/#change-log","title":"Change log","text":"<p>Learn about the latest Auto SDK features, enhancements, resolved issues, and known issues in the Auto SDK change log.</p> <p>&gt;&gt; Change log</p>"},{"location":"releases/#migration-guide","title":"Migration guide","text":"<p>Keep your Auto SDK version up-to-date with help from the Auto SDK migration guide, which describes changes you'll need to make when upgrading your application to the latest Auto SDK version.</p> <p>&gt;&gt; Migration guide</p>"},{"location":"releases/changelog/","title":"Change Log","text":""},{"location":"releases/changelog/#v43-released-on-2023-06-15","title":"v4.3 Released on 2023-06-15","text":""},{"location":"releases/changelog/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>AACS and the Alexa Auto App are no longer part of the Alexa Auto SDK. Please contact your Amazon SA partner for how to get newer version of AACS and Alexa Auto App.</li> </ul>"},{"location":"releases/changelog/#enhancements","title":"Enhancements","text":"<ul> <li>Added new Mobile Bridge module that provides platform-agnostic implementation of 'Connect via Phone' functionality to automatically use customer's phone data to provide connectivtiy to Alexa in vehicle. For additional details, please contact your SA partner.</li> <li>Added <code>AlexaConfiguration::createMediaPlayerFingerprintConfig</code> for enabling Digital Rights Management (DRM) support</li> <li>Updated <code>AudioOutput</code> interface to provide info required for playing DRM-protected audio.</li> <li>Added the support to enable navigation to phone contact feature by uploading postal address while uploading phone contacts to cloud. Note: the end-to-end feature to allow the user to navigate to a contact will be available once the cloud side changes are in place.</li> <li>Refactored metrics infrastructure and overhauled the implementation.</li> </ul>"},{"location":"releases/changelog/#resolved-issues","title":"Resolved Issues","text":"<p>Communications</p> <ul> <li>Fixed the issue that Alexa-to-Alexa calls do not work on Linux armv8 platforms</li> </ul> <p>Local Voice Control</p> <ul> <li>Fixed the issue that Alexa responds with an error to the utterance \"Play FM radio\" and requests to tune to a station name.</li> </ul>"},{"location":"releases/changelog/#known-issues","title":"Known Issues","text":"<p>General</p> <ul> <li>The Alexa Automotive UX guidelines specify when to automatically dismiss a <code>TemplateRuntime</code> display card for each template type. The Engine publishes the <code>TemplateRuntime</code> interface messages <code>ClearTemplate</code> and <code>ClearPlayerInfo</code> based on the timeouts configured in the <code>aace.alexa.templateRuntimeCapabilityAgent</code> Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., <code>LocalSearchListTemplate2</code>) with a different timeout than other templates (e.g., <code>WeatherTemplate</code>). The configuration also does not provide a way for you to specify infinite timeout for <code>NowPlaying</code> cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly.</li> <li>There is a rare race condition in which publishing the <code>AlexaClient.StopForegroundActivity</code> message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the <code>THINKING</code> state <code>AlexaClient.DialogStateChanged</code> transition.</li> </ul> <p>Car control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try</li> </ul> <p>Communications</p> <ul> <li>The dual-tone multi-frequency (DTMF) does work correctly when selecting the number 1.</li> </ul> <p>Entertainment</p> <ul> <li>When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song.</li> <li>When using the LVC extension, if the application publishes the <code>MediaPlaybackRequestor.RequestMediaPlayback</code> AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the <code>RequestMediaPlayback</code> message.</li> </ul> <p>Local Voice Control</p> <ul> <li>Some contacts in the addressbook are not resolved correctly in offline mode.</li> </ul> <p>C++ sample app</p> <ul> <li>The sample app may fail to handle synchronous-style <code>AASB messages</code> within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected.</li> </ul>"},{"location":"releases/changelog/#v42-released-on-2022-12-21","title":"v4.2 Released on 2022-12-21","text":""},{"location":"releases/changelog/#enhancements_1","title":"Enhancements","text":""},{"location":"releases/changelog/#auto-sdk","title":"Auto SDK","text":"<ul> <li>Added <code>MultiAgent</code> components in AVS Device SDK. All the AVS directives and events are tagged with assistant ID. With the new MultiAgent environment, agent-based metrics are also introduced. The metrics can now be filtered by assistants, programs, and sources.</li> <li>When receiving <code>AlexaClient</code> messages, the payload of <code>DialogStateChanged</code> message will now have the ID of the assistant that the change is associated.</li> <li>Disabled timers, alarms, and reminders by removing the <code>Alerts</code> AVS capability from the Engine. The corresponding <code>Alerts</code> AASB messages and Engine configuration are also removed.</li> <li>The Alexa Auto SDK 3rd Party Wake Word (3PWW) feature provides OEMs an opportunity to enable support for 3rd party voice assistants (3PVA) such as Apple Siri on the same in-vehicle infotainment system alongside Alexa Custom Assistant (ACA)/Alexa wake words.</li> <li>Added the AASB message <code>AudioPlayer.SetAsForegroundActivity</code>, which the application can use to tell the Auto SDK Engine that the Alexa <code>AudioPlayer</code> interface is the foreground media source the user sees on screen. The <code>SetAsForegroundActivity</code> message is useful to ensure VUI and GUI commands act on the <code>AudioPlayer</code> source for scenarios in which the user played an Alexa media source (e.g., Amazon Music), switched to a different Alexa-aware external media source like FM radio or a deep-linked media app, and then manually returned visual activity to the Alexa media screen. The Alexa Auto App is updated to use the new message in the Alexa <code>MediaSession</code>.</li> <li>Updated the Alexa cloud retention period for address book storage from 24 hours to 30 days. Implementations can now reduce data usage by reducing the frequency of address book upload accordingly.</li> <li>Updated the Auto SDK to use AVS Device SDK Version 1.26.0. For information about this version of AVS Device SDK, see the AVS Documentation.</li> </ul>"},{"location":"releases/changelog/#alexa-auto-app","title":"Alexa Auto App","text":"<ul> <li>Renamed the AACS Sample App to Alexa Auto App. Any previous mentions of the name AACS Sample App should be treated the same as Alexa Auto App.</li> <li>Added a landing page to Alexa Auto App. The landing page provides sample utterances for supported domains and UI to update the settings.</li> <li>The Alexa Auto App has an updated UI for setup and settings screens. These improvements scale responsively for medium landscape screens (approximately 1300 x 900 resolution and screen size ranging from 1100dp to 1549dp).</li> <li>Updated Alexa Auto App to post a notification to the Notification Center when Alexa delivers a notification to the user. The user must ask Alexa to read their notifications to hear the notification content.</li> <li>Simplified building of the Alexa Auto App by reducing the number of build options during setup.</li> <li>Added SMS features to Alexa Auto App. The user can ask Alexa to read unread messages, send a message to a phone number or contact, and reply to a message using the primary bluetooth connected mobile phone.</li> <li>Removed the red voice chrome animation previously used when Alexa was not available. The voice chrome now uses the standard blue speaking animation as Alexa speaks an error prompt.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_1","title":"Resolved Issues","text":""},{"location":"releases/changelog/#auto-sdk_1","title":"Auto SDK","text":"<ul> <li>Fixed an issue in which the Engine would not send an <code>AudioOutput.Resume</code> message to the client app in cases where the client has not yet responded to the previous <code>AudioOutput.Pause</code> message. This could cause a state where the SDK thinks the transient pause initiated for user and Alexa dialog never finished, preventing any further Alexa media from playing until the head unit restarts.</li> <li>Fixed a race condition in <code>DoNotDisturb</code> capability agent that could cause a crash during Engine shutdown.</li> <li>Fixed an issue in which Alexa speech did not play when the user asks to redial while their phone is disconnected.</li> <li>Updated <code>MessageStream::write()</code> to return 0 when writing the data to the consumer fails rather than returning the data size.</li> <li>Fixed issues in which the Engine did not send the <code>TemplateRuntime.ClearTemplate</code> message at the right time.</li> <li>Pinned Conan package revisions of various dependencies to avoid sudden failures building Auto SDK.</li> <li>Fixed an issue in which the Engine did not send <code>TemplateRuntime.ClearPlayerInfo</code> when the user signs out.</li> <li>Fixed an issue in which the <code>Navigation.StartNavigation</code> AASB message did not include the correct POI details of the destination when the user selected the destination from the POI card shown on screen. Previously the \u201cname\u201d field in the template payload was populated with the address instead of the POI name.</li> <li>Fixed an issue in which the local navigation skill produced a second, duplicate <code>TemplateRuntime.RenderTemplate</code> message for the <code>LocalSearchDetailTemplate1</code> card when the user started offline navigation with Alexa.</li> <li>Fixed an issue in offline mode in which Alexa did not recognize followup requests like \"select the first one\" after the user requests a search for POIs or addresses.</li> </ul>"},{"location":"releases/changelog/#alexa-auto-app_1","title":"Alexa Auto App","text":"<ul> <li>Fixed various issues in the Alexa media session:<ul> <li>Rather than leaving the media session active and open indefinitely, the media session deactivates, stops its service, and removes the foreground service notification when media is no longer playing. The media service also sets the session to be inactive when the user signs out of their Alexa account or disables Alexa on the head unit.</li> <li>The media session no longer reports error states when there is no player or sign-in error. The issue in which the error state could overtake a valid state of active media and remove all its supported controls from the session, breaking the media app UI and the instrument cluster or media widget display, is also resolved.</li> <li>Previously, if the user played Alexa media and then switched to the Spotify app or a local media source, Alexa media could not resume with voice or button press after the user switched back to the Alexa media UI . This is resolved so the user can switch between the two types of Alexa-aware players and properly pause or resume the content they are viewing on screen.</li> <li>The media session clears its playback data and stops playback when the customer signs out of their Alexa account on the head unit. Also resolved the issues that un-recoverably corrupted the state of the media session after user sign out.</li> <li>Fixed issues in which the media session could report unexpected playback states to Auto SDK, causing problems such as not being able to resume properly when paused for an utterance or skipping to the next song unexpectedly.</li> </ul> </li> <li>Fixed an issue in which the Alexa Voice UI would remain open and transparent after the voice session ended.</li> <li>Fixed an issue in which the points of interest display card remained open when navigation started. Previously, the user had to manually close the card.</li> <li>Fixed an issue in which the wake word is recognized before the user signed in to their Alexa account when LVC is enabled.</li> <li>Fixed an issue in which the \u201cNone\u201d string in the Alexa communications settings was always displayed in English.</li> <li>Fixed an issue in which asking Alexa to set the volume updated the volume on the head unit as expected, but Alexa would respond with the wrong value to subsequent voice requests like \"Alexa, what's the volume?\"</li> <li>Fixed a crash when using local media source control when notification listener access was not granted. Allowlisting the Alexa Auto App for privileged install permission MEDIA_CONTENT_CONTROL  prior to installation is required by default, and notification listener access is no longer required to use local media source control.</li> <li>Fixed an issue in which the user could not add an additional stop to the active navigation route because Alexa could not properly retrieve navigation context from the head unit.</li> <li>Fixed an issue with offline calling in which Alexa would repeatedly prompt \"Which phone number or contact do you want to call?\" without ending the interaction if she could not resolve the user's requested contact name.</li> <li>Fixed an external wake word engine integration issue.</li> <li>Improved app stability</li> </ul>"},{"location":"releases/changelog/#known-issues_1","title":"Known Issues","text":""},{"location":"releases/changelog/#auto-sdk_2","title":"Auto SDK","text":"<p>General</p> <ul> <li>The Alexa Automotive UX guidelines specify when to automatically dismiss a <code>TemplateRuntime</code> display card for each template type. The Engine publishes the <code>TemplateRuntime</code> interface messages <code>ClearTemplate</code> and <code>ClearPlayerInfo</code> based on the timeouts configured in the <code>aace.alexa.templateRuntimeCapabilityAgent</code> Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., <code>LocalSearchListTemplate2</code>) with a different timeout than other templates (e.g., <code>WeatherTemplate</code>). The configuration also does not provide a way for you to specify infinite timeout for <code>NowPlaying</code> cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly.</li> <li>There is a rare race condition in which publishing the <code>AlexaClient.StopForegroundActivity</code> message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the <code>THINKING</code> state <code>AlexaClient.DialogStateChanged</code> transition.</li> </ul> <p>Car control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try</li> </ul> <p>Communications</p> <ul> <li>The dual-tone multi-frequency (DTMF) does work correctly when selecting the number 1.</li> <li>Alexa-to-Alexa calls do not work on Linux armv8 platforms</li> </ul> <p>Entertainment</p> <ul> <li>When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song.</li> <li>When using the LVC extension, if the application publishes the <code>MediaPlaybackRequestor.RequestMediaPlayback</code> AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the <code>RequestMediaPlayback</code> message.</li> </ul> <p>Local Voice Control</p> <ul> <li>Alexa responds with an error to the utterance \"Play FM radio\" and requests to tune to a station name. \"Change to FM radio\" and \"Switch to FM radio\" work as expected.</li> <li>Some contacts in the addressbook are not resolved correctly in offline mode.</li> </ul> <p>C++ sample app</p> <ul> <li>The sample app may fail to handle synchronous-style <code>AASB messages</code> within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected.</li> </ul>"},{"location":"releases/changelog/#alexa-auto-app_2","title":"Alexa Auto App","text":"<ul> <li>If there is no internet connection when the user launches Alexa for the first time in the ignition cycle, the \u201cNo Network Connection\u201d message displays momentarily and disappears.</li> <li>The Alexa Auto App doesn\u2019t reconnect to LVC when when the user switches the default assistant from Alexa to a different voice assistant and then back to Alexa. Alexa Auto App needs to be restarted (e.g., by a new ignition cycle) to reconnect to LVC.</li> <li>Alexa can take up to 90 seconds to reconnect when lost network connection is restored.</li> <li>If the user has two phones connected to the head unit and asks Alexa to read their SMS messages, the reply comes from the secondary phone instead of the primary phone.</li> <li>When the user asks Alexa to read their messages after she has already read them, Alexa reads the same messages again instead of replying that there are no new messages to read.</li> </ul>"},{"location":"releases/changelog/#v411-released-on-2022-80-08","title":"v4.1.1 released on 2022-80-08","text":""},{"location":"releases/changelog/#enhancements_2","title":"Enhancements","text":"<ul> <li>Improved Auto SDK AACS Sample App Setup and Settings UX.</li> <li>Updated APL renderer app component, as well as dependent APL Viewhost Android libraries (AARs). It is highly recommended you update to release 4.1.1 for APL integrations. <p>Note: All Auto SDK 4.1 extensions are compatible with 4.1.1.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_2","title":"Resolved Issues","text":"<ul> <li>Improved the settings menu by expanding the clickable area of settings, and added missing descriptions for menu items.</li> <li>Fixed a race condition in which updating the Alexa language setting, and then navigating away from the menu page could crash the application without switching the language.</li> <li>Fixed an issue in which the Alexa comms permission screen did not render properly. Improved the margin alignment issue in the setup screens.</li> </ul>"},{"location":"releases/changelog/#known-issues_2","title":"Known Issues","text":"<p>General</p> <ul> <li>The Alexa Automotive UX guidelines specify when to automatically dismiss a <code>TemplateRuntime</code> display card for each template type. The Engine publishes the <code>TemplateRuntime</code> interface messages <code>ClearTemplate</code> and <code>ClearPlayerInfo</code> based on the timeouts configured in the <code>aace.alexa.templateRuntimeCapabilityAgent</code> Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., <code>LocalSearchListTemplate2</code>) with a different timeout than other templates (e.g., <code>WeatherTemplate</code>). The configuration also does not provide a way for you to specify infinite timeout for <code>NowPlaying</code> cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly.</li> <li>There is a rare race condition in which publishing the <code>AlexaClient.StopForegroundActivity</code> message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the <code>THINKING</code> state <code>AlexaClient.DialogStateChanged</code> transition.</li> </ul> <p>Car control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try</li> </ul> <p>Communications</p> <ul> <li>If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone.</li> </ul> <p>Entertainment</p> <ul> <li>When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song.</li> <li>When using the LVC extension, if the application publishes the <code>MediaPlaybackRequestor.RequestMediaPlayback</code> AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the <code>RequestMediaPlayback</code> message.</li> <li>There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player.</li> <li>If your application cancels an Alexa interaction by sending the <code>AlexaClient.StopForegroundActivity</code> message to the Engine during music playback, the Engine might erroneously request your application to dismiss the <code>NowPlaying</code> media info by publishing the <code>TemplateRuntime.ClearPlayerInfo</code> message. Your application should not dismiss the media info in this scenario.</li> </ul> <p>Local Voice Control</p> <ul> <li>In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection.</li> </ul> <p>AACS sample app</p> <ul> <li>Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in.</li> <li>APL Card is prematurely closed if there is music playing in the background and APL command <code>SpeakItem</code> or <code>SpeakList</code>is executed.</li> <li>The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls.</li> <li>The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses.</li> <li>When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically.</li> <li>When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app.</li> <li>If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech.</li> </ul> <p>C++ sample app</p> <ul> <li>The sample app may fail to handle synchronous-style <code>AASB messages</code> within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected.</li> </ul>"},{"location":"releases/changelog/#v410-released-on-2022-05-27","title":"v4.1.0 released on 2022-05-27","text":""},{"location":"releases/changelog/#enhancements_3","title":"Enhancements","text":"<p>Auto SDK</p> <ul> <li>Added support to display a smart home dashboard using voice requests such as \u201cAlexa, show me my smart home dashboard\u201d. The user can use the dashboard to monitor and control the states of their smart home devices such as lights, plugs, switches, and thermostats. The smart home dashboard is powered by APL and updates to reflect the vehicle\u2019s settings for day and night mode, custom themes, and driving state.</li> <li>Added the Feature Discovery interface, enabling users to learn about Alexa features by providing an API for your application to retrieve and display suggested utterances dynamically. For more information, see the Feature Discovery documentation.</li> <li>Deprecated the Local Voice Control (LVC) APK in favor of a new LVC AACS App Component that integrates LVC directly into AACS. See the Local Voice Control extension documentation for more information.</li> <li>Enhanced LVC offline local search to support voice-based search and navigation to cheap gas stations and electric vehicle charging stations for en-US locale.</li> <li>Enhanced LVC offline navigation feature to show/navigate to previous destinations, show alternate route,  route-based ETA, and  add/remove waypoints to POI, user favorites, and address for en-US locale.</li> <li>Updated Alexa to disallow Alexa Presentation Language (APL), directives from skills that are not explicitly certified as safe for automotive. Certified skills may render APL, and uncertified skills fall back to experiences with TemplateRuntime (if supported) or voice-only.</li> <li>Updated the aace.vehicle.info configuration to include two additional optional fields, engineType and rseEmbeddedFireTvs. See the Core module documentation for additional information.</li> <li>Updated the Auto SDK Builder Tool to use a custom Python interpreter /usr/bin/env python3 rather than the previously hardcoded /usr/bin/python3</li> <li>Updated the Auto SDK Builder Tool to use the additional compiler and linker flags that enable exploit mitigation techniques, including safe stack, stack canary, fortifying source, and RELRO.</li> <li>Updated the following dependency versions:<ul> <li>Android NDK r21e</li> <li>Curl 7.81.0</li> <li>SQLite 3.37.2</li> </ul> </li> <li>The Auto SDK build system was updated to support QNX 7.0 and QNX 7.1 SDP cross-compilation.</li> <li>Added the option <code>libcurl:openssl_version</code> to the Auto SDK build system recipes to specify the <code>OpenSSL</code> version.</li> <li>Enhanced Auto SDK logs to display thread ID and uses different colors per log level.</li> <li>Added support to build Auto SDK using a custom toolchain. See the Build Alexa Auto SDK documentation for more information.</li> </ul> <p>AACS Sample App for Android Automotive OS</p> <ul> <li>Added an Alexa app icon that allows users to launch the AACS sample app directly from the app launcher instead of the system settings menu.</li> <li>Added Things-to-try in setting menu that displays a list of utterances for user to try out in different domains.</li> <li>Enhanced the Navigation app component that provides a plugin framework for 3P navigation provider. See Alexa Auto Navigation app-component for details.</li> <li>Interruption Behavior - Push-to-talk (PTT) now interrupts while Alexa is speaking/thinking, and cancels when Alexa is listening. Barge-in sounds now play, in the previous version the new dialog would start silently.</li> <li>Alexa setup flow is now interrupted if the vehicle is in motion, and setup flow is resumed when the vehicle returns to the parked state. Implemented a BACK button that returns the user to the previous activity when pressed.</li> <li>Enhanced the contacts sharing consent UI to display the consent screen when a new phone is paired and to persist consent for subsequent pairings. Previously, the consent UI only displayed as part of the setup flow.</li> <li>Enhanced the communications screen UI to display all paired phones instead of only connected phones. This enables the user to enable or disable contacts from a paired phone at any time.</li> <li>Added a short \"exit\" animation to the voice chrome UI that displays on transitions from Speaking to Idle or Listening to Idle.</li> <li>Added support for handling Alexa's Language selection mismatch between system and Alexa supported languages during first-time user experience (FTUE) and subsequent language changes.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_3","title":"Resolved Issues","text":"<p>Auto SDK</p> <ul> <li>Fixed an issue in which the CBL module did not check the network connection status when attempting to refresh an access token. If there was no network connection when the refresh was attempted, the token would not refresh immediately when connection was restored.</li> <li>Fixed an issue in which the \u201cAlexa, stop\u201d utterance did not stop music playback when audio ducking is enabled.</li> <li>Fixed periodic Engine shutdown crashes in <code>ContextManager</code>, <code>ExternalMediaPlayer</code>, and AACS.</li> <li>Fixed an issue in which the <code>Navigation module</code> inserted an invalid error code in the payload of the <code>ShowAlternativeRoutesFailed</code> event. Additionally added the <code>NOT_NAVIGATING</code> error code to the <code>Navigation AASB</code> interface. See the Navigation module documentation for info about which error codes to use.</li> <li>Fixed issues that could cause the Engine to hang indefinitely at shutdown.</li> <li>Fixed an issue in the Local Navigation module of the LVC extension that could cause Engine restart to fail after a previous Engine stop.</li> <li>Fixed an issue in which applications had to manually include header files from the Nlohmann - JSON for Modern C++ library (https://github.com/nlohmann/json) because the Auto SDK build did not export them</li> <li>Fixed an issue in which offline local search and navigation for POIs was not working.</li> <li>Fixed an issue in which the C++ sample app crashed during launch on the Poky Linux 32-bit platform.</li> </ul> <p>AACS Sample App</p> <ul> <li>Fixed the language selection screen in the AACS sample app when the Preview Mode feature is enabled.</li> <li>Fixed an issue in which the AACS sample app did not play alarms when the device is offline.</li> <li>Fixed an issue in which the display card for a second weather utterance closed too soon.</li> <li>Fixed an issue which the AACS sample app did not reset the contact permissions when switching accounts</li> <li>Fixed an issue in which the AACS sample app stopped music playback when the user tapped the screen showing a display card.</li> <li>Fixed an issue in which AACS did not play the Alexa confirmation speech when the user creates a notification while music is playing.</li> </ul>"},{"location":"releases/changelog/#known-issues_3","title":"Known Issues","text":"<p>General</p> <ul> <li>The Alexa Automotive UX guidelines specify when to automatically dismiss a <code>TemplateRuntime</code> display card for each template type. The Engine publishes the <code>TemplateRuntime</code> interface messages <code>ClearTemplate</code> and <code>ClearPlayerInfo</code> based on the timeouts configured in the <code>aace.alexa.templateRuntimeCapabilityAgent</code> Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., <code>LocalSearchListTemplate2</code>) with a different timeout than other templates (e.g., <code>WeatherTemplate</code>). The configuration also does not provide a way for you to specify infinite timeout for <code>NowPlaying</code> cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly.</li> <li>There is a rare race condition in which publishing the <code>AlexaClient.StopForegroundActivity</code> message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the <code>THINKING</code> state <code>AlexaClient.DialogStateChanged</code> transition.</li> </ul> <p>Car control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try</li> </ul> <p>Communications</p> <ul> <li>If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone.</li> </ul> <p>Entertainment</p> <ul> <li>When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song.</li> <li>When using the LVC extension, if the application publishes the <code>MediaPlaybackRequestor.RequestMediaPlayback</code> AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the <code>RequestMediaPlayback</code> message.</li> <li>There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player.</li> <li>If your application cancels an Alexa interaction by sending the <code>AlexaClient.StopForegroundActivity</code> message to the Engine during music playback, the Engine might erroneously request your application to dismiss the <code>NowPlaying</code> media info by publishing the <code>TemplateRuntime.ClearPlayerInfo</code> message. Your application should not dismiss the media info in this scenario.</li> </ul> <p>Local Voice Control</p> <ul> <li>In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection.</li> </ul> <p>C++ sample app</p> <ul> <li>The sample app may fail to handle synchronous-style <code>AASB messages</code> within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected.</li> </ul> <p>AACS sample app</p> <ul> <li>Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in.</li> <li>APL Card is prematurely closed if there is music playing in the background and APL command <code>SpeakItem</code> or <code>SpeakList</code>is executed.</li> <li>The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls.</li> <li>The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses.</li> <li>When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically.</li> <li>When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app.</li> <li>If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech.</li> </ul>"},{"location":"releases/changelog/#v400-released-on-2021-12-15","title":"v4.0.0 released on 2021-12-15","text":""},{"location":"releases/changelog/#enhancements_4","title":"Enhancements","text":"<ul> <li> <p>Deprecated the C++ and Java platform interfaces in favor of an asynchronous message-based API. Auto SDK client applications use the new <code>MessageBroker</code> to publish and subscribe to Alexa Auto Services Bridge (AASB) messages. The C++ sample app is refactored to use the new API to provide a reference implementation for Linux platforms. The Alexa Auto Client Service (AACS) sample app provides the reference implementation for Android platforms. See the Auto SDK Migration Guide for help migrating your application to use the new API.</p> </li> <li> <p>Enhanced the Auto SDK build system with the Conan package manager. The new build system introduces modular builds, better dependency management, and simpler build artifacts. The Auto SDK build system includes the Auto SDK Builder Tool script, which wraps the Conan build commands with a simple interface similar to the previous version of Auto SDK Builder. See the Build Alexa Auto SDK documentation for details about the build system and the migration guide for help migrating your build to the new version of Builder Tool.</p> </li> <li> <p>Extended the features of Alexa Presentation Language (APL) support for automotive. The <code>APL</code> module provides messages to report vehicle properties such as the display theme, driving state, and ambient light conditions. The property settings affect how APL documents render on screen; for example, some APL content is automatically hidden when the vehicle starts moving, and the display contrast updates with the day or night mode setting. Auto SDK 4.0 supports APL 1.9. For more information about the Auto SDK <code>APL</code> interface, see the APL module documentation.</p> </li> <li> <p>Added the <code>CustomDomain</code> interface, which establishes a bidirectional communication channel between your Auto SDK client application and your custom cloud skill. <code>CustomDomain</code> includes messages for exchanging directives, events, and context between the vehicle and your skill, achieving a fully customizable experience. For more information about the Auto SDK <code>CustomDomain</code> interface, See the Custom Domain module documentation.</p> </li> <li> <p>Added the <code>MediaPlaybackRequestor</code> interface, which enables Alexa to play the user\u2019s favorite media content as soon as they start their vehicle. <code>MediaPlaybackRequestor</code> simplifies content selection for the user by removing the need for the user to use buttons or voice commands to resume the Alexa media content that was playing when they stopped the vehicle. For more information about the Auto SDK <code>MediaPlaybackRequestor</code> interface, See the Alexa module documentation.</p> </li> <li> <p>Extended the <code>AudioOutput</code> interface and added configuration to allow ducking Alexa media. Your application can use this feature for enhanced control of Alexa content audio focus according to your platform requirements. For more information about audio ducking, see the Core module documentation.</p> </li> <li> <p>Updated the Auto SDK to use AVS Device SDK Version 1.25.0. For information about this version of AVS Device SDK, see the AVS Device SDK release notes.</p> </li> <li> <p>Added LVC support for Alexa Custom Assistant specialized handoffs. You can configure the default fallback and self-introduction prompts for your custom assistant while offline. For more information, see the <code>Alexa Custom Assistant</code> extension documentation.</p> </li> <li> <p>Integrated the Auto SDK Conan build system enhancements to AACS and the AACS sample app. You can use a single Gradle command to build AACS and the AACS sample app without using the Auto SDK Builder Tool directly. For build instructions, see the AACS documentation.</p> </li> <li> <p>Added the following enhancements to the AACS sample app:</p> <ul> <li> <p>Additional languages\u2014 The AACS sample app supports the following languages: US English (<code>en-US</code>), Australian English (<code>en-AU</code>), Canadian English (<code>en-CA</code>), Indian English (<code>en-IN</code>), British English (<code>en-GB</code>), German (d<code>e-DE</code>), Spanish (<code>es-ES</code>), Mexican Spanish (<code>es-MX</code>), US Spanish (<code>es-US</code>), French (<code>fr-FR</code>), Canadian French (<code>fr-CA</code>), Hindi (<code>hi-IN</code>), Italian (<code>it-IT</code>), Japanese (<code>ja-JP</code>), and Brazilian Portuguese (<code>pr-BR</code>).</p> <p>The sample app language setting matches the device\u2019s system language setting and syncs the with Alexa as long as the setting is in the supported language list. If Alexa does not support the system language, the sample app GUI defaults to en-US and presents a list of languages for the user to choose from. Once the user selects the language override, the system language does not sync with the sample app again until the user logs out or disables Alexa.</p> </li> <li> <p>Network error prompts\u2014 You can configure the sample app to provide feedback to the user when Alexa cannot respond due internet connection issues. The feedback is a voice prompt or an error screen depending on the user action.</p> </li> <li> <p>Alexa app assets\u2014 The sample app can show Alexa logos (assets) on the setup screen and display cards instead of showing placeholder assets.</p> </li> <li> <p>Comms UI improvements\u2014 Updated the contacts uploading logic in the <code>Comms UI</code> AACS app component to ensure the sample app only uploads the contacts for the primary phone.</p> </li> </ul> </li> <li> <p>Updated the AACS Telephony library to get the outgoing phone account using the Android standard API <code>getDefaultOutgoingPhoneAccount</code>. AACS Telephony no longer sends an account query intent when receiving the <code>PhoneCallController.Dial</code> message from the Auto SDK Engine.</p> </li> <li> <p>Added a new intent <code>com.amazon.aacstelephony.bluetooth.connectionCheckCompleted</code>, which AACS Telephony service broadcasts when it finishes the initial bluetooth connection check.</p> </li> <li> <p>Updated the <code>alexa-auto-lwa-auth</code> app component to use the <code>Authorization</code> Auto SDK interface for CBL authorization.</p> </li> </ul>"},{"location":"releases/changelog/#other-changes","title":"Other changes","text":"<ul> <li> <p>Removed support for the Android 32-bit ARM architecture (i.e., <code>armeabi-v7a</code>).</p> </li> <li> <p>Moved several source code directories within the <code>aac-sdk</code> root directory to support the enhanced build system.</p> <ul> <li> <p>Removed <code>aac-sdk/platforms/android/</code>. The deprecated Java platform interfaces and JNI are in their respective modules. For example, the Alexa module Java interfaces and JNI are moved from <code>aac-sdk/platforms/android/modules/alexa/</code> to <code>aac-sdk/modules/alexa/android/</code></p> </li> <li> <p>Removed <code>aac-sdk/extensions/aasb/</code> because using AASB messages with MessageBroker is the primary Auto SDK API. AASB code for each module is in the respective module directory. For example, the AASB code for the Alexa module is in <code>aac-sdk/modules/alexa/aasb/</code>. Note that the AASB message headers to include in your application are not in this directory since they are generated as part of the Auto SDK build output.</p> </li> <li> <p>Moved <code>aac-sdk/extensions/system-audio/</code> to <code>aac-sdk/modules/system-audio/</code></p> </li> <li> <p>Moved <code>aac-sdk/extensions/bluetooth/</code> to <code>aac-sdk/modules/bluetooth/</code></p> </li> <li> <p>Moved <code>aac-sdk/extensions/loopback-detector/</code> to <code>aac-sdk/modules/loopback-detector/</code></p> </li> <li> <p>Moved  <code>aac-sdk/platforms/android/alexa-auto-client-service/</code> to <code>aac-sdk/aacs/android/</code></p> </li> <li> <p>Moved <code>aac-sdk/platforms/android/alexa-auto-client-service/app-components/</code> to <code>aac-sdk/aacs/android/app-components/</code></p> </li> <li> <p>Moved <code>aac-sdk/samples/android-aacs-sample-app/</code> to <code>aac-sdk/aacs/android/sample-app/</code></p> </li> <li> <p>Moved <code>aac-sdk/platforms/android/alexa-auto-client-service</code> <code>/commonutils/</code> , <code>/ipc/</code>, and <code>/constants/</code> to <code>aac-sdk/aacs/android/common/</code></p> </li> <li> <p>Moved AACS media player files to a directory <code>audioOutput</code> within <code>aac-sdk/platforms/android/alexa-auto-client-service/service/</code></p> </li> <li> <p>Moved the Media App Command and Control Android library from <code>aac-sdk/platforms/android/maccandroid/</code> to <code>aac-sdk/aacs/android/service/modules/maccandroid/</code></p> </li> </ul> </li> <li> <p>In the LVC extension, the <code>LocalSearchProvider</code> AASB messages now have topic <code>LocalNavigation</code>. For example, the existing message <code>LocalSearchProvider.SearchRequest</code> in 3.3 is <code>LocalNavigation.SearchRequest</code> in 4.0. The next major release version of Auto SDK will change the topic back to <code>LocalSearchProvider</code>.</p> </li> <li> <p>Deprecated the option to build AACS as an APK. Starting from Auto SDK 4.0, you can only build AACS as an AAR.</p> </li> <li> <p>Removed the Android sample app based on the Java platform interfaces. The AACS sample app demonstrates using Auto SDK on Android.</p> </li> <li> <p>Updated AASB configuration fields used for AACS. See the migration guide for details.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_4","title":"Resolved issues","text":"<ul> <li> <p>Fixed an issue preventing the generic <code>DEFAULT</code> type <code>LocalMediaSource</code> from working in offline mode with LVC.</p> </li> <li> <p>Fixed a race condition in <code>SpeechRecognizer</code> in which enabling wake word detection immediately after calling <code>startCapture()</code> resulted in a missing call to <code>stopAudioInput()</code> when wake word detection was later disabled.</p> </li> <li> <p>Fixed a deadlock that could occur in an application that uses the deprecated <code>AuthProvider</code> interface and starts, stops, and restarts the Engine in quick succession.</p> </li> <li> <p>Fixed an issue in which Spotify playback commands were delayed on QNX.</p> </li> <li> <p>Fixed an issue in which the Engine added malformed <code>PhoneCallController</code> context to <code>PhoneCallController</code> events sent to Alexa.</p> </li> <li> <p>Fixed an issue in which AACS did not acquire audio focus prior to playing Alexa speech.</p> </li> </ul>"},{"location":"releases/changelog/#known-issues_4","title":"Known issues","text":"<p>General</p> <ul> <li> <p>If you do not specify the <code>deviceSettings.locales</code> field of the Alexa module configuration, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"].     The Engine does not automatically declare support for default locale combinations if you assign an empty value to the <code>locales</code> field.</p> </li> <li> <p>The Engine does not persist the <code>aace.alexa.wakewordEnabled</code> Engine property setting across device reboots. Your application has to persist the setting and set the property again at each Engine start. AACS implements persisting this property and hence does not have this issue.</p> </li> <li> <p>If your Linux platform does not use AVX2 instructions, the Amazonlite wake word library initialization causes an illegal instruction error.</p> </li> <li> <p>When using LVC and stopping the Engine, the <code>AlexaClient</code> connection status remains <code>CONNECTED</code> because the connection to LVC is not disabled. Your application should not accept user utterances while the Engine is stopped despite the connection status showing <code>CONNECTED</code>.</p> </li> <li> <p>The Alexa Automotive UX guidelines specify when to automatically dismiss a <code>TemplateRuntime</code> display card for each template type. The Engine publishes the <code>TemplateRuntime</code> interface messages <code>ClearTemplate</code> and <code>ClearPlayerInfo</code> based on the timeouts configured in the <code>aace.alexa.templateRuntimeCapabilityAgent</code> Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., <code>LocalSearchListTemplate2</code>) with a different timeout than other templates (e.g., <code>WeatherTemplate</code>). The configuration also does not provide a way for you to specify infinite timeout for <code>NowPlaying</code> cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly.</p> </li> <li> <p>When the user requests to view their list of timers on an APL-enabled application, they cannot use an utterance such as \u201cAlexa, scroll up\u201d to scroll through the list shown on the APL card.</p> </li> <li> <p>There is a rare race condition in which publishing the <code>AlexaClient.StopForegroundActivity</code> message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the <code>THINKING</code> state <code>AlexaClient.DialogStateChanged</code> transition.</p> </li> <li> <p>On the Poky Linux 32-bit platform, the C++ sample app shuts down with an error on launch.</p> </li> <li> <p>In offline mode with LVC, you might not see the <code>AlexaClient.DialogStateChanged</code> <code>THINKING</code> state transition if the user invokes Alexa with hold-to-talk and your application provides the audio input data in one large chunk.</p> </li> <li> <p>In offline mode with LVC, Alexa gets stuck in the <code>THINKING</code> state and does not respond after changing the locale setting. The state recovers after a few minutes.</p> </li> <li> <p>The <code>CBL</code> module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the Engine attempts the refresh, it might take up to a minute to refresh the token after the internet connection is restored.</p> </li> <li> <p>Some <code>Core</code> module messages published by the Engine do not have a corresponding message for the application to report a handling failure. For example, if the user invokes Alexa by tap-to-talk, and the application cannot handle the <code>AudioInput.StartAudioInput</code> message, the Engine assumes the application handled the message properly and will provide audio data. As a result, the Engine state and application state might become out of sync. The affected messages are the following:</p> <ul> <li><code>AudioInput</code>:<ul> <li><code>StartAudioInput</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>SetPosition</code></li> <li><code>VolumeChanged</code></li> <li><code>MutedStateChanged</code></li> </ul> </li> </ul> </li> </ul> <p>Car control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</li> </ul> <p>Communications</p> <ul> <li> <p>Alexa does not understand DTMF utterances that include letters. For example, \"press A\" and \"dial 3*#B\" do not result in the correct DTMF directives.</p> </li> <li> <p>The user might experience unexpected results by trying to dial or place calls in the following ways:</p> <ul> <li>Using utterances that include \u201cdouble\u201d, \u201ctriple\u201d, \u201chundred\u201d, or \u201cthousand.\u201d For example, calling a number such as 1-800-xxx-xxxx by saying \u201cAlexa call one eight double oh...\u201d</li> <li>Pressing special characters such has \u201c#\u201d or \u201c*\u201d by saying \"Alexa press * #.\"</li> </ul> </li> <li> <p>The user cannot accept or reject incoming Alexa-to-Alexa calls by voice while playing a skill with extended multi-turn dialogs, such as Jeopardy or Skyrim.</p> </li> </ul> <p>Entertainment</p> <ul> <li> <p>If the user requests Alexa to read notifications while music is playing, they might hear the music play for a split second between the end of one notification and the start of the next.</p> </li> <li> <p>When an external media player authorization is in progress during Engine shutdown, a rare race condition might cause the Engine to crash.</p> </li> <li> <p>If your application cancels an Alexa interaction by sending the <code>AlexaClient.StopForegroundActivity</code> message to the Engine during music playback, the Engine might erroneously request your application to dismiss the<code>NowPlaying</code> media info by publishing the <code>TemplateRuntime.ClearPlayerInfo</code> message. Your application should not dismiss the media info in this scenario.</p> </li> <li> <p>When using the <code>System Audio</code> module, Audible and Amazon music might not play correctly on i.MX8 boards.</p> </li> </ul> <p>Local search and navigation</p> <ul> <li>In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize followup requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection.</li> </ul> <p>AACS</p> <ul> <li>If you do not use the default audio output implementation (i.e., your application handles <code>AudioOutput</code> AASB messages), your application will not receive the <code>AudioOutput.Stop</code> message if Alexa media is playing when AACS shuts down. As a workaround, your application can listen to <code>AASB.StopService</code> or adopt <code>AACSPinger</code> to listen to the <code>STOPPED</code> state of AACS and stop the media accordingly.</li> </ul> <p>AACS Sample App</p> <ul> <li> <p>The AACS Sample App does not show the language selection screen when the app is built with Preview Mode.</p> </li> <li> <p>The AACS Sample App only shows the language selection screen if there is a language mismatch with the system language setting at the first app launch.</p> </li> </ul>"},{"location":"releases/changelog/#v330-released-on-2021-09-30","title":"v3.3.0 released on 2021-09-30","text":""},{"location":"releases/changelog/#enhancements_5","title":"Enhancements","text":"<ul> <li> <p>Added the <code>DeviceUsage</code> platform interface to provide the Alexa application network usage data to the Auto SDK Engine. The Auto SDK Engine emits this data as a metric to Amazon if Auto SDK is built with the <code>Device Client Metrics</code> extension. For more information, see the Core module documentation</p> </li> <li> <p>Extended the features of the <code>Local Navigation</code> module for the <code>Local Voice Control (LVC)</code> extension. The <code>LocalSearchProvider</code> platform interface now enables you to provide customers with offline navigation to street addresses, cities, and neighborhoods in addition to the existing support for local search and navigation to points of interest. See the Local Navigation module README for information about integrating the features.</p> <p>Note: There are updates to the <code>LocalSearchProvider</code> APIs. See the Auto SDK Migration Guide for details.</p> </li> <li> <p>Added a new generic <code>DEFAULT</code> media source to the list of sources supported by the <code>LocalMediaSource</code> platform interface. The DEFAULT source can be used for voice playback control of any arbitrary media sources on the infotainment system outside of deep-linked MACC applications using the <code>ExternalMediaAdapter</code> interface and existing sources supported by name through the <code>LocalMediaSource</code> interface. For details about integrating a default media source, see the Alexa module documentation.</p> </li> <li> <p>Added offline LVC support for tuning to station names on terrestrial radio and SiriusXM. E.g., \u201cPlay CNN on Sirius XM\u201d and \u201cPlay KISS FM\u201d. This feature is already available in online mode.</p> </li> <li> <p>Enhancements for AACS:</p> <ul> <li> <p>Added an app component called <code>alexa-auto-carcontrol</code> that deeply integrates Auto SDK car control features into the Android Automotive OS. For more information about AACS deep integration to Car Control, please refer to this README.</p> </li> <li> <p>Added an enhancement in which AACS can automatically sync Alexa\u2019s timezone and locale properties with the device system settings when you set the <code>syncSystemPropertyChange</code> field to true in your AACS configuration file. If you set the field to false or omit it, you still have flexibility to change the properties in your own implementation.</p> </li> </ul> </li> <li> <p>Enhancements for AACS Sample App:</p> <ul> <li> <p>Added a location sharing consent screen in Alexa setup and settings wherein the user has the option to enable or disable location sharing.</p> </li> <li> <p>Added support for rendering for <code>TemplateRuntime</code> display cards for the weather domain.</p> </li> <li> <p>Added support for rendering <code>Amazon Presentation Language (APL)</code> documents.</p> </li> <li> <p>Added media player transport control improvements. For example, shuffle and loop transport controls are added, and disabled transport controls are displayed.</p> </li> <li> <p>Added support for setup and setting menu specific to the Alexa Custom Assistant extension.</p> </li> </ul> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_5","title":"Resolved Issues","text":"<ul> <li> <p>Android 11 requires the attribute <code>android:foregroundServiceType</code> to be defined in services that require permissions such as microphone and location. This is added to the AACS Android Manifest file. Also, the <code>compileSdkVersion</code> and <code>targetSdkVersion</code> to are updated to 30 in <code>build.gradle</code>.</p> </li> <li> <p>Added a <code>UserIdentity</code> value in AACS <code>AuthStatus</code> when the user finishes CBL login.</p> </li> <li> <p>Made the 'stateOrRegion' field optional in the AACS <code>StartNavigation</code> directive JSON parser.</p> </li> <li> <p>Implemented the AASB <code>SetUserProfile</code> message in the CBL module to ensure the user email and username will be sent to the client application after user login when <code>enableUserProfile</code> is set to true.</p> </li> <li> <p>Fixed an issue that blocked a valid transition from the <code>THINKING</code> to <code>LISTENING</code> <code>AlexaClient</code> dialog states.</p> </li> <li> <p>Updated the <code>PhoneCallControllerCapabilityAgent</code> to include context in <code>PhoneCallController</code> events per the <code>PhoneCallController</code> API specification.</p> </li> <li> <p>Fixed a memory leak observed during Engine shutdown in the <code>Local Voice Control</code> extension.</p> </li> <li> <p>Fixed a rare deadlock issue during Engine stop and start when using the <code>AuthProvider</code> interface.</p> </li> <li> <p>Fixed an issue in which the Engine erroneously allowed 3,000 coordinates in the \"shapes\" array of navigation state queried via <code>Navigation::getNavigationState()</code>. The limit is updated to 100 coordinates.</p> </li> </ul>"},{"location":"releases/changelog/#known-issues_5","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> <ul> <li> <p>The <code>wakewordEnabled</code> property is not persistent across device reboots. If you use AACS, however, this issue does not occur.</p> </li> <li> <p>For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error.</p> </li> <li> <p>When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED.</p> </li> <li> <p>The automotive HMI guidelines for display cards state that actionable display cards should be dismissed automatically after 30 seconds, and non-actionable display cards should be dismissed automatically after 8 seconds. This guideline is not descriptive enough since it does not clarify what is actionable and non-actionable content. The UX team is working on correcting the guideline to specify specific template types. The current automatic dismissal time for all Template Runtime display cards is 8 seconds.</p> </li> </ul> </li> <li> <p>Car Control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</li> </ul> </li> <li> <p>Communications</p> <ul> <li> <p>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</p> </li> <li> <p>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</p> </li> <li> <p>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</p> </li> </ul> </li> <li> <p>Entertainment</p> <ul> <li> <p>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</p> </li> <li> <p>The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response.</p> </li> <li> <p>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</p> </li> <li> <p>If your application displays the NowPlaying <code>TemplateRuntime</code> display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to <code>TemplateRuntime::clearPlayerInfo()</code> if your application calls <code>AlexaClient::stopForegroundActivity()</code> to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario.</p> </li> <li> <p>The generic <code>DEFAULT</code> <code>LocalMediaSource</code> type is not supported offline with LVC. If user gives a generic playback control request like \"Alexa, play\" when the Alexa application is operating in the offline mode with LVC, Alexa responds \"Sorry, something went wrong\". Other named players like USB work as expected in the offline mode.</p> </li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> </ul> </li> <li> <p>Local Search and Navigation</p> <ul> <li>When using LVC in offline mode, after requesting a list of POIs (e.g., \"find Starbucks nearby\"), Alexa does not recognize utterances like \"select the first one\" and does not display or read detailed information about the requested selection.</li> </ul> </li> <li> <p>AACS</p> <ul> <li> <p>For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs:</p> <ul> <li><code>AudioInput</code>:<ul> <li><code>startAudioInput()</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>setPosition(int64_t position)</code></li> <li><code>volumeChanged(float volume)</code></li> <li><code>mutedStateChanged(MutedState state)</code></li> </ul> </li> </ul> </li> <li> <p>If you are not using the default audio output implementation (i.e. your application handles <code>AudioOutput</code> AASB messages) and even though you are playing the Alexa pushed media content, <code>Stop</code> message would not be sent from AACS when AACS shuts down. e.g. If you are playing an audio stream for AmazonMusic, if AACS is stopped, AASB <code>AudioOutput.Stop</code> message would not be received. As a result, the media playing from your application would not be stopped. This issue will be fixed in the next release. As a workaround, your application can listen to <code>AASB.StopService</code> message or adopt <code>AACSPinger</code> to listen to the <code>STOPPED</code> state of AACS and stop the media accordingly.</p> </li> </ul> </li> </ul>"},{"location":"releases/changelog/#v321-released-on-2021-08-06","title":"v3.2.1 released on 2021-08-06","text":"<p>Note: All Auto SDK 3.2 extensions are compatible with 3.2.1.</p>"},{"location":"releases/changelog/#enhancements_6","title":"Enhancements","text":"<ul> <li> <p>Added additional APIs to the <code>Connectivity</code> module, which enable the voice up-sell conversation between the user and Alexa to activate a trial data plan or a paid subscription plan. Your implementation should call <code>AlexaConnectivity::sendConnectivityEvent()</code> to notify the Engine of the data plan type. To respond, the Engine calls <code>AlexaConnectivity::connectivityEventResponse()</code>.</p> </li> <li> <p>Added the configuration field <code>aace.addressBook.cleanAllAddressBooksAtStart</code> to Engine configuration. This field specifies whether to automatically delete address books each time the Engine starts.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_6","title":"Resolved Issues","text":"<p>Fixed an issue in which wake words cannot be detected correctly when using the <code>SpeechRecognizer::startCapture()</code> API with an external wake word engine.</p>"},{"location":"releases/changelog/#known-issues_6","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> <ul> <li> <p>The <code>wakewordEnabled</code> property is not persistent across device reboots. If you use AACS, however, this issue does not occur.</p> </li> <li> <p>For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error.</p> </li> <li> <p>When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED.</p> </li> </ul> </li> <li> <p>Car Control</p> <ul> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</li> </ul> </li> <li> <p>Communications</p> <ul> <li> <p>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</p> </li> <li> <p>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</p> </li> <li> <p>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</p> </li> </ul> </li> <li> <p>Entertainment</p> <ul> <li> <p>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</p> </li> <li> <p>The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response.</p> </li> <li> <p>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</p> </li> <li> <p>If your application displays the NowPlaying <code>TemplateRuntime</code> display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to <code>TemplateRuntime::clearPlayerInfo()</code> if your application calls <code>AlexaClient::stopForegroundActivity()</code> to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario.</p> </li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> </ul> </li> <li> <p>AACS</p> <ul> <li>For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs:<ul> <li><code>AudioInput</code>:<ul> <li><code>startAudioInput()</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>setPosition(int64_t position)</code></li> <li><code>volumeChanged(float volume)</code></li> <li><code>mutedStateChanged(MutedState state)</code></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"releases/changelog/#v320-released-on-2021-05-19","title":"v3.2.0 released on 2021-05-19","text":""},{"location":"releases/changelog/#enhancements_7","title":"Enhancements","text":"<ul> <li> <p>Added the <code>DeviceSetup</code> platform interface that handles events and directives related to device setup during or after an out-of-the-box experience (OOBE). After the user login, Alexa is informed that device setup is complete and starts the on-boarding experience, for example, by starting a short first-time conversation. For more information, see the Alexa module documentation.</p> </li> <li> <p>Added support in the Connectivity module to provide the network identifier from the vehicle to Alexa, which enables automakers to offer full connectivity plans to customers. For connectivity status, the module supports sending the version of the terms and conditions through a field called <code>termsVersion</code>. Also, the <code>termsStatus</code> field accepts <code>DEFERRED</code>, which means Alexa can remind users to respond to the terms and conditions at a later time.</p> </li> <li> <p>Added the Mobile Authorization extension, which enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone, instead of opening a web browser and entering a code.</p> </li> <li> <p>Added the Bluetooth extension, which allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol.</p> </li> <li> <p>Added the Geolocation extension, which provides geolocation consent support. The user can grant consent to location sharing with Alexa from your application.</p> </li> <li> <p>Added the <code>locationServiceAccessChanged(LocationServiceAccess access)</code> API in the <code>LocationProvider</code> interface, which allows the Engine not to query the device location when the location service access is turned off on the device.</p> </li> <li> <p>Added the APL Render module, which enables APL rendering capabilities in an Android application.</p> <p>Note: This module is for you to experiment with APL document rendering on an automotive device. Do not use the module to render APL documents in a production vehicle.</p> </li> <li> <p>Added support in the Address Book module for a phonetic field. The phonetic field is required for resolving the name of a contact or navigation favorite if the name uses Kanji characters in Japanese.</p> </li> <li> <p>Updated the Docker container for the Auto SDK builder script to use OpenSSL 1.1.1k by default. Added an environment variable for you to change the OpenSSL version, if desired. For information about the OpenSSL version, see the Builder README.</p> </li> <li> <p>Updated the Auto SDK to use AVS Device SDK Version 1.22.0. For information about the AVS Device SDK, see the AVS Device SDK Release Notes.</p> </li> <li> <p>Enhancements for AACS:</p> <ul> <li> <p>Added AACS instrumentation, which enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. For information about AACS instrumentation, see the AACS documentation.</p> </li> <li> <p>Added an app component called <code>alexa-auto-telephony</code>, which enables you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony.</p> </li> <li> <p>Added an app component called <code>alexa-auto-contacts</code> to enable AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information.</p> </li> <li> <p>Added the AACS AAR, which you can include in your application.</p> </li> <li> <p>The timeout for AASB synchronous messages is now configurable. For information about configuring the timeout, see the AACS documentation.</p> </li> </ul> </li> <li> <p>Enhancements for AACS Sample App:</p> <ul> <li> <p>Added support for new features in the AACS Sample App. For example, it includes a menu for the user to select a language if the in-vehicle infotainment (IVI) language is not supported by Alexa, and it supports authorization with Preview Mode.</p> </li> <li> <p>Added support for the Alexa Custom Assistant extension to the Alexa Auto Client Service (AACS) Sample App. The sample app demonstrates how an application can use AACS with this extension. With app components included with the sample app, you can develop an application that handles assistant handoff and displays custom animation for your custom assistant.</p> <p>Note: In order to use the Alexa Custom Assistant extension with the AACS Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details.</p> </li> </ul> </li> <li> <p>Enhancements for metrics uploading:</p> <ul> <li> <p>The Auto SDK emits only registration metrics before user login is complete. Other metrics are emitted after user login.</p> </li> <li> <p>The Device Client Metrics (DCM) extension supports uploading more metrics from the vehicle than in previous versions.</p> </li> <li> <p>The DCM extension supports anonymizing all Auto SDK metrics.</p> </li> </ul> </li> <li> <p>Enhancements for car control:</p> </li> <li> <p>Added prompt improvements. Alexa can provide a recommendation or ask for clarification after receiving an invalid or ambiguous user request. Suppose a user request targets the wrong mode, setting, or value for an appliance, such as \"Alexa, set fan speed to 100\", Alexa responds, \"Sorry, you can only set the fan between 1 and 10\". When the target in a user request is ambiguous, Alexa prompts for more information to determine the exact meaning of the request. For example, when a user says, \"Turn on fan\" (when the fan's default zone is not set), Alexa responds, \"For the driver, the passenger, or the rear?\" This feature is supported online and offline.</p> </li> <li> <p>Improved asset management for car control, which enables Alexa to accept utterances only a few seconds after the user logs in. Previously, the user had to wait up to 20 seconds for Alexa to accept utterances.</p> </li> <li> <p>Improved the Auto SDK Voice Chrome extension to allow the height and width of the linear voice chrome to be controlled by the parent layout. Previously, the dimensions were fixed.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_7","title":"Resolved Issues","text":"<ul> <li> <p>Disabled APL by default in AACS to make sure utterances like \"tell me a joke\" work correctly without handling APL. If your platform wants to implement APL, see the AACS Configuration README to enable it.</p> </li> <li> <p>An SMS message can be sent to an Alexa contact correctly. A user request to send an SMS message to an Alexa contact no longer results in an Alexa-to-Alexa message.</p> </li> <li> <p>For car control, there is no longer a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID).</p> </li> <li> <p>After the AmazonLite Wake Word locale model is switched from the default (en-US) to another locale model (e.g., de-DE), the newly selected locale remains in effect after the user quits and then restarts the application.</p> </li> <li> <p>Numeric weather IDs are passed to AVS for the <code>TemplateRunTime</code> API, making it easier for you to display weather icons that are consistent with your user interface.</p> </li> <li> <p>After the user disconnects the phone, if the user tries to use Alexa to make a call, Alexa responds correctly by reminding the user to connect the phone. Previously, Alexa tried to dial the number.</p> </li> <li> <p>After the user pauses on Spotify and presses \u201cPlay\u201d to resume, the player starts correctly from the point where the player stops. Previously the player skipped ahead, resuming from an incorrect place.</p> </li> <li> <p><code>AutoVoiceChromeController</code> and <code>StateChangeAnimationScheduler</code> of the Voice Chrome extension are thread-safe now, preventing the Alexa app from crashing in different scenarios (e.g. when changing to the previous music track).</p> </li> <li> <p>Fixed a race condition in <code>AuthorizationManager</code> during the Engine shutdown.</p> </li> </ul>"},{"location":"releases/changelog/#known-issues_7","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> <ul> <li> <p>The <code>wakewordEnabled</code> property is not persistent across device reboots. If you use AACS, however, this issue does not occur.</p> </li> <li> <p>For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error.</p> </li> <li> <p>When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED.</p> </li> </ul> </li> <li> <p>Car Control</p> <ul> <li> <p>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</p> </li> <li> <p>Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d.</p> </li> </ul> </li> <li> <p>Communications</p> <ul> <li> <p>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</p> </li> <li> <p>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</p> </li> <li> <p>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</p> </li> </ul> </li> <li> <p>Entertainment</p> <ul> <li> <p>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</p> </li> <li> <p>The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response.</p> </li> <li> <p>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</p> </li> <li> <p>If your application displays the NowPlaying <code>TemplateRuntime</code> display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to <code>TemplateRuntime::clearPlayerInfo()</code> if your application calls <code>AlexaClient::stopForegroundActivity()</code> to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario</p> </li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> </ul> </li> <li> <p>AACS</p> <ul> <li>For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs:<ul> <li><code>AudioInput</code>:<ul> <li><code>startAudioInput()</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>setPosition(int64_t position)</code></li> <li><code>volumeChanged(float volume)</code></li> <li><code>mutedStateChanged(MutedState state)</code></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"releases/changelog/#v310-released-on-2020-12-15","title":"v3.1.0 released on 2020-12-15","text":""},{"location":"releases/changelog/#enhancements_8","title":"Enhancements","text":"<ul> <li>Added the Authorization platform interface that replaces the CBL platform interface and the AuthProvider platform interface. For information about how the Alexa Auto SDK Engine handles authorization with the Authorization platform interface, see the Core module documentation.</li> </ul> <p>Note: Logging out from CBL or Auth Provider authorization clears the databases that store user data, such as alerts and settings. For example, when the user logs out, pending alerts in the database are cleared to ensure that the next user who logs in does not receive the alerts. In addition, upon logout, the locale setting is reset to the default value in the Engine configuration. Therefore, if the current device locale is different from the default locale, you must set the locale before starting an authorization flow.</p> <ul> <li> <p>Added the Text-To-Speech module that exposes the platform interface for requesting synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Added the Text-To-Speech Provider module that synthesizes the Alexa speech. The Text-to-Speech provider requires Auto SDK to be built with the Local Voice Control extension. For information about these modules, see the Text-To-Speech module documentation and Text-To-Speech Provider documentation.</p> <p>Note: This feature may only be used with voice-guided turn-by-turn navigation.</p> </li> <li> <p>Added the Connectivity module that creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. For information about the Connectivity module, see the Connectivity documentation.</p> </li> <li> <p>Added the Local Navigation module for the Local Voice Control (LVC) extension. This module enables you to provide customers with offline search and navigation to points of interest (POI) by leveraging the POI data of an onboard navigation provider. The POIs include categories, chains, and entities. The Local Voice Control (LVC) extension is required for the Local Navigation module.</p> </li> </ul> <p>Note: Offline search with the Local Navigation module is only supported in the en-US locale.</p> <ul> <li> <p>Added the Alexa Auto Client Service (AACS) sample app that demonstrates how an application uses AACS. The Auto SDK includes the app components used by the AACS sample app, which you can also use when developing an application that communicates with AACS. For information about the AACS sample app, see the AACS sample app documentation</p> </li> <li> <p>Added support for Digital Audio Broadcasting (DAB) radio. For more information about the DAB local media source, see the Alexa module documentation.</p> </li> <li> <p>Enhancements for AACS:</p> </li> <li> <p>Enhanced the file sharing protocol of AACS by using Android's FileProvider. This enhancement grants AACS permission to access files within your AACS client application, which are required by configuration fields for the Auto SDK.</p> </li> <li> <p>Added support for the Android <code>ContentProvider</code> class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information.</p> <p>For information about how AACS uses <code>FileProvider</code> and <code>ContentProvider</code>, see the AACS documentation.</p> </li> <li> <p>Added support for a <code>ping</code> broadcast to check the AACS connection state. For more information about how to use <code>ping</code>, see the AACS documentation.</p> </li> <li> <p>Added support for caching AASB message intent targets based on AASB Action. This enables you to define an intent filter with a subset of the possible actions for an AASB topic. For more information on specifying intent targets, see the AACS documentation.</p> </li> <li> <p>Added support for Text-to-Speech Service, which allows Android applications to interact with Android TTS APIs to convert text to speech. For information about the Text-to-Speech Service, see the AACS TTS app component documentation.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_8","title":"Resolved Issues","text":"<ul> <li> <p>On Android, the Engine returns the correct value (<code>UNDEFINED</code>) for requests to <code>LocationProvider.getLocation()</code> when the device does not have access to location. Previously the Engine populated the user geolocation with a default value when <code>Location.UNDEFINED</code> was returned in <code>LocationProvider.getLocation()</code>.</p> </li> <li> <p>In the AACS commonutils library, the JSON parser (<code>RenderPlayerInfo.kt</code>) for the <code>renderPlayerInfo</code> message of <code>templateRuntime</code> could only parse the <code>payload</code> field of the AASB <code>RenderPlayerInfo</code> message payload. Now it can parse the overall AASB payload.</p> </li> <li> <p>Notifications sound plays correctly. Previously, the sound did not play as expected due to improper channel configuration.</p> </li> <li> <p>The CBL module code request flow correctly applies the locale setting to the Login With Amazon (LWA) code request. Previously, the URL returned by LWA was always in the en-US locale.</p> </li> <li> <p>If you log out and log in, the client-side Do Not Disturb (DND) state is synchronized with Alexa.</p> </li> </ul>"},{"location":"releases/changelog/#known-issues_8","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> <ul> <li>The <code>wakewordEnabled</code> property is not persistent across device reboots. If you use AACS, however, this issue does not occur.</li> </ul> </li> <li> <p>Car Control</p> <ul> <li> <p>For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN.</p> </li> <li> <p>It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login.</p> </li> <li> <p>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</p> </li> <li> <p>Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d.</p> </li> <li>The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings.</li> </ul> </li> <li> <p>Communications</p> <ul> <li> <p>A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However, \u2018send message\u2019 instead of \u2018send SMS\u2019 to a contact works.</p> </li> <li> <p>When using LVC in online mode, users can redial a call when the phone connection state is OFF.</p> </li> <li> <p>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</p> </li> <li> <p>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</p> </li> <li> <p>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</p> </li> </ul> </li> <li> <p>Entertainment</p> <ul> <li> <p>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</p> </li> <li> <p>The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response.</p> </li> <li> <p>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</p> </li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> </ul> </li> <li> <p>AACS</p> <ul> <li>For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs:<ul> <li><code>AudioInput</code>:<ul> <li><code>startAudioInput()</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>setPosition(int64_t position)</code></li> <li><code>volumeChanged(float volume)</code></li> <li><code>mutedStateChanged(MutedState state)</code></li> </ul> </li> </ul> </li> <li>AACS enables APL by default, but it does not have a default implementation for APL. AACS expects the client application to handle the messages or directives from the Engine. If APL is not handled on the client side, utterances that trigger APL capabilities, such as \"tell me a joke,\" fail. To disable APL, add the lines below to the AACS configuration file.</li> </ul> </li> </ul> <pre><code>        \"aasb.apl\": {\n            \"APL\": {\n                   \"enabled\" : false\n               }\n        }\n</code></pre>"},{"location":"releases/changelog/#additional-changes","title":"Additional Changes","text":"<p>Starting with v3.1.0, the Local Voice Control (LVC) extension is no longer supported on ARM32 platforms.</p>"},{"location":"releases/changelog/#v300-released-on-2020-10-09","title":"v3.0.0 released on 2020-10-09","text":""},{"location":"releases/changelog/#enhancements_9","title":"Enhancements","text":"<ul> <li> <p>Added Alexa Auto Client Service (AACS), which enables OEMs of Android-based devices to simplify the process of integrating the Auto SDK. For more information about AACS, see the AACS documentation.</p> </li> <li> <p>Added support for removing local media sources at runtime, such as a USB drive or a Bluetooth device. Previously, if a user removed a USB drive and then requested to play music from the USB drive, the Auto SDK would attempt to play and not return an appropriate error message. This feature is enabled with an existing field in the <code>LocalMediaSource</code> platform interface state. For information about the platform interface state, see the Alexa module documentation.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_9","title":"Resolved Issues","text":"<ul> <li>On QNX, when a portion of music on Spotify is skipped, either by the user saying, \"Skip forward,\" or by the user skipping to a different song, the volume is no longer reset to the default level.</li> <li>A user barging in when music is playing no longer hears an Alexa response to the barge-in request. Previously, this issue happened if the System Audio extension was used.</li> <li>When streaming music from Alexa, the user can switch to a local media source by using one utterance, such as \"Alexa, play radio.\" Previously, Alexa would not switch to the local media source after the first utterance. The user needed to issue the request again before Alexa could play from the local media source.</li> </ul>"},{"location":"releases/changelog/#known-issues_9","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> </li> <li> <p>Car Control</p> <ul> <li>For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN.</li> <li>It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login.</li> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</li> <li>Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d.</li> <li>The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings.</li> </ul> </li> <li> <p>Communications</p> <ul> <li>A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works.</li> <li>When using LVC in online mode, users can redial a call when the phone connection state is OFF.</li> <li>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</li> <li>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</li> <li>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</li> </ul> </li> <li> <p>Entertainment</p> <ul> <li>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</li> <li>The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response.</li> <li>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> <li>If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.</li> </ul> </li> <li> <p>AACS</p> <ul> <li> <p>For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs:</p> <ul> <li><code>AudioInput</code>:<ul> <li><code>startAudioInput()</code></li> </ul> </li> <li><code>AudioOutput</code>:<ul> <li><code>setPosition(int64_t position)</code></li> <li><code>volumeChanged(float volume)</code></li> <li><code>mutedStateChanged(MutedState state)</code></li> </ul> </li> </ul> </li> <li> <p>In the commonutils library, the JSON parser (<code>RenderPlayerInfo.kt</code>) for the <code>renderPlayerInfo</code> message of <code>templateRuntime</code> can only parse the <code>payload</code> field of the AASB <code>RenderPlayerInfo</code> message payload. The <code>payload</code> field of <code>RenderPlayerInfo</code> is the inner payload of the nested payload structure. When using <code>TemplateRuntime.parseRenderInfo(String json)</code>, provide it with the embedded JSON as a string of the string value whose key is <code>payload</code> in the <code>RenderPlayerInfo</code> message\u2019s payload instead of the overall AASB payload.</p> </li> </ul> </li> </ul>"},{"location":"releases/changelog/#additional-changes_1","title":"Additional Changes","text":"<p>Starting with Auto SDK v3.0, we no longer support the Automotive Grade Linux (AGL) Alexa Voice agent in the Auto SDK. If you intend to use the AGL Alexa Voice Agent, continue using Auto SDK v2.3.0, which is the last version that provides AGL support.</p>"},{"location":"releases/changelog/#v230-released-on-2020-07-31","title":"v2.3.0 released on 2020-07-31","text":""},{"location":"releases/changelog/#enhancements_10","title":"Enhancements","text":"<ul> <li>Added a new Messaging module that provides support for Short Message Service (SMS) to allow a user to send, reply to, and read messages through Alexa.</li> <li>Added support for zones to car control for online-only devices so the customer can target endpoints by location (e.g., \u201cset the front fan to 7\u201d). This feature was supported only with the Local Voice Control (LVC) extension, and endpoints belonged to exactly one zone. The features for online-only and LVC devices are at parity and now include assigning an endpoint to multiple zones and setting a default zone. Endpoints in the default zone take higher priority than endpoints not in the default zone when no zone is specified in an utterance.</li> <li>Added support for \u201csemantics\u201d for car control to enable \u201copen\u201d, \u201cclose\u201d, \u201craise\u201d, and \u201clower\u201d utterances to control endpoints.</li> <li>Added a method to the 'AlexaClient' platform interface to stop foreground-focused Alexa activity on the device (e.g., locally canceling ongoing TTS when the user selects a list item or presses a cancel button).</li> <li>Added support for Dynamic Language Switching. Previously, Alexa could only understand and respond in one language at a time. Now Alexa supports two languages at once and automatically detects the user's spoken language and responds in the same language as the utterance. The supported locale pairs are the following:<ul> <li>[ \"en-US\", \"es-US\" ]</li> <li>[ \"es-US\", \"en-US\" ]</li> <li>[ \"en-IN\", \"hi-IN\" ]</li> <li>[ \"hi-IN\", \"en-IN\" ]</li> <li>[ \"en-CA\", \"fr-CA\" ]</li> <li>[ \"fr-CA\", \"en-CA\" ]</li> </ul> </li> </ul> <p>Note: Dynamic Language Switching works online only. For hybrid systems using the LVC extension, offline Alexa understands and responds in the language of the primary locale. * Updated radio tuning increments for \u201cAM_RADIO\u201d and \u201cFM_RADIO\u201d Local Media Source types to support the en_IN locale. * Alexa Voice Agent now supports AGL Itchy Icefish v9.0.2. * Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binary.</p>"},{"location":"releases/changelog/#resolved-issues_10","title":"Resolved Issues","text":"<ul> <li>Fixed an issue in which navigation road regulation and maneuver events resulted in \u201cINVALID_REQUEST_EXCEPTION\" or \"INTERNAL_SERVICE_EXCEPTION\" error logs.</li> <li>Fixed several failing car control utterances including those for offline AC controls and those using the words \u201cmy\u201d or \u201clights.\u201d</li> <li>Fixed an issue in External Media Player that caused the \u201cNEXT\u201d play control request to be issued twice for ExternalMediaAdapter (e.g., MACC) and LocalMediaSource platform interface handlers.</li> <li>Fixed an issue in which the Engine did not stop music playback after user logout.</li> <li>Fixed an issue that caused Spotify to play at an increased and unsteady rate on QNX.</li> <li>Fixed an issue with the  <code>--use-mbedtls</code> build option that caused a crash in the Android sample app at startup.</li> <li>Fixed an issue in the Engine metrics implementation in which regular expression matching with a large number of data points caused a crash.</li> <li>Fixed an issue in MACC in which players removed while the Engine was running (such as by the uninstallation of a linked MACC-compliant app) could not be rediscovered properly and used again, even if the player was restored (such as by the reinstallation of the app and user login). Previously, the rediscovery logic left insufficient time to process the player removal event before trying to discover players again, resulting in a loop. Now the rediscovery step runs at 5-minute intervals.</li> <li>Fixed an issue with the Engine's SQLite local storage database in which concurrent access to the database caused a crash.</li> <li>Fixed various memory leaks and intermittent crashes caused by race conditions at Engine shutdown.</li> <li>Fixed an issue on Android API 25 in which a large number of emitted logs could cause a crash due to a JNI local reference table overflow.</li> <li>Fixed an issue in which you experienced unexpected results if the local timezone of your device differed from the timezone configured through the Alexa companion app.</li> </ul>"},{"location":"releases/changelog/#known-issues_10","title":"Known Issues","text":"<ul> <li> <p>General</p> <ul> <li>A user barging in when music is playing sometimes hears the Alexa response to the barge-in request and the music at the same time if System Audio extension is used.</li> <li>If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations:     [\"en-US\", \"es-US\"],     [\"es-US\", \"en-US\"],     [\"en-IN\", \"hi-IN\"],     [\"hi-IN\", \"en-IN\"],     [\"fr-CA\", \"en-CA\"],     [\"en-CA\", \"fr-CA\"].</li> </ul> <p>The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value.</p> </li> <li> <p>Car Control</p> <ul> <li>For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN.</li> <li>It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login.</li> <li>If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try.</li> <li>Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d.</li> <li>The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings.</li> </ul> </li> <li> <p>Communications</p> <ul> <li>A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works.</li> <li>When using LVC in online mode, users can redial a call when the phone connection state is OFF.</li> <li>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</li> <li>Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</li> <li>A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls.</li> </ul> </li> <li> <p>Entertainment</p> <ul> <li>A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next.</li> <li>The user must enunciate \u201cline-in\u201d in utterances targeting the \u201cLINE_IN\u201d Local Media Source type in order for Alexa to recognize the intent.</li> <li>When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash.</li> <li>On QNX, when a portion of music on Spotify is skipped, either by the user saying \"Skip forward\" or by the user skipping to a different song, the volume is reset to the default level.</li> </ul> </li> <li> <p>Authentication</p> <ul> <li>The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored.</li> <li>If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.</li> </ul> </li> </ul>"},{"location":"releases/changelog/#v221-released-on-2020-05-29","title":"v2.2.1 released on 2020-05-29","text":""},{"location":"releases/changelog/#enhancements_11","title":"Enhancements","text":"<ul> <li>Added enhancements to the maccandroid module to allow <code>SupportedOperations</code> to be overridden to support custom actions.</li> <li>Enhanced the <code>TemplateRuntime</code> platform interface to support focus and audio player metadata in renderTemplate and renderPlayerInfo methods. This is a backward compatible change, see the migration guide for details.</li> <li><code>SpeakerManager</code> is now a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\".</li> </ul>"},{"location":"releases/changelog/#resolved-issues_11","title":"Resolved Issues","text":"<ul> <li>Fixed issues in the maccandroid module to a) rediscover media apps after getting the app removed callback, and b) change the behavior to only report unauthorized when the user specifically asks to play a media app.</li> <li>On the QNX platform, prevent unnecessary flushing for audio output.</li> </ul>"},{"location":"releases/changelog/#known-issues_11","title":"Known Issues","text":"<ul> <li>On the Android Sample App, media playback gets into \"No Content Playing\" state where all GUI playback control breaks, when pressing next after force closing an external media app.</li> <li>Playback controls in the C++ Sample App Playback Controller Menu are static text items and do not change visual state (e.g. add/remove, hilite, select) based on audio player metadata.</li> </ul>"},{"location":"releases/changelog/#v220-released-on-2020-04-15","title":"v2.2.0 released on 2020-04-15","text":""},{"location":"releases/changelog/#enhancements_12","title":"Enhancements","text":"<ul> <li>Added a Car Control module to support online-only car control use cases without the optional Local Voice Control (LVC) extension. The Car Control module provides the car control functionality introduced in Auto SDK 2.0.0 but does not require the LVC extension.</li> <li>Made various enhancements to the External Media Player (EMP) Adapter to improve EMP behavior and facilitate implementation of Alexa audio focus.</li> <li>Introduced the Property Manager, a new platform interface that allows you to set and retrieve Engine property values and be notified of property value changes.</li> <li>Added support for setting the timezone of a vehicle. The <code>PropertyManager</code> interface supports a new a <code>\"TIMEZONE\"</code> property setting.</li> <li>Added support for specifying a custom volume range for voice interactions in implementations that use the optional Local Voice Control (LVC) extension.</li> <li>Separated the LVC language models into independent APKs rather than providing them directly in the LVC APK as was done in previous releases. One language model APK is provided for each supported locale (currently en-US, en-CA, and fr-CA).</li> </ul>"},{"location":"releases/changelog/#resolved-issues_12","title":"Resolved Issues","text":"<ul> <li>Fixed an issue where the CBL state did not change to stopped when you cancelled login with <code>CBL::cancel()</code>.</li> <li>Fixed an issue where volume adjustments were lost when pausing and resuming music.</li> <li>Fixed an External Media Player (EMP) Engine implementation that caused an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession.</li> <li>Fixed an issue where the Engine might hang during shutdown if it was shut down while TTS was being played or read.</li> <li>Fixed an issue where Auto SDK initialization failed at startup when applications using the optional LVC extension didn't register a NetworkInfoProvider platform interface.</li> <li>Fixed an issue where building the Auto SDK with sensitive logging enabled was not working as expected.</li> <li>Added alerts error enums (<code>DELETED</code> and <code>SCHEDULED_FOR_LATER</code>) to the <code>Alerts</code> platform interface.</li> <li>With the exception of road regulation and maneuver events, the Alexa cloud no longer returns an <code>INVALID_REQUEST_EXCEPTION</code> or <code>INTERNAL_SERVICE_EXCEPTION</code> in response to navigation events sent by the Auto SDK.</li> <li>Alexa now prompts or notifies the clients and rejects the ping packet when the user deregisters from the companion app.</li> </ul>"},{"location":"releases/changelog/#known-issues_12","title":"Known Issues","text":"<ul> <li>General</li> <li>If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". Auto SDK v2.2.0 adds support for setting the timezone of the vehicle, which allows your device to synchronize with the timezone set in the Alexa companion app; however, the Auto SDK currently does not receive a <code>SetTimeZone</code> directive when the timezone is changed from the companion app.</li> <li>Navigation</li> <li>The Alexa cloud currently returns an <code>INTERNAL_SERVICE_EXCEPTION</code> in response to any navigation road regulation or maneuver event sent by the Auto SDK (triggered by an utterance such as \"which lane should I take\", for example). You may see a harmless error/exception in the logs.</li> <li>Car Control</li> <li>Certain car control utterances return errors. Problematic utterances include natural versions of certain test utterances (for example, \u201cturn on the light\u201c instead of \u201cplease turn on the light in the car\u201d); utterances that include the words \u201clights\u201d or \u201cmy\u201d; and utterances to control the defroster or defogger that use \u201cput on\u201d or \u201cset on\u201d rather than \u201cturn on\u201d or \u201cswitch on\u201d.</li> <li>Setting the air conditioner using range controller control capabilities (for example \u201cset the air conditioner to 65\u201d or \u201cset the air conditioner to low\u201d) is not currently supported.</li> <li>In offline mode, the utterances \"turn ac on\u201d, \u201cturn off ac\u201d, \u201cturn ac off\u201d, and \u201cturn up ac\" return errors.</li> <li>Communications</li> <li>When using LVC in online mode, users can redial a call when the phone connection state has been switched to OFF.</li> <li>DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored.</li> <li>Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</li> <li>Entertainment</li> <li>A user playing any skill with extended multi-turn dialogues (such as Jeopardy or Skyrim) cannot accept or reject incoming Alexa-to-Alexa calls using voice.</li> <li>A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next.</li> <li>When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d</li> <li>Authentication</li> <li>The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored.</li> <li>If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.</li> </ul>"},{"location":"releases/changelog/#v210-released-on-2019-12-19","title":"v2.1.0 released on 2019-12-19:","text":""},{"location":"releases/changelog/#enhancements_13","title":"Enhancements","text":"<ul> <li> <p>Added Navigation enhancements to support the following features:</p> <ul> <li>Add a waypoint - Enables users to search and add waypoints to their current route along the way or start a new route with a given set of waypoints.</li> <li>Cancel a waypoint - Enables users to cancel a waypoint with voice.</li> <li>Show/Navigate to previous destinations - Enables users to view previous destinations and navigate to any of their previous destinations..</li> <li>Turn and Lane Guidance - Enables users to ask Alexa for details about their next navigation instruction.</li> <li>Control Display - Enables users to interact with their onscreen map applications.</li> </ul> <p>Note: The Navigation enhancements are not backward-compatible with previous versions of the Auto SDK. The <code>startNavigation()</code> method supersedes the <code>setDestination()</code> method, and many new methods have been implemented. See the Auto SDK Migration Guide for details.</p> </li> <li> <p>Added support for Alexa Presentation Language (APL) rendering to present visual information and manage user interactions with Alexa.</p> <p>Note: In order to use APL rendering with the Android Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details.</p> </li> <li> <p>Added support for the Alexa DoNotDisturb (DND) interface, which allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation.</p> <p>Note: Alexa does not notify the user of the DND state.</p> </li> <li> <p>Added a System Audio extension to provide the default audio capturing and playback functionality for various platforms, including audio input/output on QNX platforms. The Alexa Auto SDK Builder automatically includes the System Audio extension when you build the Auto SDK.</p> </li> <li> <p>Added local media sources (LMS) and hybrid car control support to the Automotive Grade Linux (AGL) Alexa Voice Agent.</p> </li> <li> <p>Added <code>onAuthFailure()</code> to the <code>AuthProvider</code> platform interface and an <code>AUTHORIZATION_EXPIRED</code> argument to the <code>cblStateChanged()</code> method of the CBL platform interface to expose 403 unauthorized request exceptions from Alexa Voice Service (AVS). These may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app.</p> </li> <li> <p>Added support for call display information change notifications (caller ID) to the optional Alexa Communication extension.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_13","title":"Resolved Issues","text":"<ul> <li>Fixed an issue where contact uploading failed for contacts without addresses.</li> <li>Fixed an issue where if the user rejected an incoming Alexa-to-Alexa call via voice, ringtones did not sound for subsequent incoming calls until the user either answered an incoming call via voice or made an outbound call.</li> <li>Fixed an issue that required you to assign unique entry IDs to contacts and navigation favorites to ensure that the ID space used for contacts and navigation favorites did not collide.</li> <li>Fixed an issue where multiple automotive devices using the same account at the same time could access contacts from phones paired across those devices.</li> <li>Fixed an issue where uttering \"stop\" when a timer sounded during an Alexa-to-Alexa call ended the call, not the timer.</li> <li>Added enhancements to the maccandroid module (Spotify) to simplify the <code>MACCPlayer</code> handler implementation. Rediscovery now occurs automatically, and the authorization TTS error events no longer occur repeatedly.</li> </ul>"},{"location":"releases/changelog/#known-issues_13","title":"Known Issues","text":"<ul> <li>The Alexa cloud currently returns an <code>INVALID_REQUEST_EXCEPTION</code> or <code>INTERNAL_SERVICE_EXCEPTION</code> in response to any navigation event sent by the Auto SDK. You may see a harmless error/exception in the logs.</li> <li>The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored.</li> <li>If the user deregisters from the companion app, Alexa does not prompt or notify the clients and does not reject the ping packet.</li> <li>If you log out and log in, the Do Not Disturb (DND) state is not synchronized with Alexa.</li> <li>When you cancel login with <code>CBL::cancel()</code>, the CBL state does not change to stopped.</li> <li>Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or* using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits.</li> <li>The Engine may sometimes stop abruptly on shutdown due to a race condition. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected.</li> <li>The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio.</li> <li>When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d</li> <li>A user playing Jeopardy or Skyrim cannot accept or reject incoming Alexa-to-Alexa calls using voice.</li> <li>If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\".</li> <li>When pausing and resuming music, volume adjustments are lost.</li> <li>A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next.</li> <li>The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession.</li> </ul>"},{"location":"releases/changelog/#v200-released-on-2019-09-10","title":"v2.0.0 released on 2019-09-10:","text":""},{"location":"releases/changelog/#enhancements_14","title":"Enhancements","text":"<ul> <li> <p>Added offline enhancements to improve offline car control support and add support for:</p> <ul> <li> <p>offline car control enhancements - to support generic controls that represent what can be controlled in a vehicle; for example: interior lighting, fans, temperature zone (driver and passenger), vent position, defroster, air conditioner, and recirculation.     &gt;Note: The car control enhancements are not backward compatible with previous versions of car control. The configuration and platform interface have changed.</p> </li> <li> <p>offline entertainment - to support tuning to a specific frequency or SiriusXM channel, tuning to radio presets, switching between car audio sources (bluetooth, radio, satellite radio, CD player, etc.), and controlling local audio sources (pause, shuffle, loop, etc.)</p> </li> <li>offline communications - to support uploading contacts, calling a number or a contact, answering, declining, redialing, or ending a call, and dialing digits during a call</li> <li>offline navigation - to support navigating to favorite locations and canceling navigation</li> <li>Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets.</li> <li>Added online navigation enhancements to support navigating to favorite locations and answering ETA and time to destination questions.</li> <li>Introduced the Address Book module, which includes a common platform interface that you can implement to either upload user data to the Alexa cloud or allow the local communications and navigation capabilities to access user data for offline use cases (supported by the optional Local Voice Control (LVC) module). The Address Book module supersedes the Contacts Uploader module, which supports only phone contacts and only online use cases.</li> <li>Introduced a new core Audio service and API to implement audio input and output providers, and deprecated the existing MediaPlayer and Speaker platform interfaces in the Alexa module. This redesign simplifies integration with platform-specific audio capabilities and enables implementation of new, advanced audio features. <p>NOTE: The new core Audio service and APIs are not backward compatible with previous versions of the Alexa Auto SDK (prior to version 2.0.0).</p> </li> </ul> </li> <li> <p>Added a library to support the Device Client Metrics (DCM) extension for additional platforms such as Linux and QNX in addition to Android, which was supported in release 1.5. This library is required to upload metrics and vehicle information to the Amazon cloud.</p> </li> <li>Added support for Voice Chrome for Android, an extension available through your Solutions Architect or Partner Manager that provides a Voice Chrome library for the Android platform. This library allows you to display voice chrome animations of different Alexa states to the user on screen.</li> <li>Added an integrated wake word enhancement to ignore Alexa waking itself up. In order to implement this enhancement, you must provide audio loopback via the platform or application.</li> <li>Added local pause handling to the PlaybackController to allow non-voice interactions to pause media playback from the AudioPlayer source immediately, without waiting for a response from the cloud.</li> <li> <p>Added Geolocation support to the Navigation module. Geolocation support enables location-based services (which are used to answer questions such as \u201cwhere am I\u201d or \u201cwhat\u2019s the weather\u201d) to use the location information provided by the platform.</p> <p>Note: In order to make use of this functionality, you must register the Navigation platform interface for Geolocation support. * Enhanced the builder scripts to simplify the build process by removing unnecessary options and including the default components for different targets. For details see the Builder documentation. * Refactored the Java Native Interface (JNI) code used for Android platform interfaces for more modular deployment. In place of a single AAR including all Auto SDK native libraries, the Alexa Auto SDK now generates multiple AARs (one per module). See the builder documentation and the Android Sample App documentation for details.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_14","title":"Resolved Issues","text":"<ul> <li>Fixed an issue where music streaming from online music service providers continued to play when the user switched to a local media source.</li> <li>Fixed an issue where an MACC app (Spotify) could automatically play after the first utterance.</li> <li>Fixed a race condition in the Navigation module that occasionally caused Cancel Navigation to fail.</li> <li>Fixed broken links in the documentation.</li> </ul>"},{"location":"releases/changelog/#known-issues_14","title":"Known Issues","text":"<ul> <li>Calling numbers such as 1800xxxxxxx using utterances such as \"Alexa call one eight double oh...\" may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore, when requesting Alexa to call or press digits, we recommend that your client application ignore special characters, dots, and non-numeric characters if not relevant to the context.</li> <li>The Engine may crash during shutdown due to a race condition in the Local Media Source Engine implementation. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected.</li> <li>The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio.</li> <li>In online mode, Alexa does not recognize the utterance \"Switch to line in.\"</li> <li>A user interacting with multiturn skills such as Jeopardy cannot accept or reject incoming Alexa-to-Alexa calls using voice.</li> <li>If the user rejects an incoming Alexa-to-Alexa call via voice, ringtones do not sound for subsequent incoming calls until the user either answers an incoming call via the VUI or makes an outbound call.</li> <li>If you change your Car Control configuration or custom assets during development after Local Voice Control (LVC) was previously running, you should stop your application and LVC, change the configuration or custom assets, uninstall and reinstall LVC, and relaunch your application to ensure the changes are applied.</li> <li>To ensure that the ID space used for contacts and navigation favorites does not collide, you must assign unique <code>entryId</code>s to contacts and navigation data. If you use the same <code>entryId</code>, re-uploading contacts may cause navigation favorites to become unavailable to Alexa, and re-uploading navigation favorites may cause contacts to become unavailable.</li> <li>If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\"</li> <li>Alexa uses different audio channels, such as dialog (user utterance or TTS) and content (music), and shuffles between them to respond to user requests. As a result of this shuffling, content (such as music playback) that gets paused to accommodate higher priority channels may regain foreground audio focus and resume content in bursts between the outputs of higher priority channels (such as Alexa TTS or ongoing alerts). To avoid this, platforms should maintain the audio focus for a few extra milliseconds.</li> <li>The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source <code>playControl()</code> method invocations such as play, then pause, followed by play again in quick succession</li> <li>When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer.</li> <li>Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.</li> </ul>"},{"location":"releases/changelog/#v163-released-on-2019-12-02","title":"v1.6.3 released on 2019-12-02:","text":""},{"location":"releases/changelog/#enhancements_15","title":"Enhancements","text":"<p>This release is for bug fixes only. There are no new features or enhancements.</p>"},{"location":"releases/changelog/#resolved-issues_15","title":"Resolved Issues","text":"<ul> <li>Fixed a race condition that could cause follow-ons to a TTS request (for example asking for movies nearby) not to play while Alexa is speaking or playing something.</li> </ul>"},{"location":"releases/changelog/#known-issues_15","title":"Known Issues","text":"<p>All known issues from v1.6.0.</p>"},{"location":"releases/changelog/#v162-released-on-2019-10-11","title":"v1.6.2 released on 2019-10-11:","text":""},{"location":"releases/changelog/#enhancements_16","title":"Enhancements","text":"<p>Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets.</p>"},{"location":"releases/changelog/#resolved-issues_16","title":"Resolved Issues","text":"<p>n/a</p>"},{"location":"releases/changelog/#known-issues_16","title":"Known Issues","text":"<p>All known issues from v1.6.0.</p>"},{"location":"releases/changelog/#v161-released-on-2019-06-21","title":"v1.6.1 released on 2019-06-21:","text":""},{"location":"releases/changelog/#enhancements_17","title":"Enhancements","text":"<p>This release of Alexa Auto SDK includes updates for music certification.</p>"},{"location":"releases/changelog/#resolved-issues_17","title":"Resolved Issues","text":"<p>Resolved issues are limited to music certification updates:</p> <ul> <li>Added fixes from AVS Device SDK v1.12.1 for music certification.</li> <li>Fixed live radio offset for stations that use a dynamic window (<code>mime=audio/mp4a-latm</code>).</li> <li>Documentation updates.</li> </ul>"},{"location":"releases/changelog/#known-issues_17","title":"Known Issues","text":"<p>All known issues from v1.6.0.</p>"},{"location":"releases/changelog/#v160-released-on-2019-05-16","title":"v1.6.0 released on 2019-05-16:","text":""},{"location":"releases/changelog/#enhancements_18","title":"Enhancements","text":"<ul> <li>General availability for Linux target platforms, including: Linux x86-64, Linux ARM 64 (armv8a), and Linux ARM 32 (armv7a).</li> <li>Alexa Auto SDK v1.6.0 enhances the C++ Sample App by improving the reference implementation for Linux platforms. See the C++ sample app documentation for details.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_18","title":"Resolved Issues","text":"<ul> <li>Fixed an issue where Alexa Auto SDK Engine becomes unresponsive if it receives a <code>Play</code> directive during shutdown.</li> <li>Made changes to External Media Player events to send the service id and agent details, which are now mandated by the Alexa Music service. If you are using previous versions with Local Media Source switching or third-party app with MACC, you should upgrade to Alexa Auto SDK v1.6.0 to continue using the corresponding functionality.</li> </ul>"},{"location":"releases/changelog/#known-issues_18","title":"Known Issues","text":"<ul> <li>If the local timezone of the device differs from the timezone that was configured through the Alexa companion app, you may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\u201d</li> <li>If you play your notifications while music is playing, you will hear the music for a split second between the end of one notification and the start of the next.</li> <li>When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer.</li> <li>Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.</li> </ul>"},{"location":"releases/changelog/#v150-released-on-2019-03-06","title":"v1.5.0 released on 2019-03-06:","text":""},{"location":"releases/changelog/#enhancements_19","title":"Enhancements","text":"<ul> <li>Added a C++ sample application to demonstrate use cases that the Alexa Auto SDK supports. For details, see the C++ sample app documentation.</li> <li>Released the code for the AGL Alexa Voice Agent, a binding for Automotive Grade Linux powered by Alexa Auto SDK v1.5. The software is shipped as a standard AGL binding that exposes an API for speech recognition using the Alexa Voice Service. Please refer to the AGL Alexa Voice Agent documentation for instructions to build, install, and test the binding on an R-Car M3 board.</li> <li>Added support for runtime selection of the AmazonLite wake word locale. The AmazonLite locale will automatically switch when the AVS locale is switched.</li> <li>Added support for optionally logging and uploading Alexa Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and UPL between the request and Alexa\u2019s response. Please contact your SA or Partner Manager for details or to request this package for Android.</li> <li>Added support for an optional platform interface <code>EqualizerController</code>. The Equalizer Controller enables Alexa voice control of device audio equalizer settings by making gain adjustments to three frequency bands (\u201cBASS\u201d, \u201cMIDRANGE\u201d, and/or \u201cTREBLE\u201d).</li> <li>Added an optional Code-Based Linking (CBL) authorization implementation in the Engine. With the new <code>cbl</code> module, the Engine handles acquiring access tokens. A <code>CBL</code> platform implementation should be registered with the Engine in place of an <code>AuthProvider</code> implementation to use this method for authorization.</li> <li>Improved the usage and deployment of the Local Voice Control extension on Android. Please contact your SA or Partner Manager for more information.</li> <li>Updated the vehicle information configuration API to include a vehicle identifier. An <code>aace.vehicle.info.vehicleIdentifier</code> property of vehicle configuration is now available through the existing <code>VehicleConfiguration</code>.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_19","title":"Resolved Issues","text":"<ul> <li>Fixed an issue where barging in while many unprocessed Speak directives are queued could cause SpeechSynthesizer to become unresponsive or crash</li> <li>Added an <code>EXPECTING</code> state to the <code>AlexaClient DialogState</code> to accommodate multi-turn for hold-to-talk interactions. When more user input is required during an interaction, tap-to-talk interactions will transition directly from <code>EXPECTING</code> to <code>LISTENING</code> whereas hold-to-talk will remain in the <code>EXPECTING</code> state until listening is manually triggered.</li> <li>Fixed an issue where the Android Sample App could get stuck in a loop of INVALID_REQUEST_EXCEPTION errors being thrown repeatedly after MACCAndroidClient reported an error. Note: To fix this, the C++ <code>ExternalMediaAdapter::getState</code> method signature changed to allow the implementation to say whether the state it provides is valid. This change is not backward compatible.</li> <li>Fixed an issue where the Android Sample App created a syslog sink and logged VERBOSE in release builds. Note: As part of the fix, the default Engine logger sink id changed from console to default. Existing calls to <code>LoggerConfiguration::createLoggerRuleConfig</code> with sink id <code>\"console\"</code> should be changed to sink id <code>\"default\"</code>.</li> </ul>"},{"location":"releases/changelog/#known-issues_19","title":"Known Issues","text":"<ul> <li>The Alexa Auto SDK Engine becomes unresponsive if it receives a <code>Play</code> directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected.</li> <li>When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer.</li> <li>Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.</li> </ul>"},{"location":"releases/changelog/#v140-released-on-2018-12-17","title":"v1.4.0 released on 2018-12-17:","text":""},{"location":"releases/changelog/#enhancements_20","title":"Enhancements","text":"<ul> <li> <p>The Alexa Auto SDK now supports the Local Voice Control extension. The Local Voice Control extension enhances the Alexa Auto experience by providing voice-based car controls whether connected to the internet or not. In this release, the Local Voice Control extension will provision access only to the car\u2019s climate control.</p> <p>Note: This extension is available on request - Please contact your Amazon Solutions Architect (SA) or Partner Manager for more information.</p> </li> </ul>"},{"location":"releases/changelog/#resolved-issues_20","title":"Resolved Issues","text":"<p>No resolved issues.</p>"},{"location":"releases/changelog/#known-issues_20","title":"Known Issues","text":"<ul> <li>The Alexa Auto SDK Engine becomes unresponsive if it receives a <code>Play</code> directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected.</li> <li>When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer.</li> <li>Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.</li> </ul>"},{"location":"releases/changelog/#v131-released-on-2019-06-21","title":"v1.3.1 released on 2019-06-21:","text":""},{"location":"releases/changelog/#enhancements_21","title":"Enhancements","text":"<p>This release of Alexa Auto SDK includes updates for music certification.</p>"},{"location":"releases/changelog/#resolved-issues_21","title":"Resolved Issues","text":"<p>Resolved issues are limited to music certification updates:</p> <ul> <li>Migrated to AVS Device SDK v1.12.1 for music certification. As part of the migration there is a new dependency on <code>openssl</code>. Developers using their own build system may need to make changes in order to accommodate this new dependency when linking AVS Device SDK.</li> <li>Fixed ExternalMediaPlayerAdapter getState() failure that triggered <code>INVALID_REQUEST_EXCEPTION/Bad Request</code> exceptions.</li> <li>Fixed live radio offset for stations that use a dynamic window (<code>mime=audio/mp4a-latm</code>).</li> <li>Updated the Android Sample App log view implementation for improved stability and performance.</li> <li>Bug fixes and documentation updates:</li> <li>Additional test in <code>AuthProviderEngineImpl::doShutdown()</code> to avoid null pointer exception.</li> <li>Fixed an issue with <code>SQLiteStorage::removeKey()</code> where the <code>DELETE FROM</code> statement repeated the <code>FROM</code>.</li> <li>Fixed a race condition in <code>AudioChannelEngineImpl::setSource()</code> with back to back TTS.</li> <li>Internal calls to <code>AudioChannelEngineImpl::executePlaybackFinished()</code> now save the player offset.</li> <li>Internal calls to <code>AudioPlayerEngineImpl::removeObserver()</code> now remove an AudioPlayerObserverInterface observer instance instead of adding it.</li> <li>Use <code>static_cast&lt;unsigned char&gt;</code> for upper/lower character conversions.</li> </ul> <p>The platform interfaces have not changed, however the following C++ and Android enums are updated: * The enum class <code>DialogState</code> inserts the <code>EXPECTING</code> enum constant. * The enum class <code>ConnectionChangedReason</code> inserts <code>NONE</code>, <code>SUCCESS</code>, and <code>UNRECOVERABLE_ERROR</code> enum constants.</p>"},{"location":"releases/changelog/#known-issues_21","title":"Known Issues","text":"<p>All known issues from v1.3.0.</p>"},{"location":"releases/changelog/#v130-released-on-2018-11-20","title":"v1.3.0 released on 2018-11-20:","text":""},{"location":"releases/changelog/#enhancements_22","title":"Enhancements","text":"<ul> <li>Android 8 and ARM v8a platform support.</li> <li>Making calls to contacts from a locally-paired mobile phone as long as the Alexa Auto SDK has a valid auth token. For details, see the Contact Uploader documentation.</li> <li>Redial, answer, terminate, and decline calls using voice. End users can also send dual-tone multi-frequency (DTMF) via voice to interact with Interactive Voice Responders (IVRs). For details, see the Phone Control documentation.</li> <li>Switching to local media sources, generic controls and deep linking into 3rd party media applications compatible with the Amazon Media App Command and Control (MACC) specification using the External Media Player Interface 1.1. This allows customers to switch between a CD player, AM/FM player, and auxiliary input that is MACC-compliant. For details, see the Alexa documentation.</li> <li>Enhancement for 3rd party wake word engine to enable cloud based verification.</li> <li>Provides a way to override Template Runtime display card timeout values for RenderTemplate and RenderPlayerInfo by updating the <code>templateRuntimeCapabilityAgent</code> Engine configuration values.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_22","title":"Resolved Issues","text":"<p>No resolved issues.</p>"},{"location":"releases/changelog/#known-issues_22","title":"Known Issues","text":"<ul> <li>The Alexa Auto SDK Engine becomes unresponsive if it receives a <code>Play</code> directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected.</li> <li>When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer.</li> <li>Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.</li> </ul>"},{"location":"releases/changelog/#v120-released-on-2018-10-15","title":"v1.2.0 released on 2018-10-15:","text":""},{"location":"releases/changelog/#enhancements_23","title":"Enhancements","text":"<ul> <li>Additional information related to the presentation of alerts is now available. The extended interface now includes Alert token, type, rendering time, and label if applicable when an alert is set and notification when an alert is deleted.</li> <li>In the Navigation platform interface, <code>SetDestination</code> now provides business hours and contact information for a returned location when available.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_23","title":"Resolved Issues","text":"<ul> <li>If a location is not available, the location state is set to <code>unavailable</code>. Previously it was treated as <code>(0,0)</code>, which was a valid value for longitude and latitude.</li> <li>Fixed an issue related to stopping an alert where there could be up to a 10 second delay before the alert completely stopped.</li> <li>Fixed issue where the <code>TemplateRuntime</code> platform interface could not be registered before <code>AudioPlayer</code>.</li> </ul>"},{"location":"releases/changelog/#known-issues_23","title":"Known Issues","text":"<p>There are no known issues in this release.</p>"},{"location":"releases/changelog/#v111-released-on-2018-09-10","title":"v1.1.1 released on 2018-09-10:","text":""},{"location":"releases/changelog/#enhancements_24","title":"Enhancements","text":"<p>This release is for bug fixes only. There are no new features or enhancements.</p>"},{"location":"releases/changelog/#resolved-issues_24","title":"Resolved Issues","text":"<ul> <li>Updated a dependency build recipe to skip the checksum verification to allow for document changes in the current tag.</li> </ul>"},{"location":"releases/changelog/#known-issues_24","title":"Known Issues","text":"<p>There are no known issues in this release.</p>"},{"location":"releases/changelog/#v110-released-on-2018-08-31","title":"v1.1.0 released on 2018-08-31:","text":""},{"location":"releases/changelog/#enhancements_25","title":"Enhancements","text":"<ul> <li>Added support for choosing one of multiple network adaptors before starting the Engine.</li> <li>Added support for the latest Amazon Wakeword Engine.</li> <li>Added custom volume control support for infotainment system's native input volume range. The range that comes down to the device will be 0 to 100.</li> <li>Added support for encoding the utterance in OPUS format with the Amazon Wakeword Engine as well as PTT. Our builder pulls the libopus source code as a part of build process.</li> <li>Added Locale API to return the list of Alexa-supported locales.</li> <li>Updated Vehicle Information API to capture the microphone details.</li> <li>Added support for routines, music alarms, timers and alarms volume management, and deleting all timers and alarms.</li> <li>Added support for TemplateRuntime Interface 1.1, which provides visual playback control for Alexa-enabled products with TemplateRuntime Interface support. This includes upgrades to PlaybackController Interface 1.1 and TemplateRuntime Interface 1.1.<ul> <li> <p>Note: The older button-press APIs (<code>playButtonPressed()</code>, <code>nextButtonPressed()</code>, etc.) have been deprecated in favor of the new generic <code>buttonPressed(PlaybackButtonType)</code>.</p> </li> </ul> </li> <li>Updated the builder script to confirm compliance with open source component licenses.</li> </ul>"},{"location":"releases/changelog/#resolved-issues_25","title":"Resolved Issues","text":"<p>There are no resolved issues in this release.</p>"},{"location":"releases/changelog/#known-issues_25","title":"Known Issues","text":"<p>There are no known issues in this release.</p>"},{"location":"releases/changelog/#v102-released-on-2018-08-08","title":"v1.0.2 released on 2018-08-08:","text":""},{"location":"releases/changelog/#enhancements_26","title":"Enhancements","text":"<p>This release is only for documentation updates. There are no new features or enhancements.</p>"},{"location":"releases/changelog/#resolved-issues_26","title":"Resolved Issues","text":"<p>Only name change updates were made to the documentation. There are no resolved issues in this release.</p>"},{"location":"releases/changelog/#known-issues_26","title":"Known Issues","text":"<p>There are no known issues in this release.</p>"},{"location":"releases/changelog/#v101-released-on-2018-07-31","title":"v1.0.1 released on 2018-07-31:","text":""},{"location":"releases/changelog/#enhancements_27","title":"Enhancements","text":"<p>This release is for bug fixes only. There are no new features or enhancements.</p>"},{"location":"releases/changelog/#resolved-issues_27","title":"Resolved Issues","text":"<ul> <li>The Engine now reconnects to Alexa when the <code>NetworkInfoProvider</code> updates the network status.</li> <li>All shared memory objects are now freed when the Engine object is disposed.</li> <li>We fixed a media playback state issue in the Engine that caused an unexpected pause and resume for a media stream that was already stopped.</li> <li>We added AudioPlayer::playerActivityChanged to the Android APIs.</li> <li>Updated the <code>AuthError</code> enumeration with additional error types.</li> <li>Removed deprecated <code>createAuthConfig()</code> configuration method.</li> <li>Fixed issue in the JNI where trying to create a UTF-8 string with invalid characters caused a crash, seen when sensitive logging is enabled.</li> <li>Improved JNI thread handling.</li> <li>Enabled capability registration for phone call control.</li> <li>We fixed an issue where the Android platform build failed on the initial attempt when using clean code.</li> </ul>"},{"location":"releases/changelog/#known-issues_27","title":"Known Issues","text":"<p>There are no known issues in this release.</p>"},{"location":"releases/changelog/#v100-released-on-2018-06-29","title":"v1.0.0 released on 2018-06-29:","text":""},{"location":"releases/changelog/#enhancements_28","title":"Enhancements","text":"<ul> <li>Alexa Auto SDK now supports two <code>Navigation</code> directives.<ul> <li><code>SetDestination</code></li> <li><code>CancelNavigation</code></li> </ul> </li> <li>Added support for phone control APIs. The <code>PhoneCallController</code> platform interface supports the <code>Dial</code> directive with three events:<ul> <li><code>CallActivated</code></li> <li><code>CallTerminated</code></li> <li><code>CallFailed</code></li> </ul> </li> <li>Support for Amazon Wake Word Engine (WWE)</li> </ul>"},{"location":"releases/changelog/#known-issues_28","title":"Known Issues","text":"<ul> <li>The Engine doesn't immediately reconnect to AVS when the <code>NetworkInfoProvider</code> updates network status.</li> <li>Some shared memory objects are not freed when the Engine object is disposed.</li> </ul> <p>Sample App issues are documented in the Sample App README.</p>"},{"location":"releases/changelog/#v100-beta-released-on-2018-04-29","title":"v1.0.0 Beta released on 2018-04-29:","text":""},{"location":"releases/changelog/#enhancements_29","title":"Enhancements","text":"<p>The following enhancements were added to the Alexa Auto SDK since the last Alpha release (binary).</p> <ul> <li><code>SetDestination()</code> API added to the Navigation module</li> <li>Android Sample Application updated with a number of features such as rendering of Display Cards (Shopping List, Coffee Shops Nearby, etc), handling of the <code>SetDestination()</code> API, Notifications, LWA (Login with Amazon)</li> </ul>"},{"location":"releases/changelog/#known-issues_29","title":"Known Issues","text":"<p>SDK:</p> <ul> <li>While the SDK does build against Android API22 and above and runs successfully on Android O devices, our current testing shows a native-code linking error when actually running on API22 devices.</li> </ul> <p>Android Sample App:</p> <ul> <li>M3U and PLS based stream URLs are not parsed before sent to the Android Mediaplayer. Affects live streams typically coming from TuneIn and IHeartRadio services</li> <li>Media playback can take a long time to start sometimes for iHeartRadio and TuneIn</li> <li>The Android Alexa Auto SDK Sample App was developed on an Android tablet with 2048 x 1536 resolution screen size. It can run on smaller devices, but some of the display cards may not display correctly</li> <li>During Playing Media in the Sample App we see the following messages (none of these will cause any issues):</li> <li>E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=streamFormat</li> <li>E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=progressReportDelayInMilliseconds</li> <li>E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=expectedPreviousToken</li> <li>E/AAC:aace.alexa.AudioChannelEngineImpl:validateSource:reason=invalidSource</li> <li>E/AAC:aace.alexa.AudioChannelEngineImpl:pause:reason=invalidSource,expectedState=X</li> <li>On App startup we see the following messages (none of these will cause any issues):</li> <li>E/AVS:SQLiteAlertStorage:openFailed::File specified does not exist.:file path=/data/user/0/com.amazon.sampleapp/cache/appdata/alerts.sqlite</li> <li>Several minor documentation issues that will be addressed in the GA release</li> </ul>"},{"location":"releases/migrate-to-messagebroker/","title":"Migrate to the MessageBroker API","text":""},{"location":"releases/migrate-to-messagebroker/#overview","title":"Overview","text":"<p>Auto SDK 4.0 introduces a new MessageBroker API for applications to subscribe to and publish AASB messages. This API replaces the existing platform interfaces that developers use to integrate platform-specific functionality such as audio, location, and Alexa capabilities. MessageBroker also replaces the deprecated AASB interface used in previous Auto SDK versions.</p> <p>Developers integrating with Auto SDK for the first time should only use the MessageBroker API. Developers who upgrade to Auto SDK 4.0 (and plan to continue to upgrade beyond 4.0), should migrate their existing applications as soon as possible. The next major release of Auto SDK will remove the platform interface API without maintaining backward compatibility with older versions of the SDK.</p>"},{"location":"releases/migrate-to-messagebroker/#application-architecture","title":"Application architecture","text":"<p>In most cases, the interface changes in Auto SDK do not require modifying the architecture of the existing Auto SDK client application. The following diagram shows an application with a typical architecture based on Auto SDK 3.3 next to the same application using the Auto SDK 4.0 MessageBroker API:</p> <p></p> <p>In the example above, the key difference is that rather than creating handlers that extend platform interfaces, the new implementation uses a loosely coupled MessageBroker API to subscribe to and publish messages. It is straightforward to adapt the existing application handlers to MessageBroker by using a simple adapter pattern that does not require completely redesigning the application.</p>"},{"location":"releases/migrate-to-messagebroker/#migrating-existing-platform-interface-handlers","title":"Migrating existing platform interface handlers","text":"<p>The following diagram highlights the core differences between using the old platform interfaces and the new MessageBroker API. The left side shows the steps for creating the Engine and handlers and invoking interface methods in Auto SDK 3.3. The right side shows the equivalent steps using the MessageBroker API required for Auto SDK 4.0.</p> <p></p> <p>Even though the MessageBroker API provides flexibility for how to design an application, it may be easier to adapt an existing implementation rather than redesigning it. </p> <p>The following example demonstrates how to modify a DoNotDisturb platform interface handler to use MessageBroker. </p> <p>Example implementation of a DoNotDisturb handler in Auto SDK 3.3:</p> <p>In Auto SDK 3.3, the DoNotDisturb platform interface has the following methods: </p> <pre><code>    /**\n     * Handle setting of DND directive. \n     * \n     * @param [in] doNotDisturb setting state\n     */\nvirtual void setDoNotDisturb(const bool doNotDisturb) = 0;\n\n/**\n     * Notifies the Engine of a platform request to set the DND State\n     * \n     * @param [in] doNotDisturb setting state\n     * @return true if successful, false if change was rejected\n     */\nbool doNotDisturbChanged(const bool doNotDisturb);\n</code></pre> <p>The implementation overrides the <code>setDoNotDisturb()</code> platform interface method to provide application-specific behavior (in this case, logging a message to the console) and calls the Engine interface method <code>doNotDisturbChanged</code> to request a change to the DoNotDisturb setting.</p> <pre><code>#include &lt;AACE/Alexa/DoNotDisturb.h&gt;\n\nclass DoNotDisturbHandler : public DoNotDisturb {\npublic:\nDoNotDisturbHandler() = default;\nvoid setDoNotDisturb(bool doNotDisturb) override;\nvoid notifyDoNotDisturbSettingChange(bool doNotDisturb);\n};\n\n\nvoid DoNotDisturbHandler::setDoNotDisturb(bool doNotDisturb) {\nstd::cout &lt;&lt; \"setDoNotDisturb: \" &lt;&lt; doNotDisturb &lt;&lt; std::endl;\n}\n\nvoid DoNotDisturbHandler::notifyDoNotDisturbSettingChange(bool doNotDisturb) {\n// Notify the Engine of a request to change the DND setting by calling\n// the Engine interface method implemented in the DoNotDisturb base class\ndoNotDisturbChanged(bool doNotDisturb);\n}\n</code></pre> <p>Example implementation of a DoNotDisturb handler in Auto SDK 4.0:</p> <p>In Auto SDK 4.0 the SetDoNotDisturbMessage and the DoNotDisturbChangedMessage replace <code>setDoNotDisturb</code> the <code>doNotDisturbChanged</code> methods, respectively. </p> <p>The following example shows the same core logic in the handler, but it uses the MessageBroker API instead of extending a platform interface.</p> <p><pre><code>#include &lt;AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h&gt;\n#include &lt;AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h&gt;\n#include &lt;AACE/Core/MessageBroker.h&gt;\n\nclass DoNotDisturbHandler {\npublic:\nDoNotDisturbHandler(std::shared_ptr&lt;MessageBroker&gt; messageBroker);\nvoid setDoNotDisturb(bool doNotDisturb);\nvoid doNotDisturbChanged(bool doNotDisturb);\nprivate:\nstd::shared_ptr&lt;MessageBroker&gt; m_messageBroker;\n};\n\n\nDoNotDisturbHandler::DoNotDisturbHandler( std::shared_ptr&lt;MessageBroker&gt; messageBroker) : m_messageBroker(messageBroker) {\n\n// subscribe to the \"SetDoNotDisturb\" message\nm_messageBroker-&gt;subscribe(\n[=](const std::string&amp; msg) {\nSetDoNotDisturbMessage _msg = json::parse(msg);\nsetDoNotDisturb(_msg.payload.doNotDisturb);\n},    SetDoNotDisturbMessage::topic(),\nSetDoNotDisturbMessage::action());\n}\n\nvoid DoNotDisturbHandler::setDoNotDisturb(bool doNotDisturb) {\nstd::cout &lt;&lt; \"setDoNotDisturb: \" &lt;&lt; doNotDisturb &lt;&lt; std::endl;\n}\n\nvoid DoNotDisturbHandler::notifyDoNotDisturbSettingChange(bool doNotDisturb) {\n// Notify the Engine of a request to change the DND setting by publishing\n// a \"DoNotDisturbChanged\" message\nDoNotDisturbChangedMessage _msg;\n_msg.payload.doNotDisturb = doNotDisturb;\nm_messageBroker-&gt;publish(_msg.toString()); // publish is fire and forget\n}\n</code></pre> A reference to the MessageBroker is required. This can be accessed from the Engine object and provided when creating the DoNotDisturbHandler instance in the main application code:</p> <pre><code>auto handler = std::make_shared&lt;DoNotDisturbHandler&gt;(engine-&gt;getMessageBroker());\n</code></pre>"},{"location":"releases/migrate-to-messagebroker/#handling-audio-and-stream-based-interfaces","title":"Handling audio and stream based interfaces","text":"<p>Auto SDK 4.0 replaces audio stream platform interfaces <code>AudioInput</code> and <code>AudioOutput</code> with the MessageBroker's <code>MessageStream</code> API and corresponding AASB messages with \"AudioInput\" and \"AudioOutput\" topics. When the application receives a message that requires it to read from or write to a stream, the message payload includes a stream ID. The application uses the stream ID to \u201copen\u201d the stream for I/O. Developers with existing handlers for media players or microphone, for example, should migrate their handlers to use the new MessageBroker and MessageStream API. </p> <p>Note In previous versions of Auto SDK, the Engine \"opened\" audio channels through the <code>AudioInputProvider</code> and <code>AudioOutputProvider</code> platform interfaces prior to requesting audio input or output through the <code>AudioInput</code> and <code>AudioOutput</code> platform interface instances representing each channel. In Auto SDK 4.0, there is no AASB message equivalent of <code>AudioInputProvider</code> or <code>AudioOutputProvider</code>. When the Engine needs audio input from a particular channel, it sends the <code>AudioInput.StartAudioInput</code> message with the channel type specified in the payload. Similarly, when the Engine needs to play audio for a particular channel, it sends the <code>AudioOutput.Prepare</code> message with the channel type specified in the payload.</p> <p>The following example demonstrates how the application would open an input stream after receiving the <code>StartAudioInput</code> message, and write data to the stream until a <code>StopAudioInput</code> message is received:</p> <pre><code>#include &lt;AASB/Message/Audio/AudioInput/StartAudioInputMessage.h&gt;\n#include &lt;AASB/Message/Audio/AudioInput/StopAudioInputMessage.h&gt;\n\n// subscribe to the StartAudioInput message\nmessageBroker-&gt;subscribe([=](const std::string&amp; msg) {\n// parse the json message\nStartAudioInputMessage _msg = json::parse(msg);\n// open the stream for writing\nauto streamId = _msg.payload.streamId;\nauto stream = messageBroker-&gt;openStream(\nstreamId,\nMessageStream::Mode::WRITE);\nstartAudioInput(streamId, stream)\n}),\nStartAudioInputMessage::topic(),\nStartAudioInputMessage::action());\n\n// subscribe to the StopAudioInput message\nmessageBroker-&gt;subscribe([=](const std::string&amp; msg) {\n// parse the json message\nStopAudioInputMessage _msg = json::parse(msg);\nauto streamId = _msg.payload.streamId;\nstopAudioInput(streamId);\n}),\nStopAudioInputMessage::topic(),\nStopAudioInputMessage::action());    void startAudioInput(const std::string&amp; streamId, std::shared_ptr&lt;MessageStream&gt; stream) {\n// On another thread, write data to the stream until\n// you receive a StopAudioInput message with the same streamId\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\n} void stopAudioInput(const std::string&amp; streamId) {\n// Stop writing audio data to the stream\n// ...\n// Return quickly to avoid blocking the MessageBroker's outgoing thread!\n}\n</code></pre> <p>A MessageStream can be read-only, write-only, or support both read and write operations. It is required to specify the operation mode when opening the stream using the <code>MessageStream::Mode</code> enumeration. If the MessageBroker cannot open a stream for the specified operation, the <code>openStream()</code> call will fail and return a null object.</p>"},{"location":"releases/migrate-to-messagebroker/#handling-synchronous-style-messages","title":"Handling synchronous-style messages","text":"<p>Most AASB messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special <code>reply</code> message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message.</p>"},{"location":"releases/migrate-to-messagebroker/#replying-to-messages-from-the-engine","title":"Replying to messages from the Engine","text":"<p>In most cases in which a message requires a reply, the Engine will block sending other messages until it receives the reply (or until a timeout occurs), so it is important to send the reply message right away. </p> <p>The following example demonstrates how to subscribe to the GetLocation message from the LocationProvider interface and send a reply back to the Engine:</p> <pre><code>#include &lt;AASB/Message/Location/LocationProvider/GetLocationMessage.h&gt;\n\n// subscribe to GetLocation message\nm_messageBroker-&gt;subscribe([=](const std::string&amp; msg) {\nGetLocationMessageReply _reply;\n// set the reply message \"replyToId\" to the id of the\n// original message:\n_reply.header.messageDescription.replyToId = _msg.header.id;\n// populate the reply message payload data\n_reply.payload.location.latitude = m_latitude;\n_reply.payload.location.longitude = m_longitude;    // publish ther reply\nm_messageBroker-&gt;publish(_reply.toString());\n\n},\nGetLocationMessage::topic(),\nGetLocationMessage::action());\n</code></pre>"},{"location":"releases/migrate-to-messagebroker/#receiving-reply-messages-from-the-engine","title":"Receiving reply messages from the Engine","text":"<p>For some messages published by the application, the Engine may send a <code>reply</code> back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The \"replyToId\" in the reply message will contain the message ID for which the reply is sent.</p> <p>The following example demonstrates how subscribe to <code>GetPropertyReply</code> message from the Engine.</p> <pre><code>m_messageBroker-&gt;subscribe(\n[=](const std::string&amp; message) { handleGetPropertyReplyMessage(message); },\nGetPropertyMessage::topic(),\nGetPropertyMessage::action());\n\n\n// Publish GetPropertyMessage \nvoid publishGetProperty(const std::string&amp; name) {\nGetPropertyMessage msg;\nmsg.payload.name = name;\nm_messageBroker-&gt;publish(msg.toString());\n// Engine sends the GetProperty message reply with the requested property\n// The \"replyToId\" in the reply message will contain the ID of this published message\n}\n\nvoid handleGetPropertyReplyMessage(const std::string&amp; message) {\nGetPropertyMessageReply msg = json::parse(message);\n\n// Get the property value from the reply and handle in the implementation\nconst std::string&amp; propertyValue = msg.payload.value\n}\n</code></pre>"},{"location":"releases/migrate-to-messagebroker/#migrating-existing-aasb-platform-interface-handler-implementation","title":"Migrating existing AASB platform interface handler implementation","text":"<p>Auto SDK 3.3 supports AASB as an optional extension and platform interface. Developers using the AASB platform interface need to migrate the AASB platform interface handler to use the new MessageBroker API instead. This can be accomplished by following a similar pattern as described in the sections above; however, use MessageBroker to subscribe to ALL messages in order to provide the same functionality as the existing AASB platform interface.</p> <pre><code>class AASBHandler {\npublic:\nAASBHandler(std::shared_ptr&lt;MessageBroker&gt; messageBroker);\nvoid messageReceived(const std::string&amp; message);\n// engine interface implementation\nvoid publish(const std::string&amp; message);\nstd::shared_ptr&lt;MessageStream&gt; openStream(\nconst std::string&amp; streamId, MessageStream::Mode mode);\nprivate:\nstd::shared_ptr&lt;MessageBroker&gt; m_messageBroker;\n};\n\nAASBHandler::AASBHandler(\nstd::shared_ptr&lt;MessageBroker&gt; messageBroker) : m_messageBroker(messageBroker) {\n\n// subscribe to ALL messages and bind to the messageReceived() function\n// since it has the same method signature as the message handler\nm_messageBroker-&gt;subscribe(\nstd::bind(&amp;AASBHandler::messageReceived, this, std::placeholders::_1)\n);\n}\n\nvoid AASBHandler::messageReceived(const std::string&amp; message){\n// application logic for handling AASB messages\nstd::cout &lt;&lt; message &lt;&lt; std::endl;\n}\n\nvoid AASBHandler::publish(const std::string&amp; message){\n// invoke the MessageBroker publish method\nm_messageBroker-&gt;publish(message);\n}\n\nstd::shared_ptr&lt;MessageStream&gt; AASBHandler::openStream(\nconst std::string&amp; streamId, MessageStream::Mode mode){\n// invoke the MessageBroker openStream method\nreturn m_messageBroker-&gt;openStream(mode);\n}\n</code></pre>"},{"location":"releases/migrate-to-messagebroker/#hybrid-or-incremental-migration","title":"Hybrid or incremental migration","text":"<p>Although Amazon recommends migrating the entire application to MessageBroker when upgrading to Auto SDK 4.0, it is possible to use a hybrid implementation of platform interface handlers and MessageBroker until Auto SDK removes the platform interface API. New interfaces added in Auto SDK 4.0 are enabled to use the MessageBroker API by default. </p> <p>The following diagram illustrates the architecture for a hybrid application:</p> <p></p>"},{"location":"releases/migration/","title":"Auto SDK Migration Guide","text":""},{"location":"releases/migration/#overview","title":"Overview","text":"<p>This guide highlights the changes in each Auto SDK version that require your application to update to maintain compatibility. The guide outlines the changes with step-by-step recommendations to help you stay up-to-date with the latest Auto SDK version. Each section describes an increment of one release, so if you skip intermediate versions when you upgrade, ensure you follow the steps in each section from your current version to the latest version.</p>"},{"location":"releases/migration/#backward-compatibility","title":"Backward compatibility","text":"<p>Auto SDK remains backward compatible across minor version updates; however, to continually improve, Auto SDK sometimes deprecates APIs, configuration fields, and build options in a minor version. The changes this guide outlines in minor version upgrade sections are intended to highlight deprecations and help you stop using deprecated features as soon as possible to prepare for their removal in the next major version.</p> <p>Although rare, if Auto SDK makes an exception to the backward compatibility tenants in a minor version, this guide explicitly calls out the change.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v420-to-v430","title":"Migrating from Auto SDK v4.2.0 to v4.3.0","text":""},{"location":"releases/migration/#moved-alexa-auto-app","title":"Moved Alexa Auto App","text":"<p>AACS and the Alexa Auto App are removed from the Alexa Auto SDK source. If your vehicle uses the Android platform, contact your Amazon Solutions Architect or Partner Manager for access to Alexa Auto App and its documentation.</p>"},{"location":"releases/migration/#updated-extensions-packaging","title":"Updated extensions packaging","text":"<p>Auto SDK extensions are released as a single package on the Amazon developer portal instead of a separate package for each extension like previous releases. Replace each extension folder in your Auto SDK source tree with the equivalent folder extracted from the new package.</p>"},{"location":"releases/migration/#updated-alexa-client-info-vehicle-info-and-metrics-configuration","title":"Updated Alexa client info, vehicle info, and metrics configuration","text":"<p>Auto SDK 4.3 adjusts configuration format for device info in <code>aace.alexa</code>, <code>aace.vehicle</code>, and <code>aace.dcm</code> configuration objects to reduce duplication and reorganize fields to be consumed by the appropriate Engine service. Update your configuration from something like this</p> <pre><code>{\n\"aace.alexa\": {\n\"avsDeviceSDK\": {\n\"deviceInfo\": {\n\"clientId\": \"${CLIENT_ID}\",\n\"productId\": \"${PRODUCT_ID}\",\n\"deviceSerialNumber\": \"${DEVICE_SERIAL_NUMBER}\",\n\"manufacturerName\": \"${MANUFACTURER_NAME}\",\n\"description\": \"${DEVICE_DESCRIPTION}\"\n},\n\"libcurlUtils\": {\n...\n...\n},\n\"aace.dcm\": {\n\"metricsFilePath\": \"${PATH_TO_STORE_METRICS}\",\n\"metricsTag\": \"${SALT_FOR_METRICS_ID_HASH}\",\n\"deviceInfo\": {\n\"deviceType\": \"${AMAZON_ID}\",\n\"deviceId\": \"${DEVICE_SERIAL_NUMBER}\"\n}\n},\n{\n\"aace.vehicle\": {\n\"info\": {\n\"make\": \"${VEHICLE_MAKE}\",\n\"model\": \"${VEHICLE_MODEL}\",\n\"year\": \"${VEHICLE_YEAR}\",\n\"trim\":  \"${VEHICLE_TRIM}\",\n\"geography\": \"${COUNTRY_CODE}\",\n\"version\": \"${APP_VERSION}\",\n\"os\": \"${DEVICE_OS_NAME_AND_VERSION}\",\n\"arch\":  \"${DEVICE_HARDWARE_ARCH}\",\n\"language\": \"${DEVICE_LANGUAGE}\",\n\"microphone\": \"${VEHICLE_MICROPHONE_TYPE}\",\n\"vehicleIdentifier\":  \"${VEHICLE_IDENTIFIER}\",\n\"engineType\": \"${VEHICLE_ENGINE_TYPE}\",\n\"rseEmbeddedFireTvs\": \"${RSE_FIRE_TV_COUNT}\"\n},\n\"operatingCountry\": \"${COUNTRY_CODE}\"\n}\n},\n...\n}\n</code></pre> <p>to something like this</p> <pre><code>{\n\"aace.alexa\": {\n\"alexaClientInfo\": {\n\"clientId\": \"${CLIENT_ID}\",\n\"productId\": \"${PRODUCT_ID}\",\n\"amazonId\": \"${AMAZON_ID}\"\n},\n\"avsDeviceSDK\": {\n\"libcurlUtils\": {\n...\n...\n},\n\"aace.metrics\": {\n\"metricDeviceIdTag\": \"${SALT_FOR_METRICS_ID_HASH}\",\n\"metricStoragePath\": \"${PATH_TO_STORE_METRICS}\"\n},\n\"aace.vehicle\": {\n\"deviceInfo\": {\n\"manufacturer\": \"${DEVICE_MANUFACTURER}\",\n\"model\": \"${DEVICE_MODEL}\",\n\"platform\": \"${DEVICE_PLATFORM}\",\n\"osVersion\": \"${DEVICE_OS_VERSION}\",\n\"hardwareArch\": \"${DEVICE_HARDWARE_ARCH}\",\n\"serialNumber\":  \"${DEVICE_SERIAL_NUMBER}\"\n},\n\"appInfo\": {\n\"softwareVersion\": \"${APP_VERSION}\"\n},\n\"vehicleInfo\": {\n\"make\": \"${VEHICLE_MAKE}\",\n\"model\": \"${VEHICLE_MODEL}\",\n\"year\": \"${VEHICLE_YEAR}\",\n\"trim\": \"${VEHICLE_TRIM}\",\n\"microphoneType\": \"${VEHICLE_MICROPHONE}\",\n\"operatingCountry\": \"${COUNTRY_CODE}\",\n\"vehicleIdentifier\": \"${VEHICLE_IDENTIFIER}\",\n\"engineType\": \"${VEHICLE_ENGINE_TYPE}\",\n\"rseEmbeddedFireTvs\": \"${RSE_FIRE_TV_COUNT}\"\n}\n},\n...\n}\n</code></pre> <p>In particular,</p> <ul> <li>Alexa client info is moved out of <code>aace.alexa.avsDeviceSDK</code> into <code>aace.alexa.alexaClientInfo</code>. The updated object removes DSN and adds Amazon ID. All fields are required.</li> <li>DCM configuration is removed and replaced with <code>aace.metrics</code>, which includes a subset of values as the previous <code>aace.dcm</code>. The <code>aace.metrics</code> configuration object is required.</li> <li>Vehicle configuration organizes fields by category, removes duplicated values available through other means, adds additional info, and replaces the DSN value previously in <code>aace.alexa.avsDeviceSDK</code>. The <code>aace.vehicle</code> object is required. See the Core module documentation for further information about which fields are required.</li> </ul> <p>The relevant configuration factory functions have updated signatures. See the Alexa module and Core module documentation for complete details about the configuration.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v411-to-v420","title":"Migrating from Auto SDK v4.1.1 to v4.2.0","text":"<p>This section provides the information you need to migrate from Auto SDK v4.1.1 to Auto SDK v4.2.0</p>"},{"location":"releases/migration/#alerts-alarms-timers-and-reminders-interface-disabled","title":"Alerts (Alarms, timers and reminders) interface disabled","text":"<p>The Alerts AASB messages and the corresponding Engine implementation for Reminders, Alarms and Timers have been removed in the SDK from this release. OEMs should no longer subscribe to the Alerts AASB messages and must remove their applications' alert-related features.</p>"},{"location":"releases/migration/#updated-build-option","title":"Updated build option","text":"<p>The build option flag to generate metrics has been changed from with_latency_logs to with_metrics. The \"with_metrics\" variable is a more accurate representation to describe metrics emission. The default value of with_metrics is True, meaning metrics logs will be emitted when built with DCM extension without explicitly specifying any flag.</p>"},{"location":"releases/migration/#deprecated-api","title":"Deprecated API","text":"<p>Deprecated <code>dialogStateChanged(DialogState state</code>) API in AlexaClient in favor of a new one with the assistant ID specified. If you use <code>MessageBroker</code> (recommended) to receive AlexaClient messages, the payload of the DialogStateChanged message will now have the ID of the assistant that the change is associated.</p>"},{"location":"releases/migration/#breaking-configuration-api-changes","title":"Breaking Configuration &amp; API Changes","text":"<p>The Assistant ID in the Alexa Custom Assistant extension is now an integer, and the previous ID in string format is renamed to uuid. This change applies to the related extension configuration fields and APIs, including <code>SetAssistantsSetting</code>. Please refer to the extension documentation for further details.</p>"},{"location":"releases/migration/#alexa-auto-app","title":"Alexa Auto App","text":""},{"location":"releases/migration/#building","title":"Building","text":"<p>We deprecated the optional non-extension module arguments to the gradlew build script \u2014 by default, components like <code>APL</code>, and <code>Car Control</code>, will now be built with only one argument.</p> <p>Example <pre><code>./gradlew assembleLocal{Debug|Release}\n</code></pre> This means that all required resources to build these optional components must be already downloaded and placed in the correct directories for the build to succeed \u2014 please refer to the Alexa Auto App README for more information.</p> <p>For developing with Android Studio, we've upgraded the AGP version to 7.3.1, and the corresponding bundled Gradle version to 7.5.1. We've also raised the compileSDK across our modules to 33 while temporarily fixing the minSDK=targetSDK to 27.</p> <p>Note: Modules that utilize VHAL APIs (e.g., APL, Car Control, and UXRestrictions) expect to be able to use android.car library, which is available on AAOS platforms. The Alexa Auto App will still run on AOSP, but you are responsible for adequately implementing these modules so that all features work end-to-end on your AOSP device..</p>"},{"location":"releases/migration/#permissions","title":"Permissions","text":"<p>These are the new privileged permissions required to be added to the alexa auto app privileged permission allowlist XML file:</p> <pre><code>&lt;permission name=\"android.permission.WRITE_SECURE_SETTINGS\" /&gt;\n&lt;permission name=\"android.permission.SET_TIME_ZONE\" /&gt;\n&lt;permission name=\"android.permission.BLUETOOTH_PRIVILEGED\" /&gt;\n&lt;permission name=\"android.permission.READ_PRIVILEGED_PHONE_STATE\" /&gt;\n&lt;permission name=\"android.permission.PACKAGE_USAGE_STATS\" /&gt;\n&lt;permission name=\"android.permission.MEDIA_CONTENT_CONTROL\" /&gt;\n\n&lt;permission name=\"android.car.permission.CAR_POWER\" /&gt;\n&lt;permission name=\"android.car.permission.CONTROL_CAR_ENERGY_PORTS\" /&gt;\n&lt;permission name=\"android.car.permission.CAR_VENDOR_EXTENSION\" /&gt;\n</code></pre>"},{"location":"releases/migration/#breaking-api-changes","title":"Breaking API Changes","text":"<ul> <li>The <code>FetchStreamCallback.onStreamFetchCancelled</code> callback now has a second parameter; the signature now is (<code>String streamID, long bytesWritten</code>). The <code>bytesWritten</code> parameter returns the total number of bytes successfully written to AutoSDK relative to the start of <code>AudioInputMessageHandler</code>.</li> <li><code>LocaleUtil</code> has been refactored to be greatly simplified \u2014 all app-locale setting has been replaced with <code>AppCompatDelegate.[get/set]ApplicationLocales</code> (backwards-compatible, but requires <code>compileSDK=33</code>)</li> <li>Every fragment/UI layout was updated. If you had any code that previously modified these pages, you need to first carefully re-evaluate if your local changes conflict with the newer UI updates. The following are some particular cases you\u2019ll need to be aware of:<ul> <li>The sign-in URL used to be hard-coded in the <code>CBLFragment</code> and LoginFragment within the setup module. Now, the Auto SDK provides the sign-in URL as a part of the CBL authorization payload \u2014 we mandate that all partners use this functionality over the hard-coded URL..</li> <li>Certain pages were translated from Java to Kotlin on top of new additions to those same pages (<code>SettingsActivity</code>). If you had any local additions to these pages initially written in Java, these would undoubtedly break, and you will need to port those over to Kotlin.</li> </ul> </li> <li>If your device relied on the <code>DefaultNaviProvider</code> to broadcast intents to your navigation app, then be mindful that there was a minor change to the <code>controlDisplay</code> method to parse the <code>controlDisplayData</code> into a JSON object instead of passing it in as a raw string.</li> </ul>"},{"location":"releases/migration/#migrating-from-auto-sdk-v400-to-v410","title":"Migrating from Auto SDK v4.0.0 to v4.1.0","text":"<p>This section provides the information you need to migrate from Auto SDK v4.0.0 to Auto SDK v4.1.0</p>"},{"location":"releases/migration/#showalternativeroutessucceeded-savings-amount-must-be-float","title":"ShowAlternativeRoutesSucceeded savings amount must be float","text":"<p>The field <code>alternateRoute.savings.amount</code> in the <code>Navigation.ShowAlternativeRoutesSucceeded</code> AASB message (and corresponding deprecated platform interface API <code>Navigation::showAlternativeRoutesSucceeded</code>) is a float, but Auto SDK versions 4.0 and earlier incorrectly allowed passing a string for this value. Auto SDK 4.1 fixes the issue, so you must update your code to use a float if your code is also incorrectly using a string.</p>"},{"location":"releases/migration/#lvc-app-components-replace-lvc-apk-on-android-platform","title":"LVC App Components replace LVC APK on Android Platform","text":"<p>AACS LVC App Components replace the LVC APK on Android. Auto SDK no longer releases the LVC APK, and the previous LVC APK does not work with 4.1 AACS. The LVC App Components are Android libraries (AARs) that run LVC in the same application as AACS, and the AACS Sample App integrates them by default.</p> <ul> <li> <p>If your Alexa client application uses the Java platform interfaces (deprecated in 4.0), you are required to update your application to use AACS before integrating with LVC App Components. See Migrate to the MessageBroker API and the AACS documentation for information about migrating your application.</p> </li> <li> <p>If your Alexa client application is AACS-based already and has LVC functionality, the previous implementation based on AIDL interfaces and the LVC APK no longer applies. Specifically,</p> <ul> <li><code>ILVCClient</code> and <code>ILVCService</code> are removed. Remove your implementation of <code>ILVCClient</code> and the binding to the LVC service. Instead, by default, no additional implementation is needed with AACS in 4.1 because AACS starts and configures LVC.</li> <li>You do not need to specify <code>android:sharedUserId</code> previously required for inter-application UDS IPC.</li> </ul> </li> </ul> <p>For more details about integrating the LVC App Components, see the documentation in the Local Voice Control extension on the Amazon developer portal.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v330-to-v400","title":"Migrating from Auto SDK v3.3.0 to v4.0.0","text":"<p>This section provides the information you need to migrate from Auto SDK v3.3.0 to Auto SDK v4.0.0</p>"},{"location":"releases/migration/#platform-interfaces-are-deprecated","title":"Platform Interfaces are deprecated","text":"<p>The C++ and Java platform interfaces are deprecated in favor of Alexa Auto Services Bridge (AASB). Auto SDK 4.0 replaces the platform interfaces with a new <code>MessageBroker</code> API for subscribing to and publishing AASB messages. See <code>Migrate to the MessageBroker API</code>  for information and instructions to migrate your application.</p>"},{"location":"releases/migration/#aasb-configuration-for-aacs-is-updated","title":"AASB configuration for AACS is updated","text":"<p>In Auto SDK version 3.3, your application using AACS was required to configure the AASB version with the following <code>aacs.aasb</code> object in your AACS configuration file:</p> <pre><code>\"aacs.aasb\" : {\n    \"version\": \"3.3\"\n}\n</code></pre> <p>Remove this configuration from your 4.0 AACS configuration file.</p> <p>Additionally, the optional <code>defaultMessageTimeout</code> and <code>autoEnableInterfaces</code> configuration fields are moved from the <code>aasb</code> object to the <code>messageBroker</code> object, so you must update your AACS configuration file if you use these fields. For example, if your AACS configuration file includes this block:</p> <pre><code>{\n    \"aacs.aasb\": {\n        \"autoEnableInterfaces\": false,\n        \"defaultMessageTimeout\": 1000\n    }\n}\n</code></pre> <p>change it to this:</p> <pre><code>{\n    \"aacs.messageBroker\": {\n        \"autoEnableInterfaces\": false,\n        \"defaultMessageTimeout\": 1000\n    }\n}\n</code></pre>"},{"location":"releases/migration/#migrating-from-auto-sdk-v321-to-v330","title":"Migrating from Auto SDK v3.2.1 to v3.3.0","text":"<p>This section provides the information you need to migrate from Auto SDK v3.2.1 to Auto SDK v3.3.0</p>"},{"location":"releases/migration/#local-media-source-and-global-preset-enhancements","title":"Local Media Source and Global Preset Enhancements","text":""},{"location":"releases/migration/#globalpreset-is-deprecated","title":"GlobalPreset is deprecated","text":"<p>The <code>GlobalPreset</code> platform interface is deprecated because its feature set is supported by the new <code>DEFAULT</code> <code>LocalMediaSource</code> type. To preserve functionality for utterances targeting generic presets like \"Alexa, play preset 1\", implement and register a <code>LocalMediaSource</code> handler of <code>Source::DEFAULT</code> type. The user utterances that cause the Engine to invoke <code>GlobalPreset::setGlobalPreset()</code> will cause the Engine to invoke <code>LocalMediaSource::play()</code> with <code>ContentSelector::PRESET</code> instead. The <code>GlobalPreset</code> platform interface will be removed in a future version of Auto SDK.</p>"},{"location":"releases/migration/#additional-localmediasource-playerevent-calls-are-needed","title":"Additional LocalMediaSource playerEvent calls are needed","text":"<p>Previous Auto SDK documentation stated that you must call <code>LocalMediaSource::playerEvent()</code> to report events \"PlaybackStated\" and \"PlaybackStopped\" only. Please update your implementation to call <code>playerEvent()</code> with states \"PlaybackSessionStarted\" and \"PlaybackSessionEnded\" as well. See the Alexa module documentation for information about when to report these events.</p>"},{"location":"releases/migration/#setfocus-is-deprecated","title":"setFocus is deprecated","text":"<p>The API <code>LocalMediaSource::setFocus()</code> is deprecated because its functionality is equivalent to calling <code>LocalMediaSource::playerEvent()</code> with event name \"PlaybackSessionStarted\" when a player is brought into focus or \"PlaybackSessionEnded\" when a player is removed from focus. Please replace your calls to <code>setFocus(true)</code> and <code>setFocus(false)</code> with calls to <code>playerEvent(\"PlaybackSessionStarted\")</code> and <code>playerEvent(\"PlaybackSessionEnded\")</code>, respectively. <code>setFocus</code> will be removed in a future version of Auto SDK.</p>"},{"location":"releases/migration/#reporting-playback-session-id-is-needed","title":"Reporting playback session ID is needed","text":"<p>The Alexa cloud requires <code>ExternalMediaPlayer</code> events and context for a particular player to include the playback session ID of a player's active session. To support this, the <code>LocalMediaSource::play()</code> function signature is updated to include a parameter for session ID for an Alexa-initiated session, which you must use when reporting player events for the player. The <code>playerEvent</code> and <code>playerError</code> signatures are also updated to include session ID. You must generate your own session ID when the playback is initiated by the user without Alexa. See the Alexa module documentation for more details about the <code>sessionId</code>. The versions of APIs without the session ID will be removed in a future version of Auto SDK.</p>"},{"location":"releases/migration/#migrating-the-local-navigation-module-apis","title":"Migrating the Local Navigation Module APIs","text":"<p>The local search features of the Local Voice Control Extension's Local Navigation module are extended to support offline navigation to addresses, cities, and neighborhoods. To support the new feature set, the existing APIs are updated to a more general name. The changes are backward compatible, but the old APIs are deprecated and will be removed in a future version. Use the following steps to assist the migration to the new APIs:</p>"},{"location":"releases/migration/#localsearchprovider-platform-interface-changes","title":"LocalSearchProvider Platform Interface Changes","text":"<p>We have deprecated the functions <code>poiSearchRequest</code>, <code>poiLookupRequest</code>, <code>poiSearchResponse</code>, and <code>poiLookupResponse</code> in favor of <code>searchRequest</code>, <code>lookupRequest</code>, <code>searchResponse</code>, and <code>lookupResponse</code>, respectively.</p> <ul> <li>Override <code>LocalSearchProvider::searchRequest()</code> instead of <code>LocalSearchProvider::poiSearchRequest()</code>.</li> <li>Override <code>LocalSearchProvider::lookupRequest()</code> instead of <code>LocalSearchProvider::poiLookupRequest()</code>.</li> <li>Call <code>LocalSearchProvider::searchResponse()</code> instead of <code>LocalSearchProvider::poiSearchResponse()</code>.</li> <li>Call <code>LocalSearchProvider::lookupResponse()</code> instead of <code>LocalSearchProvider::poiLookupResponse()</code>.</li> </ul> <p>We have also deprecated the AASB messages <code>PoiSearchRequestMessage</code>, <code>PoiLookupRequestMessage</code>, <code>PoiSearchResponseMessage</code>, and <code>PoiLookupResponseMessage</code> in favor of <code>SearchRequestMessage</code>, <code>LookupRequestMessage</code>, <code>SearchResponseMessage</code>, and <code>LookupResponseMessage</code>, respectively.</p> <ul> <li>Subscribe to <code>SearchRequestMessage</code> instead of <code>PoiSearchRequestMessage</code>.</li> <li>Subscribe to <code>LookupRequestMessage</code> instead of <code>PoiLookupRequestMessage</code>.</li> <li>Publish to <code>SearchResponseMessage</code> instead of <code>PoiSearchResponseMessage</code>.</li> <li>Publish to <code>LookupResponseMessage</code> instead of <code>PoiLookupResponseMessage</code>.</li> </ul> <p>The JSON schemas of search and response are still the same. Note: Do not use/implement a mix of the old APIs and the new APIs</p>"},{"location":"releases/migration/#local-navigation-module-engine-configuration-changes","title":"Local Navigation Module Engine Configuration Changes","text":"<p>The <code>aace.localNavigation.localSearch</code> configuration keys <code>navigationPOISocketPath</code> and <code>poiEERSocketPath</code> are renamed to <code>navigationLocalSearchSocketPath</code> and <code>localSearchEERSocketPath</code>, respectively. For example, if your configuration was this</p> <p><pre><code>{\n   \"aace.localNavigation\": {\n        \"localSearch\": {\n            \"navigationPOISocketPath\": \"/opt/LVC/data/poi-er-service/poi_navigation.socket\",\n            \"poiEERSocketPath\": \"/opt/LVC/data/poi-er-service/poi_eer.socket\"\n        }\n    }\n}\n</code></pre> change it to this</p> <pre><code>{\n   \"aace.localNavigation\": {\n        \"localSearch\": {\n            \"navigationLocalSearchSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_navigation.socket\",\n            \"localSearchEERSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_eer.socket\"\n        }\n    }\n}\n</code></pre> <p>If you are using the <code>LocalNavigationConfiguration::createLocalSearchConfig()</code> factory function to generate the configuration, your usage does not have to change because the signature is the same and implementation of this function generates the new JSON.</p> <p>Note: the socket paths in the Linux default sample configuration file are updated, so if you use different values, ensure you update your LVC app configuration accordingly</p>"},{"location":"releases/migration/#lvc-apk-configuration-changes","title":"LVC APK Configuration Changes","text":"<p>If you use LVC on Android, update the configuration returned by your implementation of the interface <code>ILVCClient.getConfiguration()</code>.</p> <p>The paths <code>NavigationPOISocketDir</code> and <code>POIEERSocketDir</code> have been deprecated in favor of <code>NavigationLocalSearchSocketDir</code> and <code>LocalSearchEERSocketDir</code>, respectively. The socket names <code>NavigationPOISocketName</code> and <code>POIEERSocketName</code> have been deprecated in favor of <code>NavigationLocalSearchSocketName</code> and <code>LocalSearchEERSocketName</code>, respectively.</p>"},{"location":"releases/migration/#lvc-linux-app-configuration-changes","title":"LVC Linux App Configuration Changes","text":"<p>The LVC configuration file <code>lvc-config.json</code> installed at <code>/opt/LVC/config</code> by the installation script <code>LVC.sh</code> has no changes to its JSON configuration schema since Auto SDK 3.2. However, the socket directories and names used by default in this file are updated to use more general names.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v310-to-v320","title":"Migrating from Auto SDK v3.1.0 to v3.2.0","text":"<p>This section provides the information you need to migrate from Auto SDK v3.1.0 to Auto SDK 3.2.0. All information about 3.2.0 is also applicable to 3.2.1.</p>"},{"location":"releases/migration/#using-the-alexa-communication-extension","title":"Using the Alexa Communication Extension","text":"<p>The Alexa Comms library in Auto SDK v3.2.0 uses Device Client Metrics (DCM) instead of AWS IoT for uploading metrics. Therefore, remove the <code>iotCertificateDirPath</code>, <code>iotHostAddress</code>, and <code>deviceTypeId</code> fields from the communication configuration file. For information about the configuration file format, see the Alexa Communication extension documentation.</p> <p>If you build the Alexa Comms module configuration using the programmatic factory function <code>AlexaCommsConfiguration::createCommsConfig()</code> (C++) or <code>AlexaCommsConfiguration.createCommsConfig()</code> (Java), remove the parameters that are no longer present in the signature.</p>"},{"location":"releases/migration/#using-the-device-client-metrics-dcm-extension","title":"Using the Device Client Metrics (DCM) Extension","text":"<p>The Device Client Metrics extension in Auto SDK v3.2.0 requires a field called <code>metricsTag</code> to be defined in the DCM configuration. The value of <code>metricsTag</code> is used for generating a unique identifier for anonymous registration metrics.</p> <p>Note: You must not use the vehicle identification number (VIN) or device serial number (DSN) as <code>metricsTag</code>. For information about how to use this field, see the Device Client Metric extension documentation.</p> <p>If you build the DCM module configuration using the programmatic factory function <code>DCMConfiguration::createDCMConfig()</code> (C++) or <code>DCMConfiguration.createDCMConfig()</code> (Java), add the <code>metricsTag</code> parameter as instructed in the API documentation.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v300-to-v310","title":"Migrating from Auto SDK v3.0.0 to v3.1.0","text":"<p>This section provides the information you need to migrate from Auto SDK v3.0.0 to Auto SDK v3.1.0.</p>"},{"location":"releases/migration/#migrating-to-the-authorization-platform-interface","title":"Migrating to the Authorization Platform Interface","text":"<p>Auto SDK v3.1.0 introduces the Authorization module that provides a single platform interface to manage different types of authorizations supported by the Engine. This single platform interface works with the Engine services that carry out the actual authorization process or flow. For more information about how authorization works, see the Core module documentation. This section provides the information you need for migrating to the Authorization platform interface from the CBL or AuthProvider platform interface, which are deprecated in v3.1.0</p> <p>Migrating from the CBL Platform Interface</p> <p>To migrate from the CBL platform interface to the Authorization platform interface, follow the instructions in the CBL module documentation, which describes the Authorization APIs for CBL authorization.</p> <p>The Engine notifies the application of any errors during the authorization process via the <code>authorizationError</code> API. The errors reported when you use the Authorization platform interface are different from the ones reported with the CBL platform interface, as shown in the following table:</p> CBL Authorization Description ERROR UNKNOWN_ERROR Unknown error occurs during the authorization flow. TIMEOUT TIMEOUT Request for the the CBL code from LWA times out. CODE_PAIR_EXPIRED CODE_PAIR_EXPIRED The code pair obtained has expired. AUTHORIZATION_EXPIRED AUTHORIZATION_EXPIRED Refresh token is expired or revoked. START_AUTHORIZATION_FAILED Authorization fails to start. LOGOUT_FAILED Logout fails. <p>Migrating from the AuthProvider Platform Interface</p> <p>To migrate from the AuthProvider platform interface to the Authorization platform interface, follow the instructions in the Alexa module documentation, which describes the Authorization APIs for Auth Provider authorization.</p> <p>The Engine notifies the application of any errors during the authorization process via the <code>authorizationError</code> API. The errors reported when you use the Authorization platform interface are different from the ones reported with the AuthProvider platform interface, as shown in the following table:</p> AuthProvider Authorization Description authFailure AUTH_FAILURE Invalid or expired access token was provided. NOT PRESENT UNKNOWN_ERROR Unknown error occurs during the authorization flow. NOT PRESENT START_AUTHORIZATION_FAILED Authorization fails to start. NOT PRESENT LOGOUT_FAILED Logout fails."},{"location":"releases/migration/#deprecated-features-removed-in-auto-sdk-v300","title":"Deprecated Features Removed in Auto SDK v3.0.0","text":"<ul> <li>The following asset IDs for Car Control have been removed: \"Alexa.Automotive.DeviceName.DriverSeat\", \"Alexa.Automotive.DeviceName.LeftSeat\", \"Alexa.Automotive.DeviceName.PassengerSeat\", \"Alexa.Automotive.DeviceName.RightSeat\".</li> <li>The <code>createControl()</code> method has been removed. Use <code>createEndpoint()</code> instead.</li> <li>Support for the \"isMemberOf\" relationship for endpoint definition has been removed. You must list member endpoints in a zone definition.</li> <li>Implicit zone definitions have been removed.</li> <li>The following <code>TemplateRuntime</code> methods have been removed:<ul> <li>The <code>renderTemplate(const std::string&amp; payload)</code> method has been removed. Use renderTemplate(const std::string&amp; payload, FocusState focusState) instead.</li> <li>The <code>renderPlayerInfo(const std::string&amp; payload)</code> method has been removed. Use <code>renderPlayerInfo(const std::string&amp; payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState)</code> instead.</li> </ul> </li> <li>In the Alexa module, <code>AlexaProperties::SUPPORTED_LOCALES</code> has been removed. For Alexa to recognize the locale setting, specify one of these values: de-DE, en-AU, en-CA, en-GB, en-IN, en-US, es-ES, es-MX, es-US, fr-CA, fr-FR, hi-IN, it-IT, ja-JP, pt-BR.</li> <li><code>Engine::setProperty()</code> and <code>Engine::getProperty()</code> have been removed. Use <code>PropertyManager::setProperty()</code> and <code>PropertyManager::getProperty()</code> instead. For details about the Property Manager platform interface, see the Core module documentation.</li> <li>The <code>SpeechRecognizer::enableWakeWordDetection()</code>, <code>SpeechRecognizer::disableWakeWordDetection()</code>, and <code>SpeechRecognizer::isWakewordDetectionEnabled()</code> methods have been removed.</li> <li>The Contact Uploader module has been removed. Use the Address Book module instead.</li> </ul>"},{"location":"releases/migration/#using-the-address-book-module","title":"Using the Address Book Module","text":"<p>Address Book module enables the user to upload contacts from the phone that is paired with the car or the navigation favorites from the car head unit to Alexa cloud. For more information about how this module works, see the Address Book module documentation. Both the Android and C++ sample apps demonstrate the use of the <code>AddressBook</code> platform interface. See the sample app source code for specific implementation details.</p> <p>The following Address Book API descriptions help you transition from the Contact Uploader module to the Address Book module:</p> <p><code>addAddressBook</code></p> <pre><code>    bool addAddressBook(const std::string&amp; addressBookSourceId, const std::string&amp; name, AddressBookType type);\n</code></pre> <p>Use <code>addAddressBook</code> instead of <code>ContactUploader::addContactsBegin</code>. In addition, <code>addAddressBook</code> requires you to specify the source id to identify the address book, the friendly name of the address book, and the type of address book.</p> <p><code>removeAddressBook</code> <pre><code>    bool removeAddressBook(const std::string&amp; addressBookSourceId);\n</code></pre></p> <p>Use <code>removeAddressBook</code> instead of <code>ContactUploader:: removeUploadedContacts</code>. You must specify the id of the address book to be removed.</p> <p><code>getEntries</code> <pre><code>    bool getEntries(\n            const std::string&amp; addressBookSourceId,\n            std::weak_ptr&lt;IAddressBookEntriesFactory&gt; factory)\n</code></pre></p> <p>When using the Address Book module, the Engine pulls the address book contents from the platform implementation. You must upload the address book contents through the factory class, <code>IAddressBookEntriesFactory</code>, for the specified address book source id.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v221-to-v230","title":"Migrating from Auto SDK v2.2.1 to v2.3.0","text":"<p>This section outlines the changes you will need to make to migrate from Auto SDK v2.2.1 to Auto SDK v2.3.</p>"},{"location":"releases/migration/#car-control-enhancements-and-breaking-changes","title":"Car Control Enhancements and Breaking Changes","text":"<p>Read the updated Car Control module documentation to get a complete understanding of all supported features and the current format of the \"aace.carControl\" configuration schema. Read the updated API documentation for the <code>CarControlConfiguration</code> builder class if you construct your configuration programmatically. The changes to the \"aace.carControl\" configuration for v2.3 are backward-compatible, meaning your previous configuration (regardless of whether it was file-based or built programmatically with the <code>CarControlConfiguration</code> class) will still compile and produce a valid configuration to input to Auto SDK. However, several updates are recommended to ensure expected behavior, even if you do not want new features.</p>"},{"location":"releases/migration/#1-zones-configuration-schema-update","title":"1. Zones configuration schema update","text":"<p>Prior to v2.3, to assign an endpoint to exactly one zone, you would specify an \"isMemberOf\" relationship in the definition of the endpoint and specify no information about endpoints in the zone definition.</p> <pre><code>{\n    \"endpointId\": \"all.fan\",\n    \"endpointResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"Alexa.Automotive.DeviceName.Fan\"\n                }\n            }\n        ]\n    },\n    \"capabilities\": [\n        ...\n    ],\n    \"relationships\": {\n        \"isMemberOf\": {\n            \"zoneId\": \"zone.all\"\n        }\n    }\n}\n\n...\n\n{\n    \"zoneId\": \"zone.all\",\n    \"zoneResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"Alexa.Automotive.Location.All\"\n                }\n            }\n        ]\n    }\n}\n</code></pre> <p>In 2.3, the \"isMemberOf\" relationship is removed from endpoint definitions so that endpoints need not belong to zones and the zone definition can be the source of truth for all its member endpoints. The zone definition now includes a list of member endpoints:</p> <p><pre><code>{\n    \"endpointId\": \"all.fan\",\n    \"endpointResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"Alexa.Automotive.DeviceName.Fan\"\n                }\n            }\n        ]\n    },\n    \"capabilities\": [\n        ...\n    ]\n}\n\n...\n\n{\n    \"zoneId\": \"zone.all\",\n    \"zoneResources\": {\n        \"friendlyNames\": [\n            {\n                \"@type\": \"asset\",\n                \"value\": {\n                    \"assetId\": \"Alexa.Automotive.Location.All\"\n                }\n            }\n        ]\n    },\n    \"members\" : [\n      {\n        \"endpointId\": \"all.fan\"\n      },\n      ...\n    ]\n}\n</code></pre> You should update your configuration accordingly. The Auto SDK Engine translates the old format to the new format internally, but this will be deprecated in later versions. When updating to the new format, you must not combine usage of the \"isMemberOf\" format with the \"members\" list format. Fully migrate all definitions in your configuration.</p>"},{"location":"releases/migration/#2-deprecated-implicit-creation-of-zone-definitions","title":"2. Deprecated implicit creation of zone definitions","text":"<p>If you construct your configuration programmatically with the <code>CarControlConfiguration</code> builder class, your implementation prior to v2.3 might not have explicitly specified definitions for the set of zones considered \"official\", but you still used them in your endpoint configurations anyway. The builder class added these definitions to the \"aace.carControl\" configuration automatically without requiring you to call <code>CarControlConfiguration::createZone()</code>. In v2.3, <code>CarControlConfiguration</code> still includes this logic for the old \"official\" zones, but it does not implicitly create any new zones, and it is recommended to define every zone you use by calling <code>CarControlConfiguration::createZone()</code>. Implicit zone definitions will be removed in a later version.</p>"},{"location":"releases/migration/#3-new-default-zone-feature","title":"3. New default zone feature","text":"<p>Specifying a \"default\" zone ID is an optional new feature, but it is highly recommended that you use it. See the Car Control module documentation for details about why this feature is important.</p>"},{"location":"releases/migration/#4-deprecated-driverseat-and-related-assets-in-favor-of-zones","title":"4. Deprecated \"DriverSeat\" and related assets in favor of zones","text":"<p>Prior to v2.3, the default automotive catalog of assets introduced several asset IDs so that online-only systems could mock zones support for heaters on seat endpoints. The asset IDs are the following: <code>Alexa.Automotive.DeviceName.DriverSeat</code>, <code>Alexa.Automotive.DeviceName.LeftSeat</code>, <code>Alexa.Automotive.DeviceName.PassengerSeat</code>, <code>Alexa.Automotive.DeviceName.RightSeat</code>.</p> <p>Now that the cloud supports zones, you must stop using these asset IDs and properly model the endpoints using zones so that Alexa resolves user utterance intents as expected. These assets will be removed in a later version of Auto SDK. See the Car Control module documentation for sample configuration.</p>"},{"location":"releases/migration/#5-new-default-assets","title":"5. New default assets","text":"<p>The Car Control module is updated to include many new assets in the default automotive catalog to support a wider range of utterances. If you previously defined custom assets to support any of the features introduced to the v2.3 assets, it is recommended that you use the new default assets instead of your previous custom ones. See the Car Control module documentation for details about assets.</p>"},{"location":"releases/migration/#6-reset-your-account-when-changing-from-22-to-23-configuration","title":"6. Reset your account when changing from 2.2 to 2.3 configuration","text":"<p>It is a known issue that you cannot delete any previously configured endpoint IDs associated with your customer account in the cloud. When upgrading your configuration from v2.2 to v2.3, contact your SA or Partner Manager for help to reset your account's endpoint database in the cloud. This is especially important if you are updating to use new features. It is also recommended that your v2.3 configuration follows the configuration sample of supported features shown in the Car Control module documentation. Refer to this document for reference.</p>"},{"location":"releases/migration/#language-model-packaging","title":"Language Model Packaging","text":"<p>Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binaries. If you use the Local Voice Control extension, you must install the language models to successfully migrate to v2.3.0. Download the language model tar files. Installation instructions are provided in the Local Voice Control extension.</p>"},{"location":"releases/migration/#android","title":"Android","text":""},{"location":"releases/migration/#gradle","title":"Gradle","text":"<p>The gradle plugin has been updated to v3.6.2. This requires gradle v5.6.4 or above in order to build the Auto SDK for Android targets.</p>"},{"location":"releases/migration/#sample-app","title":"Sample App","text":"<p>The Android sample app supports overriding the client configuration by pushing a file named app_config.json to the /sdcard folder on the device. If the /sdcard/app_config.json file existed on the device before you migrate to v2.3.0, the file overrides the client configuration included in the v2.3.0 Android sample app APK.</p>"},{"location":"releases/migration/#clang-formatting","title":"Clang Formatting","text":"<p>Auto SDK code has been formatted with <code>clang-format</code> version 9.0.0. This may lead to merge conflicts if changes have been made to v2.2.1 source code files and you migrate to v2.3.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v22-to-v221","title":"Migrating from Auto SDK v2.2 to v2.2.1","text":"<p>This section outlines the changes you will need to make to migrate from Auto SDK v2.2 to Auto SDK v2.2.1.</p>"},{"location":"releases/migration/#templateruntime-enhancements","title":"TemplateRuntime Enhancements","text":"<p>Auto SDK v2.2.1 introduces additional TemplateRuntime platform interface features that you can integrate in your application to enrich the user's experience with Now Playing cards for AudioPlayer and ExternalMediaPlayer implementations. Now Playing cards are a form of display cards \u2014 visual aids that complement the Alexa voice experience \u2014 that contain media metadata, player controls and album art delivered in the TemplateRuntime RenderPlayerInfo directive.</p> <p>Migration is only required to support the new features, but is highly recommended for the following reasons:</p> <ol> <li>AudioPlayer and TemplateRuntime are now decoupled.</li> <li>The following TemplateRuntime methods are now deprecated:<ol> <li>The <code>renderTemplate( const std::string&amp; payload )</code> method is deprecated. Use <code>renderTemplate( const std::string&amp; payload, FocusState focusState )</code> instead.</li> <li>The <code>renderPlayerInfo( const std::string&amp; payload )</code> method is deprecated. Use <code>renderPlayerInfo( const std::string&amp; payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState )</code> instead.</li> </ol> </li> </ol>"},{"location":"releases/migration/#rendertemplate","title":"renderTemplate","text":"<p>Method <pre><code>renderTemplate( const std::string&amp; payload,\n                FocusState focusState )\n</code></pre> The new renderTemplate method provides visual metadata associated with a user request to Alexa. The platform implementation should parse the template metadata and render a display card for the user.</p> <p>Parameters</p> <ul> <li><code>payload</code> Renderable template metadata in structured JSON format</li> <li><code>focusState</code> The <code>FocusState</code> of the channel used by TemplateRuntime interface<ul> <li><code>FOREGROUND</code> Represents the highest focus a Channel can have</li> <li><code>BACKGROUND</code> Represents the intermediate level focus a Channel can have</li> </ul> </li> </ul>"},{"location":"releases/migration/#renderplayerinfo","title":"renderPlayerInfo","text":"<p>Method <pre><code>renderPlayerInfo( const std::string&amp; payload,\n                  PlayerActivity audioPlayerState,\n                  std::chrono::milliseconds offset,\n                  FocusState focusState )\n</code></pre></p> <p>The new renderPlayerInfo method provides visual metadata associated with a user request to Alexa for audio playback. The platform implementation should parse the player info metadata and render a display card for the user. The <code>audioPlayerState</code> and <code>offset</code> are useful for implementing the progress bar in the display card. It is assumed that the client is responsible for progressing the progress bar when the <code>AudioPlayer</code> is in <code>PLAYING</code> state.</p> <p>Parameters</p> <ul> <li><code>payload</code> Renderable player info metadata in structured JSON format</li> <li><code>audioPlayerState</code> The state of the <code>AudioPlayer</code><ul> <li><code>IDLE</code> Audio playback has not yet begun</li> <li><code>PLAYING</code> Audio is currently playing</li> <li><code>STOPPED</code> Audio playback is stopped, either from a stop directive or playback error</li> <li><code>PAUSED</code> Audio playback is paused</li> <li><code>BUFFER_UNDERRUN</code> Audio playback is stalled because a buffer underrun has occurred</li> <li><code>FINISHED</code> Audio playback is finished</li> </ul> </li> <li><code>offset</code> The offset in millisecond of the media that <code>AudioPlayer</code> is handling</li> <li><code>focusState</code> The <code>FocusState</code> of the channel used by TemplateRuntime interface<ul> <li><code>FOREGROUND</code> Represents the highest focus a Channel can have</li> <li><code>BACKGROUND</code> Represents the intermediate level focus a Channel can have</li> </ul> </li> </ul>"},{"location":"releases/migration/#sample-apps","title":"Sample Apps","text":"<p>The Android Sample App demonstrates the new features in <code>TemplateRuntimeHandler.java</code> in GUI form. Refer to sample app source code and Alexa Voice Service documentation for specific implementation details.</p> <p>The C++ Sample App simply demonstrates the new features by printing <code>audioPlayerState</code>, <code>offset</code>, and <code>focusState</code> to the console in the <code>TemplateRuntimeHandler::renderPlayerInfo()</code> method of <code>TemplateRuntimeHandler.cpp</code>.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v21-to-v22","title":"Migrating from Auto SDK v2.1 to v2.2","text":"<p>This section outlines the changes you will need to make to migrate from Auto SDK v2.1 to Auto SDK v2.2.</p>"},{"location":"releases/migration/#implementing-the-property-manager-interface","title":"Implementing the Property Manager Interface","text":"<p>Auto SDK v2.2 introduces the Property Manager, a component that maintains runtime properties by storing property values and listeners and delegating the <code>setProperty()</code> and <code>getProperty()</code> calls from your application to the respective Engine services. The Engine invokes the PropertyManager platform interface method <code>propertyChanged()</code> to notify your application about property value changes originating internally. The property values may be set by Auto SDK modules that define constants (for example <code>FIRMWARE_VERSION</code> and <code>LOCALE</code>), or they may be initiated from the Alexa Voice Service (AVS), such as when the user changes the <code>TIMEZONE</code> setting in the Alexa Companion App.</p> <p><code>PropertyManager::setProperty()</code> and <code>PropertyManager::getProperty()</code> replace deprecated <code>Engine::setProperty()</code> and <code>Engine::getProperty()</code>. For details about the Property Manager platform interface, see Core module documentation.</p>"},{"location":"releases/migration/#car-control-changes","title":"Car Control Changes","text":"<p>This section documents the changes you will need to make to migrate your Car Control implementation to Auto SDK v2.2.</p>"},{"location":"releases/migration/#new-asset-id-prefix","title":"New Asset ID Prefix","text":"<p>The asset ID prefix for default assets has been changed from <code>\"Alexa.\"</code> to <code>\"Alexa.Automotive.\"</code>. This change requires a code or configuration change only if your existing car control implementation uses the <code>CarControlConfiguration</code> configuration builder with the literal strings of asset IDs. If your existing car control implementation uses the predefined constants in <code>CarControlAssets.h</code> or <code>CarControlAssets.java</code>, then no change is required.</p>"},{"location":"releases/migration/#specifying-the-path-to-custom-car-control-assets","title":"Specifying the Path to Custom Car Control Assets","text":"<p>If your implementation using the Local Voice Control (LVC) extension uses custom assets for car control, you must specify the path to the custom assets in both the <code>aace.carControl</code> Auto SDK car control configuration and the LVC configuration, not just the LVC configuration as in Auto SDK v2.0.</p> <ul> <li>For C++ implementations: The default LVC configuration for Linux expects any custom assets to be defined in a file called <code>assets.json</code> located at <code>/opt/LVC/data/led-service/assets/assets.json</code>. Use this path when you configure the <code>assets.customAssetsPath</code> field in the Auto SDK car control configuration, or provide a path to an assets file with equivalent content.</li> <li>For Android implementations: The file at the path you provide in the <code>assets.customAssetsPath</code> field of the Auto SDK car control configuration must be the same as the custom assets file you configure for your <code>ILVCClient</code> using the LVC APK.</li> </ul>"},{"location":"releases/migration/#car-control-config-builder-asset-methods","title":"Car Control Config Builder Asset Methods","text":"<p>Two new <code>CarControlConfiguration</code> methods are now implemented in the Engine:</p> <ul> <li><code>CarControlConfiguration::addCustomAssetsPath()</code></li> <li><code>CarControlConfiguration::addDefaultAssetsPath()</code></li> </ul> <p>Note: These methods were also present in Auto SDK v2.1; however they didn't function as designed. They have been updated to function correctly in Auto SDK v2.2.</p> <p>This implementation populates the <code>\"aace.carControl\"</code> configuration object with the <code>\"assets.customAssetsPath\"</code> and <code>\"assets.defaultAssetsPath\"</code> nodes.</p>"},{"location":"releases/migration/#migrating-from-auto-sdk-v20-to-v21","title":"Migrating from Auto SDK v2.0 to v2.1","text":"<p>This section outlines the changes you will need to make to migrate from Auto SDK v2.0 to Auto SDK v2.1.</p>"},{"location":"releases/migration/#build-changes","title":"Build Changes","text":"<p>The following build changes have been introduced in Auto SDK v2.1:</p> <ul> <li> <p>The builder script usage has changed for Linux targets. All Linux targets now use the same platform name (<code>linux</code>), and <code>-t &lt;target&gt;</code> is mandatory. For example, to build for a Linux native target, use:</p> <p><code>builder/build.sh linux -t native</code></p> <p>to build for Linux native, pokyarm, and pokyarm64 targets, use:</p> <p><code>builder/build.sh linux -t native,pokyarm,pokyarm64</code></p> <p>See the Builder documentation for details about supported platforms and targets.</p> </li> <li> <p>For QNX targets, you must cross-compile with the QNX multimedia software for the system audio extension (which is built by default for QNX targets). This requires a QNX Multimedia Suite license. See the System Audio extension documentation for details.</p> </li> </ul>"},{"location":"releases/migration/#engine-configuration-file-updates","title":"Engine Configuration File Updates","text":"<p>The AVS Device SDK portion of the Auto SDK Engine configuration (the <code>aace.alexa.avsDeviceSDK</code> node) has been updated. See the <code>config.json.in</code> file for details.</p> <ul> <li>The <code>\"deviceInfo\"</code> node includes two new elements: <code>\"manufacturerName\"</code> and <code>\"description\"</code>.</li> <li>A path to the capabilities database is now required. Use the <code>\"capabilitiesDelegate\"</code> element to specify this path.</li> <li>The <code>\"settings\"</code> element has changed to <code>\"deviceSettings\"</code>, and it includes these changes:<ul> <li>The default locale setting has been moved from <code>\"defaultAVSClientSettings/locale\"</code> to <code>\"defaultLocale\"</code>.</li> <li><code>\"deviceSettings\"</code> now requires a <code>\"defaultTimezone\"</code>.</li> </ul> </li> </ul>"},{"location":"releases/migration/#navigation-enhancements","title":"Navigation Enhancements","text":"<p>Auto SDK v2.1 introduces additional navigation features that you can integrate in your application to enrich the user's experience: add/cancel a waypoint, show/navigate to a previous destination, turn and lane guidance, and map display control. Implementing these enhancements required deprecating the <code>setDestination()</code> interface in favor of the <code>startNavigation()</code> interface and adding several additional interfaces.</p> <p>To migrate from Auto SDK v2.0 to Auto SDK v2.1, you must update your platform implementation to use the <code>startNavigation()</code> method instead of the <code>setDestination()</code> method, modify the payload for the <code>getNavigationState()</code> method, and implement the new navigation methods. This guide takes you through these steps. See the Navigation module documentation for additional information and resources.</p>"},{"location":"releases/migration/#whats-new","title":"What's New","text":"<p>The following abstract methods have been added to the Navigation platform interface:</p> <ul> <li><code>startNavigation()</code></li> <li><code>showPreviousWaypoints()</code></li> <li><code>navigateToPreviousWaypoint()</code></li> <li><code>showAlternativeRoutes()</code></li> <li><code>controlDisplay()</code></li> <li><code>announceManeuver()</code></li> <li><code>announceRoadRegulation()</code></li> </ul> <p>The following methods have been added as well:</p> <ul> <li><code>navigationEvent()</code></li> <li><code>navigationError()</code></li> <li><code>showAlternativeRoutesSucceeded()</code></li> </ul> <p>The following method has been removed from the Navigation module:</p> <ul> <li><code>setDestination()</code></li> </ul> <p>The following method now returns a different payload:</p> <ul> <li><code>getNavigationState()</code></li> </ul>"},{"location":"releases/migration/#implementing-the-new-navigation-features","title":"Implementing the New Navigation Features","text":"<p>To implement the new navigation features, follow these steps:</p> <p>STEP 1: Replace the <code>setDestination()</code> method with the <code>startNavigation()</code> method.</p> <p>The payload meaning of <code>startNavigation()</code> is different than that of deprecated <code>setDestination()</code>. <code>setDestination()</code> corresponded to adding a destination to the navigation system context. <code>startNavigation()</code>, on the other hand, corresponds to using the route information provided in the payload to start navigation, with one or more waypoints. In response to <code>startNavigation()</code>, your implementation should also call either the <code>navigationEvent()</code> method or the <code>navigationError()</code> method.</p> Java (Android) - click to expand or collapse <p> <pre><code>// NavigationHandler.java\n@Override\n*public void *startNavigation( String payload ) {\n    ...\n    // success\n    navigationEvent( EventName.NAVIGATION_STARTED );\n    ...\n    // failure\n    navigationError( ErrorType.NAVIGATION_START_FAILED, ErrorCode.INTERNAL_SERVICE_ERROR, \"\" );\n</code></pre> </p> C++ - click to expand or collapse <p> <pre><code>// NavigationHandler.cpp\nvoid NavigationHandler::startNavigation(const std::string&amp; payload ) {\n    ...\n    // success\n        navigationEvent( aace::navigation::NavigationEngineInterface::EventName::NAVIGATION_STARTED );\n    ...\n    // failure\n        navigationError( aace::navigation::NavigationEngineInterface::ErrorType::NAVIGATION_START_FAILED, aace::navigation::NavigationEngineInterface::ErrorCode::INTERNAL_SERVICE_ERROR, \"\" );\n</code></pre> </p> <p>STEP 2: Modify the payload for the <code>getNavigationState()</code> method.</p> <p>The functionality of the <code>getNavigationState()</code> and <code>cancelNavigationState()</code> methods is unchanged from Auto SDK v2.0, but the <code>getNavigationState()</code> payload has changed. The NavigationState context has been updated to contain more information than in Auto SDK v2.0.</p> <p>The <code>address</code> field has been updated from a string to the following object:</p> <p><pre><code>...\n\"address\": {\n       \"addressLine1\": \"{{STRING}}\", //Address line 1\n       \"addressLine2\": \"{{STRING}}\", //Address line 2\n       \"addressLine3\": \"{{STRING}}\", //Address line 3\n       \"city\": \"{{STRING}}\", //City\n       \"districtOrCounty\": \"{{STRING}}\", //district or county\n       \"stateOrRegion\": \"{{STRING}}\", //state or region\n       \"countryCode\": \"{{STRING}}\", //3 letter country code\n       \"postalCode\": \"{{STRING}}\", //postal code\n},\n...\n</code></pre> The <code>name</code> field has been added to the waypoint payload:</p> <pre><code>\"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks\n</code></pre> Here is an example of a full NavigationState context payload - click to expand or collapse <p> <pre><code>...,\n{\n  \"header\": {\n    \"namespace\": \"Navigation\",\n    \"name\": \"NavigationState\"\n  },\n  \"payload\": {\n    \"state\": \"{{STRING}}\", //NAVIGATING or NOT_NAVIGATING\n    \"waypoints\": [\n        {\n            \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM\n            \"estimatedTimeOfArrival\": {\n                \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format\n                \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format\n             },\n            \"address\": {\n                   ++ \"addressLine1\": \"{{STRING}}\", //Address line 1\n                   ++ \"addressLine2\": \"{{STRING}}\", //Address line 2\n                   ++ \"addressLine3\": \"{{STRING}}\", //Address line 3\n                   ++ \"city\": \"{{STRING}}\", //City\n                   ++ \"districtOrCounty\": \"{{STRING}}\", //district or county\n                   ++ \"stateOrRegion\": \"{{STRING}}\", //state or region\n                   ++ \"countryCode\": \"{{STRING}}\", //3 letter country code\n                   ++ \"postalCode\": \"{{STRING}}\", //postal code\n             },\n            ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks\n             \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}],\n        },\n        {\n            \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM\n            \"estimatedTimeOfArrival\": {\n                \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format\n                \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format\n             },\n            \"address\": {\n                  ++  \"addressLine1\": \"{{STRING}}\", //Address line 1\n                  ++  \"addressLine2\": \"{{STRING}}\", //Address line 2\n                  ++  \"addressLine3\": \"{{STRING}}\", //Address line 3\n                  ++  \"city\": \"{{STRING}}\", //city\n                  ++  \"districtOrCounty\": \"{{STRING}}\", //district or county\n                  ++  \"stateOrRegion\": \"{{STRING}}\", // state or region\n                  ++  \"countryCode\": \"{{STRING}}\", //3 letter country code\n                  ++  \"postalCode\": \"{{STRING}}\", // postal code\n             },\n           ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks\n            \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}],\n            \"pointOfInterest\": {\n                \"id\": \"{{STRING}}\", //POI lookup Id vended from Alexa\n                \"hoursOfOperation\": [\n                 {\n                     \"dayOfWeek\": \"{{STRING}}\",\n                     \"hours\": [\n                      {\n                         \"open\": \"{{STRING}}\", // ISO-8601 time with timezone format\n                         \"close\": \"{{STRING}}\" // ISO-8601 time with timezone format\n                      }\n                    ],\n                    \"type\": \"{{STRING}}\" // Can be: OPEN_DURING_HOURS, OPEN_24_HOURS, etc.\n                }\n                ],\n                \"phoneNumber\": \"{{STRING}}\"\n             }\n\n        },\n        ...\n      ],\n     \"shapes\": [\n            [\n              {{LATITUDE_DOUBLE}},\n              {{LONGITUDE_DOUBLE}}\n            ],\n            [\n              {{LATITUDE_DOUBLE}},\n              {{LONGITUDE_DOUBLE}}\n            ],\n        ...\n     ]\n  }\n}\n...,\n</code></pre> </p> <p>STEP 3: Implement the new navigation abstract methods.</p> <p>The new navigation methods are all called in response to navigation-based user utterances such as \u201cshow my previous route\u201d or \u201cwhat\u2019s the speed limit here?\u201d. At a minimum, your implementation should report a <code>navigationError()</code> to inform the user when the navigation system does not support that information.</p> <p>Note: The <code>navigationEvent()</code>, <code>showAlternativeRoutesSucceeded()</code> and <code>navigationError()</code> methods have been implemented in the Auto SDK but are not yet implemented on the cloud side. Sending the events will not affect navigation functionality, but the Alexa cloud will return an <code>INVALID_REQUEST_EXCEPTION</code> or <code>INVALID_SERVICE_EXCEPTION</code> until these events are implemented on the cloud side.</p> Java (Android) - click to expand or collapse <p> <pre><code>@Override\npublic void showPreviousWaypoints() {\n    //handle showing information about previous waypoints...\n    navigationError( ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, ErrorCode.NOT_SUPPORTED, *\"\"** *);\n}\n...\n\n@Override\npublic void navigateToPreviousWaypoint() {\n    //handle navigation to previous waypoint\n    navigationError( ErrorType.PREVIOUS_NAVIGATION_START_FAILED, ErrorCode.NOT_SUPPORTED, \"\" );\n}\n...\n\n@Override\npublic void showAlternativeRoutes( AlternateRouteType alternateRouteType ) {\n    //pass AlternateRouteType enum\n    navigationError( ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, ErrorCode.NOT_SUPPORTED, \"\" );\n}\n...\n\n@Override\npublic void controlDisplay ( ControlDisplay controlDisplay ) {\n    //pass ControlDisplay enum\n    navigationError( ErrorType.ROUTE_OVERVIEW_FAILED, ErrorCode.NOT_SUPPORTED, \"\" );\n}\n...\n\n@Override\npublic void announceManeuver( String payload  ) {\n    //pass the JSON string payload from AnnounceManeuver directive\n    navigationError( ErrorType.TURN_GUIDANCE_FAILED, ErrorCode.NOT_SUPPORTED, \"\" );\n}\n...\n\n@Override\npublic void announceRoadRegulation( RoadRegulation roadRegulation ) {\n    //pass RoadRegulation enum\n    navigationError( ErrorType.SPEED_LIMIT_REGULATION_FAILED, ErrorCode.NOT_SUPPORTED, \"\" );\n}\n</code></pre> </p> C++ - click to expand or collapse <p> <pre><code>void NavigationHandler::showPreviousWaypoints() {\n        //handle showing information about previous waypoints...\n        navigationError( aace::navigation::Navigation::ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\"* *);\n   }\n    ...\n\n    void NavigationHandler::navigateToPreviousWaypoint() {\n        //handle navigation to previous waypoint\n        navigationError( aace::navigation::Navigation::ErrorType.PREVIOUS_NAVIGATION_START_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" );\n    }\n    ...\n\n    void NavigationHandler::showAlternativeRoutes( aace::navigation::Navigation::AlternateRouteType alternateRouteType ) {\n        //pass AlternateRouteType enum\n        navigationError( aace::navigation::Navigation::ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" );\n    }\n    ...\n\n    void NavigationHandler::controlDisplay ( aace::navigation::Navigation::ControlDisplay controlDisplay ) {\n        //pass ControlDisplay enum\n        navigationError( aace::navigation::Navigation::ErrorType.ROUTE_OVERVIEW_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" );\n    }\n    ...\n\n    void NavigationHandler::announceManeuver( String payload  ) {\n        //pass the JSON string payload from AnnounceManeuver directive\n        navigationError( aace::navigation::Navigation::ErrorType.TURN_GUIDANCE_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" );\n    }\n    ...\n\n    void NavigationHandler::announceRoadRegulation( aace::navigation::Navigation::RoadRegulation roadRegulation ) {\n        //pass RoadRegulation enum\n        navigationError( aace::navigation::Navigation::ErrorType.SPEED_LIMIT_REGULATION_FAILED,\n            aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" );\n    }\n</code></pre> </p>"},{"location":"releases/migration/#new-templateruntime-interface-version","title":"New TemplateRuntime Interface Version","text":"<p>The Auto SDK now implements version 1.2 of the TemplateRuntime interface to handle display card templates. If you support TemplateRuntime in your implementation, you must update your implementation to support the new card types.</p> <p>The TemplateRuntime interface remains the same, but the <code>LocalSearchListTemplate1</code> template has been deprecated in favor of the new <code>LocalSearchListTemplate2</code> template. In addition, two new templates (<code>TrafficDetailsTemplate</code> and <code>LocalSearchDetailTemplate1</code>), are now supported. The <code>TrafficDetailsTemplate</code> includes commute information to favorite destinations such as home or work. The <code>LocalSearchDetailTemplate1</code> template includes information about specific locations or information in response to users asking for details about locations presented in the <code>LocalSearchListTemplate2</code> template. For details about the TemplateRuntime interface, see the Alexa Voice Service (AVS) documentation. For details about implementing TemplateRuntime in your Auto SDK implementation, see the Alexa module documentation.</p>"},{"location":"releases/migration/#car-control-source-file-relocation","title":"Car Control Source File Relocation","text":"<p>The Car Control module platform interface files and documentation are now located in <code>aac-sdk/modules/car-control</code> for C++ and <code>aac-sdk/platforms/android/modules/car-control</code> for Android, rather than in the Local Voice Control (LVC) extension directory structure.</p> <p>Note: In addition, if you use custom assets for car control in an implementation with the optional Local Voice Control (LVC) extension, you must specify the path to the custom assets in both the Auto SDK car control configuration and the LVC configuration, not just the LVC configuration. For details, see Car Control module documentation.</p>"},{"location":"releases/migration/#code-based-linking-cbl-handler-in-the-sample-apps","title":"Code-Based-Linking (CBL) Handler in the Sample Apps","text":"<p>Both of the Auto SDK Sample Apps now include the Code-Based Linking (CBL) handler implementation (in favor of the <code>AuthProvider</code> handler implementation ) to handle obtaining access tokens from Login with Amazon (LWA). Changing from the <code>AuthProvider</code> handler to the CBL handler is not a required change, but we recommend that you use the Auto SDK CBL interface for ease of implementation. For details about the CBL handler, please see the CBL module documentation.</p> <p>If you want to continue using the <code>AuthProvider</code> interface, we recommend that you implement the new <code>onAuthFailure()</code> method that exposes 403 \"unauthorized request\" exceptions from Alexa Voice Service (AVS). This method may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. In the Sample Apps, you can override the  interface and unset your login credentials as if the user had done so with your GUI interface:</p> Java (Android) - click to expand or collapse <p> <pre><code>@Override\n    public void authFailure( String token ) {\n        // handle user de-authorize scenario\n</code></pre> </p> C++ - click to expand or collapse <p> <pre><code>void AuthProviderHandler::authFailure( const std::string&amp; token ) {\n        // handle user de-authorize scenario\n</code></pre> </p>"}]}